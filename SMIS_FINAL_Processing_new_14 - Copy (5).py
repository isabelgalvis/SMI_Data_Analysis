#!/usr/bin/ python
#!/usr/bin/env python
# coding: utf-8
#! -*- coding: utf-8 -*-

from __future__ import print_function 
from __future__ import unicode_literals
from __future__ import absolute_import
from __future__ import division
# from future.utils import python_2_unicode_compatible

###########################
## MAIN SMI NAME

main_smi = 'JAMESCHARLES'
# main_smi = 'JEFFREESTAR'
# main_smi = 'MANNYMUA733'
# main_smi = 'MICHELLEPHAN'
# main_smi = 'NIKKIETUTORIALS'
# main_smi = 'ZOELLA'
# main_smi = 'ZOESUGG'

if main_smi == 'JAMESCHARLES':
  total_followers_jamescharles = 4500000
  main_smi_no_followers = total_followers_jamescharles  
  SMI_1_FILE_1 = 'JAMESCHARLES_E_A_TOTAL_2_TEXT_TO_COLUMMS.xlsx'
#  SMI_1_FILE_1 = '1_6_1_SMI1_df_tweets_processes_1_CSV.csv'
  SMI_1_Mentions_User_Data_FILE = 'JAMESCHARLES_Mentions_User_Data.xlsx'
  SMI_1_Followers_Get_FILE = 'JAMESCHARLES_Followers_Get.xlsx'
  SMI_1_Followers_User_Data_FILE = 'JAMESCHARLES_Followers_Data.xlsx'
  SMI_1_Friends_FILE = 'JAMESCHARLES_Friends.xlsx'
  SMI_1_Friends_User_Data_FILE = 'JAMESCHARLES_Friends_Data.xlsx'
  SMI_1_TFF_FILE = 'JAMESCHARLES_TWEETS_FOLLOWERS_FAVS.xlsx'
  main_smi_1 = 'jamescharles'
  print('The SMI is..')
  print(main_smi)
elif main_smi == 'JEFFREESTAR':
  total_followers_jeffreestar = 6100000
  main_smi_no_followers = total_followers_jeffreestar
  SMI_1_FILE_1 = 'JEFFREESTAR_E_A_TOTAL_2_TEXT_TO_COLUMMS.xlsx'
#  SMI_1_FILE_1 = 'A_SMI1_df_tweets_processes_total_CSV.csv'
  SMI_1_Mentions_User_Data_FILE = 'JEFFREESTAR_Mentions_User_Data.xlsx'
  SMI_1_Followers_Get_FILE = 'JEFFREESTAR_Followers_Get.xlsx'
  SMI_1_Followers_User_Data_FILE = 'JEFFREESTAR_Followers_Data.xlsx'
  SMI_1_Friends_FILE = 'JEFFREESTAR_Friends.xlsx'
  SMI_1_Friends_User_Data_FILE = 'JEFFREESTAR_Friends_Data.xlsx'
  SMI_1_TFF_FILE = 'JEFFREESTAR_TWEETS_FOLLOWERS_FAVS.xlsx'
  main_smi_1 = 'jeffreestar'
  print('The SMI is..')
  print(main_smi)
elif main_smi == 'MICHELLEPHAN':
  total_followers_michellephan = 900900
  main_smi_no_followers = total_followers_michellephan
  SMI_1_FILE_1 = 'MICHELLEPHAN_E_A_TOTAL_2_TEXT_TO_COLUMMS.xlsx'
#  SMI_1_FILE_1 = 'A_SMI1_df_tweets_processes_total_CSV.xlsx'
  SMI_1_Mentions_User_Data_FILE = 'MICHELLEPHAN_Mentions_User_Data.xlsx'
  SMI_1_Followers_Get_FILE = 'MICHELLEPHAN_Followers_Get.xlsx'
  SMI_1_Followers_User_Data_FILE = 'MICHELLEPHAN_Followers_Data.xlsx'
  SMI_1_Friends_FILE = 'MICHELLEPHAN_Friends.xlsx'
  SMI_1_Friends_User_Data_FILE = 'MICHELLEPHAN_Friends_Data.xlsx'
  SMI_1_TFF_FILE = 'MICHELLEPHAN_TWEETS_FOLLOWERS_FAVS.xlsx'
  main_smi_1 = 'michellephan'
  print('The SMI is..')
  print(main_smi)
elif main_smi == 'NIKKIETUTORIALS':
  total_followers_nikkietutorials = 1800000
  main_smi_no_followers = total_followers_nikkietutorials
  SMI_1_FILE_1 = 'NIKKIETUTORIALS_E_A_TOTAL_2_TEXT_TO_COLUMMS.xlsx'
#  SMI_1_FILE_1 = 'A_SMI1_df_tweets_processes_total_CSV.csv'
  SMI_1_Mentions_User_Data_FILE = 'NIKKIETUTORIALS_Mentions_User_Data.xlsx'
  SMI_1_Followers_Get_FILE = 'NIKKIETUTORIALS_Followers_Get.xlsx'
  SMI_1_Followers_User_Data_FILE = 'NIKKIETUTORIALS_Followers_Data.xlsx'
  SMI_1_Friends_User_Data_FILE = 'NIKKIETUTORIALS_Friends_Data.xlsx'
  SMI_1_Friends_FILE = 'NIKKIETUTORIALS_Friends.xlsx'
  SMI_1_TFF_FILE = 'NIKKIETUTORIALS_TWEETS_FOLLOWERS_FAVS.xlsx'
  main_smi_1 = 'nikkietutorials'
  print('The SMI is..')
  print(main_smi)
elif main_smi == 'ZOELLA':
  total_followers_zoella = 12315343
  main_smi_no_followers = total_followers_zoella
  SMI_1_FILE_1 = 'zoella_E_A_TOTAL_2_TEXT_TO_COLUMMS.xlsx'
#  SMI_1_FILE_1 = 'A_SMI1_df_tweets_processes_total_CSV.csv'
  SMI_1_Mentions_User_Data_FILE = 'zoella_Mentions_User_Data.xlsx'
  SMI_1_Followers_Get_FILE = 'zoella_Followers_Get.xlsx'
  SMI_1_Followers_User_Data_FILE = 'zoella_Followers_Data.xlsx'
  SMI_1_Friends_User_Data_FILE = 'zoella_Friends_Data.xlsx'
  SMI_1_Friends_FILE = 'zoella_Friends.xlsx'
  SMI_1_TFF_FILE = 'zoella_TWEETS_FOLLOWERS_FAVS.xlsx'
  main_smi_1 = 'zoella'
  print('The SMI is..')
  print(main_smi)
else:
  main_smi == 'MANNYMUA733'
  total_followers_mannymua733 = 1500000
  main_smi_no_followers = total_followers_mannymua733
  SMI_1_FILE_1 = 'MANNYMUA733_E_A_TOTAL_2_TEXT_TO_COLUMMS.xlsx'
#  SMI_1_FILE_1 = 'A_SMI1_df_tweets_processes_total_CSV.csv'
  SMI_1_Mentions_User_Data_FILE = 'MANNYMUA733_Mentions_User_Data.xlsx'
  SMI_1_Followers_Get_FILE = 'MANNYMUA733_Followers_Get.xlsx'
  SMI_1_Followers_User_Data_FILE = 'MANNYMUA733_Followers_Data.xlsx'
  SMI_1_Friends_FILE = 'MANNYMUA733_Friends.xlsx'
  SMI_1_Friends_User_Data_FILE = 'MANNYMUA733_Friends_Data.xlsx'
  SMI_1_TFF_FILE = 'MANNYMUA733_TWEETS_FOLLOWERS_FAVS.xlsx'
  main_smi_1 = 'mannymua733'
  print('The SMI is..')
  print(main_smi)

total_followers_zoella = 12315343
total_followers_jeffreestar = 6100000
total_followers_jamescharles = 4500000
total_followers_mannymua733 = 1500000
total_followers_nikkietutorials = 1800000
total_followers_michellephan = 900900

# total_followers_zoella = 209400

# main_smi_number_followers = total_followers_jamescharles #################### REPLACE PER SMI!!!!!!!!
# main_smi_number_followers = total_followers_jeffreestar
# main_smi_number_followers = total_followers_mannymua733
main_smi_number_followers = total_followers_michellephan  
# main_smi_number_followers = total_followers_nikkietutorials
# main_smi_number_followers = total_followers_zoella

###### smi_file_4_4 = '1_6_1_SMI1_df_tweets_processes_1_CSV.csv'
smi_file_4_4 = '1_6_1_SMI1_df_tweets_processes_1_CSV.csv'
# smi_file_4_4_text_only = '1_6_1_SMI1_df_tweets_processes_1_TEXT_ONLY.txt'
# smi_file_4_4_hashtags_total = '1_6_1_SMI1_hashtags_total_1_CSV.csv'
# smi_file_4_4_mentions_total = '1_6_1_SMI1_mentions_total_1_CSV.csv'
# smi_file_4_4_mentions_total_with_smi_names = '1_6_1_SMI1_mentions_total_with_smi_names_1_CSV.csv'
# smi_file_4_4_missing_emoji_unicode = '1_6_1_SMI1_missing_emojis_unicode_1_CSV.csv'

# smi_file_4_4_missing_image_link = ## NEED TO DO FIX FROM 1_3

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')



# main_smi_no_followers = total_followers_jamescharles #################### REPLACE PER SMI!!!!!!!!
# main_smi_no_followers = total_followers_jeffreestar
# main_smi_no_followers = total_followers_mannymua733
# main_smi_no_followers = total_followers_michellephan   
# main_smi_no_followers = total_followers_nikkietutorials
# main_smi_no_followers = total_followers_zoella

# SMI_1_FILE_1 = 'JAMESCHARLES_E_A_TOTAL_2_TEXT_TO_COLUMMS.xlsx'
# SMI_1_FILE_1 = 'JEFFREESTAR_E_A_TOTAL_2_TEXT_TO_COLUMMS.xlsx'
# SMI_1_FILE_1 = 'MANNYMUA733_E_A_TOTAL_2_TEXT_TO_COLUMMS.xlsx'
# SMI_1_FILE_1 = 'MICHELLEPHAN_E_A_TOTAL_2_TEXT_TO_COLUMMS.xlsx'
# SMI_1_FILE_1 = 'NIKKIETUTORIALS_E_A_TOTAL_2_TEXT_TO_COLUMMS.xlsx'
# SMI_1_FILE_1 = 'zoella_E_A_TOTAL_2_TEXT_TO_COLUMMS.xlsx'

# nikkietutorias 06/12/2019 

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

###########################################################################################


print('---')
print('Loading Libs 1')
print('---')

# LOAD LIBRARIES

import sys
import importlib
import types
import os
from os import path
import locale
# from tableone import TableOne
import codecs
import io
from io import open
# import math
 
import dask as dd 
# import toolz

import re
import regex
import string

import fonts
# import fonttools

import spacy
# import squarify
import scattertext as st

import rich
from rich import print
from rich import inspect
from time import sleep
from rich.progress import track
from rich.traceback import install
install()
from rich import pretty 
pretty.install()
locals()

import numpy as np

# import twython
import functools
# import string

# import html5lib
# import urllib
# import urllib2
# import urllib3
# import urlextract
# from urlextract import URLExtract
# from HTMLParser import HTMLParser
# from html.parser import HTMLParser

import matplotlib
# matplotlib.axes.Axes.pie
# matplotlib.pyplot.pie
import matplotlib.pyplot as plt
import matplotlib.colors as colors
import matplotlib.dates as mdates
import matplotlib.ticker as mticker
import matplotlib.patches as mpatches
import matplotlib.font_manager as mfm

import wx
# import gtk

from matplotlib.legend import Legend
from matplotlib import cm
from matplotlib import style
from matplotlib.colors import ListedColormap, LinearSegmentedColormap
from matplotlib.legend_handler import HandlerLine2D, HandlerTuple
from matplotlib.offsetbox import OffsetImage, AnnotationBbox
from matplotlib import ft2font
from matplotlib.font_manager import ttfFontProperty
from matplotlib.font_manager import FontProperties
from matplotlib.dates import (YEARLY, DateFormatter, rrulewrapper, RRuleLocator, drange)
# import matplotlib.candlestick_ohlc # from matplotlib.finance import candlestick_ohlc
from matplotlib import rcsetup
from matplotlib import rcParams, rcParamsDefault, get_backend, rcParamsOrig
# from matplotlib import venn

matplotlib.font_manager._rebuild()

# NEED TO DO IMPORT CANDLESTICK FROM MATPLOTLIB

print('----')
print('---- MATPLOTLIB CACHE LIBRARY ')
# print(plt.get_cachedir())
print('----')

import pandas as pd
from pandas import DataFrame, Series
# from pandas import ExcelWriter
# from pandas import ExcelFile
# from pandas_datareader import data, wb

print('----')
print('Pandas Version:')
print(pd.__version__)
print('---')

from pandas.plotting import register_matplotlib_converters
register_matplotlib_converters()
pd.set_option('precision', 2)
from matplotlib import rc
rc('font',**{'family':'fantasy','serif':['fantasy']})
rc('text', usetex=True)

import pylab
from pylab import *
# from pylab import rcParams

from streamlit import caching
caching.clear_cache()

import wordcloud
from wordcloud import WordCloud #, STOPtweets_words #, ImageColorGenerator

import nltk
import nltk.twitter
import nltk.corpus
from nltk import word_tokenize
from nltk import toolbox
from nltk import bigrams
from nltk.util import ngrams
# from nltk import RegexTokenizer
# from nltk.tokenize import RegexTokenizer
from nltk.tokenize import WordPunctTokenizer
from nltk.probability import FreqDist
from nltk.stem.snowball import SnowballStemmer
from nltk.stem import WordNetLemmatizer
from nltk.stem.wordnet import WordNetLemmatizer
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.sentiment.util import *
from nltk import tokenize
# import nltk.corpus.stoptweets_words ## NEED TO DO FIX STOPtweets_words
# from nltk.corpus import stopwords
# stopwords = set(stopwords.words('english'))
tok = WordPunctTokenizer()
# nltk.download()
# showing info http://nltk.github.com/nltk_data

# import time
import datetime as dt
from datetime import datetime
# from mlp_toolkits.basemap import Basemap

print('Loading Libs 2')

# import pydot

import itertools
from itertools import *
from itertools import chain
from itertools import groupby

import sklearn
from sklearn import metrics
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.cluster import spectral_clustering

import textblob
from textblob import TextBlob
from textblob.classifiers import NaiveBayesClassifier

import simplejson
import json
# import jsonlib
# import getopt
 
# import cookiejar
# import cookielib
# from pillow import Image

# from pyquery import PyQuery
# import pprint
# import graph

import xlrd
xlrd.xlsx.ensure_elementtree_imported(False, None)
xlrd.xlsx.Element_has_iter = True

# import csvkit
# import pyexcel
# import xlsxwriter
import openpyxl
import csv
import xml
import defusedxml

# pd.set_option('precision', 1)

# import tweepy as tw
# from tweepy import OAuthHandler

# import pygraphviz
# import simplejson
# import json

import statistics
import latext
import latext
import pdftex

import scipy
from scipy import linalg
from scipy.cluster.vq import kmeans2
import scipy.stats

print('Loading Libs 10')

# import processor as p

print('Loading Libs 3')

# from text_unidecode import unidecode

import ftfy
import ftfy.bad_codecs # enables sloppy- codecs
# import preprocessor as p

# import unicode
import unicodedata
from unicodedata import name as unicode_name
import unidecode
from unidecode import unidecode
# import unicodedata2
# import decode

import emoji
import emojis
# import emoji-encoding
import emojiencoding
# import emoji-unicode
import emoji_extractor
# import emoji2text
# import emote
from emoji.unicode_codes import UNICODE_EMOJI

# from .. import fix_unicode

# import emojipedia
# from emojipedia import Emojipedia
import emoji_data
# import twemoji

# import six

# import pygal
# import pyspark 

print('Loading Libs 17')

# import stoptweets_words
# import corpus

print('Loading Libs 18') 

import collections
import collections.abc
# try:
#  except ImportError:
# from collections import Mapping

from collections import Counter, Iterable
from collections import Sequence, defaultdict
from collections import defaultdict
collections_abc = getattr(collections, 'abc', collections)
from itertools import groupby 

import warnings
warnings.filterwarnings('ignore')

# import geotext
# from geotext import GeoText

# USING CUFFLNKS

# import plotly
# from plotly.offline import init_notebook_mode, iplot
# import plotly.figure_factory as ff
# import cufflinks
# cufflinks.go_offline()
# cufflinks.set_config_file(world_readable=True, theme='pearl')

# import plotly.express as px
# import plotly.graph_objects as go  ######## NEED TO DO PLOTLY NOT WORKING"!!!
# import chart_studio.plotly as py

# NEED TO DO - FIX PLOTLY

# import plotly.graph_objs as go
# import plotly.plotly as py
# from plotly import tools
####  plotly.tools.set_credentials_file(username='XXX', api_key='XXX')

# from CStringIO import SringIO
# import StringIO

# Seaborn visualization library
import seaborn as sns
# sns.set(color_codes=True)

from nltk.tokenize import word_tokenize
from nltk.tokenize import sent_tokenize
# from nltk.corpus import stoptweets_words
from nltk.stem.porter import PorterStemmer
from nltk.probability import FreqDist
from nltk.stem.lancaster import LancasterStemmer
from nltk.stem import SnowballStemmer
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.sentiment.util import *
from nltk import toolbox
from nltk import bigrams

nltk.download('maxent_ne_chunker')
nltk.download('maxent_treebank_pos_tagger')
nltk.download('words')
nltk.download('treebank')
nltk.download('punkt')
# nltk.download('stopwords')

import vaderSentiment
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

print('Loading Libs 19')

import community as community_louvain

import networkx as nx
from networkx.algorithms import community
from networkx.drawing.nx_agraph import graphviz_layout
from networkx.algorithms import bipartite
from networkx.algorithms.approximation import clique
from networkx.algorithms import node_classification
from networkx.classes.graph import Graph
from networkx.classes.coreviews import AdjacencyView
from networkx.classes.reportviews import OutEdgeView, InEdgeView, DiDegreeView, InDegreeView, OutDegreeView
from networkx.exception import NetworkXError
import networkx.convert as convert

# import sklearn
# from sklearn.metrics import accuracy_score
# from sklearn.metrics import classification_report, confusion_matrix

print('Loading Libs 7')

# import subprocess; subprocess.check_call(["latex"])
# import toolz 
# import pypi

# import uniseg
# import latex
# import pylatex

# from itertools import islice, izip

print('Loading Libs 34')

# import squarify

print('---')
print('FINISHED LOADING LIBS MAIN')
print('---')



###############################################################################################################
#
#				SETTING FONT PARAMS PLT MATPLOTLIB 
#
###############################################################################################################

## ## ###
# TO FIX plt.figure(figsize=(14,10)) //  total_ // value //  Graph // All tweets 

# ccc NEED TO CHANGE IN GRAPHS ???? 

#  bbox_to_anchor=(1.05, 1.1),  loc='upper left', borderaxespad=0.
# bbox_to_anchor=(1.05, 1.05)
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)

#  bbox_to_anchor=(1.8, 1.6),  FOR PIE TAKEN OUT

# SETTING COLOR MAPS ## NEED TO DO NOT WORKING 
## plt.rcParams['image.cmap']='Blues'

# cmap = plt.set_cmap('Blues')

# figure.max_open_warning
# font = FontProperties()

## ## ##

print('----- FONT PARAMS -------')
print(rcParams.keys())
print('-----')

# fpath = 'C:\Users\MACHENIKE\AppData\Local\Microsoft\Windows\Fonts\TwitterColorEmoji-SVGinOT.ttf'
# fprop = fm.FontProperties(fname=fpath)

# font = ft2font.FT2Font(fpath)
# fprop = fm.FontProperties(fname=fpath)

# ttfFontProp = ttfFontProperty(font)

# fontprop = fm.FontProperties(family='sans-serif',
#                            fname=ttfFontProp.fname,
#                            size=12,
#                            stretch=ttfFontProp.stretch,
#                            style=ttfFontProp.style,
#                            variant=ttfFontProp.variant,
#                           weight=ttfFontProp.weight)
							
# emoji_font = mfm.FontProperties(fname="C:/Users/MACHENIKE/AppData/Local/Microsoft/Windows/Fonts/Symbola_hint.ttf")


###
###  C:\\Users\\MACHENIKE\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\mpl-data\\matplotlibrc'
###   HAD TO PUT THE FONTS IN THIS FOLDER !!!!!  IN THE TTF FONT FOLDER    !!!
###  CHANGED THE FILE C:\Users\MACHENIKE\AppData\Local\Programs\Python\Python39\Lib\site-packages\matplotlib\mpl-data
###  ---- > FILE matplotlibrc 

mfm._rebuild()
mfm.findSystemFonts(fontpaths=None, fontext='ttf')
# font_dirs = C:/Users/MACHENIKE/AppData/Local/Microsoft/Windows/Fonts/
# mfm.findSystemFonts(fontpaths=font_dirs, fontext="ttf")
# font_files = mfm.findSystemFonts(fontpaths=font_dirs)

# for font_file in font_files:
#    mfm.fontManager.addfont(font_file)

# set font
# plt.rcParams['font.family'] = 'Symbola'
# plt.rcParams['font.family'] = 'Noto Emoji'
# plt.rcParams['font.family'] = 'Noto'
# plt.rcParams['font.family'] = 'Roboto'
# plt.rcParams['font.family'] = 'Segoe UI Emoji'
# plt.rcParams['font.family'] = 'Twitter Color Emoji'


# emoji_font = mfm.FontProperties(fname="C:\Users\MACHENIKE\AppData\Local\Microsoft\Windows\Fonts\TwitterColorEmoji-SVGinOT.ttf")

# import mplcairo
# matplotlib.use("module://mplcairo.macosx")

print(' BACKENDDDDDDDDDDDDDDDDDDDDDDDD BEFORE')
print('Backend is now ' + matplotlib.get_backend())
print(' BACKENDDDDDDDDDDDDDDDDDDDDDDDD BEFORE')

# SETTING COLOR MAPS ## NEED TO DO NOT WORKING 

colors_blue = ['#73C2FB', '#6593F5', '#0F52BA', '#000080', 'blue', 'lightskyblue', 'blue']
explode_pie_6 = (0.5, 0.5, 0.5, 0.5, 0.5, 0.5)
explode_pie_10 = (0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2)
# explode_pie_6 = (0.1, 0.1, 0.1, 0.1, 0.1, 0.1)


## BACKENDDDDDDDDDDDDDDDDDDDDDDDD

#import pyobject

# matplotlib.use('GTK3Agg')
# matplotlib.use('GTK3Cairo') # REQUIRES PYOBJECT
# matplotlib.use('MacOSX')
# matplotlib.use('Agg')
# matplotlib.use('wxTKAgg')
# matplotlib.use('TKAgg')
# matplotlib.use('TKCairo')
# matplotlib.use('tornado')
# matplotlib.use('wxCairo')

matplotlib.use('nbAgg')

# ['GTK3Agg', 'GTK3Cairo', 'MacOSX', 'nbAgg', 'Qt4Agg', 'Qt4Cairo', 'Qt5Agg', 'Qt5Cairo', 'TkAgg', 'TkCairo', 'WebAgg', 'WX', 'WXAgg', 'WXCairo', 'agg', 'cairo', 'pdf', 'pgf', 'ps', 'svg', 'template']


print(' BACKENDDDDDDDDDDDDDDDDDDDDDDDD AFTER')
print('Backend is now ' + matplotlib.get_backend())
print(' BACKENDDDDDDDDDDDDDDDDDDDDDDDD AFTER')

######
#######

# plt.rcParams['image.cmap']='#73C2FB'
# plt.rcParams['image.cmap']='PuBu_r'
# plt.rcParams['image.cmap']='GnBu'
plt.rcParams['image.cmap']='Blues'

plt.rcParams['figure.facecolor']='#6593F5'
plt.rcParams['figure.edgecolor']='white'
plt.rcParams['figure.autolayout'] = True
# plt.rcParams['subplots_adjust'] = 1.0
# plt.rcParams['subplots_adjust.bottom'] = 1.5

# plt.set_cmap('PuBu_r')
# plt.set_cmap('GnBu')
# plt.set_cmap('colors_blue')
plt.set_cmap('Blues')

# plt.rcParams['xtick']=labelsize=14)
# plt.rcParams['ytick']=labelsize=14)
# plt.rcParams['xtick']=labelsize= 12)
# plt.rcParams['ytick']=labelsize= 12)

plt.interactive(False)

def ioff():
	matplotlib.interactive(False)
	uninstall_repl_display_hook()

norm_favs = 'Blues'

# figure.max_open_warning


# plt.rcParams.update({'font.size': 16})

# plt.rcParams['xtick']=labelsize=14)
# plt.rcParams['ytick']=labelsize=14)

font = FontProperties()
# font.set_family('Twitter Color Emoji')
# font.set_name('Segoe UI Emoji')
# font.set_name('Symbola')
# font.set_name('Noto')
# font.set_name('Noto Emoji')
# font.set_name('Roboto)
# font.set_style('italic')

### ->Open..Sans ->Emo..ji  ??? 

title_font = {'fontname':'Noto Emoji', 'size': '8'}
suptitle_font = {'fontname':'Noto Emoji', 'size': '10'}
axis_font = {'fontname':'Noto Emoji', 'size': '6'}
legend_font = {'fontname': 'Noto Emoji', 'size': '6'}
xlabel_font = {'fontname': 'Noto Emoji', 'size': '6'}
ylabel_font = {'fontname': 'Noto Emoji', 'size': '6'}
text_font = {'fontname': 'Noto Emoji', 'size': '7'}

# axis_font = {'fontname':'Segoe UI Emoji', 'size':'12'}
# axis_font = {'Symbola', 'size':'12'}

# legend_font = {'fontname':'Segoe UI Emoji', 'size': 10}

font = {'family': 'Noto Emoji',
#        'color':  'darkred',
#        'weight': 'normal',
#        'size': 12,
        }

from matplotlib import rc
rc("text", usetex=False)

# plt.rcParams.update({
#    'axes.labelsize': '10',
#    'text.usetex': True,
#    'font.family': 'Symbola',
#    'font.sans-serif': ['Helvetica']
#    'font.size': 12})

# plt.rc('text', usetex='True')
# plt.rc('font', family='Noto')
# plt.rc('font', family='Noto Emoji')
# plt.rc('font', family='Roboto')
# plt.rc('font', family='Symbola')
## plt.rc('font', family='DejaVu Sans')
# plt.rc('font', family='Twitter Color Emoji')
# plt.rc('font', family='Segoe UI Emoji')

# sns.set(style='ticks')
# sns.palplot(sns.color_palette('GnBu_d'))
# sns.palplot(sns.color_palette('Blues'))

### rcParams['figure.figsize'] = 18, 8

# Large plot
# matplotlib.rcParams['figure.figsize'] = (16.0, 9.0)

# Colormap
# cmap = matplotlib.cm.coolwarm

# from pylab import rcParams
# rcParams['figure.figsize'] = 18, 8

# Seaborn visualization library

sns.set(color_codes=True)

# sns.set(style='ticks')
sns.palplot(sns.color_palette('Blues'))
sns.set()

print('---')
print('Loaded PLT MATPLOTLIB FONT COLOR AXIS SNS SEABORN PARAMETERS')
print('---')

########################################################################################################################
########################################################################################################################
########################################################################################################################
########################################################################################################################
#################################################################################################################


################################################################################################
################################################################################################

print('--- PRINTING EMOJIS')

print('--- 0')
print('<u+1f600>')
print('---')

print('--- 1')
print('<U+1F600>')
print('---')

print('--- 2')
print('<\u0001f600>')
print('---')

print('--- 3')
print('\U0001F600')
print('---')

print('--- 4')
print(emoji.emojize(':thumbs_up:'))
print('---')


print('MAIN SMI:')
print(main_smi)

print('----------------------------------------')

########################################################################################################
########################################################################################################

# Read dataset and store into dataframe

# tweets_smi_1 = pd.read_html(SMI_1_FILE_1)
# tweets_smi_1 = openpyxl.load_workbook(SMI_1_FILE_1)

# PUSE PARSE DATES FALSE

tweets_smi_1 = pd.concat(pd.read_excel(SMI_1_FILE_1, sheet_name=None, parse_dates=False, dtype={'screenName': 'str', 'text': 'str', 'latitude': 'str', 'longitude': 'str', 'mentions': 'str', 'hashtags': 'str', 'url': 'str', 'emojis_unicode': 'str', 'emojis_converted': 'str', 'image_link': 'str', 'language': 'str'}), ignore_index=True)
# tweets_smi_1 = pd.concat(pd.read_excel(SMI_1_FILE_1, axis=0, sheet_name=None, parse_dates=False, sort=False, memory_map=True), ignore_index=True)
# tweets_smi_1 = pd.read_csv(SMI_1_FILE_1, sep='\t')

# tweets_smi_1 = pd.concat(pd.read_excel(SMI_1_FILE_1, axis=0, sheet_name=None, parse_dates=False, sort=False, dtype={'screenname': 'str', 'text': 'str', 'latitude': 'str', 'longitude': 'str', 'mentions': 'str', 'hashtags': 'str', 'url': 'str', 'emojis_unicode': 'str', 'emojis_converted': 'str', 'image_link': 'str', 'language': 'str'}), ignore_index=True)
# tweets_smi_1 = pd.read_csv(SMI_1_FILE_1, sep=';', encoding='utf-8', parse_dates=True, dtype={'screenname': 'str', 'author_id': 'int', 'retweets': 'int', 'favorites': 'int', 'text': 'str', 'latitude': 'str', 'longitude': 'str', 'mentions': 'str', 'hashtags': 'str', 'id': 'int', 'url': 'str', 'emojis_unicode': 'str', 'emojis_converted': 'str', 'image_link': 'str', 'language': 'str'}, header=0, error_bad_lines=False, warn_bad_lines=False, low_memory=True, memory_map=True, float_precision=None)


# DROP author_id latitude longitude url 

# NEED THIS ONE IF STARTING FROM ZERO !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

# XXX NEED TO FIX NEED TO MAKE THIS AN IF !!! NOT WORKING 

tweets_smi_1 = tweets_smi_1.drop(columns='latitude')
tweets_smi_1 = tweets_smi_1.drop(columns='longitude')
tweets_smi_1 = tweets_smi_1.drop(columns='image_link')
tweets_smi_1 = tweets_smi_1.drop(columns='url')
# tweets_smi_1 = tweets_smi_1.drop(columns='screenName_lowercase')
# tweets_smi_1 = tweets_smi_1.drop(columns='text_lowercase')
# tweets_smi_1 = tweets_smi_1.drop(columns='geo_formula')
# tweets_smi_1 = tweets_smi_1.drop(columns='mentions_formula')
# tweets_smi_1 = tweets_smi_1.drop(columns='hashtags_formula')
# tweets_smi_1 = tweets_smi_1.drop(columns='emojis_trim')
# tweets_smi_1 = tweets_smi_1.drop(columns='time')


# author_id_df = pd.DataFrame(tweets_smi_1['author_id'])

### DELETE VARIABLE

# del author_id_df

##################################################################################################
##################################################################################################

print('SMI_1 BEFORE FIRST INT CHANGE DTYPES')
print(tweets_smi_1.dtypes)
print('---')


# tweets_smi_1['id'] = tweets_smi_1['id'].fillna('0')
tweets_smi_1['screenName'] = tweets_smi_1['screenName'].fillna('')
tweets_smi_1['author_id'] = tweets_smi_1['author_id'].fillna('0')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].fillna('0')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].fillna('0')
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].fillna('0')
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].fillna('0')
# tweets_smi_1['time'] = tweets_smi_1['time'].fillna('0:00:00 AM')
# # tweets_smi_1['is_follower'] = tweets_smi_1['is_follower'].fillna('False')
# # tweets_smi_1['is_friend'] = tweets_smi_1['is_friend'].fillna('False')

# tweets_smi_1['time'] = tweets_smi_1['time'].apply(pd.Timestamp)

# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(int32)
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(int32)
# tweets_smi_1['id'] = tweets_smi_1['id'].astype(int64)
# tweets_smi_1['author_id'] = tweets_smi_1['author_id'].astype(int64)
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(int32)
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(int32)
# tweets_smi_1['is_follower'] = bool(tweets_smi_1['is_follower'])
# tweets_smi_1['is_friend'] = bool(tweets_smi_1['is_friend'])

# tweets_smi_1['screenName'] = tweets_smi_1['screenName'].astype(str)
# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str)
# tweets_smi_1['language'] = tweets_smi_1['language'].astype(str)
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str)
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str)
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str)
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str)

print('SMI_1 AFTER FIRST INT CHANGE DTYPES')
print(tweets_smi_1.dtypes)
print('---')

##################################################################################################
##################################################################################################

# tweets_smi_1['id'] = tweets_smi_1['id'].fillna('0')
# tweets_smi_1['screenname'] = tweets_smi_1['screenname'].fillna('')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].fillna('0')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].fillna('0')

# tweets_smi_1['text'] = tweets_smi_1['text'].fillna('')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('NaN', '')

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].fillna('none')
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].fillna('none')
tweets_smi_1['language'] = tweets_smi_1['language'].fillna('und')

tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('')
tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('')

# tweets_smi_1['author_id'] = tweets_smi_1['author_id'].astype(str, errors='ignore')
tweets_smi_1['author_id'] = tweets_smi_1['author_id'].str.replace('x', '')
tweets_smi_1['author_id'] = tweets_smi_1['author_id'].fillna('0')
tweets_smi_1['author_id'] = pd.to_numeric(tweets_smi_1['author_id'], errors='ignore')

tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' the ', ' ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' a ', ' ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' to ', ' ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' ... ', ' ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' .. ', ' ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' or ', ' ')

# tweets_smi_1['screenName'] = tweets_smi_1['screenName'].astype(str, errors='ignore')
tweets_smi_1['screenName'] = tweets_smi_1['screenName'].str.lower()
# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str, errors='ignore')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str, errors='ignore')
# tweets_smi_1['language'] = tweets_smi_1['language'].astype(str, errors='ignore')

# tweets_smi_1 = tweets_smi_1.drop(columns='hashtags')
# tweets_smi_1 = tweets_smi_1.drop(columns='mentions')

print('---')
print('tweets_smi_1 info')
print(tweets_smi_1.info)
print('---')

print('---')
print('tweets_smi_1 SHAPE')
print(tweets_smi_1.shape)
print('---')

print('tweets_smi_1 dtypes')
print(tweets_smi_1.dtypes)
print('---')

pattern_letters = r'([a-zA-Z])'

# # tweets_smi_1['author_id'] = tweets_smi_1['author_id'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# tweets_smi_1['id'] = tweets_smi_1['id'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore').str.replace(pattern_letters, '')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(str, errors='ignore').str.replace('\.0', '')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore').str.replace('\.0', '')

# # tweets_smi_1['author_id'] = tweets_smi_1['author_id'].astype(str, errors='ignore').str.replace('-', '')
# tweets_smi_1['author_id'] = pd.to_numeric(tweets_smi_1['author_id'], errors='ignore')
tweets_smi_1['author_id'] = tweets_smi_1['author_id'].astype(np.int64, errors='ignore')


################## OJ CAMBIAR

# <U+0001F494>
# connor_harbin

#######################################################################

# ANALYSING THE DATA

# Retweets

#### NEED TO COMPLETE DATA: TAKE OUT MENTIONS, HASTAGS, SUMMARY EMOJI CODES WITH EMOTICONS, 
#### NEED FOLLOWER GROWTH OVER TIME GRAPHICS
#### NEED TO COMPLETE DATA: TAKE OUT MENTIONS, HASTAGS, SUMMARY EMOJI CODES WITH EMOTICONS, 
#### NEED FOLLOWER GROWTH OVER TIME GRAPHICS
# FIX FORMATING OF PIE CHARTS
# NEED TO LINK TO TWITTER R DATA AND GET LOCATION INFO
# SAVE TABLES TO FILES
######## CHECK ALL 'NEED TO DO'

#####################################################################################################
#
#                                     TWITTER CLIENT
#
#####################################################################################################

#####################################################################################################
#
#                              SMIS Processing - PART 1 : DATA CLEANUP 
#
#####################################################################################################

# REMOVE DUPLICATES

# Check that there are duplicates 

# tweets_smi_1.duplicated()

# Delete duplicates

tweets_smi_1.drop_duplicates()


###################################################################################################


### XXX OJO TEMPORARY NEED TO FIX NOT WORKING

tweets_smi_1['text'] = tweets_smi_1['text'].fillna('')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('NaN', '')

tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('NONE')
tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('NONE')
tweets_smi_1['mentions_total'] = tweets_smi_1['mentions'].fillna('NONE')
tweets_smi_1['hashtags_total'] = tweets_smi_1['hashtags'].fillna('NONE')
tweets_smi_1['missing_mentions'] = tweets_smi_1['mentions'].fillna('NONE')
# tweets_smi_1['missing_hashtags'] = tweets_smi_1['hashtags'].fillna('NONE')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str, errors='ignore').str.replace('#', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str, errors='ignore').str.replace('@', '')
tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].fillna('NONE')
tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].fillna('NONE')
tweets_smi_1['total_missing_geo'] = tweets_smi_1['geo'].fillna('NONE')

###################################################################################################

# MAKE NEW COLUMN TO KEEP ORIGINAL TEXT WITH NUMBERS AND EXCLAMATION MARKS AND STOP WORDS AND ORIG DATES 

# NEED TO DO  /// NOT WORKING!!!!

print('---')
print('SMI DF info 0')
print(tweets_smi_1.info)
print('---')

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str, errors='ignore')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str, errors='ignore')
# tweets_smi_1['language'] = tweets_smi_1['language'].astype(str, errors='ignore')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore')

# SAVE TO CSV 

# tweets_smi_1.iloc['author_id']

# tweets_smi_1.to_csv('1_6_1_SMI1_df_tweets_processes_1_WITH_STOPWORDS_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_df_tweets_processes_1_WITH_STOPWORDS_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('A_SMI1_DF_Tweets_Processes_total_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)

################################################################################################

# MAKE A 1 TWEET COLLUMN TO COUNT LATER ON THE NUMBER OF TWEETS

tweets_smi_1['single_tweet'] = 1
tweets_smi_1['single_tweet'] = pd.to_numeric(tweets_smi_1['single_tweet'], errors='ignore')

# tweets_smi_1 = tweets_smi_1.assign(single_tweet='1')

print('---')
print('Making a 1 column')
print(tweets_smi_1['single_tweet'].head)
print('---')

print('---')
print('tweets_smi_1 mentions 1 column')
print(tweets_smi_1['mentions'].head(20))
print('---')


print('---')
print('tweets_smi_1 hashtags 1 column')
# print(tweets_smi_1['hashtags'].head(20))
print('---')

# Make a Year Column

tweets_smi_1['year'] = pd.DatetimeIndex(tweets_smi_1['created']).year
# tweets_smi_1['year'] = tweets_smi_1['year'].transform(int)

# tweets_smi_1['year'] = pd.to_numeric(tweets_smi_1['year'], errors='ignore')

# tweets_smi_1['month'] = pd.DatetimeIndex(tweets_smi_1['created']).month
# tweets_smi_1['month'] = tweets_smi_1['month'].astype(np.int32, errors='ignore')


### XXX TEMP 

tweets_smi_1['screenName_orig'] = tweets_smi_1['screenName']
tweets_smi_1['language_orig'] = tweets_smi_1['language']
tweets_smi_1['year_orig'] = tweets_smi_1['year']

print('---')
print('Done Year Column')
print(tweets_smi_1['year'].head)
print('---')

############################################################################################################
############################################################################################################
#
#       	            ADD ADDITIONAL FOLLOWER FRIEND TWITTER DATA - FROM R LISTENER
#
############################################################################################################
############################################################################################################

# REMOVE DUPLICATES

# Delete duplicates

# tweets_smi_1.drop_duplicates()

############################################################################################################################

# REMOVE DUPLICATES

# Delete duplicates

# tweets_smi_1.drop_duplicates()

print('---')
print('DONE NUMBERS - BEGINNING MATRIX - DTYPES')
print(tweets_smi_1.dtypes)
print('---')

# REMOVE LETTERS

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# # tweets_smi_1['following'] = tweets_smi_1['following'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# tweets_smi_1['quote_count'] = tweets_smi_1['quote_count'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# tweets_smi_1['reply_count'] = tweets_smi_1['reply_count'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# tweets_smi_1['network_weight'] = tweets_smi_1['network_weight'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# tweets_smi_1['total_tweets'] = tweets_smi_1['total_tweets'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# tweets_smi_1['lists'] = tweets_smi_1['lists'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# # tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# tweets_smi_1['number_total_hashtags'] = tweets_smi_1['number_total_hashtags'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# tweets_smi_1['number_emojis_unicode'] = tweets_smi_1['number_emojis_unicode'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# tweets_smi_1['number_missing_emojis_unicode'] = tweets_smi_1['number_missing_emojis_unicode'].astype(str, errors='ignore').str.replace(pattern_letters, '')
# tweets_smi_1['number_total_emojis_unicode'] = tweets_smi_1['number_total_emojis_unicode'].astype(str, errors='ignore').str.replace(pattern_letters, '')

# tweets_smi_1[''] = tweets_smi_1[''].astype(str, errors='ignore').str.replace(pattern_letters, '')

# REMOVE SCOTT

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore').str.replace('scott', '')
# # tweets_smi_1['followers'] = tweets_smi_1['followers'].astype(str, errors='ignore').str.replace('scott', '')
# # tweets_smi_1['following'] = tweets_smi_1['following'].astype(str, errors='ignore').str.replace('scott', '')
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(str, errors='ignore').str.replace('scott', '')
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['quote_count'] = tweets_smi_1['quote_count'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['reply_count'] = tweets_smi_1['reply_count'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['total_tweets'] = tweets_smi_1['total_tweets'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['lists'] = tweets_smi_1['lists'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(str, errors='ignore').str.replace('scott', '')
# # tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['number_total_hashtags'] = tweets_smi_1['number_total_hashtags'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['number_emojis_unicode'] = tweets_smi_1['number_emojis_unicode'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['number_missing_emojis_unicode'] = tweets_smi_1['number_missing_emojis_unicode'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['number_total_emojis_unicode'] = tweets_smi_1['number_total_emojis_unicode'].astype(str, errors='ignore').str.replace('scott', '')

print('Tweets_SMI_1 DF DTYPES Before Follower Count Friend Count Change')
print(tweets_smi_1.dtypes)
print('---')

# CHANGE BACK TO NP.INT32

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int32)
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int32)

# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(np.int64)
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(np.int64)

# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].transform(np.float64)
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].transform(np.float64)

# tweets_smi_1['number_emojis_unicode'] = tweets_smi_1['number_emojis_unicode'].astype(np.int32)
# tweets_smi_1['number_missing_emojis_unicode'] = tweets_smi_1['number_missing_emojis_unicode'].astype(np.int32)
# tweets_smi_1['number_total_emojis_unicode'] = tweets_smi_1['number_total_emojis_unicode'].astype(np.int32)

# # tweets_smi_1['followers'] = tweets_smi_1['followers'].astype(np.int64)
# # tweets_smi_1['following'] = tweets_smi_1['following'].astype(np.int32)
# tweets_smi_1['quote_count'] = tweets_smi_1['quote_count'].astype(np.int32)
# tweets_smi_1['reply_count'] = tweets_smi_1['reply_count'].astype(np.int32)
# tweets_smi_1['lists'] = tweets_smi_1['lists'].astype(np.int32)
# tweets_smi_1['total_tweets'] = tweets_smi_1['total_tweets'].astype(np.int32)
# tweets_smi_1['number_total_hashtags'] = tweets_smi_1['number_total_hashtags'].astype(np.int32)
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int32)
# # tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int32)

# NOT NUMERIC FIELDS

# location                         
# country                           
# location_name                   
# missing_geo                     
# missing_country                  
# missing_geo_orig                 
# missing_geo_total                
# total_missing_geo               
# missing_country_orig              
# missing_country_total            
# total_missing_country            
# missing_emojis_unicode           
# emojis_unicode_orig              
# emojis_unicode_total        
# total_emojis_unicode


########################################################################

tweets_smi_1['text'] = tweets_smi_1['text'].fillna('')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('NaN', '')


### XXX TEMP

tweets_smi_1['missing_hashtags'] = tweets_smi_1['old_hashtags']

tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('')
tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('')
tweets_smi_1['mentions_total'] = tweets_smi_1['mentions_total'].fillna('')
# tweets_smi_1['hashtags_total'] = tweets_smi_1['hashtags_total'].fillna('')
tweets_smi_1['missing_mentions'] = tweets_smi_1['missing_mentions'].fillna('NONE')
tweets_smi_1['missing_hashtags'] = tweets_smi_1['missing_hashtags'].fillna('NONE')
tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('')
tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('')
tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].fillna('')
tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].fillna('')

############################################################################################

# FILL NAS

# tweets_smi_1['text'] = tweets_smi_1['text'].fillna('')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('NaN', '')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(str, errors='ignore').str.replace(' nan', '0')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore').str.replace(' nan', '0')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].replace(' nan', '0')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].replace('NaN', '0')
tweets_smi_1['favorites'] = tweets_smi_1['favorites'].fillna('0')

# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].replace(' nan', '0')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].replace('nan', '0')
tweets_smi_1['retweets'] = tweets_smi_1['retweets'].fillna('0')

# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].str.replace('nan', '0').astype(str, errors='ignore')
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].str.replace('NaN', '0').astype(str, errors='ignore')
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].fillna('0')

# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].str.replace('nan', '0').astype(str, errors='ignore')
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].str.replace('NaN', '0').astype(str, errors='ignore')
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].fillna('0')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(str, errors='ignore').str.replace('\.0', '')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore').str.replace('\.0', '')

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int32, errors='ignore')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int32, errors='ignore')
# tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(np.int32, errors='ignore')
# tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(np.int32, errors='ignore')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].round()
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].round()

# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(str, errors='ignore').str.replace('\.0', '')
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(str, errors='ignore').str.replace('\.0', '')

# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(np.int64, errors='ignore')
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(np.int64, errors='ignore')

# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].transform(int)
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].transform(int)


tweets_smi_1['favorites'] = pd.to_numeric(tweets_smi_1['favorites'], errors='ignore')
tweets_smi_1['retweets'] = pd.to_numeric(tweets_smi_1['retweets'], errors='ignore')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.float64, errors='ignore')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.float64, errors='ignore')

tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int64)
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int32)

tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int64)
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int32)


# tweets_smi_1['favorites'] = float(tweets_smi_1['favorites'])
# tweets_smi_1['retweets'] = float(tweets_smi_1['retweets'])

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(int32)
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(int32)

# tweets_smi_1['favorites'] = int(float(tweets_smi_1['favorites']))
# tweets_smi_1['retweets'] = int(float(tweets_smi_1['retweets']))

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.float64, errors='ignore')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.float64, errors='ignore')


print('tweets_smi_1 DF DTYPES BEFORE-- NETWORK WEIGHT')
print(tweets_smi_1.dtypes)
print('---')

####################################################################################################################

# tweets_smi_1['text'] = tweets_smi_1['text'].replace('\'nan\'', '', inplace=True)

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].replace('\'nan\'', '[]', inplace=True)
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].replace('NaN', '[]', inplace=True)
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].replace('\'nan\'', '[]', inplace=True)
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].replace('NaN', '[]', inplace=True)

# tweets_smi_1 = pd.DataFrame(tweets_smi_1)
# tweets_smi_1['created'] = tweets_smi_1['created'].fillna('')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].fillna('0')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].fillna('0')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('none')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('none')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].fillna('none')
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].fillna('none')

# tweets_smi_1.to_csv('1_6_1_11B_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_11B_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

############################################################################################################

print('---')
print('tweets_smi_1 DTYPES')
print(tweets_smi_1.dtypes)
print('---')

# tweets_smi_1['author_id'] = tweets_smi_1['author_id'].fillna('0')
# tweets_smi_1['author_id'] = pd.to_numeric(tweets_smi_1['author_id'], errors='ignore')
# tweets_smi_1['author_id'] = tweets_smi_1['author_id'].astype(np.int64, errors='ignore')

print('---')
print('tweets_smi_1 DF AUTHOR ID HEAD AFTER 2ND A JOIN MERGE')
# print(tweets_smi_1['author_id'].head)
print('---')

# tweets_smi_1['text'] = tweets_smi_1['text'].fillna('')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('NaN', '')

# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].fillna('0')
# tweets_smi_1['followers_count'] = pd.to_numeric(tweets_smi_1['followers_count'], errors='ignore')
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(np.int32, errors='ignore')

# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].fillna('0')
# tweets_smi_1['friends_count'] = pd.to_numeric(tweets_smi_1['friends_count'], errors='ignore')
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(np.int32, errors='ignore')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].fillna('0')
# tweets_smi_1['favorites'] = pd.to_numeric(tweets_smi_1['favorites'], errors='ignore')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int32, errors='ignore')

# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].fillna('0')
# tweets_smi_1['retweets'] = pd.to_numeric(tweets_smi_1['retweets'], errors='ignore')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int32, errors='ignore')

# tweets_smi_1['id'] = tweets_smi_1['id'].fillna('0')
# tweets_smi_1['id'] = pd.to_numeric(tweets_smi_1['id'], errors='ignore')
# tweets_smi_1['id'] = tweets_smi_1['id'].astype(np.int32, errors='ignore')

# # # tweets_smi_1['location'] = tweets_smi_1['location'].astype(str, errors='ignore')

# # # tweets_smi_1['location'] = tweets_smi_1['location'].fillna('undefined')



###################################################################################################################
##################################################################################################
##################################################################################################

# tweets_smi_1['id'] = tweets_smi_1['id'].fillna('0')
# tweets_smi_1['author_id'] = tweets_smi_1['author_id'].fillna('0')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].fillna('0')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].fillna('0')
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].fillna('0')
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].fillna('0')
# tweets_smi_1['time'] = tweets_smi_1['time'].fillna('0:00:00 AM')
# tweets_smi_1['is_follower'] = tweets_smi_1['is_follower'].fillna('False')
# tweets_smi_1['is_friend'] = tweets_smi_1['is_friend'].fillna('False')
# tweets_smi_1['year_x'] = tweets_smi_1['year_x'].fillna('2006')
# tweets_smi_1['year_y'] = tweets_smi_1['year_x'].fillna('2006')

# tweets_smi_1['time'] = tweets_smi_1['time'].apply(pd.Timestamp)

# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(int32)
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(int32)
# tweets_smi_1['id'] = tweets_smi_1['id'].astype(int64)
# tweets_smi_1['author_id'] = tweets_smi_1['author_id'].astype(int64)
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(int32)
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(int32)
# tweets_smi_1['is_follower'] = bool(tweets_smi_1['is_follower'])
# tweets_smi_1['is_friend'] = bool(tweets_smi_1['is_friend'])

# tweets_smi_1['screenName'] = tweets_smi_1['screenName'].astype(str)
# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str)
# tweets_smi_1['language'] = tweets_smi_1['language'].astype(str)
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str)
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str)
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str)
# tweets_smi_1['hashtags'] = tweets_smi_1['old_hastags'].astype(str)
# tweets_smi_1['year'] = tweets_smi_1['year'].astype(int32)
# tweets_smi_1['year_x'] = tweets_smi_1['year_x'].astype(int32)
# tweets_smi_1['year_y'] = tweets_smi_1['year_y'].astype(int32)

print('SMI_1 AFTER INT CHANGE DTYPES 5')
print(tweets_smi_1.dtypes)
print('---')

##################################################################################################
##################################################################################################

# SAVE DATAFRAME TO CSV 

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

##################################################################################################################

# REMOVE DUPLICATES

# Delete duplicates

# tweets_smi_1.drop_duplicates()

tweets_smi_1['text'] = tweets_smi_1['text'].fillna('')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('NaN', '')

# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('')
# tweets_smi_1['mentions_total'] = tweets_smi_1['mentions_total'].fillna('')
# tweets_smi_1['hashtags_total'] = tweets_smi_1['hashtags_total'].fillna('')
# tweets_smi_1['missing_mentions'] = tweets_smi_1['missing_mentions'].fillna('')
# tweets_smi_1['missing_hashtags'] = tweets_smi_1['missing_hashtags'].fillna('')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].fillna('')
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].fillna('')

print('SMI DF info 1')
print(tweets_smi_1.info)
print('---')

# REMOVE ~ and '

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore').str.replace('~', '')

#######################################################################################################
#######################################################################################################

# Replace Values

# Covert column with replaced value of language 

tweets_smi_1['language'].replace('und', 'undefined', inplace=True) 
tweets_smi_1['language'].replace('en', 'english', inplace=True)    
tweets_smi_1['language'].replace('am', 'amharic', inplace=True)        
tweets_smi_1['language'].replace('ar', 'arabic', inplace=True)        
tweets_smi_1['language'].replace('hy', 'armenian', inplace=True)        
tweets_smi_1['language'].replace('eu', 'basque', inplace=True)     
tweets_smi_1['language'].replace('bn', 'bengali', inplace=True)       
tweets_smi_1['language'].replace('bg', 'bulgarian', inplace=True)        
tweets_smi_1['language'].replace('my', 'burmese', inplace=True)        
tweets_smi_1['language'].replace('ca', 'catalan', inplace=True)        
tweets_smi_1['language'].replace('zh', 'chinese ', inplace=True)        
tweets_smi_1['language'].replace('zh-cn', 'chinese ', inplace=True)        
tweets_smi_1['language'].replace('zh-tw', 'chinese ', inplace=True)        
tweets_smi_1['language'].replace('hr', 'croatian', inplace=True)        
tweets_smi_1['language'].replace('cs', 'czech', inplace=True)        
tweets_smi_1['language'].replace('da', 'danish', inplace=True)        
tweets_smi_1['language'].replace('nl', 'dutch', inplace=True)        
tweets_smi_1['language'].replace('et', 'estonian', inplace=True)        
tweets_smi_1['language'].replace('fi', 'finnish', inplace=True)        
tweets_smi_1['language'].replace('fr', 'french', inplace=True)        
tweets_smi_1['language'].replace('fil', 'filipino', inplace=True)        
tweets_smi_1['language'].replace('ka', 'georgian', inplace=True)        
tweets_smi_1['language'].replace('de', 'german', inplace=True)        
tweets_smi_1['language'].replace('el', 'greek', inplace=True)        
tweets_smi_1['language'].replace('gu', 'gujarati', inplace=True)        
tweets_smi_1['language'].replace('he', 'hebrew', inplace=True)
tweets_smi_1['language'].replace('iw', 'hebrew', inplace=True)         
tweets_smi_1['language'].replace('ht', 'haitian', inplace=True)        
tweets_smi_1['language'].replace('hi', 'hindi', inplace=True)        
tweets_smi_1['language'].replace('hu', 'hungarian', inplace=True)        
tweets_smi_1['language'].replace('is', 'icelandic', inplace=True)        
tweets_smi_1['language'].replace('in', 'indonesian', inplace=True)        
tweets_smi_1['language'].replace('id', 'indonesian', inplace=True)        
tweets_smi_1['language'].replace('it', 'italian', inplace=True)        
tweets_smi_1['language'].replace('ja', 'japanese', inplace=True)        
tweets_smi_1['language'].replace('kn', 'kannada', inplace=True)        
tweets_smi_1['language'].replace('km', 'khmer', inplace=True)        
tweets_smi_1['language'].replace('ko', 'korean', inplace=True)        
tweets_smi_1['language'].replace('lo', 'lao', inplace=True)        
tweets_smi_1['language'].replace('lv', 'latvian', inplace=True)        
tweets_smi_1['language'].replace('lt', 'lithuanian', inplace=True)        
tweets_smi_1['language'].replace('ml', 'malayalam', inplace=True)        
tweets_smi_1['language'].replace('dv', 'maldivian', inplace=True)        
tweets_smi_1['language'].replace('ms', 'malay', inplace=True)        
tweets_smi_1['language'].replace('mr', 'marathi', inplace=True)        
tweets_smi_1['language'].replace('ne', 'nepali', inplace=True)        
tweets_smi_1['language'].replace('no', 'norwegian', inplace=True)        
tweets_smi_1['language'].replace('or', 'oriya', inplace=True)        
tweets_smi_1['language'].replace('pa', 'panjabi', inplace=True)        
tweets_smi_1['language'].replace('ps', 'pashto', inplace=True)        
tweets_smi_1['language'].replace('fa', 'persian', inplace=True)        
tweets_smi_1['language'].replace('pl', 'polish', inplace=True)        
tweets_smi_1['language'].replace('pt', 'portuguese', inplace=True)        
tweets_smi_1['language'].replace('ro', 'romanian', inplace=True)        
tweets_smi_1['language'].replace('ru', 'russian', inplace=True)        
tweets_smi_1['language'].replace('sr', 'serbian', inplace=True)        
tweets_smi_1['language'].replace('sd', 'sindhi', inplace=True)        
tweets_smi_1['language'].replace('si', 'sinhala', inplace=True)        
tweets_smi_1['language'].replace('sk', 'slovak', inplace=True)        
tweets_smi_1['language'].replace('sl', 'slovenian', inplace=True)        
tweets_smi_1['language'].replace('ckb', 'kurdish', inplace=True)        
tweets_smi_1['language'].replace('es', 'spanish', inplace=True)        
tweets_smi_1['language'].replace('sv', 'swedish', inplace=True)        
tweets_smi_1['language'].replace('tl', 'tagalog', inplace=True)        
tweets_smi_1['language'].replace('ta', 'tamil', inplace=True)        
tweets_smi_1['language'].replace('te', 'telegu', inplace=True)        
tweets_smi_1['language'].replace('th', 'thai', inplace=True)        
tweets_smi_1['language'].replace('bo', 'tibetan', inplace=True)        
tweets_smi_1['language'].replace('tr', 'turkish', inplace=True)       
tweets_smi_1['language'].replace('uk', 'ukrainian', inplace=True)       
tweets_smi_1['language'].replace('ur', 'urdu', inplace=True)        
tweets_smi_1['language'].replace('ug', 'uyghur', inplace=True)        
tweets_smi_1['language'].replace('vi', 'vietnamese', inplace=True)        
tweets_smi_1['language'].replace('cy', 'welsh', inplace=True) 
 
# tweets_smi_1

tweets_smi_1.shape
# tweets_smi_1.head(10)

#######################################################################


# CONVERT TO LOWERCASE

# tweets_smi_1['screenName'] = tweets_smi_1['screenName'].str.lower()
# tweets_smi_1['text'] = tweets_smi_1['text'].str.lower()


# STRIP LEFT WHITE SPACE

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore').str.lstrip()
# tweets_smi_1['screenName'] = tweets_smi_1['screenName'].astype(str, errors='ignore').str.lstrip()
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str, errors='ignore').str.lstrip()
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str, errors='ignore').str.lstrip()
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore').str.lstrip()
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].astype(str, errors='ignore').str.lstrip()

print('Done lowercase')

# SAVE DATAFRAME TO CSV 

tweets_smi_1.to_csv('A_SMI1_DF_Tweets_Processes_total_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)

#######################################################################

# tweets_smi_1['created'] = tweets_smi_1['created_1']

print('---')
print('SMI DF info 3')
print(tweets_smi_1.info)
print('---')

# FILL NAN 

# tweets_smi_1['text'] = tweets_smi_1['text'].fillna('0')

# REMOVE SPACES

# Remove empty spaces at the beginning and end of the string

# tweets_smi_1['text'] = tweets_smi_1['text'].str.strip()

######################################################################

print('---')
print('Tweets Without Stop Words:')
print(tweets_smi_1['text'].head())
print('---')

print('---')
print('SMI DF info 4')
print(tweets_smi_1.info)
print('---')

####################################################################################################################

print('---')
print('Loading Libs 6')
print('---')

# REMOVING STOP WORDS

# tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]
                                
# stop_words=set(stopwords.words('english'))
# print(stop_words)

######################    tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('s://', ' ') # NEED TP CHECK

#####################################################################
#####################################################################

# FINAL REPLACES

####################################################################

tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('NONE')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('NONE')
tweets_smi_1['mentions_total'] = tweets_smi_1['mentions_total'].fillna('NONE')
# tweets_smi_1['hashtags_total'] = tweets_smi_1['hashtags_total'].fillna('NONE')
tweets_smi_1['missing_mentions'] = tweets_smi_1['missing_mentions'].fillna('NONE')
tweets_smi_1['missing_hashtags'] = tweets_smi_1['missing_hashtags'].fillna('NONE')
tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('NONE')
tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('NONE')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('[]')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('[]')

# tweets_smi_1['missing_hashtags'] = tweets_smi_1['missing_hashtags'].fillna('[]')

##### ---OJO !!! cambie missing mentions por mentions solo y hastags 

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags']
# tweets_smi_1['mentions'] = tweets_smi_1['mentions']

# tweets_smi_1['missing_mentions'] = tweets_smi_1['missing_mentions'].fillna('[]')
# tweets_smi_1['text'] = tweets_smi_1['text'].fillna('[]')

print('---')
print('Head Missing Mentions 1')
print(tweets_smi_1['mentions'].head(20))
print('---')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('none')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('none')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('  ', ' ')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('  ', ' ')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('  ', ' ')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace('  ', ' ')
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.replace('  ', ' ')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('  ', ' ')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('  ', ' ')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('  ', ' ')

############################################################################################################
#############################################################################################################
############################################################################################################
#############################################################################################################

# medium.com/learn-nlp/a-quick-guide-to-text-analysis-seaborn-4c1a20addba3

# JOIN MISSING AND ORIG DATA

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['hashtags'].str.replace('[', '')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['hashtags'].str.replace(']', '')

# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('@', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('#', '')


# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\[', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\]', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('  ', ' ')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\[\]', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\[', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\]', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('  ', ' ')

# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\[\]', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\[', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\]', ',')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace(' ', ' ')

# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\[\]', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\[', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\]', ',')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('  ', ' ')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\'', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\'', '')

# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\'', '')
# tweets_smi_1['missing_mentions'] = tweets_smi_1['missing_mentions'].str.replace('\'', '')

#####################################

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.lstrip()
# tweets_smi_1['missing_mentions'] = tweets_smi_1['missing_mentions'].str.lstrip()

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('0')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('0')

# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\'nan\'', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('NaN', '')

# tweets_smi_1['missing_hashtags'] = tweets_smi_1['missing_hashtags'].str.replace('\"', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\'nan\'', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('NaN', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('0')
# tweets_smi_1['missing_hashtags'] = tweets_smi_1['missing_hashtags'].fillna('[]')

print('Head Missing Mentions 1A')
print(tweets_smi_1['mentions'].head(20))
print('---')

# tweets_smi_1['missing_mentions'] = tweets_smi_1['missing_mentions'].fillna('[]')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('0')
# tweets_smi_1['missing_mentions'] = tweets_smi_1['missing_mentions'].str.replace('\"', '')
# tweets_smi_1['missing_mentions'] = tweets_smi_1['missing_mentions'].str.replace(',', ' ')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\'nan\'', '')

# tweets_smi_1['text'] = tweets_smi_1['text'].fillna('[]')

print('Head Missing Mentions 2')
print(tweets_smi_1['mentions'].head(20))
print('---')

hashtags_df = pd.DataFrame(tweets_smi_1['hashtags'])

# hashtags_df = hashtags_df.astype(str, errors='ignore')

# missing_hashtags = missing_hashtags.replace('\[', '')
# missing_hashtags = missing_hashtags.replace('\]', '')

# NEED TO PUT MISSING ITEM IN DATAFRAME AND ROW PER ROW AS ORIGINAL - NEED TO DO!!!!!!!!

# tweets_smi_1['missing_mentions'] = tweets_smi_1['missing_mentions'].fillna('0')

# SAVE DATAFRAME TO CSV 

hashtags_df.to_csv('1_6_1_SMI1_Missing_Hashtags_DF_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# hashtags_df.to_csv('1_6_1_SMI1_Missing_Hashtags_DF_1_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

# tweets_smi_1.to_csv('1_6_1_4A_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_4A_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('A_SMI1_DF_Tweets_Processes_Total_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)

### DELETE VARIABLE

del hashtags_df

print('---')
print('SMI DF info 4')
# print(tweets_smi_1.info)
print('---')


#################################################################################################################
#################################################################################################################

print('Head hashtags: OJO REVISAR 3')
print(tweets_smi_1['hashtags'].head)
print('---')

# HASHTAGS

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str, errors='ignore')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].to_string()
# tweets_smi_1['missing_hashtags'] = tweets_smi_1['missing_hashtags'].astype(str, errors='ignore')
# tweets_smi_1['missing_hashtags'] = tweets_smi_1['missing_hashtags'].to_string()

hashtags_0 = pd.DataFrame(tweets_smi_1['hashtags'])

# hashtags_0 = hashtags_0.astype(str, errors='ignore')

# hashtags_0 = hashtags_0.replace('\[', '')
# hashtags_0 = hashtags_0.replace('\]', '')

# SAVE DATAFRAME TO CSV 

# hashtags_0.to_csv('1_6_1_SMI1_Missing_Hashtags_0_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# hashtags_0.to_csv('1_6_1_SMI1_Missing_Hashtags_0_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

### DELETE VARIABLE

del hashtags_0

################################################################################################

print('---')
print('Head Missing Mentions')
print(tweets_smi_1['mentions'].head)
print('---')

print('---')
print('Head Missing hashtags 1x : OJOOOOOOOOOOOOOO')
print(tweets_smi_1['hashtags'].head)
print('---')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\"', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\'', '')

print('Head TOTAL hashtags_total x: OJO REVISAR 6')
print(tweets_smi_1['hashtags'].head)
print('---')

#######
######
#####
###
# MISSING MENTIONS ABAJO!!!!!!

########
###############################################################################################################

# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('http://www.', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('https://', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('http://', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('https:', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('www.', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('http', '')

# SAVE TO CSV 

# tweets_smi_1.to_csv('1_6_1_5A_SMI1_DF_Tweets_Processes_SEPERATE_URLS_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_5A_SMI1_DF_Tweets_Processes_SEPERATE_URLS_1_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_SEPERATE_URLS_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_SEPERATE_URLS_1_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

# print('done - NOT WORKING processing Text SEPERATE URLSSSSS - DONE')

# SAVE DATAFRAME TO CSV 

# mentions_with_smi_names.to_csv('1_6_1_SMI1_Missing_Mentions_with_Smi_Names_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# mentions_with_smi_names.to_csv('1_6_1_SMI1_Missing_Mentions_with_Smi_Names_1_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

### DELETE VARIABLE

# del mentions_with_smi_names

# SAVE DATAFRAME TO CSV 

# tweets_smi_1.to_csv('1_6_1_6A_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_6A_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('A_SMI1_DF_Tweets_Processes_Total_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)

# missing_mentions.head(10)

### DELETE VARIABLE

# del missing_mentions

################################################################################################################
###############################################################################################################

print('Head mentions: OJO REVISAR 3')
print(tweets_smi_1['mentions'].head)
print('---')

# mentions

# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str, errors='ignore')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].to_string()
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str, errors='ignore')
# tweets_smi_1['missing_mentions'] = tweets_smi_1['missing_mentions'].to_string()

mentions_0 = pd.DataFrame(tweets_smi_1['mentions'])

# mentions_0 = mentions_0.astype(str, errors='ignore')

# mentions_0 = mentions_0.replace('\[', '')
# mentions_0 = mentions_0.replace('\]', '')

# SAVE DATAFRAME TO CSV 

mentions_0.to_csv('1_6_1_SMI1_Missing_Mentions_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# mentions_0.to_csv('1_6_1_SMI1_Missing_Mentions_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

### DELETE VARIABLE

del mentions_0

#######################################################################################

tweets_smi_1.to_csv('A_SMI1_DF_Tweets_Processes_Total_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)

print('---')
print('Head Missing Mentions')
print(tweets_smi_1['mentions'].head)
# print('---')

print('---')
print('Head Missing mentions 1x : OJOOOOOOOOOOOOOO')
print(tweets_smi_1['mentions'].head)
# print('---')

# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\"', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\'', '')

print('Head TOTAL mentions_total x: OJO REVISAR 6')
print(tweets_smi_1['mentions'].head)
print('---')

################################################################################################################
#################################################################################################################
#################################################################################################################

# CALCULATE LEN - TOTAL TWEETS - LEN OF DATAFRAME

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.float64, errors='ignore')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.float64, errors='ignore')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(str, errors='ignore').str.replace('\.0', '')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore').str.replace('\.0', '')

# tweets_smi_1['favorites'] = int(float(tweets_smi_1['favorites']))
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(int, errors='ignore')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int32, errors='ignore')
## tweets_smi_1['favorites'] = tweets_smi_1['favorites'].round()

# tweets_smi_1['retweets'] = int(float(tweets_smi_1['retweets']))
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(int, errors='ignore')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int32, errors='ignore')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].round()

# Save FILES

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_TEXT_ONLY.txt', sep='\t', encoding='utf-8', index=False, header=True)

print('done - processing Text - DONE')

###################################################################################################################################


# SAVE DATAFRAME TO CSV 

# tweets_smi_1.to_csv('1_6_1_9_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_9_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

############
############################################################################################################
####################################################################################################################

# QUITE EL NAN NEED TO FIX NOT WORKING

# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore').str.replace('\.0', '')

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore').str.replace('NaN', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str, errors='ignore').str.replace('NaN', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str, errors='ignore').str.replace('NaN', '')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore').str.replace('NaN', '')
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].astype(str, errors='ignore').str.replace('NaN', '')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].str.lstrip()
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].str.lstrip()

# tweets_smi_1['text'] = tweets_smi_1['text'].str.lstrip()
# tweets_smi_1['screenName'] = tweets_smi_1['screenName'].str.lstrip()
# tweets_smi_1['id'] = tweets_smi_1['id'].astype(str, errors='ignore').str.lstrip()
# tweets_smi_1['author_id'] = tweets_smi_1['author_id'].str.lstrip()

# MAKE ALL WORDS LOWERCASE AGAIN

# tweets_smi_1['text'] = tweets_smi_1['text'].str.lower()
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.lower()
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.lower()
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.lower()
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.lower()
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str, errors='ignore').str.lower()

############# NEED TO JOIN OLD AND MISSING COLLUMS TOGETHER !!!!

############################################################################################################
############################################################################################################
############################################################################################################
############################################################################################################
############################################################################################################
############################################################################################################
#########################################################################################################

# tweets_smi_1 = tweets_smi_1.drop(columns='hashtags_orig') 
# tweets_smi_1 = tweets_smi_1.drop(columns='mentions_orig')
# tweets_smi_1 = tweets_smi_1.drop(columns='hashtags') 
# tweets_smi_1 = tweets_smi_1.drop(columns='mentions')
# tweets_smi_1 = tweets_smi_1.drop(columns='emojis_unicode_orig')

print('Head SMI_1 TWEETS DATAFRAME: dtyPES OJO REVISAR 7')
# print(tweets_smi_1.dtypes)
print('---')

#############################################################################################################
#############################################################################################################

# DROP 2

# tweets_smi_1 = tweets_smi_1.drop(columns='location_orig')
# tweets_smi_1 = tweets_smi_1.drop(columns='emojis_converted_orig')
# tweets_smi_1 = tweets_smi_1.drop(columns='missing_geo')
# tweets_smi_1 = tweets_smi_1.drop(columns='missing_country')
# tweets_smi_1 = tweets_smi_1.drop(columns='missing_location')
# tweets_smi_1 = tweets_smi_1.drop(columns='missing_emojis_converted')
# tweets_smi_1 = tweets_smi_1.drop(columns='number_emojis_unicode')
# tweets_smi_1 = tweets_smi_1.drop(columns='number_missing_emojis_unicode')
# tweets_smi_1 = tweets_smi_1.drop(columns='missing_emojis_unicode')
# tweets_smi_1 = tweets_smi_1.drop(columns='total_emojis_unicode')
# tweets_smi_1 = tweets_smi_1.drop(columns='total_emojis_converted')
# tweets_smi_1 = tweets_smi_1.drop(columns='total_mentions')
# tweets_smi_1 = tweets_smi_1.drop(columns='user')
# tweets_smi_1 = tweets_smi_1.drop(columns='mentions_author_id')

print('tweets_smi_1 DTYPES')
# print(tweets_smi_1.dtypes)
print('---')

print('tweets_smi_1 head')
print(tweets_smi_1.head)
print('---')

###########################################################################################

# REMOVE DUPLICATES

# Delete duplicates

# tweets_smi_1.drop_duplicates()


###################################################################################
#####################################################################################################

tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('NONE')
tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('NONE')
tweets_smi_1['mentions_total'] = tweets_smi_1['mentions_total'].fillna('NONE')
# tweets_smi_1['hashtags_total'] = tweets_smi_1['hashtags_total'].fillna('NONE')
tweets_smi_1['missing_mentions'] = tweets_smi_1['missing_mentions'].fillna('NONE')
tweets_smi_1['missing_hashtags'] = tweets_smi_1['missing_hashtags'].fillna('NONE')
tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('NONE')
tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('NONE')

# CONVERT TO LOWERCASE

# tweets_smi_1['text'] = tweets_smi_1['text'].str.lower()

tweets_smi_1['screenName'] = tweets_smi_1['screenName'].fillna('NONE')
# tweets_smi_1['screenName'] = tweets_smi_1['screenName'].str.lower()
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['language'] = tweets_smi_1['language'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['mentions_screen_name'] = tweets_smi_1['mentions_screen_name'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['quoted_screen_name'] = tweets_smi_1['quoted_screen_name'].astype(str, errors='ignore').str.lower()

tweets_smi_1['geo'] = tweets_smi_1['geo'].fillna('NONE')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].astype(str, errors='ignore').str.lower()
# # tweets_smi_1['location'] = tweets_smi_1['location'].fillna('')
# # tweets_smi_1['location'] = tweets_smi_1['location'].astype(str, errors='ignore').str.lower()

# # tweets_smi_1['geo'] = tweets_smi_1['geo'].astype(str, errors='ignore').str.lower()

# tweets_smi_1['place_full_name'] = tweets_smi_1['place_full_name'].fillna('NONE')
# tweets_smi_1['place_full_name'] = tweets_smi_1['place_full_name'].astype(str, errors='ignore').str.lower()

# # tweets_smi_1['geo'] = tweets_smi_1['geo'].fillna('NONE')
# # tweets_smi_1['geo'] = tweets_smi_1['geo'].astype(str, errors='ignore').str.lower()

# tweets_smi_1['country'] = tweets_smi_1['country'].fillna('NONE')
# tweets_smi_1['country'] = tweets_smi_1['country'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['hashtags_total'] = tweets_smi_1['hashtags_total'].fillna('NONE')
# tweets_smi_1['hashtags_total'] = tweets_smi_1['hashtags_total'].astype(str, errors='ignore').str.lower()
tweets_smi_1['mentions_total'] = tweets_smi_1['mentions_total'].fillna('NONE')
# tweets_smi_1['mentions_total'] = tweets_smi_1['mentions_total'].astype(str, errors='ignore').str.lower()

# tweets_smi_1['missing_emojis_unicode '] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['emojis_unicode_orig'] = tweets_smi_1['emojis_unicode_orig'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['url'] = tweets_smi_1['url'].str.lower()
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['total_emojis_unicode'] = tweets_smi_1['total_emojis_unicode'].astype(str, errors='ignore').str.lower()

print('------------------------------------')
print('BEFORE DTYPE CHANGE 0')
print(tweets_smi_1.dtypes)
print('------------------------------------')

print('---')
print('SMI DF info 6')
# print(tweets_smi_1.info)
print('---')

print('------------------')
print('TEXT HEAD 6')
print(tweets_smi_1['text'].head)

print('------------------')
print('HASHTAGS HEAD 6')
print(tweets_smi_1['hashtags'].head)

print('------------------')
print('MENTIONS HEAD 6')
print(tweets_smi_1['mentions'].head)


print('------------------')
print('EMOJIS UNICODE HEAD 6')
print(tweets_smi_1['emojis_unicode'].head)

print('------------------')
print('EMOJIS CONVERTED HEAD 6')
print(tweets_smi_1['emojis_converted'].head)

print('------------------')
print('TEXT HEAD BEFORE 6')
print(tweets_smi_1['text'].head)

#####################################################################################################

# CONVERT TO STRING TYPE DTYPE TIME DATE 


# tweets_smi_1['text'] = str(tweets_smi_1['text'])
# tweets_smi_1['screenName'] = str(tweets_smi_1['screenName'])

# tweets_smi_1['mentions'] = str(tweets_smi_1['mentions'])
# tweets_smi_1['hashtags'] = str(tweets_smi_1['hashtags'])
# tweets_smi_1['language'] = str(tweets_smi_1['language'])

# tweets_smi_1['mentions_screen_name'] = str(tweets_smi_1['mentions_screen_name'])
# tweets_smi_1['quoted_screen_name'] = str(tweets_smi_1['quoted_screen_name'])


# tweets_smi_1['text'] = tweets_smi_1['text'].to_string()
# tweets_smi_1['screenName'] = tweets_smi_1['screenName'].to_string()

# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].to_string()
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].to_string()
# tweets_smi_1['language'] = tweets_smi_1['language'].to_string()


# tweets_smi_1['time'] = pd.to_datetime(tweets_smi_1['time'])

# tweets_smi_1['missing_emojis_unicode '] = tweets_smi_1['missing_emojis_unicode '].astype(str, errors='ignore').str.lower()
# tweets_smi_1['emojis_unicode_orig'] = tweets_smi_1['emojis_unicode_orig'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['url'] = tweets_smi_1['url'].str.lower()
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['total_emojis_unicode'] = tweets_smi_1['total_emojis_unicode'].astype(str, errors='ignore').str.lower()


print('---')
print('SMI DF info 7')
# print(tweets_smi_1.info)
print('---')

print('------------------')
print('TEXT HEAD 7')
print(tweets_smi_1['text'].head)

print('------------------')
print('HASHTAGS HEAD 7')
print(tweets_smi_1['hashtags'].head)

print('------------------')
print('MENTIONS HEAD 7')
print(tweets_smi_1['mentions'].head)


print('------------------')
print('EMOJIS UNICODE HEAD 7')
print(tweets_smi_1['emojis_unicode'].head)

print('------------------')
print('EMOJIS CONVERTED HEAD 7')
print(tweets_smi_1['emojis_converted'].head)

print('------------------')
print('GEO HEAD 7')
print(tweets_smi_1['geo'].head)


print('---')
print('tweets_smi_1')
print(tweets_smi_1.dtypes)
print('---')

# DROP author_id latitude longitude url 

# tweets_smi_1 = tweets_smi_1.drop(columns='id')
# tweets_smi_1 = tweets_smi_1.drop(columns='author_id')
# tweets_smi_1 = tweets_smi_1.drop(columns='latitude')
# tweets_smi_1 = tweets_smi_1.drop(columns='longitude')
# tweets_smi_1 = tweets_smi_1.drop(columns='image_link')
# tweets_smi_1 = tweets_smi_1.drop(columns='url')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].replace('nan', '')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].replace('NaN', '')

# tweets_smi_1['screenName'] = tweets_smi_1['screenName'].astype(str, errors='ignore').dtype
# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore').dtype
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str, errors='ignore').dtype
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str, errors='ignore').dtype
# tweets_smi_1['language'] = tweets_smi_1['language'].astype(str, errors='ignore').dtype

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(str, errors='ignore').str.replace('\.0', '')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore').str.replace('\.0', '')



#########################

# LOCATION NAME TEMP FIX

# tweets_smi_1['location'] = tweets_smi_1['geo'].astype(str, errors='ignore').dtype

#########################

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace('\\\', '\')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace('\\\', '\')

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore').dtype

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(str, errors='ignore').str.replace('\.0', '')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore').str.replace('\.0', '')

# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].astype(str, errors='ignore').str.replace('NaN', 'undefined')
# tweets_smi_1['missing_geo_orig'] = tweets_smi_1['missing_geo_orig'].astype(str, errors='ignore').str.replace('NaN', 'undefined')
# tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].astype(str, errors='ignore').str.replace('NaN', 'undefined')
# tweets_smi_1['missing_country_orig'] = tweets_smi_1['missing_country_orig'].astype(str, errors='ignore').str.replace('NaN', 'undefined')
## tweets_smi_1['total_missing_country'] = tweets_smi_1['total_missing_country'].astype(str, errors='ignore').str.replace('NaN', 'undefined')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].fillna('0')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].fillna('0')
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].fillna('0')
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].fillna('0')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].round()
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int32, errors='ignore')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int32, errors='ignore')


#################################################################################

# tweets_smi_1['language'] = tweets_smi_1['language'].astype(str, errors='ignore')

tweets_smi_1['language'] = tweets_smi_1['language'].fillna('undefined')
# tweets_smi_1['language'] = tweets_smi_1['language'].str.lstrip()
# tweets_smi_1['language'] = tweets_smi_1['language'].str.rstrip()
# tweets_smi_1['language'] = tweets_smi_1['language'].str.replace('\'nan\'', '')
# tweets_smi_1['language'] = tweets_smi_1['language'].str.replace('NaN', 'undefined')

# # tweets_smi_1['location'] = tweets_smi_1['location'].astype(str, errors='ignore')

# # tweets_smi_1['location'] = tweets_smi_1['location'].fillna('undefined')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.lstrip()
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.rstrip()
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\'nan\'', '')
# # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('NaN', 'undefined')

# # tweets_smi_1['geo'] = tweets_smi_1['geo'].astype(str, errors='ignore')

# # tweets_smi_1['geo'] = tweets_smi_1['geo'].fillna('undefined')
# # tweets_smi_1['geo'] = tweets_smi_1['geo'].str.lstrip()
# # tweets_smi_1['geo'] = tweets_smi_1['geo'].str.rstrip()
# # tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('\'nan\'', '')
# # tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('NaN', 'undefined')

# tweets_smi_1['country'] = tweets_smi_1['country'].astype(str, errors='ignore')

# tweets_smi_1['country'] = tweets_smi_1['country'].fillna('undefined')
# # tweets_smi_1['country'] = tweets_smi_1['country'].str.lstrip()
# # tweets_smi_1['country'] = tweets_smi_1['country'].str.rstrip()
# # tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('\'nan\'', '')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('NaN', 'undefined')

print('---')
print('SMI DF info 8')
# print(tweets_smi_1.info)
print('---')

print('------------------')
print('TEXT HEAD 8')
print(tweets_smi_1['text'].head)

print('------------------')
print('HASHTAGS HEAD 8')
print(tweets_smi_1['hashtags'].head)

print('------------------')
print('MENTIONS HEAD 8')
print(tweets_smi_1['mentions'].head)


print('------------------')
print('EMOJIS UNICODE HEAD 8')
print(tweets_smi_1['emojis_unicode'].head)

print('------------------')
print('EMOJIS CONVERTED HEAD 8')
print(tweets_smi_1['emojis_converted'].head)

print('------------------')
print('GEO HEAD 8')
print(tweets_smi_1['geo'].head)

print('------------------')
print('TEXT HEAD BEFORE 8')
print(tweets_smi_1['text'].head)


# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore')
# tweets_smi_1['screenName'] = tweets_smi_1['screenName'].astype(str, errors='ignore')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str, errors='ignore')
# tweets_smi_1['mentions_total'] = tweets_smi_1['mentions_total'].astype(str, errors='ignore')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str, errors='ignore')
# # tweets_smi_1['hashtags_total'] = tweets_smi_1['hashtags_total'].astype(str, errors='ignore')
# tweets_smi_1['language'] = tweets_smi_1['language'].astype(str, errors='ignore')
# # tweets_smi_1['location'] = tweets_smi_1['location'].astype(str, errors='ignore')
# # tweets_smi_1['geo'] = tweets_smi_1['geo'].astype(str, errors='ignore')
# tweets_smi_1['country'] = tweets_smi_1['country'].astype(str, errors='ignore')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].astype(str, errors='ignore')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore')
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].astype(str, errors='ignore')

# tweets_smi_1['mentions_screen_name'] = tweets_smi_1['mentions_screen_name'].astype(str, errors='ignore')
# tweets_smi_1['quoted_screen_name'] = tweets_smi_1['quoted_screen_name'].astype(str, errors='ignore')

print('--- after str change')
print(tweets_smi_1.dtypes)
print('---')

#########################################################################################

#  REMOVE SCOTT

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['followers'] = tweets_smi_1['followers'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['following'] = tweets_smi_1['following'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['quote_count'] = tweets_smi_1['quote_count'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['reply_count'] = tweets_smi_1['reply_count'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['total_tweets'] = tweets_smi_1['total_tweets'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['lists'] = tweets_smi_1['lists'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(str, errors='ignore').str.replace('scott', '')
# # tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['number_total_hashtags'] = tweets_smi_1['number_total_hashtags'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['number_emojis_unicode'] = tweets_smi_1['number_emojis_unicode'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['number_missing_emojis_unicode'] = tweets_smi_1['number_missing_emojis_unicode'].astype(str, errors='ignore').str.replace('scott', '')
# tweets_smi_1['number_total_emojis_unicode'] = tweets_smi_1['number_total_emojis_unicode'].astype(str, errors='ignore').str.replace('scott', '')


# CHANGE BACK TO NP.INT32

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int32)
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int32)
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(np.int32)
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(np.int32)

# tweets_smi_1['number_emojis_unicode'] = tweets_smi_1['number_emojis_unicode'].astype(np.int32)
# tweets_smi_1['number_missing_emojis_unicode'] = tweets_smi_1['number_missing_emojis_unicode'].astype(np.int32)
# tweets_smi_1['number_total_emojis_unicode'] = tweets_smi_1['number_total_emojis_unicode'].astype(np.int32)

# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(np.int64)
# # tweets_smi_1['following'] = tweets_smi_1['following'].astype(np.int32)
# tweets_smi_1['quote_count'] = tweets_smi_1['quote_count'].astype(np.int32)
# tweets_smi_1['reply_count'] = tweets_smi_1['reply_count'].astype(np.int32)
# tweets_smi_1['lists'] = tweets_smi_1['lists'].astype(np.int32)
# tweets_smi_1['total_tweets'] = tweets_smi_1['total_tweets'].astype(np.int32)
# tweets_smi_1['number_total_hashtags'] = tweets_smi_1['number_total_hashtags'].astype(np.int32)
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int32)

# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str)

#########################################################################################

# ###############   NEED TO DO 

# tweets_smi_1 = pd.DataFrame(tweets_smi_1)

# tweets_smi_1 = pd.read_excel(wb)
# tweets_smi_1 = pd.read_excel(smi_file_4_4, parse_dates=['created'], sort=False)

# missing_hashtags_1 = codecs.open(smi_file_4_4_missing_hashtags, 'r', 'utf-8')
# missing_mentions_1 = codecs.open(smi_file_4_4_missing_mentions, 'r', 'utf-8')
# missing_mentions_with_smi_names_1 = codecs.open(smi_file_4_4_missing_mentions_with_smi_names, 'r', 'utf-8')

############## NEED TO DO MISSING EMOJIS

# missing_emojis_unicode_1 = codecs.open(smi_file_4_4_missing_emoji_unicode, 'r', 'utf-8')
# missing_image_link_1 = codecs.open(smi_file_4_4_missing_image_link, 'r', 'utf-8')

# missing_hashtags_1 = pd.DataFrame(missing_hashtags_1)
# missing_mentions_1 = pd.DataFrame(missing_mentions_1)
# missing_mentions_with_smi_names_1 = pd.DataFrame(missing_mentions_with_smi_names_1)
# missing_emojis_unicode_1 = pd.DataFrame(missing_emojis_unicode_1)
# missing_image_link_1 = pd.DataFrame(missing_image_link_1)

# print('-- imported missing files')


#################################################################################################################
#################################################################################################################

# FINAL FIXES 


print('------------------')
print('TEXT HEAD BEFORE SPECIAL CHARACTER CHANGES')
print(tweets_smi_1['text'].head)

print('------------------')
print('HASHTAGS HEAD BEFORE SPECIAL CHARACTER CHANGES')
print(tweets_smi_1['hashtags'].head)

print('------------------')
print('MENTIONS HEAD BEFORE SPECIAL CHARACTER CHANGES')
print(tweets_smi_1['mentions'].head)


print('------------------')
print('EMOJIS UNICODE HEAD BEFORE SPECIAL CHARACTER CHANGES')
print(tweets_smi_1['emojis_unicode'].head)

print('------------------')
print('EMOJIS CONVERTED HEAD BEFORE SPECIAL CHARACTER CHANGES')
print(tweets_smi_1['emojis_converted'].head)

print('------------------')
print('TEXT HEAD BEFORE SPECIAL CHARACTER CHANGES')
print(tweets_smi_1['text'].head)

print('------------------')
print('GEO HEAD BEFORE SPECIAL CHARACTER CHANGES')
print(tweets_smi_1['geo'].head)

#######
#######
#######

print('------------------')
print('TEXT HEAD AFTER SPECIAL CHARACTER CHANGES')
print(tweets_smi_1['text'].head)

print('------------------')
print('HASHTAGS HEAD AFTER SPECIAL CHARACTER CHANGES')
print(tweets_smi_1['hashtags'].head)

print('------------------')
print('MENTIONS HEAD AFTER SPECIAL CHARACTER CHANGES')
print(tweets_smi_1['mentions'].head)


print('------------------')
print('EMOJIS UNICODE HEAD AFTER SPECIAL CHARACTER CHANGES')
print(tweets_smi_1['emojis_unicode'].head)

print('------------------')
print('EMOJIS CONVERTED HEAD AFTER SPECIAL CHARACTER CHANGES')
print(tweets_smi_1['emojis_converted'].head)

print('------------------')
print('TEXT HEAD AFTER SPECIAL CHARACTER CHANGES')
print(tweets_smi_1['text'].head)

print('------------------')
print('GEO HEAD AFTER SPECIAL CHARACTER CHANGES')
print(tweets_smi_1['geo'].head)

print('---')
print('tweets_smi_1 dtypes doing stats')
# print(tweets_smi_1.dtypes)
print('---')

print('---')
print('tweets_smi_1 favorites Head')
print(tweets_smi_1['favorites'].head)
print('---')

print('---')
print('tweets_smi_1 retweets Head')
print(tweets_smi_1['retweets'].head)
print('---')

print('---')
print('tweets_smi_1 friends_count Head')
# print(tweets_smi_1['friends_count'].head)
print('---')


print('---')
print('tweets_smi_1 followers_count Head')
# print(tweets_smi_1['followers_count'].head)
print('---')

print('----------------------------------------------------------------------------')

################################################################################################################


# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str)
# tweets_smi_1['text'] = str(tweets_smi_1['text'])

# tweets_smi_1['geo'] = tweets_smi_1['geo'].astype(str)
# tweets_smi_1['geo'] = str(tweets_smi_1['geo'])

# # tweets_smi_1['location'] = tweets_smi_1['location'].astype(str)
# tweets_smi_1['location'] = str(tweets_smi_1['location'])

# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str)
# tweets_smi_1['mentions'] = str(tweets_smi_1['mentions'])

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str)
# tweets_smi_1['hashtags'] = str(tweets_smi_1['hashtags'])

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str)
# tweets_smi_1['text'] = str(tweets_smi_1['text'])

tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int32, errors='ignore')
tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int32, errors='ignore')
# tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(np.int64, errors='ignore')
# tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(np.int64, errors='ignore')
# # tweets_smi_1['followers'] = tweets_smi_1['followers'].astype(np.int32, errors='ignore')
# # tweets_smi_1['following'] = tweets_smi_1['following'].astype(np.int32, errors='ignore')
# tweets_smi_1['total_tweets'] = tweets_smi_1['total_tweets'].astype(np.int32, errors='ignore')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int32, errors='ignore')
# # tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int32, errors='ignore')
# tweets_smi_1['lists'] = tweets_smi_1['lists'].astype(np.int32, errors='ignore')

###
########################################################################################################

# Check Data Imported

tweets_shape =  tweets_smi_1.shape # View number of rows and columms in a df

print('---')
print('Tweets Shape and Types SS')
print(tweets_smi_1.shape)
print(tweets_smi_1.dtypes)
print('---')

print('--+++++++++++++++++++++++++++++++++++++-')
print('Tweets total_favorites head SS')
# print(tweets_smi_1['favorites'].head)
print('---')

print('--+++++++++++++++++++++++++++++++++++++-')
print('Tweets retweets head SS')
# print(tweets_smi_1['retweets'].head)
print('---')

print('---')
print('Tweets text head SS')
print(tweets_smi_1['text'].head)
print('--++++++++++++++++++++++++++++++++++++++++++-')


###############################################################################################
###############################################################################################
###############################################################################################

# STARTING ANALYSIS PART 


########################################################################################################################
########################################################################################################################
########################################################################################################################
########################################################################################################################
########################################################################################################################

################################################################################################################
###############################################################################################################
###############################################################################################################
###############################################################################################################
###############################################################################################################
#
#                                 QUANTITATIVE ANALYSIS - PART 1
#
###################################################################################################################
###################################################################################################################
###################################################################################################################
###################################################################################################################
###################################################################################################################

print('----------------------------------------')
print('----------------------------------------')

print('DOING QUANT ANALYSIS SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS')

print('TWEETS_SMI_2 DTYPES')
print(tweets_smi_1.dtypes)

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')
print('----------------------------------------')


#################################################################################################################

# screenName author_id created	retweets Favorites text	latitude longitude Mentions hashtags id	url emojis_unicode emojis_converted image_link	language

###################################################################################################################


# SMIS Processing / DATA ANALYSIS QUANTITATIVE AND STATISTICS

# Read dataset and store into dataframe
## IMPORTING CREATED AS STR / INT TO LOWER MEMORY USE!!!!!!!!

# Define date as datetime objects

# pd.read_csv(smi_file_4_4, sep='\t', names=['screenName', 'author_id', 'created', 'retweets', 'favorites', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', 'id', 'url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language'], parse_dates=['created'], date_parser=mydateparser)

############################ ESTA ES LO DESCARGE DE LA MEMORIA tweets_smi_1 = pd.read_csv(smi_file_4_4, sep='\t', encoding='utf-8', parse_dates=True, header=0, cache_dates=True, low_memory=True, memory_map=True)


# https://realpython.com/python-statistics/

# DESCRIPTIVE STATISTICS / # Measures of Central Tendency

###  PERCENTAGE ORIG FORMULAS FOR Pie: %1.1f%% 

# ANALYSING THE DATA

# Retweets

#### NEED TO COMPLETE DATA: TAKE OUT MENTIONS, HASTAGS, SUMMARY EMOJI CODES WITH EMOTICONS, 
#### NEED FOLLOWER GROWTH OVER TIME GRAPHICS

# ANALYSING THE DATA

#### NEED TO COMPLETE DATA: TAKE OUT MENTIONS, HASTAGS, SUMMARY EMOJI CODES WITH EMOTICONS, 
#### NEED FOLLOWER GROWTH OVER TIME GRAPHICS

# FIX FORMATING OF PieS

# NEED TO LINK TO TWITTER R DATA AND GET LOCATION INFO

# NEED TO DO SAVE TABLES TO FILES

# CHECK ALL 'NEED TO DO'

#################################################################################################################
#################################################################################################################
#################################################################################################################
#################################################################################################################
#################################################################################################################
#################################################################################################################
#################################################################################################################

total_no_tweets = tweets_smi_1.shape[0]

print('---')
print('Total Number of Tweets:')
print(total_no_tweets)
print('---')

number_total_tweets = total_no_tweets

print('---')
print('Variable number_total_tweets Number Total Tweets')
print(number_total_tweets)
print('---')


tweets_smi_1['percentage_favorites'] = (tweets_smi_1['favorites'] * 100)/number_total_tweets

print('---')
print('Percentage Favorites Head')
# print(tweets_smi_1['percentage_favorites'].head)
print('---')

tweets_smi_1['percentage_retweets'] = (tweets_smi_1['retweets'] * 100)/number_total_tweets

print('---')
print('Percentage Retweets Head')
# print(tweets_smi_1['percentage_retweets'].head)
print('---')



###############################################################################################

# https://towardsdatascience.com/data-science-with-python-intro-to-loading-and-subsetting-data-with-pandas-9f26895ddd7f

# SUBSETS

# Number of Users Who Tweet

# users_tweet = tweets_smi_1[['screenName', 'text']]

unique_tweet_users = tweets_smi_1['screenName'].unique() ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_tweet_users = len(unique_tweet_users)
number_unique_tweet_users

print('---')
print('Number of Users Who Tweet')
print(number_unique_tweet_users)
print('---')


percentage_unique_tweet_users = ((number_unique_tweet_users * 100)/main_smi_no_followers)
percentage_unique_tweet_users

print('---')
print('Percentage of Users Who Tweet')
print(percentage_unique_tweet_users)
print('---')

number_users_dont_tweet = main_smi_no_followers - number_unique_tweet_users

print('---')
print('Number of Users Who Do Not Tweet')
print(number_users_dont_tweet)
print('---')

percentage_users_dont_tweet = 100 - percentage_unique_tweet_users

print('---')
print('Percentage of Users Who Do Not Tweet')
print(percentage_users_dont_tweet)
print('---')

##############


# Inicialize List of Lists

tweet_behaviours = [['Users Who Tweet', number_unique_tweet_users, percentage_unique_tweet_users], ['Users Who Do Not Tweet', number_users_dont_tweet, percentage_users_dont_tweet]]

# Create DataFrame

tweet_behaviours_df = pd.DataFrame(tweet_behaviours, columns =['tweet_behaviour_name', 'number_tweet_behaviour', 'percentage_tweet_behaviour'])

tweet_behaviours_df.to_csv('4_4_48_SMI1_Users_Who_Tweet_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_behaviours_df.to_excel('4_4_48_SMI1_Users_Who_Tweet_DF.xlsx', header=True)

print('---')
print('Tweet Behaviour')
print(tweet_behaviours_df)
print('---')

## 3001237379 ?? 

# PLOT TABLE NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Behaviour Counts - Bars')
plt.ioff()
tweet_behaviours_df['number_tweet_behaviour'].plot(x=tweet_behaviours_df['tweet_behaviour_name'], alpha=0.9)
# ax.bar(tweet_behaviours_df['tweet_behaviour_name'], tweet_behaviours_df['number_tweet_behaviour'])
plt.xticks(rotation=50)
plt.xlabel('Users Who Tweet - Users Who Do Not Tweet')
plt.ylabel('Count')
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_48_SMI1_Users_Who_Tweet_Plot_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Behaviour Counts - Pie')
plt.ioff()
# plt.pie(tweet_behaviours_df['number_tweet_behaviour'], labels=tweet_behaviours_df['tweet_behaviour_name'])
# plt.pie(tweet_behaviours_df['number_tweet_behaviour'], labels=tweet_behaviours_df['tweet_behaviour_name'], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.7, radius=1.0, rotatelabels=False)
tweet_behaviours_df['number_tweet_behaviour'].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
plt.legend(labels=tweet_behaviours_df['tweet_behaviour_name'], bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_48RRRRRR_SMI1_Users_Who_Tweet_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Behaviour Counts - Bars')
plt.ioff()
tweet_behaviours_df['number_tweet_behaviour'].plot.bar(x=tweet_behaviours_df['tweet_behaviour_name'], alpha=0.9)
# ax.bar(tweet_behaviours_df['tweet_behaviour_name'], tweet_behaviours_df['number_tweet_behaviour'])
plt.xticks(rotation=50)
plt.xlabel('Users Who Tweet - Users Who Do Not Tweet')
plt.ylabel('Count')
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_48_SMI1_Users_Who_Tweet_Bars_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###############################################################################################################
###############################################################################################################
###############################################################################################################
#
# TOTAL MEANS FOR DATAFRAME

# = sns.catplot(x='total_favorites', y='', hue='followers_count', height=3.5, aspect=1.5, kind=box, legend=False, data=tweets_smi_1)
# total_means.add_legend(title='followers')

#################################################################################################################


print('---')
print('Loading Libs D')
print('---')


print('--')

print('FING MENTIONS HASHTAGS GEOS EMOTICONS')
print('--')


# tweets_text = tweets_smi_1['text'].to_string()

tweets_number_hashtags = re.findall('@', tweets_text, flags=re.IGNORECASE)
tweets_number_mentions = re.findall('mentions', tweets_text, flags=re.IGNORECASE)
tweets_number_geo = re.findall('geo', tweets_text, flags=re.IGNORECASE)
tweets_number_emoticons = re.findall('emoticons', tweets_text, flags=re.IGNORECASE)


number_tweets_number_hashtags = len(tweets_smi_1['hashtags'])
number_tweets_number_mentions = len(tweets_smi_1['mentions'])
number_tweets_number_geo = len(tweets_smi_1['geo'])
number_tweets_number_emoticons = len(tweets_smi_1['emoticons'])



print('---')
print('Number of Tweets About hashtags')
print(number_tweets_number_hashtags)
print('---')

percentage_tweets_number_hashtags = ((number_tweets_number_hashtags * 100)/number_total_tweets)
percentage_tweets_number_hashtags

print('---')
print('Percentage of Tweets About hashtags')
# print(percentage_tweets_number_hashtags)
print('---')

print('---')
print('Number of Tweets About mentions')
print(number_tweets_number_mentions)
print('---')

percentage_tweets_number_mentions = ((number_tweets_number_mentions * 100)/number_total_tweets)
percentage_tweets_number_mentions

print('---')
print('Percentage of Tweets About mentions')
print(percentage_tweets_number_mentions)
print('---')

print('---')
print('Number of Tweets About geo')
print(number_tweets_number_geo)
print('---')

percentage_tweets_number_geo = ((number_tweets_number_geo * 100)/number_total_tweets)
percentage_tweets_number_geo

print('---')
print('Percentage of Tweets About geo')
print(percentage_tweets_number_geo)
print('---')

print('---')
print('Number of Tweets About emoticons')
print(number_tweets_number_emoticons)
print('---')

percentage_tweets_number_emoticons = ((number_tweets_number_emoticons * 100)/number_total_tweets)
percentage_tweets_number_emoticons

print('---')
print('Percentage of Tweets About emoticons')
print(percentage_tweets_number_emoticons)
print('---')



print('---')


# Inicialize List of Lists

tweets_number_mheg_percentages = [['hashtags', number_tweets_number_hashtags, percentage_tweets_number_hashtags], ['mentions', number_tweets_number_mentions, percentage_tweets_number_mentions], ['geo', number_tweets_number_geo, percentage_tweets_number_geo], ['emoticons', number_tweets_number_emoticons, percentage_tweets_number_emoticons]]

# Create DataFrame

tweets_number_mheg_percentages_df = pd.DataFrame(tweets_number_mheg_percentages, columns =['tweets_number_smi_item', 'tweets_number_smi_number', 'tweets_number_smi_percentage'])

tweets_number_mheg_percentages_df.to_csv('4_4_64_SMI1_Tweets_number_MHEG_Percentages_DF_CSV.csv', )
# tweets_number_mheg_percentages_df.to_excel('4_4_64_SMI1_Tweets_number_MHEG_Percentages_DF.xlsx', header=True)

############################################################################
############################################################################

####
####
####  NEW FIX !!!!!!!!!

# METHOD 1 hashtags_TOTAL

fp_hashtags_total = tweets_smi_1['hashtags_total'].to_string()

# fp_hashtags_total = fp_hashtags_total_temp.to_string()

tweets_text_hashtags_total = nltk.word_tokenize(fp_hashtags_total)

value_counts_hashtags_total = pd.value_counts(tweets_text_hashtags_total, ascending=False, normalize=True) 

smi1_value_counts_hashtags_total = value_counts_hashtags_total.sort_values(ascending=False)

# smi1_value_counts_hashtags_total_freq_dist = tweets_text_hashtags_total.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts hashtags_total - Frequency')
# print(smi1_value_counts_hashtags_total.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Hashtags Total')
print(smi1_value_counts_hashtags_total.describe().head)
print('---')

smi1_value_counts_hashtags_total_df = pd.DataFrame(smi1_value_counts_hashtags_total, columns=['hashtags_total_frequency'])

smi1_value_counts_hashtags_total_df.to_csv('4A_4_43_100_SMI1_Value_Counts_Hashtags_Total_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_hashtags_total_df.to_excel('4A_4_43_100_SMI1_Value_Counts_Hashtags_total_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts')
plt.plot(smi1_value_counts_hashtags_total[:10], alpha=0.9)
plt.xlabel('Hashtags')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_Hashtags_Total_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))     ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Pie')
# smi1_value_counts_hashtags_total[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True, subplots=True)

smi1_value_counts_hashtags_total[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True, subplots=True, explode=explode_pie_6)

###### plt.legend(loc='best', bbox_to_anchor=(-0.1, 1.), fontsize=8)

# ax1.pie(explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90, colors=colors_blue)
plt.legend(smi1_value_counts_hashtags_total, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_hashtags_total_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Bars')
smi1_value_counts_hashtags_total[:10].plot.bar(alpha=0.9)
plt.xlabel('Hashtags')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_hashtags_total_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# List MISSING Unique Hashtags ####################################### NEED TO GET HASTAGS AND hashtags!!!!!!


hashtags_total_1 = tweets_smi_1['hashtags_total']
missing_unique_hashtags = hashtags_total_1.unique()

missing_number_unique_hashtags = len(missing_unique_hashtags)
missing_number_unique_hashtags

print('---')
print('Missing Unique Number of Hashtags')
print(missing_number_unique_hashtags)
print('---')

missing_number_unique_hashtags_df = pd.DataFrame([missing_number_unique_hashtags])

missing_number_unique_hashtags_df.to_csv('4A_4_43_190_SMI1_Missing_Number_Unique_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()


###############################################################################

# METHOD 1 emojis_unicode_TOTAL

fp_emojis_unicode_total = tweets_smi_1['emojis_unicode'].to_string()

# fp_emojis_unicode_total = fp_emojis_unicode_total_temp.to_string()

tweets_text_emojis_unicode_total = nltk.word_tokenize(fp_emojis_unicode_total)

value_counts_emojis_unicode_total = pd.value_counts(tweets_text_emojis_unicode_total, ascending=False, normalize=True) 

smi1_value_counts_emojis_unicode_total = value_counts_emojis_unicode_total.sort_values(ascending=False)

# smi1_value_counts_emojis_unicode_total_freq_dist = tweets_text_emojis_unicode_total.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts emojis_unicode_total - Frequency')
# print(smi1_value_counts_emojis_unicode_total.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Emojis Total')
print(smi1_value_counts_emojis_unicode_total.describe().head)
print('---')

smi1_value_counts_emojis_unicode_total_df = pd.DataFrame(smi1_value_counts_emojis_unicode_total, columns=['emojis_unicode_total_frequency'])

smi1_value_counts_emojis_unicode_total_df.to_csv('4A_4_43_100_SMI1_Value_Counts_Emojis_Unicode_Total_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_emojis_unicode_total_df.to_excel('4A_4_43_100_SMI1_Value_Counts_Emojis_Unicode_total_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
plt.plot(smi1_value_counts_emojis_unicode_total[:10], alpha=0.9)
plt.xlabel('Emojis_Unicode')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_Emojis_Unicode_Total_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))     ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
smi1_value_counts_emojis_unicode_total[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True, subplots=True)
# ax1.pie(explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90, colors=colors_blue)
plt.legend(smi1_value_counts_emojis_unicode_total, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_Emojis_Unicode_Total_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
smi1_value_counts_emojis_unicode_total[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis_Unicode')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_emojis_unicode_total_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# List MISSING Unique Emojis ####################################### NEED TO GET HASTAGS AND emojis_unicode!!!!!!


emojis_unicode_total_1 = tweets_smi_1['emojis_unicode']
missing_unique_emojis_unicode = emojis_unicode_total_1.unique()

missing_number_unique_emojis_unicode = len(missing_unique_emojis_unicode)
missing_number_unique_emojis_unicode

print('---')
print('Missing Unique Number of Emojis_Unicode')
print(missing_number_unique_emojis_unicode)
print('---')

missing_number_unique_emojis_unicode_df = pd.DataFrame([missing_number_unique_emojis_unicode])

missing_number_unique_emojis_unicode_df.to_csv('4A_4_43_190_SMI1_Missing_Number_Unique_Emojis_Unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Emojis_Unicode')
plt.plot(missing_number_unique_emojis_unicode_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_190_SMI1_Missing_Number_Unique_Emojis_Unicode_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Emojis - Bars')
missing_number_unique_emojis_unicode_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_190_SMI1_Missing_Number_Unique_Emojis_Unicode_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# METHOD 1 emojis_converted_TOTAL

fp_emojis_converted_total = tweets_smi_1['emojis_converted'].to_string()

# fp_emojis_converted_total = fp_emojis_converted_total_temp.to_string()

tweets_text_emojis_converted_total = nltk.word_tokenize(fp_emojis_converted_total)

value_counts_emojis_converted_total = pd.value_counts(tweets_text_emojis_converted_total, ascending=False, normalize=True) 

smi1_value_counts_emojis_converted_total = value_counts_emojis_converted_total.sort_values(ascending=False)

# smi1_value_counts_emojis_converted_total_freq_dist = tweets_text_emojis_converted_total.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts emojis_converted_total - Frequency')
# print(smi1_value_counts_emojis_converted_total.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Emojis Total')
print(smi1_value_counts_emojis_converted_total.describe().head)
print('---')

smi1_value_counts_emojis_converted_total_df = pd.DataFrame(smi1_value_counts_emojis_converted_total, columns=['emojis_converted_total_frequency'])

smi1_value_counts_emojis_converted_total_df.to_csv('4A_4_43_100_SMI1_Value_Counts_Emojis_Converted_Total_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_emojis_converted_total_df.to_excel('4A_4_43_100_SMI1_Value_Counts_Emojis_Converted_total_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
plt.plot(smi1_value_counts_emojis_converted_total[:10], alpha=0.9)
plt.xlabel('Emojis_Converted')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_Emojis_Converted_Total_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))     ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
smi1_value_counts_emojis_converted_total[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True, subplots=True)
# ax1.pie(explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90, colors=colors_blue)
plt.legend(smi1_value_counts_emojis_converted_total, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_Emojis_Converted_total_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
smi1_value_counts_emojis_converted_total[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis_Converted')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_emojis_converted_total_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# List MISSING Unique Emojis ####################################### NEED TO GET HASTAGS AND emojis_converted!!!!!!


emojis_converted_total_1 = tweets_smi_1['emojis_converted']
missing_unique_emojis_converted = emojis_converted_total_1.unique()

missing_number_unique_emojis_converted = len(missing_unique_emojis_converted)
missing_number_unique_emojis_converted

print('---')
print('Missing Unique Number of Emojis_Converted')
print(missing_number_unique_emojis_converted)
print('---')

missing_number_unique_emojis_converted_df = pd.DataFrame([missing_number_unique_emojis_converted])

missing_number_unique_emojis_converted_df.to_csv('4A_4_43_190_SMI1_Missing_Number_Unique_Emojis_Converted_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 


# Pie - NEED TO DO

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Emojis - Bars')
missing_number_unique_emojis_converted_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_190_SMI1_Missing_Number_Unique_Emojis_Converted_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# METHOD 1 text_TOTAL

fp_text_total = tweets_smi_1['text'].to_string()

# fp_text_total = fp_text_total_temp.to_string()

tweets_text_text_total = nltk.word_tokenize(fp_text_total)

value_counts_text_total = pd.value_counts(tweets_text_text_total, ascending=False, normalize=True) 

smi1_value_counts_text_total = value_counts_text_total.sort_values(ascending=False)

# smi1_value_counts_text_total_freq_dist = tweets_text_text_total.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts text_total - Frequency')
# print(smi1_value_counts_text_total.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Text Total')
print(smi1_value_counts_text_total.describe().head)
print('---')

smi1_value_counts_text_total_df = pd.DataFrame(smi1_value_counts_text_total, columns=['text_total_frequency'])

smi1_value_counts_text_total_df.to_csv('4A_4_43_100_SMI1_Value_Counts_Text_Total_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_text_total_df.to_excel('4A_4_43_100_SMI1_Value_Counts_Text_total_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Text Value Counts')
plt.plot(smi1_value_counts_text_total[:10], alpha=0.9)
plt.xlabel('Text')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_Text_Total_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))     ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Text Value Counts - Pie')
smi1_value_counts_text_total[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True, subplots=True)
# ax1.pie(explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90, colors=colors_blue)
plt.legend(smi1_value_counts_text_total, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_text_total_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Text Value Counts - Bars')
smi1_value_counts_text_total[:10].plot.bar(alpha=0.9)
plt.xlabel('Text')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_text_total_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# List MISSING Unique Text ####################################### NEED TO GET HASTAGS AND text!!!!!!


text_total_1 = tweets_smi_1['text']
missing_unique_text = text_total_1.unique()

missing_number_unique_text = len(missing_unique_text)
missing_number_unique_text

print('---')
print('Missing Unique Number of Text')
print(missing_number_unique_text)
print('---')

missing_number_unique_text_df = pd.DataFrame([missing_number_unique_text])

missing_number_unique_text_df.to_csv('4A_4_43_190_SMI1_Missing_Number_Unique_Text_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Text')
plt.plot(missing_number_unique_text_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
# splt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_190_SMI1_Missing_Number_Unique_Text_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Text - Bars')
missing_number_unique_text_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_190_SMI1_Missing_Number_Unique_Text_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# METHOD 1 language_TOTAL

fp_language_total = tweets_smi_1['language'].to_string()

# fp_language_total = fp_language_total_temp.to_string()

tweets_language_language_total = nltk.word_tokenize(fp_language_total)

value_counts_language_total = pd.value_counts(tweets_language_language_total, ascending=False, normalize=True) 

smi1_value_counts_language_total = value_counts_language_total.sort_values(ascending=False)

# smi1_value_counts_language_total_freq_dist = tweets_language_language_total.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts language_total - Frequency')
# print(smi1_value_counts_language_total.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Language Total')
print(smi1_value_counts_language_total.describe().head)
print('---')

smi1_value_counts_language_total_df = pd.DataFrame(smi1_value_counts_language_total, columns=['language_total_frequency'])

smi1_value_counts_language_total_df.to_csv('4A_4_43_100_SMI1_Value_Counts_Language_Total_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_language_total_df.to_excel('4A_4_43_100_SMI1_Value_Counts_Language_total_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Language Value Counts')
plt.plot(smi1_value_counts_language_total[:10], alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_Language_Total_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))     ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Language Value Counts - Pie')
smi1_value_counts_language_total[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True, subplots=True)
# ax1.pie(explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90, colors=colors_blue)
plt.legend(smi1_value_counts_language_total, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_language_total_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Language Value Counts - Bars')
smi1_value_counts_language_total[:10].plot.bar(alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_language_total_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# List MISSING Unique Language ####################################### NEED TO GET HASTAGS AND language!!!!!!


language_total_1 = tweets_smi_1['language']
missing_unique_language = language_total_1.unique()

missing_number_unique_language = len(missing_unique_language)
missing_number_unique_language

print('---')
print('Missing Unique Number of Language')
print(missing_number_unique_language)
print('---')

missing_number_unique_language_df = pd.DataFrame([missing_number_unique_language])

missing_number_unique_language_df.to_csv('4A_4_43_190_SMI1_Missing_Number_Unique_Language_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Language')
plt.plot(missing_number_unique_language_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
# splt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_190_SMI1_Missing_Number_Unique_Language_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Language - Bars')
missing_number_unique_language_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_190_SMI1_Missing_Number_Unique_Language_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



#################################################################################################################


# METHOD 1 geo_TOTAL

fp_geo_total = tweets_smi_1['geo'].to_string()

# fp_geo_total = fp_geo_total_temp.to_string()

tweets_geo_geo_total = nltk.word_tokenize(fp_geo_total)

value_counts_geo_total = pd.value_counts(tweets_geo_geo_total, ascending=False, normalize=True) 

smi1_value_counts_geo_total = value_counts_geo_total.sort_values(ascending=False)

# smi1_value_counts_geo_total_freq_dist = tweets_geo_geo_total.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts geo_total - Frequency')
# print(smi1_value_counts_geo_total.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Geo Total')
print(smi1_value_counts_geo_total.describe().head)
print('---')

smi1_value_counts_geo_total_df = pd.DataFrame(smi1_value_counts_geo_total, columns=['geo_total_frequency'])

smi1_value_counts_geo_total_df.to_csv('4A_4_43_100_SMI1_Value_Counts_Geo_Total_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_geo_total_df.to_excel('4A_4_43_100_SMI1_Value_Counts_Geo_total_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Geo Value Counts')
plt.plot(smi1_value_counts_geo_total[:10], alpha=0.9)
plt.xlabel('Geo')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_Geo_Total_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))     ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Geo Value Counts - Pie')
smi1_value_counts_geo_total[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True, subplots=True)
# ax1.pie(explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90, colors=colors_blue)
plt.legend(smi1_value_counts_geo_total, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_geo_total_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Geo Value Counts - Bars')
smi1_value_counts_geo_total[:10].plot.bar(alpha=0.9)
plt.xlabel('Geo')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_geo_total_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# List MISSING Unique Geo ####################################### NEED TO GET HASTAGS AND geo!!!!!!


geo_total_1 = tweets_smi_1['geo']
missing_unique_geo = geo_total_1.unique()

missing_number_unique_geo = len(missing_unique_geo)
missing_number_unique_geo

print('---')
print('Missing Unique Number of Geo')
print(missing_number_unique_geo)
print('---')

missing_number_unique_geo_df = pd.DataFrame([missing_number_unique_geo])

missing_number_unique_geo_df.to_csv('4A_4_43_190_SMI1_Missing_Number_Unique_Geo_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Geo')
plt.plot(missing_number_unique_geo_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
# splt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_190_SMI1_Missing_Number_Unique_Geo_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Geo - Bars')
missing_number_unique_geo_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_190_SMI1_Missing_Number_Unique_Geo_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# METHOD 1 screenName_TOTAL

fp_screenName_total = tweets_smi_1['screenName'].to_string()

# fp_screenName_total = fp_screenName_total_temp.to_string()

tweets_screenName_screenName_total = nltk.word_tokenize(fp_screenName_total)

value_counts_screenName_total = pd.value_counts(tweets_screenName_screenName_total, ascending=False, normalize=True) 

smi1_value_counts_screenName_total = value_counts_screenName_total.sort_values(ascending=False)

# smi1_value_counts_screenName_total_freq_dist = tweets_screenName_screenName_total.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts screenName_total - Frequency')
# print(smi1_value_counts_screenName_total.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts ScreenName Total')
print(smi1_value_counts_screenName_total.describe().head)
print('---')

smi1_value_counts_screenName_total_df = pd.DataFrame(smi1_value_counts_screenName_total, columns=['screenName_total_frequency'])

smi1_value_counts_screenName_total_df.to_csv('4A_4_43_100_SMI1_Value_Counts_ScreenName_Total_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_screenName_total_df.to_excel('4A_4_43_100_SMI1_Value_Counts_ScreenName_total_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenName Value Counts')
plt.plot(smi1_value_counts_screenName_total[:10], alpha=0.9)
plt.xlabel('ScreenName')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_ScreenName_Total_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))     ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenName Value Counts - Pie')
smi1_value_counts_screenName_total[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True, subplots=True)
# ax1.pie(explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90, colors=colors_blue)
plt.legend(smi1_value_counts_screenName_total, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_screenName_total_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenName Value Counts - Bars')
smi1_value_counts_screenName_total[:10].plot.bar(alpha=0.9)
plt.xlabel('ScreenName')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4A_4_43_100_SMI1_Top_screenName_total_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# List MISSING Unique ScreenName ####################################### NEED TO GET HASTAGS AND screenName!!!!!!

### XXX TEMP 

screenName_total_1 = tweets_smi_1['screenName']
missing_unique_screenName = screenName_total_1.unique()

missing_number_unique_screenName = len(missing_unique_screenName)
missing_number_unique_screenName

print('---')
print('Missing Unique Number of ScreenName')
print(missing_number_unique_screenName)
print('---')

missing_number_unique_screenName_df = pd.DataFrame([missing_number_unique_screenName])

missing_number_unique_screenName_df.to_csv('4A_4_43_190_SMI1_Missing_Number_Unique_ScreenName_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique ScreenName')
plt.plot(missing_number_unique_screenName_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
# splt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_190_SMI1_Missing_Number_Unique_ScreenName_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique ScreenName - Bars')
missing_number_unique_screenName_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4A_4_43_190_SMI1_Missing_Number_Unique_ScreenName_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###############################################################################################################

# METHOD 1 screenName

fp_screenName = tweets_smi_1['screenName'].to_string()

tweets_text_screenName = nltk.word_tokenize(fp_screenName)

value_counts_screenName = pd.value_counts(tweets_text_screenName, ascending=False, normalize=True) 

smi1_value_counts_screenName = value_counts_screenName.sort_values(ascending=False)

# smi1_value_counts_screenName_freq_dist = tweets_text_screenName.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts screenName - Frequency')
# print(smi1_value_counts_screenName.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts screenName')
# print(smi1_value_counts_screenName.describe().head)
print('---')

smi1_value_counts_screenName_df = pd.DataFrame(smi1_value_counts_screenName, columns=['screenName_frequency'])

smi1_value_counts_screenName_df.to_csv('4_4C_43_100_SMI1_Value_Counts_screenName_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_screenName_df.to_excel('4_4C_43_100_SMI1_Value_Counts_screenName_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenName Value Counts')
plt.ioff()
plt.plot(smi1_value_counts_screenName[:10], alpha=0.9)
plt.xlabel('ScreenName')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4C_43_100_SMI1_Top_ScreenName_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top screenName Value Counts - Pie')
plt.ioff()
smi1_value_counts_screenName[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True, explode = explode_pie_6)
# ax1.pie(explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90, colors=colors_blue)
plt.legend(smi1_value_counts_screenName, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4C_43_100_SMI1_Top_ScreenName_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top screenName Value Counts - Bars')
plt.ioff()
smi1_value_counts_screenName[:10].plot.bar(alpha=0.9)
plt.xlabel('screenName')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4C_43_100_SMI1_Top_screenName_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#######################################################

###############################################################################################################

# METHOD 1 geo

fp_geo = tweets_smi_1['geo'].to_string()

tweets_text_geo = nltk.word_tokenize(fp_geo)

value_counts_geo = pd.value_counts(tweets_text_geo, ascending=False, normalize=True) 

smi1_value_counts_geo = value_counts_geo.sort_values(ascending=False)

# smi1_value_counts_geo_freq_dist = tweets_text_geo.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts geo - Frequency')
# print(smi1_value_counts_geo.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts geo')
# print(smi1_value_counts_geo.describe().head)
print('---')

smi1_value_counts_geo_df = pd.DataFrame(smi1_value_counts_geo, columns=['geo_frequency'])

smi1_value_counts_geo_df.to_csv('4_4C_43_100_SMI1_Value_Counts_geo_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_geo_df.to_excel('4_4C_43_100_SMI1_Value_Counts_geo_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Geo Value Counts')
plt.ioff()
plt.plot(smi1_value_counts_geo[:10], alpha=0.9)
plt.xlabel('Geo')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4C_43_100_SMI1_Top_Geo_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top geo Value Counts - Pie')
plt.ioff()
smi1_value_counts_geo[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True, explode = explode_pie_6)
# ax1.pie(explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90, colors=colors_blue)
plt.legend(smi1_value_counts_geo, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4C_43_100_SMI1_Top_geo_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top geo Value Counts - Bars')
plt.ioff()
smi1_value_counts_geo[:10].plot.bar(alpha=0.9)
plt.xlabel('geo')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4C_43_100_SMI1_Top_geo_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



#######################################################

#######################################################

# METHOD 1 LANGUAGES

fp_language = tweets_smi_1['language'].to_string()

# fp_language = fp_language_temp.to_string()

tweets_text_language = nltk.word_tokenize(fp_language)

value_counts_language = pd.value_counts(tweets_text_language, ascending=False, normalize=True) 

smi1_value_counts_language = value_counts_language.sort_values(ascending=False)

# smi1_value_counts_language_freq_dist = tweets_text_language.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Language - Frequency')
print(smi1_value_counts_language.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts language')
print(smi1_value_counts_language.describe().head)
print('---')

smi1_value_counts_language_df = pd.DataFrame(smi1_value_counts_language, columns=['language_frequency'])

smi1_value_counts_language_df.to_csv('4_4C_43_100_SMI1_Value_Counts_Language_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_language_df.to_excel('4_4C_43_100_SMI1_Value_Counts_Language_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Languages Value Counts')
plt.plot(smi1_value_counts_language[:10], alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4C_43_100_SMI1_Top_Language_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Languages Value Counts - Pie')
smi1_value_counts_language[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.7, radius=1.0, rotatelabels=False)
# ax1.pie(explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90, colors=colors_blue)
plt.legend(smi1_value_counts_language, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# s# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4C_43_100_SMI1_Top_Language_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Languages Value Counts - Bars')
smi1_value_counts_language[:10].plot.bar(alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4C_43_100_SMI1_Top_Language_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# List Unique Language

unique_languages = tweets_smi_1['language'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_languages = len(unique_languages)
number_unique_languages

print('---')
print('Number Unique Languages')
print(number_unique_languages)
print('---')

number_unique_languages_df = pd.DataFrame([number_unique_languages], columns =['number_unique_languages'])

number_unique_languages_df.to_csv('4_4C_43_194_SMI1_Number_Unique_Languages_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()


## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Languages')
plt.plot(number_unique_languages_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4C_43_194_SMI1_Number_Unique_Languages_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Languages Value Counts - Bars')
number_unique_languages_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4C_43_194_SMI1_Number_Unique_Languages_DF_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')

###############################################################################################################
###############################################################################################################

## NEED TO DO Emojis_Unicode STAS!!!!!!!!!!!!!!

##############################################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Value Counts All Emojis Unicode   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].encode('unicode-escape')

value_counts_emojis_unicode = pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True)

smi1_value_counts_emojis_unicode = value_counts_emojis_unicode.sort_values(ascending=False)

print('---')
print('value_counts_emojis_unicode')
# print(value_counts_emojis_unicode.head)
print('---')

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Emojis Unicode 1A')
# print(smi1_value_counts_emojis_unicode.describe().head)
print('---')

smi1_value_counts_emojis_unicode_df = pd.DataFrame(value_counts_emojis_unicode, columns =['emojis_unicode'])

smi1_value_counts_emojis_unicode_df.to_csv('4_4_111_SMI1_Emojis_Unicode_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_emojis_unicode_df.to_excel('4_4_111_SMI1_Emojis_Unicode_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
plt.ioff()
# smi1_value_counts_emojis_unicode.plot(6,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_emojis_unicode[:6].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend()
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_111_SMI1_Top_Emojis_Unicode_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,5))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
plt.ioff()
# plt.pie(smi1_value_counts_emojis_unicode[:6], labels=smi1_tweets_text_words_fdist['emojis_unicode'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
smi1_value_counts_emojis_unicode[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, explode = explode_pie_6)
plt.legend(tweets_smi_1['emojis_unicode'], bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_111_SMI1_Top_Emojis_Unicode_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



############################################################################################################

## NEED TO DO Emojis Converted STAS!!!!!!!!!!!!!!

############################################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Value Counts All Emojis Converted  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_emojis_converted = pd.value_counts(tweets_smi_1['emojis_converted'], ascending=False, normalize=True)

smi1_value_counts_emojis_converted = value_counts_emojis_converted.sort_values(ascending=False)

print('---')
print('value_counts_emojis_converted')
# print(value_counts_emojis_converted.head)
print('---')

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Emojis 1A')
print(smi1_value_counts_emojis_converted.describe().head)
print('---')

smi1_value_counts_emojis_converted_df = pd.DataFrame(value_counts_emojis_converted, columns =['emojis_converted'])

smi1_value_counts_emojis_converted_df.to_csv('4_4_111_SMI1_Emojis_Converted_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_emojis_converted_df.to_excel('4_4_111_SMI1_Emojis_Converted_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 



# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
plt.ioff()
# plt.pie(smi1_value_counts_emojis_converted[:6], labels=smi1_tweets_text_words_fdist['emojis_converted'], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_emojis_converted[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, explode = explode_pie_6)
# plt.legend(smi1_value_counts_emojis_converted[:6], bbox_to_anchor=(1.1, 1,1), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_111_SMI1_Top_Emojis_Converted_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
plt.ioff()
# smi1_value_counts_emojis_converted[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
sns.barplot(smi1_value_counts_emojis_converted, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_111SB_SMI1_Top_Emojis_Converted_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Emojis Converted FREQ DISTRIBUTION

smi1_emojis_converted = tweets_smi_1['emojis_converted']

# Calculate frequency distribution
smi1_emojis_converted_fdist = nltk.FreqDist(smi1_emojis_converted)

# Output top 50 tweets_words

# for smi1_emojis_converted, frequency in smi1_emojis_converted_fdist.most_common(10):
#    print(u'{};{}'.format(smi1_emojis_converted, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_emojis_converted_fdist_df = pd.DataFrame(smi1_emojis_converted_fdist)

smi1_emojis_converted_fdist_df = pd.DataFrame([smi1_emojis_converted_fdist])

print('---')
print('Frequency Distribution of Emojis Converted 1B')
# print(smi1_emojis_converted_fdist_df.head)
print('---')

smi1_emojis_converted_fdist_df.to_csv('4_4_112_SMI1_Emojis_Converted_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_emojis_converted_fdist_df.to_excel('4_4_112_SMI1_Emojis_Converted_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

##################################################################################

# METHOD 1 HASHTAGS

# fp_hashtags = tweets_smi_1['hashtags'].to_string()
# fp_hashtags = tweets_smi_1['hashtags'].astype(str, errors='ignore')

fp_hashtags = str(tweets_smi_1['hashtags'])

# fp_hashtags = fp_hashtags_temp.to_string()


tweets_text_hashtags = nltk.word_tokenize(fp_hashtags)

total_number_hashtags = len(tweets_text_hashtags)
smi1_total_number_hashtags_df = pd.DataFrame([total_number_hashtags], columns=['total_number_hashtags'])

print('smi1_total_number_hashtags_df dtypes')
print(smi1_total_number_hashtags_df.dtypes)
print('---')

print('smi1_total_number_hashtags_df HEAD')
print(smi1_total_number_hashtags_df.head)
print('---')

smi1_total_number_hashtags_df.to_csv('4_4_50_100_SMI1_Total_Number_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_total_number_hashtags_df.to_excel('4_4_43_100_SMI1_Total_Number_Hashtags_DF.xlsx', header=True)

smi1_value_counts_hashtags_df = pd.value_counts(tweets_text_hashtags, ascending=False, normalize=True).to_frame()

# smi1_value_counts_hashtags_df[['item','count']] = smi1_value_counts_hashtags_df.astype(str).split(" ", expand=True)

# smi1_value_counts_hashtags_df = pd.DataFrame(smi1_value_counts_hashtags_df.str.split(' ',1).tolist(), columns = ['item','count'])

# smi1_value_counts_hashtags_freq_dist = tweets_text_hashtags.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Hashtags - Frequency HEAD')
print(smi1_value_counts_hashtags_df.head)
print('----')

print('----')
print('Value Counts Hashtags - Frequency DTYPES')
print(smi1_value_counts_hashtags_df.dtypes)
print('----')

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Hashtags OJO REVISAR!!!!! NEED TO FIX NEED TO DO')
print('Summary Statistics - All Value Counts hashtags')
print(smi1_value_counts_hashtags_df.describe().head)
print('---')

# smi1_value_counts_hashtags = str(smi1_value_counts_hashtags)

print('---')


### OJO PUSE HASHTAS POQ NO SE COMO ARREGLAR DF CONSTRUCTOR INPROPERLY CALLED !!!

smi1_value_counts_hashtags_df = pd.DataFrame(tweets_text_hashtags) 

smi1_value_counts_hashtags_df.to_csv('4_4_43_100_SMI1_Value_Counts_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_hashtags_df.to_excel('4_4_43_100_SMI1_Value_Counts_Hashtags_DF.xlsx', index=True, header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT # XXX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts')
tweets_smi_1['hashtags'][:10].value_counts(ascending=False).plot(alpha=0.9)
plt.xlabel('Hashtags')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
# plt.savefig('4_4_43_100AA_SMI1_Top_Hashtags_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()




# Bars - NEED TO DO # XXX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Bars')
# smi1_value_counts_hashtags_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Hashtags')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
# plt.savefig('4_4_43_100_SMI1_Top_Hashtags_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################

# https://towardsdatascience.com/data-science-with-python-intro-to-loading-and-subsetting-data-with-pandas-9f26895ddd7f

#### TWEETS WITH NO hashtags NOT UNIQUE

# SUBSETS

# Number of Tweets With hashtags  ########### NEED TO FIX

print('---')
print('Tweets With hashtags Info -- SERIES VALUE')
print(tweets_smi_1['hashtags'].head)
print('---')

tweets_with_hashtags_count = tweets_smi_1['hashtags'].count()

print('---')
print('Tweets With hashtags Count')
# print(tweets_with_hashtags_count)
print('---')


tweets_without_hashtags_filter = tweets_smi_1[tweets_smi_1.hashtags == 0]

# tweets_without_hashtags_filter = pd.DataFrame(tweets_without_hashtags_filter)

number_tweets_without_hashtags_filter = len(tweets_without_hashtags_filter)
number_tweets_without_hashtags_filter

print('---')
print('Number of Tweets Without Hashtags - FILTER')
# print(number_tweets_without_hashtags_filter)
print('---')


percentage_tweets_without_hashtags_filter = ((number_tweets_without_hashtags_filter * 100)/number_total_tweets)
percentage_tweets_without_hashtags_filter

print('---')
print('Percentage of Tweets Without Hashtags - Filter')
# print(percentage_tweets_without_hashtags_filter)
print('---')

number_tweets_with_hashtags_not_unique = number_total_tweets - number_tweets_without_hashtags_filter
number_tweets_with_hashtags_not_unique

print('---')
print('Number of Tweets With hashtags')
# print(number_tweets_with_hashtags_not_unique)
print('---')

percentage_tweets_with_hashtags_not_unique = ((number_tweets_with_hashtags_not_unique * 100)/number_total_tweets)
percentage_tweets_with_hashtags_not_unique

print('---')
print('Percentage of Tweets Without hashtags')
# print(percentage_tweets_with_hashtags_not_unique)
print('---')

number_tweets_no_hashtags = number_total_tweets - number_tweets_with_hashtags_not_unique

print('---')
print('Number of Tweets Without hashtags')
# print(number_tweets_no_hashtags)
print('---')

percentage_tweets_no_hashtags = 100 - percentage_tweets_with_hashtags_not_unique

print('---')
print('Percentage of Tweets Without hashtags')
# print(percentage_tweets_no_hashtags)
print('---')



##############

# Inicialize List of Lists TWEETS WITH hashtags NOT UNIQUES hashtags

tweet_info_hashtags_not_unique = [['Tweets With Hashtags', number_tweets_with_hashtags_not_unique, percentage_tweets_with_hashtags_not_unique], ['Tweets Without Hashtags', number_tweets_without_hashtags_filter, percentage_tweets_without_hashtags_filter]]

# Create DataFrame

tweet_info_hashtags_not_unique_df = pd.DataFrame(tweet_info_hashtags_not_unique, columns =['tweet_info_hashtags_not_unique', 'number_tweet_info_hashtags_not_unique', 'percentage_tweet_info_hashtags_not_unique'])

print('---')
print('Tweet Info hashtags NOT UNIQUE Information')
# print(tweet_info_hashtags_not_unique_df)
print('---')

tweet_info_hashtags_not_unique_df.to_csv('4_4_43_38_SMI1_Tweet_info_Hashtags_Not_Unique_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_hashtags_not_unique_df.to_excel('4_4_43_38_SMI1_Tweet_info_Hashtags_Not_Unique_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets With Hashtags Not Unique - Pie')
# plt.pie(tweet_info_hashtags_df['number_tweet_info_hashtags'], labels=tweet_info_hashtags_df['tweet_info_hashtags'])
plt.pie(tweet_info_hashtags_not_unique_df['number_tweet_info_hashtags_not_unique'], labels=tweet_info_hashtags_not_unique_df['tweet_info_hashtags_not_unique'], colors=colors_blue, startangle=80, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweet_info_hashtags_not_unique_df['tweet_info_hashtags_not_unique'], bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_38_SMI1_Tweet_Info_Hashtags_Not_Unique_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Counts Not Unique - Bars')
tweet_info_hashtags_not_unique_df['number_tweet_info_hashtags_not_unique'].plot.bar(x=tweet_info_hashtags_not_unique_df['tweet_info_hashtags_not_unique'], alpha=0.9, subplots=True)
# ax.bar(tweet_info_hashtags_not_unique_df['tweet_info_hashtags_not_unique'], tweet_info_hashtags_not_unique_df['number_tweet_info_hashtags_not_unique'], alpha=0.9)
plt.xticks(rotation=50)
plt.xlabel('Tweets With Hashtags, Tweets With NO Hashtags')
plt.ylabel('Count')
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_38_SMI1_Tweet_Info_Hashtags_Not_Unique_df_Counts_Bars_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# List Unique Hashtags ####################################### NEED TO GET HASTAGS AND hashtags!!!!!!


unique_hashtags = tweets_smi_1['hashtags'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_hashtags = len(unique_hashtags)
number_unique_hashtags

print('---')
print('List Unique Hashtags')
print(number_unique_hashtags)
print('---')

number_unique_hashtags_df = pd.DataFrame([number_unique_hashtags])

number_unique_hashtags_df.to_csv('4_4_43_SMI1_Number_Unique_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# number_unique_hashtags_df.to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Hashtags')
# plt.plot(number_unique_hashtags_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Unique_Hashtags_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Hashtags - Pie')
# plt.pie(tweet_info_friends_df['number_unique_hashtags_df'], labels=number_unique_hashtags_df)
# plt.pie(number_unique_hashtags_df, labels=number_unique_hashtags_df, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=number_unique_hashtags_df, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Unique_Hashtags_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Hashtags - Bars')
number_unique_hashtags_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Unique_Hashtags_DF_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################################################################################
###############################################################################################################
###

# METHOD 1 MENTIONS

# fp_mentions_1 = tweets_smi_1['mentions'].to_string()
# fp_mentions_1 = tweets_smi_1['mentions'].astype(str, errors='ignore')

fp_mentions_1 = str(tweets_smi_1['mentions'])

# fp_mentions_1 = fp_mentions_temp.to_string()

print('fp_mentions_1 dtypes 0')
# print(fp_mentions_1.dtypes)
print('---')


tweets_text_mentions_1 = nltk.word_tokenize(fp_mentions_1)

total_number_mentions_1 = len(tweets_text_mentions_1)
smi1_total_number_mentions_1_df = pd.DataFrame([total_number_mentions_1], columns=['total_number_mentions_1'])

smi1_total_number_mentions_1_df.to_csv('4_4_43_100_SMI1_Total_Number_Mentions_1_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_total_number_mentions_1_df.to_excel('4_4_43_100_SMI1_Total_Number_Mentions_1_DF.xlsx', header=True)

# value_counts_mentions_1 = pd.value_counts(tweets_text_mentions_1) 

smi1_value_counts_mentions_1_df = pd.value_counts(tweets_smi_1['mentions'], ascending=False, normalize=True).to_frame() 
# smi1_value_counts_mentions_1_df[['item','count']] = pd.DataFrame(smi1_value_counts_mentions_1_df.str.split(' ',1).tolist(), columns = ['item','count'])

print('----')
print('Value Counts Mentions_1 - Frequency')
print(smi1_value_counts_mentions_1_df.head)
print('----')

print('----')
print('Value Counts Mentions_1 - Frequency DTYPES')
print(smi1_value_counts_mentions_1_df.dtypes)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Mentions_1')
# print(smi1_value_counts_mentions_1_df.describe().head)
print('---')

# smi1_value_counts_mentions_1 = str(smi1_value_counts_mentions_1)


smi1_value_counts_mentions_1_df.to_csv('4_4_43_100_SMI1_Value_Counts_Mentions_1_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_mentions_1_df.to_excel('4_4_43_100_SMI1_Value_Counts_Mentions_1_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT # XXX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts')
# plt.plot(smi1_value_counts_mentions_1_df[:10], alpha=0.9)
plt.xlabel('Mentions')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
# plt.savefig('4_4_43_100_SMI1_Top_Mentions_1_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



# Bars - NEED TO DO # XXX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Bars')
# smi1_value_counts_mentions_1_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Mentions')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
# plt.savefig('4_4_43_100_SMI1_Top_Mentions_Value_Counts_1_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# https://towardsdatascience.com/data-science-with-python-intro-to-loading-and-subsetting-data-with-pandas-9f26895ddd7f

#### TWEETS WITH NO Mentions NOT UNIQUE

# SUBSETS

# Number of Tweets With Mentions  ########### NEED TO FIX

print('---')
print('Tweets With Mentions Info -- SERIES VALUE')
print(tweets_smi_1['mentions'].head)
print('---')

tweets_with_mentions_count = tweets_smi_1['mentions'].count()

print('---')
print('Tweets With Mentions Count')
# print(tweets_with_mentions_count.head)
print('---')


tweets_without_mentions_filter = tweets_smi_1[tweets_smi_1.mentions == 0]

# tweets_without_mentions_filter = pd.DataFrame(tweets_without_mentions_filter)

number_tweets_without_mentions_filter = len(tweets_without_mentions_filter)
number_tweets_without_mentions_filter

print('---')
print('Number of Tweets Without Mentions - FILTER')
print(number_tweets_without_mentions_filter)
print('---')


percentage_tweets_without_mentions_filter = ((number_tweets_without_mentions_filter * 100)/number_total_tweets)
percentage_tweets_without_mentions_filter

print('---')
print('Percentage of Tweets Without Mentions - Filter')
print(percentage_tweets_without_mentions_filter)
print('---')

number_tweets_with_mentions_not_unique = number_total_tweets - number_tweets_without_mentions_filter
number_tweets_with_mentions_not_unique

print('---')
print('Number of Tweets With Mentions not Unique')
print(number_tweets_with_mentions_not_unique)
print('---')

percentage_tweets_with_mentions_not_unique = ((number_tweets_with_mentions_not_unique * 100)/number_total_tweets)
percentage_tweets_with_mentions_not_unique

print('---')
print('Percentage of Tweets With Mentions')
print(percentage_tweets_with_mentions_not_unique)
print('---')

number_tweets_no_mentions = number_total_tweets - number_tweets_with_mentions_not_unique

print('---')
print('Number of Tweets Without Mentions')
print(number_tweets_no_mentions)
print('---')

percentage_tweets_no_mentions = 100 - percentage_tweets_with_mentions_not_unique

print('---')
print('Percentage of Tweets Without Mentions')
print(percentage_tweets_no_mentions)
print('---')

##############

# Inicialize List of Lists TWEETS WITH Mentions NOT UNIQUE Mentions

tweet_info_mentions_not_unique = [['Tweets With Mentions', number_tweets_with_mentions_not_unique, percentage_tweets_with_mentions_not_unique], ['Tweets Without Mentions', number_tweets_without_mentions_filter, percentage_tweets_without_mentions_filter]]

# Create DataFrame

tweet_info_mentions_not_unique_df = pd.DataFrame(tweet_info_mentions_not_unique, columns =['tweet_info_mentions_not_unique', 'number_tweet_info_mentions_not_unique', 'percentage_tweet_info_mentions_not_unique'])

print('---')
print('Tweet Info Mentions NOT UNIQUE Information')
# print(tweet_info_mentions_not_unique_df)
print('---')

tweet_info_mentions_not_unique_df.to_csv('4_4_43_38_SMI1_Tweet_Info_Mentions_Not_Unique_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_mentions_not_unique_df.to_excel('4_4_43_38_SMI1_Tweet_Info_Mentions_Not_Unique_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets With Mentions Not Unique - Pie')
# plt.pie(tweet_info_mentions_df['number_tweet_info_mentions'], labels=tweet_info_mentions_df['tweet_info_mentions'])
plt.pie(tweet_info_mentions_not_unique_df['number_tweet_info_mentions_not_unique'], labels=tweet_info_mentions_not_unique_df['tweet_info_mentions_not_unique'], colors=colors_blue, startangle=80, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(labels=tweet_info_mentions_not_unique_df['tweet_info_mentions_not_unique'], bbox_to_anchor=(1.8, 1.6), loc='upper right')
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_38_SMI1_Tweet_Info_Mentions_Not_Unique_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Counts Not Unique - Bars')
tweet_info_mentions_not_unique_df['number_tweet_info_mentions_not_unique'].plot.bar(alpha=0.9)
# ax.bar(tweet_info_mentions_not_unique_df['tweet_info_mentions_not_unique'], tweet_info_mentions_not_unique_df['number_tweet_info_mentions_not_unique'])
plt.xticks(rotation=50)
plt.xlabel('Tweets With Mentions, Tweets With NO Mentions')
plt.ylabel('Count')
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_38_SMI1_Tweet_Info_Mentions_Not_Unique_df_Counts_Bars_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# List Unique Mentions ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!


unique_mentions = tweets_smi_1['mentions'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_mentions = len(unique_mentions)
number_unique_mentions


print('---')
print('Number Unique Mentions')
print(number_unique_mentions)
print('---')

number_unique_mentions_df = pd.DataFrame([number_unique_mentions])

number_unique_mentions_df.to_csv('4_4_43_189_SMI1_Number_Unique_Mentions_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 



# Pie - NEED TO DO

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Mentions - Bars')
number_unique_mentions_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_189_SMI1_Number_Unique_Mentions_DF_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###############################################################################################################

# List Unique Emojis Converted

unique_emojis_converted = tweets_smi_1['emojis_converted'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_emojis_converted = len(unique_emojis_converted)
number_unique_emojis_converted

print('---')
print('Number Unique Emojis Converted')
print(number_unique_emojis_converted)
print('---')

number_unique_emojis_converted_df = pd.DataFrame([number_unique_emojis_converted])

number_unique_emojis_converted_df.to_csv('4_4_43_193_SMI1_Number_Unique_Emojis_Converted_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Emojis Graphics')
plt.plot(number_unique_emojis_converted_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_193_SMI1_Number_Unique_EMOJIS_Converted_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Emojis Graphics - Bars')
number_unique_emojis_converted_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_193_SMI1_Number_Unique_EMOJIS_Converted_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



###################################################################################################
###################################################################################################
#############################################################################################################
############################################################################

print('---')
print('Loading Libs 13')
print('---')

print('---')
print('SMI 1 DTYPES 13')
print(tweets_smi_1.dtypes)
print('---')

print('---')
print('SMI 1 HEAD 13')
print(tweets_smi_1.head)
print('---')


print('---')
print('SMI 1 TEXT HEAD 13')
print(tweets_smi_1['text'].head)
print('---')


print('SELECTED SMIS TWEET MENTIONS AND AUTHORS')

# Tweets About SMI


# tweets_text = tweets_smi_1['text'].to_string()

tweets_about_jamescharles = re.findall('jamescharles', tweets_text, flags=re.IGNORECASE)

print('--')
print('Tweets About JamesCharles - Head 10 -- NEED TO DO THE WHOLE STRING!!!')
# print(tweets_about_jamescharles)
print('--')

tweets_about_jeffreestar = re.findall('jeffreestar', tweets_text, flags=re.IGNORECASE)
tweets_about_mannymua733 = re.findall('mannymua733', tweets_text, flags=re.IGNORECASE)
tweets_about_michellephan = re.findall('michellephan', tweets_text, flags=re.IGNORECASE)
tweets_about_nikkietutorials = re.findall('nikkietutorials', tweets_text, flags=re.IGNORECASE)
tweets_about_zoella = re.findall('zoella', tweets_text, flags=re.IGNORECASE)

number_tweets_about_jamescharles = len(tweets_about_jamescharles)
number_tweets_about_jeffreestar = len(tweets_about_jeffreestar)
number_tweets_about_mannymua733 = len(tweets_about_mannymua733)
number_tweets_about_michellephan = len(tweets_about_michellephan)
number_tweets_about_nikkietutorials = len(tweets_about_nikkietutorials)
number_tweets_about_zoella = len(tweets_about_zoella)


print('---')
print('Number of Tweets About JamesCharles')
print(number_tweets_about_jamescharles)
print('---')

percentage_tweets_about_jamescharles = ((number_tweets_about_jamescharles * 100)/number_total_tweets)
percentage_tweets_about_jamescharles

print('---')
print('Percentage of Tweets About JamesCharles')
print(percentage_tweets_about_jamescharles)
print('---')

print('---')
print('Number of Tweets About JeffreeStar')
print(number_tweets_about_jeffreestar)
print('---')

percentage_tweets_about_jeffreestar = ((number_tweets_about_jeffreestar * 100)/number_total_tweets)
percentage_tweets_about_jeffreestar

print('---')
print('Percentage of Tweets About JeffreeStar')
print(percentage_tweets_about_jeffreestar)
print('---')

print('---')
print('Number of Tweets About mannymua733')
print(number_tweets_about_mannymua733)
print('---')

percentage_tweets_about_mannymua733 = ((number_tweets_about_mannymua733 * 100)/number_total_tweets)
percentage_tweets_about_mannymua733

print('---')
print('Percentage of Tweets About mannymua733')
print(percentage_tweets_about_mannymua733)
print('---')

print('---')
print('Number of Tweets About MichellePhan')
print(number_tweets_about_michellephan)
print('---')

percentage_tweets_about_michellephan = ((number_tweets_about_michellephan * 100)/number_total_tweets)
percentage_tweets_about_michellephan

print('---')
print('Percentage of Tweets About MichellePhan')
print(percentage_tweets_about_michellephan)
print('---')

print('---')
print('Number of Tweets About NikkieTutorials')
print(number_tweets_about_nikkietutorials)
print('---')

percentage_tweets_about_nikkietutorials = ((number_tweets_about_nikkietutorials * 100)/number_total_tweets)
percentage_tweets_about_nikkietutorials

print('---')
print('Percentage of Tweets About NikkieTutorials')
print(percentage_tweets_about_nikkietutorials)
print('---')

print('---')
print('Number of Tweets About zoella')
print(number_tweets_about_zoella)
print('---')

percentage_tweets_about_zoella = ((number_tweets_about_zoella * 100)/number_total_tweets)
percentage_tweets_about_zoella

print('---')
print('Percentage of Tweets About zoella')
print(percentage_tweets_about_zoella)
print('---')

number_tweets_about_other = (number_total_tweets - (number_tweets_about_jamescharles + number_tweets_about_jeffreestar + number_tweets_about_mannymua733 + number_tweets_about_michellephan + number_tweets_about_nikkietutorials + number_tweets_about_zoella))
number_tweets_about_other

print('---')
print('Number of Tweets About Other')
print(number_tweets_about_other)
print('---')

percentage_tweets_about_other = ((number_tweets_about_other * 100)/number_total_tweets)
percentage_tweets_about_other

print('---')
print('Percentage of Tweets About Other Topic')
print(percentage_tweets_about_other)
print('---')


# Inicialize List of Lists

tweets_about_percentages = [['jamescharles', number_tweets_about_jamescharles, percentage_tweets_about_jamescharles], ['jeffreestar', number_tweets_about_jeffreestar, percentage_tweets_about_jeffreestar], ['mannymua733', number_tweets_about_mannymua733, percentage_tweets_about_mannymua733], ['michellephan', number_tweets_about_michellephan, percentage_tweets_about_michellephan], ['nikkietutorials', number_tweets_about_nikkietutorials, percentage_tweets_about_nikkietutorials], ['zoella', number_tweets_about_zoella, percentage_tweets_about_zoella], ['tweets_other_topic', number_tweets_about_other, percentage_tweets_about_other]]

# Create DataFrame

tweets_about_percentages_df = pd.DataFrame(tweets_about_percentages, columns =['tweets_about_smi_item', 'tweets_about_smi_number', 'tweets_about_smi_percentage'])

tweets_about_percentages_df.to_csv('4_4_64_SMI1_Tweets_About_Percentages_DF_CSV.csv', )
# tweets_about_percentages_df.to_excel('4_4_64_SMI1_Tweets_About_Percentages_DF.xlsx', header=True)


print('---')
print('Tweets About and Values')
# print(tweets_about_percentages_df.head)
print(tweets_about_percentages_df.dtypes)
print('---')

# tweets_about_percentages_df['tweets_about_smi_number'] = np.arange(tweets_about_percentages_df['tweets_about_smi_number']) ## NEED TO DO FIX

# TABLE PLOT NEED TO DO

# PLOT NEED TO DO 

# Pie ## NEED TO DO - FIX FORMATTING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets About an SMI - Pie')
plt.ioff()
plt.pie(tweets_about_percentages_df['tweets_about_smi_number'], labels=tweets_about_percentages_df['tweets_about_smi_item'], colors=colors_blue, startangle=70, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.6, radius=1.0, rotatelabels=True)
# plt.xlabel('Tweets About an SMI')
# plt.ylabel('Count')
plt.legend(labels=tweets_about_percentages_df['tweets_about_smi_item'], bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_4_64_SMI1_Tweets_About_SMI_Pie_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets About an SMI - Bars')
plt.ioff()
tweets_about_percentages_df['tweets_about_smi_number'].plot.bar(alpha=0.9)
ax.bar(tweets_about_percentages_df['tweets_about_smi_item'], tweets_about_percentages_df['tweets_about_smi_number'])
plt.xlabel('JamesCharles, JeffreeStar, MannyMua733, MichellePhan, NikkieTutorials, Zoella, Other Topics')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_64_SMI1_Tweets_About_SMI_Tweets_Bars_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

############################################################################

# Tweets Per SMI

tweets_authors = tweets_smi_1['screenName'].to_string()

tweets_by_jamescharles = re.findall('jamescharles', tweets_authors, flags=re.IGNORECASE)

print('--')
print('Tweets by JamesCharles - Head 10 -- NEED TO DO THE WHOLE STRING!!!')
# print(tweets_by_jamescharles)
print('--')

tweets_by_jeffreestar = re.findall('jeffreestar', tweets_authors, flags=re.IGNORECASE)
tweets_by_mannymua733 = re.findall('mannymua733', tweets_authors, flags=re.IGNORECASE)
tweets_by_michellephan = re.findall('michellephan', tweets_authors, flags=re.IGNORECASE)
tweets_by_nikkietutorials = re.findall('nikkietutorials', tweets_authors, flags=re.IGNORECASE)
tweets_by_zoella = re.findall('zoella', tweets_authors, flags=re.IGNORECASE)

number_tweets_by_jamescharles = len(tweets_by_jamescharles)
number_tweets_by_jeffreestar = len(tweets_by_jeffreestar)
number_tweets_by_mannymua733 = len(tweets_by_mannymua733)
number_tweets_by_michellephan = len(tweets_by_michellephan)
number_tweets_by_nikkietutorials = len(tweets_by_nikkietutorials)
number_tweets_by_zoella = len(tweets_by_zoella)


print('---')
print('Number of Tweets by JamesCharles')
print(number_tweets_by_jamescharles)
print('---')

percentage_tweets_by_jamescharles = ((number_tweets_by_jamescharles * 100)/number_total_tweets)
percentage_tweets_by_jamescharles

print('---')
print('Percentage of Tweets by JamesCharles')
print(percentage_tweets_by_jamescharles)
print('---')


print('---')
print('Number of Tweets by JeffreeStar')
print(number_tweets_by_jeffreestar)
print('---')

percentage_tweets_by_jeffreestar = ((number_tweets_by_jeffreestar * 100)/number_total_tweets)
percentage_tweets_by_jeffreestar

print('---')
print('Percentage of Tweets by JeffreeStar')
print(percentage_tweets_by_jeffreestar)
print('---')

print('---')
print('Number of Tweets by mannymua733')
print(number_tweets_by_mannymua733)
print('---')

percentage_tweets_by_mannymua733 = ((number_tweets_by_mannymua733 * 100)/number_total_tweets)
percentage_tweets_by_mannymua733

print('---')
print('Percentage of Tweets by mannymua733')
print(percentage_tweets_by_mannymua733)
print('---')

print('---')
print('Number of Tweets by MichellePhan')
print(number_tweets_by_michellephan)
print('---')

percentage_tweets_by_michellephan = ((number_tweets_by_michellephan * 100)/number_total_tweets)
percentage_tweets_by_michellephan

print('---')
print('Percentage of Tweets by MichellePhan')
print(percentage_tweets_by_michellephan)
print('---')

print('---')
print('Number of Tweets by NikkieTutorials')
print(number_tweets_by_nikkietutorials)
print('---')

percentage_tweets_by_nikkietutorials = ((number_tweets_by_nikkietutorials * 100)/number_total_tweets)
percentage_tweets_by_nikkietutorials

print('---')
print('Percentage of Tweets by NikkieTutorials')
print(percentage_tweets_by_nikkietutorials)
print('---')

print('---')
print('Number of Tweets by zoella')
print(number_tweets_by_zoella)
print('---')

percentage_tweets_by_zoella = ((number_tweets_by_zoella * 100)/number_total_tweets)
percentage_tweets_by_zoella

print('---')
print('Percentage of Tweets by zoella')
print(percentage_tweets_by_zoella)
print('---')

numrber_of_tweets_smis = number_tweets_by_jamescharles + number_tweets_by_mannymua733 + number_tweets_by_michellephan + number_tweets_by_nikkietutorials + number_tweets_by_zoella
print(number_tweets_by_jamescharles + number_tweets_by_jeffreestar + number_tweets_by_mannymua733 + number_tweets_by_michellephan + number_tweets_by_nikkietutorials + number_tweets_by_zoella)

number_tweets_by_audience = (number_total_tweets - (number_tweets_by_jamescharles + number_tweets_by_mannymua733 + number_tweets_by_michellephan + number_tweets_by_nikkietutorials + number_tweets_by_zoella))
number_tweets_by_audience

print('Need to DO')

print('---')
print('Number of Tweets by Audience')
print(number_tweets_by_audience)     ############### NEED TO DO!!!!!!!!
print('---')

percentage_tweets_by_audience = ((number_tweets_by_audience * 100)/number_total_tweets)
percentage_tweets_by_audience

print('---')
print('Percentage of Tweets by Audience')
print(((number_tweets_by_audience * 100)/number_total_tweets))
print('---')


# percentage_tweets_by_jamescharles
# percentage_tweets_by_jeffreestar
# percentage_tweets_by_mannymua733
# percentage_tweets_by_michellephan
# percentage_tweets_by_nikkietutorials
# percentage_tweets_by_zoella
# percentage_tweets_by_audience

# Inicialize List of Lists

tweets_by_percentages = [['jamescharles', number_tweets_by_jamescharles, percentage_tweets_by_jamescharles], ['jeffreestar', number_tweets_by_jeffreestar, percentage_tweets_by_jeffreestar], ['mannymua733', number_tweets_by_mannymua733, percentage_tweets_by_mannymua733], ['michellephan', number_tweets_by_michellephan, percentage_tweets_by_michellephan], ['nikkietutorials', number_tweets_by_nikkietutorials, percentage_tweets_by_nikkietutorials], ['zoella', number_tweets_by_zoella, percentage_tweets_by_zoella], ['audience', number_tweets_by_audience, percentage_tweets_by_audience]]

# Create DataFrame

tweets_by_percentages_df = pd.DataFrame(tweets_by_percentages, columns =['tweets_by_smi', 'number_tweets_by', 'tweets_by_percentage'])

tweets_by_percentages_df.to_csv('4_4_65_SMI1_Tweets_by_Percentages_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_by_percentages_df.to_excel('4_4_65_SMI1_Tweets_by_Percentages_DF.xlsx', header=True)


print('---')
print('Percentages of Tweets by Author')
# print(tweets_by_percentages_df)
print(tweets_by_percentages_df.dtypes)
print('---')

# TABLE PLOT NEED TO DO

# tweets_by_percentages['number_tweets_by'] = np.arange(tweets_by_percentages['number_tweets_by'])  ## NEED TO DO FIX SORTING - ARRANGE

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentages of Tweets By Author - Pie')
plt.ioff()
# plt.pie(tweets_by_percentages_df['number_tweets_by'], labels=tweets_by_percentages['tweets_by_smi'])
plt.pie(tweets_by_percentages_df['number_tweets_by'], labels=tweets_by_percentages_df['tweets_by_smi'], colors=colors_blue, startangle=68, autopct='%1.1f%%', pctdistance=1.3, labeldistance=1.5, radius=1.0, rotatelabels=True)
plt.legend(labels=tweets_by_percentages_df['tweets_by_smi'], bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_65_SMI1_Percentage_Tweets_By_PLT_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets By Author - Bars')
plt.ioff()
tweets_by_percentages_df['number_tweets_by'].plot.bar(alpha=0.9)
ax.bar(tweets_by_percentages_df['tweets_by_smi'], tweets_by_percentages_df['number_tweets_by'])
plt.xlabel('JamesCharles, JeffreeStar, MannyMua733, MichellePhan, NikkieTutorials, Zoella, Audience')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_65_SMI1_Tweets_by_SMI_Tweets_Bars_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################################################################
###################################################################################################

# PLOT BARS - MULTIPLE - Tweets ABOUT AND BY SMI ## NEED TO DO - FIX 

# Set Parameters
fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

r1 = np.arange(len(tweets_about_percentages_df['tweets_about_smi_number']))
r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentages of Tweets About - By Author - Bars')
plt.ioff()

plt.bar(r1, tweets_about_percentages_df['tweets_about_smi_number'], color='#73C2FB', edgecolor='white', label='Tweets About', alpha=0.9)
plt.bar(r2, tweets_by_percentages_df['number_tweets_by'], color='blue', edgecolor='white', label='Tweets By Author', alpha=0.9)

# tweets_about_percentages_df['tweets_about_smi_number'].plot.bar(alpha=0.9)
# ax.bar(tweets_about_percentages_df['tweets_about_smi_item'], tweets_about_percentages_df['tweets_about_smi_number'])
# tweets_by_percentages_df['number_tweets_by'].plot.bar(alpha=0.9)
# ax.bar(x + (2 * barWidth), tweets_by_percentages_df['tweets_by_smi'], tweets_by_percentages_df['number_tweets_by'])
# ax.bar(x + (2 * barWidth), tweets_by_percentages_df['tweets_by_smi'], tweets_by_percentages_df['number_tweets_by'])

plt.xticks(rotation=50)
plt.xlabel('JamesCharles, JeffreeStar, MannyMua733, MichellePhan, NikkieTutorials, Zoella, Other and Audience')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_66_SMI1_Percentage_Tweets_About_By_Bar_Plot_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################################################################
###################################################################################################

print('---')
print(main_smi)
print('---')

##############


# Inicialize List of Lists

total_followers_smis = [['jamescharles', total_followers_jamescharles], ['jeffreestar', total_followers_jeffreestar], ['mannymua733', total_followers_mannymua733], ['michellephan', total_followers_michellephan], ['nikkietutorials', total_followers_nikkietutorials], ['zoella', total_followers_zoella]]

# Create DataFrame

total_followers_smis_df = pd.DataFrame(total_followers_smis, columns =['smi_name', 'total_number_followers'])

# total_followers_smis_df.to_csv('4_4_67_SMI1_Total_Followers_SMIs_DF_CSV.csv')
# total_followers_smis_df.to_excel('4_4_67_SMI1_Total_Followers_SMIs_DF.xlsx', header=True)

###############################################################################################

# AUDIENCE ANALYSIS


print('AUDIENCE AND ENGAGEMENT STATISTICS')

print('---')
print('SMI and Number of Followers ')
# print(total_followers_smis_df)
print('---')

##### NEED TABLE OF TOTAL USER VS EACH ONE

print('---')
print('Follower Counts vs Followers vs Friends')     ## NEED TO DO
print('---------- NEED TO DO')
print('---')


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Follower Counts - Pie')
plt.ioff()
plt.pie(total_followers_smis_df['total_number_followers'], labels=total_followers_smis_df['smi_name'], colors=colors_blue, startangle=70, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(labels=total_followers_smis_df['smi_name'], bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_47_SMI1_Followers_Counts_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Follower Counts - Bars')
plt.ioff()
total_followers_smis_df['total_number_followers'].plot.bar(alpha=0.9)
ax.bar(total_followers_smis_df['smi_name'], total_followers_smis_df['total_number_followers'])
plt.xticks(rotation=50)
plt.xlabel('JamesCharles, JeffreeStar, MannyMua733, MichellePhan, NikkieTutorials, Zoella')
plt.ylabel('follower count')
plt.legend(labels=total_followers_smis_df['smi_name']) 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_47_SMI1_Followers_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



###############################################################################################################
###############################################################################################################
###############################################################################################################




# ONLY ENGLISH

tweets_smi_1 =  tweets_smi_1[(tweets_smi_1['language'] == 'english')]

# TO LOWERCASE METHOD 1 - VERY MEMORY INTENSIVE

# tweets_smi_1['clean_text'] = map(lambda x: x.lower(), tweets_smi_1['text'])

###############################################################################################################
###############################################################################################################
###############################################################################################################
###############################################################################################################


###############################################################################################################
###############################################################################################################
###############################################################################################################
###############################################################################################################
#
#                  	             TEXTUAL ANALYTICS
#
##############################################################################################################
##############################################################################################################

print('---')
print('Loading Libs 14')
print('---')

# Word Frequency Distribution

# TURN COLLUMS TO STRING 

# tweets_smi_1['screenName'] = tweets_smi_1['screenName'].pd.to_string()
# tweets_smi_1['author_id'] = tweets_smi_1['author_id'].to_numeric(, errors='ignore')
# tweets_smi_1['created'] = pd.to_datetime(tweets_smi_1['created'])
# tweets_smi_1['created'] = tweets_smi_1['created'].to_datetime()
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].to_numeric(, errors='ignore')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].to_numeric(, errors='ignore')
# tweets_smi_1['text'] = tweets_smi_1['text'].to_string()
# tweets_smi_1['latitude'] = tweets_smi_1['latitude'].to_string()      ########################## NEED TO CHECK PLACES OR GEO LOCATION!!!!!!
# tweets_smi_1['longitude'] = tweets_smi_1['longitude'].to_numeric(, errors='ignore')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].to_string()
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].to_string()
# tweets_smi_1['id'] = tweets_smi_1['id'].to_numeric(, errors='ignore')
# tweets_smi_1['url'] = tweets_smi_1['url'].to_string()
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].to_string()
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].to_string()
# tweets_smi_1['image_link'] = tweets_smi_1['image_link'].to_string()
# tweets_smi_1['language'] = tweets_smi_1['language'].to_string()

print('---')
print('DataFrame Types')
# print(tweets_smi_1.dtypes)
print('---')


# tweets_smi_1['screenName'].pd.astype('str').dtypes
# tweets_smi_1['text'].astype('str').dtypes
# tweets_smi_1['latitude'] = tweets_smi_1['latitude'].to_string()      ########################## NEED TO CHECK PLACES OR GEO LOCATION!!!!!!
# tweets_smi_1['longitude'] = tweets_smi_1['longitude'].to_numeric(, errors='ignore')
# tweets_smi_1['hashtags'].pd.astype('str').dtypes
# tweets_smi_1['mentions'].pd.astype('str').dtypes
# tweets_smi_1['url'].pd.astype('str').dtypes
# tweets_smi_1['emojis_unicode'].pd.astype('str').dtypes
# tweets_smi_1['emojis_converted'].astype('str').dtypes
# tweets_smi_1['image_link'].pd.astype('str').dtypes
# tweets_smi_1['language'].pd.astype('str').dtypes

#########################################################

# TURN COLLUMS TO STRING 

#############################################################################

# https://www.strehle.de/tim/weblog/archives/2015/09/03/1569

# WORD FREQUENCY DISTRIBUTION IN TEXT OF Tweets

# fp_text = tweets_smi_1['text'].astype(str, errors='ignore')
# fp_text['tweet_text_fp_text'] = pd.DataFrame(tweets_smi_1['text'].astype(str, errors='ignore'))
# fp_text = tweets_smi_1.text.astype(str, errors='ignore')

# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('NaN', '')

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore')

# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\'nan\'', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\'0\'', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(',', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace(',', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace(',', '')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace(',', '')
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.replace(',', '')

fp_text_temp = tweets_smi_1['text']
fp_text = fp_text_temp.to_string()

print('---')
print('DataFrame Types fp_text')
# print(fp_text.dtypes)
print('---')

# fp_text = pd.DataFrame(tweets_smi_1['text'].astype('str'))
# fp_text = pd.DataFrame(StringIO(tweets_smi_1['text']))

# input_file = sys.argv[1]

# fp_text = pd.DataFrame(tweets_smi_1['text'].astype('str'))
# fp_text = StringIO(tweets_smi_1['text'])

# fp_text = pd.read_csv(StringIO(smi_file_4_4_text_only, 'r', 'utf-8'))
# fp_text = pd.read_csv(smi_file_4_4_text_only, sep='\t', encoding='utf-8', parse_dates=True, header=0, low_memory=False)
# fp_text = codecs.open(smi_file_4_4_text_only, 'r', 'utf-8')
# fp_text = pd.DataFrame(tweets_smi_1['text'].astype('str'))
# fp_text = np.to_string(fp_text)

# fp_text = pd.DataFrame(fp_text)

# fp_text = open(smi_file_4_4_text_only, encoding='utf-8')
# f_text = fp_text.read() # As bytes

# data_f = fp_text.read() # As bytes

# f_text = fp_text

# f_text = data_f.decode('utf-8') # Unicode not bytes

print('---')
# print(f_text)
print('---')

# fp_text = f_text

print('---')
print('Tweets Text First 10')
print(tweets_smi_1['text'].head)
print('---')

tweets_text_words = nltk.word_tokenize(fp_text)
# tweets_text_words = nltk.word_tokenize(fp['tweet_text_fp'])
# tweets_text_words = pd.DataFrame(tweets_text_words)
tweets_text_words_df = pd.DataFrame(tweets_text_words)

# tweets_text_words = nltk.word_tokenize((tweets_smi_1['text']).pd.to_string())
# tweets_text_words = tweets_smi_1['text']).nltk.word_tokenize()

print('--')
print('Tokenized tweets_words')
print(tweets_text_words_df.head)
print('--')

print('--')
print('Tokenized tweets_words Shape')
print(tweets_text_words_df.shape)
print('--')

print('--')
print('Tokenized tweets_words Info')
print(tweets_text_words_df.info)
print('--')

# Remove single-character tokens (mostly punctuation) ######## NEED TO DO FIX 
# tweets_text_words = [word for word in tweets_text_words if len(word) > 1]

# Remove numbers ######## NEED TO DO FIX
# tweets_text_words = [word for word in tweets_text_words if not word.isnumeric()]

# Lowercase all tweets_words (default_stoptweets_words are lowercase too) ######## NEED TO DO FIX
# tweets_text_words = [word.lower() for word in tweets_text_words]

# Stemming tweets_words seems to make matters worse, disabled
# stemmer = nltk.stem.snowball.SnowballStemmer('english')
# tweets_text_words = [stemmer.stem(word) for word in tweets_text_words]

# Remove stoptweets_words          ################################################################
# tweets_text_words = [word for word in tweets_text_words if word not in stoptweets_words]

# print('removed stoptweets_words')

########################################################################################################################
##########################################################################################################
###########################################################################################################
#
#					WORDCLOUD
#
############################################################################################################

# https://www.datacamp.com/community/tutorials/wordcloud-python

# textblob_obj_text_c_str = textblob_obj_text_c.transform(str)

# WORDCLOUD 

# SMI_WordCloud_1 = WordCloud(background_color="white",width=800, height=400).generate(textblob_obj_text_c_str)

# SMI_WordCloud_1 = WordCloud(background_color="white",width=800, height=400).generate(' '.join(fp_text))

# SMI_WordCloud_1 = WordCloud(background_color="white", colors=colors_blue).generate(' '.join(fp_text))

# SMI_WordCloud_1 = WordCloud(background_color='white').generate(' '.join(tweets_text_words)) # tweets_text_words  fp_text tweets_text_words

# SMI_WordCloud_1 = WordCloud(background_color='white').generate(fp_text) # fp_text_temp

# SMI_WordCloud_1 = WordCloud(background_color='white').generate(tweets_text_words)


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet WordCloud Visualization')
plt.ioff()
# plt.imshow(SMI_WordCloud_1, interpolation='bilinear')
plt.axis('off')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# plt.show()
plt.savefig('4_4_237_SMI1_WordCloud_SB_1.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



print('-----------')
print('SMI_1 DTypes')
print(tweets_smi_1.dtypes)
print('-----------')



#####
######################################################################################################

## SELECTED WORDS

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Calculate Frequency Distribution

smi1_tweets_text_words_fdist = nltk.FreqDist(tweets_text_words)

print('---')
print('Word Frequency Distribution - NEED TO DO - FIX KNOW TYPE')
# print(smi1_tweets_text_words_fdist)
print('---')

print('---')
print('Word Frequency Distribution - Love')
# print(smi1_tweets_text_words_fdist['love'])
print('---')

print('---')
print('Word Frequency Distribution - Hate')
# print(smi1_tweets_text_words_fdist['hate'])
print('---')

print('---')
print('Word Frequency Distribution - Thanks')
# print(smi1_tweets_text_words_fdist['thanks'])
print('---')

print('---')
print('Word Frequency Distribution - Fuck')
# print(smi1_tweets_text_words_fdist['fuck'])
print('---')

print('---')
print('Word Frequency Distribution - Follow')
# print(smi1_tweets_text_words_fdist['follow'])
print('---')

print('---')
print('Word Frequency Distribution - Friend')
# print(smi1_tweets_text_words_fdist['friend'])
print('---')

print('---')
print('Word Frequency Distribution - Buy')
# print(smi1_tweets_text_words_fdist['buy'])
print('---')

print('---')
print('Word Frequency Distribution - Brand')
# print(smi1_tweets_text_words_fdist['brand'])
print('---')

print('---')
print('Word Frequency Distribution - Feel')
# print(smi1_tweets_text_words_fdist['feel'])
print('---')

print('---')
print('Word Frequency Distribution - Recommend')
# print(smi1_tweets_text_words_fdist['recommend'])
print('---')

print('---')
print('Word Frequency Distribution - Review')
# print(smi1_tweets_text_words_fdist['review'])
print('---')

word_love = smi1_tweets_text_words_fdist['love']

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency of Word Love')
plt.ioff()
plt.plot(smi1_tweets_text_words_fdist['love'], alpha=0.9)
# ax.bar(tweet_info_selectec_words_df['tweet_info_selectec_words'], tweet_info_selectec_words_df['number_tweet_info_selectec_words'])
plt.xticks(rotation=50)
plt.xlabel('Word Love')
plt.ylabel('Count')
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_101_SMI1_Tweet_info_words_love_df_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

word_hate = smi1_tweets_text_words_fdist['hate']
word_thanks = smi1_tweets_text_words_fdist['thanks']
word_fuck = smi1_tweets_text_words_fdist['fuck']
word_follow = smi1_tweets_text_words_fdist['follow']
word_friend = smi1_tweets_text_words_fdist['friend']
word_buy = smi1_tweets_text_words_fdist['buy']
word_brand = smi1_tweets_text_words_fdist['brand']
word_feel = smi1_tweets_text_words_fdist['feel']
word_feel = smi1_tweets_text_words_fdist['recommend']
word_feel = smi1_tweets_text_words_fdist['review']

# NEED TO DO !!!!

# Inicialize List of Lists 

# tweet_info_selectec_words = [['love', word_love], ['hate', word_hate], ['thanks', word_thanks], ['fuck', word_fuck], ['follow', word_follow, ['friend', word_friend], ['buy', word_buy], ['brand', word_brand], ['buy', word_buy], ['brand', word_brand], ['feel', word_feel], ['recommend', word_recommend], ['buy', word_buy], ['review', word_review]]

# Create DataFrame

# tweet_info_selectec_words_df = pd.DataFrame(tweet_info_selectec_words, columns =['tweet_info_selectec_words', 'tweet_info_selectec_words_count'])

# tweet_info_selectec_words_df = pd.DataFrame(tweet_info_selectec_words)

print('---')
print('Tweet Info Selected Words')
# print(tweet_info_selectec_words_df)
print('---')


# tweet_info_selectec_words_df.to_csv('4_4_101_SMI1_Tweet_info_selectec_words_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_selectec_words_df.to_excel('4_4_101_SMI1_Tweet_info_selectec_words_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets Info Selected Words - Pie')
plt.ioff()
# plt.pie(tweet_info_selectec_words_df['number_tweet_info_selectec_words'], labels=tweet_info_selectec_words_df['tweet_info_selectec_words'], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweet_info_selectec_words_df['tweet_info_selectec_words'], loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_101_SMI1_Tweet_info_selectec_words_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Info Selected Words - Bars')
plt.ioff()
# tweet_info_selectec_words_df['number_tweet_info_selectec_words'].plot.bar(alpha=0.9)
# ax.bar(tweet_info_selectec_words_df['tweet_info_selectec_words'], tweet_info_selectec_words_df['number_tweet_info_selectec_words'])
plt.xticks(rotation=50)
plt.xlabel('Tweets Info Selected Words')
# plt.ylabel('Count')
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_101_SMI1_Tweet_Info_Selected_Words_df_Counts_Bars_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## NEED TO DO PLOTS AND SAVE

# Output top 50 tweets_words

# for word, frequency in smi1_tweets_text_words_fdist.most_common(10):
#   print(u'{};{}'.format(word, frequency))
#     smi1_tweets_text_words_freq['tweets_text_words'] = pd.DataFrame(smi1_tweets_text_words_fdist.word)
#     smi1_tweets_text_words_freq['tweets_text_words_freq'] = pd.DataFrame(smi1_tweets_text_words_fdist.frequency)


# tweets_text_words_freq =  tweets_text_words_fdist.keys()   ### NEED TO DO - FIX FROM ABOVE

print('---')
print('Word Frequency Distribution from List and Counts - Try 1')
# print(type(smi1_tweets_text_words_fdist))
print('---')

print('---')
print('Number of Words In Text')
print(len(smi1_tweets_text_words_fdist))
print('---')


smi1_tweets_text_words_fdist_df = pd.DataFrame([smi1_tweets_text_words_fdist])

smi1_tweets_text_words_fdist_df.to_csv('4_4_101_SMI1_Word_Freq_Dist_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_tweets_text_words_fdist_df.to_excel('4_4_101_SMI1_Word_Freq_Dist_DF.xlsx', header='frequency_distribution') # Only argument is a string of the output file path


# PLOT TABLE NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Words Frequency Distribution')
plt.ioff()
# smi1_tweets_text_words_fdist[:10].plot(alpha=0.9)   ########### NEED TO FIX -SHOWING FEW
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_101_SMI1_Words_Freq_Dist_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4)) 
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Words Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_tweets_text_words_fdist, patch_artist=True, vert=False, notch=False, showfliers=False)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_101_SMI1_Words_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################

# HISTOGRAM PLOT NEED TO DO ## need to change

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Words Frequency Distribution - Histogram')
plt.ioff()
# plt.hist(smi1_tweets_text_words_fdist['smi1_tweets_text_words_fdist':10], labels=smi1_tweets_text_words_fdist, colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_101_SMI1_Words_Freq_Dist_PLOT_Hist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_tweets_text_words_fdist = tweets_text_words_fdist.sort(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets Words Frequency Distribution - Bars')
plt.ioff()
# plt.hist(smi1_tweets_text_words_fdist, alpha=0.9)
# plt.bar(smi1_tweets_text_words_fdist[:10])
# smi1_tweets_text_words_fdist[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_101_SMI1_Words_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################

## METHOD 2 - SEVERAL TRIES

# TO DF - NOT WORKING

# smi1_df_tweets_text_words_fdist = pd.DataFrame(smi1_tweets_text_words_fdist)

print('---')
print('Frequency Distribution of Words DF')
# print(smi1_df_tweets_text_words_fdist.head)
print('---')

#### TRY 2 NOT WORKING

# smi1_tweets_text_words_fdist_list = smi1_tweets_text_words_fdist.str.split()

# smi1_tweets_text_words_freq = ['smi1_tweets_text_words', 'smi1_tweets_text_words_freq']

# for w in smi1_tweets_text_words_fdist_list:
#	smi1_tweets_text_words_freq.append(smi1_tweets_text_words_fdist_list.count(w))
	

print('---')
print('Word Frequency Distribution from List and Counts - Try 2')
# print(smi1_tweets_text_words_freq)
print('---')
print('---')
# print('List\n' + str(smi1_tweets_text_words_freq) + '\n')
print('---')
print('---')
# print('Frequencies\n' + str(smi1_tweets_text_words_freq) + '\n')
print('---')
print('---')
# print('Pairs\n' + str(list(zip(smi1_tweets_text_words_fdist_list, smi1_tweets_text_words_freq)))
print('---')

# TABLE PLOT NEED TO DO 

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tweets Words - Pie')
plt.ioff()
# plt.pie(smi1_tweets_text_words_fdist[:6], labels=smi1_tweets_text_words_fdist, colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_tweets_text_words_fdist[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_words, loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_102_SMI1_Tweets_Text_Words_fdist_df_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Words - Bars')
plt.ioff()
# plt.bar(smi1_tweets_text_words_fdist)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_102_SMI1_Tweets_Text_Words_fdist_df_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################### NEED TO FIX

# TUPLE TO DATAFRAME

# tweets_text_words_fdist_df = pd.DataFrame.from_records(tweets_text_words_fdist, columns=['tweets_text_words', 'tweets_text_words_freq'])
# tweets_text_words_fdist_df = pd.DataFrame.from_items(tweets_text_words_fdist)
# tweets_text_words_fdist_df = pd.DataFrame(tweets_text_words_fdist, index=[0])
# tweets_text_words_fdist_df = pd.DataFrame([tweets_text_words_fdist])
# tweets_text_words_fdist_df = pd.DataFrame(list(tweets_text_words_fdist), columns=['tweets_text_words', 'tweets_text_words_freq'], index['tweets_text_words', 'tweets_text_words_freq'])

# tweets_text_words_fdist_df = pd.DataFrame(tweets_text_words_fdist, columns=['tweets_text_words', 'tweets_text_words_freq'])
# a_tweets_text_words_fdist_df = tweets_text_words_fdist_df.pivot('tweets_text_words', 'tweets_text_words_freq')


# pd.DataFrame.from_dict(list(tweets_text_words_fdist.items()), columns=['tweets_words', 'tweets_words_frequency_counts'])
# pd.DataFrame.from_dict(tweets_text_words_fdist, orient='index')

# tweets_text_words_fdist_d_f = list(tweets_text_words_fdist, name='tweets_words_frequency_counts')

# tweets_text_words_fdist_d_f.index.name = 'tweets_words_frequency_counts' 

# tweets_text_words_fdist_df = pd.DataFrame(tweets_text_words_fdist, index=[0])

print('---')
print('Tweets_words Frequency Distribution DataFrame')
# print(tweets_text_words_fdist_df.head)


############ df_tweets_words_fdist is a tuple!!! NEED TO CHANGE TO DF and PLOT DUPLE!!!!


print('---')
print('DF tweets_words Frequency Distribution - fdist ')
# print(tweets_text_words_fdist_df)
print('---')

print('---')
print('Frequency Distribution of tweets_words')
# print(tweets_text_words_fdist_df.head)
print('---')

# tweets_text_words_fdist_df.to_csv('4_4_103_SMI1_Tweets_Text_Words_fdist_df_CSV.csv', sep='\t', encoding='utf-8', index=True)
# tweets_text_words_fdist_df.to_excel('4_4_103_SMI1_Tweets_Text_Words_fdist_df.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# NEED TO DO TABLE PLOT

# PLOT NEED TO DO 

# BOX PLOT 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tweets Words- Box')
plt.ioff()
# plt.boxplot(tweets_text_words_fdist_df, patch_artist=True, vert=False, notch=False, showfliers=True) 
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_103_SMI1_Tweets_Text_Words_fdist_df_PLOT_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tweets Words- Pie')
plt.ioff()
# plt.pie(tweets_text_words_fdist_df[:6], labels=tweets_text_words_fdist_df, colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# tweets_text_words_fdist_df[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_words, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_103_SMI1_Tweets_Text_Words_fdist_df_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## PLOT 2 TEST ## NEED TO DO FIX NOT WORKING

print('PLOT2 WORD DIST TEST - NEED TO FIX')

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Word Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(tweets_text_words_fdist_df, patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_103_SMI1_Tweets_Text_Words_fdist_df_Box_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Words')
plt.ioff()
# tweets_text_words_fdist_df.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
# tweets_text_words_fdist_df[:10].plot(alpha=0.9)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_103_SMI1_Tweets_Text_Words_fdist_df_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# Bars ## NEED TO DO FIX NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Words- Bars')
plt.ioff()
# tweets_text_words_fdist_df[:10].plot.bars(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_103_SMI1_Tweets_Text_Words_fdist_df_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#######################################################################

# Bars  ######### NEED TO DO!!!!!!!!!!!!!

value_counts_text = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)

# Create DataFrame

value_counts_text_df = pd.DataFrame(value_counts_text, columns =['item', 'word_number_value', 'tweets_words_by_percentage'])
value_counts_text_df

print('---')
print('Tweets_words in Tweets and Values')
print(value_counts_text_df.head)
print('---')

value_counts_text_df.to_csv('4_4_104_SMI1_Value_Counts_Text_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_text_df.to_excel('4_4_104_SMI1_Value_Counts_Text_DF.xlxs', header=True)

# top_tweets_words_fdist = pd.DataFrame(tweets_words_fdist.sort_values(ascending=False))

# top_tweets_words_fdist = value_counts_df_tweets_words_fdist.sort_values(ascending=False)  ######## NEED TO PUT FIX SORTING DUPLE

# TABLE PLOT NEED TO DO 

# Bars

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Word Frequency Distribution - Bars')
plt.ioff()
# tweets_smi_1['text'].value_counts()[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_104_SMI1_Top_Tweets_Words_Freqdists_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')



##################################################

# PLOTS  ######### NEED TO DO!!!!!!!!!!!!! NOT WORKING

# USE DICTIONARY?????

# value_counts_text = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)
# top_tweets_words_fdist = df_tweets_words_fdist.sort_values(ascending=False)

# value_counts_df_tweets_words_fdist = pd.value_counts(pd.DataFrame(df_tweets_words_fdist), ascending=False, normalize=True)
# top_tweets_words_fdist = pd.DataFrame(value_counts_df_tweets_words_fdist.sort_values(ascending=False))

# top_tweets_words_fdist_f = value_counts_df_tweets_words_fdist.sort_values(ascending=False)

## NEED TO DO SAVE INFO TO CSV!!!!

# top_tweets_words_fdist.to_csv('4_4_104_SMI1_Top_Tweets_Value_Counts_Words_fdist_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# top_tweets_words_fdist.to_excel('4_4_104_SMI1_Top_Tweets_Value_Counts_Words_fdist.xlsx', header=True)

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi )
plt.title('Top Words Value Counts')
plt.ioff()
# top_tweets_words_fdist.plot(6,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
# top_tweets_words_fdist[:6].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_104_1_SMI1_Top_Tweets_Words_Value_Counts_fdists_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(30,30))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi )
plt.title('Top Words Value Counts - Pie')
plt.ioff()
# plt.pie(top_tweets_words_fdist[:6], labels=top_tweets_words_fdist, colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# top_tweets_words_fdist[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(top_tweets_words_fdist, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_4_104_1_SMI1_Top_Tweets_Words_Value_Counts_fdists_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Word Frequency Distribution - Bars')
plt.ioff()
# top_tweets_words_fdist[:10].plot.bar(alpha=0.9)
# value_counts_df_tweets_words_fdist[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_104_1_SMI1_Top_Tweets_Words_Value_Counts_fdists_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

## NEED TO DO SCREENNAME STAS!!!!!!!!!!!!!!




############################################################################################################

## NEED TO DO MENTIONS STAS!!!!!!!!!!!!!!

############################################################################################################

# Value Counts All Mentions   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_value_counts_mentions_1a_df = pd.value_counts(tweets_smi_1['mentions'], ascending=False, normalize=True).to_frame()
# smi1_value_counts_mentions_1a_df[['item','count']] = pd.DataFrame(smi1_value_counts_mentions_1a_df.str.split(' ',1).tolist(), columns = ['item','count'])

print('---')
print('smi1_value_counts_mentions_1a_df')
print(smi1_value_counts_mentions_1a_df.head)
print('---')

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Mentions_1a_ DTYPEES 0 ')
print(smi1_value_counts_mentions_1a_df.dtypes)
print('---')


smi1_value_counts_mentions_1a_df.to_csv('4_4_43_107_SMI1_Mentions_Describe_1a_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_mentions_1a_df.to_excel('4_4_43_107_SMI1_Mentions_Describe_1a_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
# plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts')
plt.ioff()
# smi1_value_counts_mentions_1a_df.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_mentions_1a_df[:10].plot(alpha=0.9)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_107_SMI1_Top_Mentions_1a_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Pie')
plt.ioff()
# plt.pie(smi1_value_counts_mentions_1a_df[:6], labels=smi1_tweets_text_words_fdist['mentions_1a'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_mentions_1a_df[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True, subplots=True) 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_107_SMI1_Top_Mentions_1a_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
# fig, ax = plt.subplots(1, 1) 
# plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title(
'Top Mentions Value Counts - Bars')
plt.ioff()
smi1_value_counts_mentions_1a_df[:6].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_107_SMI1_Top_Mentions_1a_Value_Counts_BARS.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# MENTIONS FREQ DISTRIBUTION

# Calculate frequency distribution

smi1_mentions_fdist = nltk.FreqDist(tweets_smi_1['mentions'])

smi1_mentions_fdist_df = pd.DataFrame([smi1_mentions_fdist])

# Output top 50 tweets_words

# for smi1_mentions, frequency in smi1_mentions_fdist.most_common(10):
#    print(u'{};{}'.format(smi1_mentions, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Frequency Distribution of Mentions 1')
# print('smi1_mentions_fdist_df.head')
print('---')

smi1_mentions_fdist_df.to_csv('4_4_43_108_SMI1_Mentions_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_mentions_fdist_df.to_excel('4_4_43-108_SMI1_Mentions_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
# plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution')
plt.ioff()
# plt.plot(smi1_mentions_fdist[:6], alpha=0.9) 
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_108_SMI1_Mentions_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
# plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_mentions_fdist, patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_43_108_SMI1_Mentions_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution - Pie')
plt.ioff()
# smi1_mentions_fdist[:6], labels=top_smi1_mentions_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_mentions_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_mentions_fdist, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_4_43_108_SMI1_Mentions_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_mentions_fdist = smi1_mentions_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution - Bars')
plt.ioff()
# smi1_mentions_fdist[:6].plot.bar(alpha=0.9)
plt.xlabel('Mentions')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_108_SMI1_Mentions_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#####

# METHOD 1 MENTIONS

# fp_mentions_1 = tweets_smi_1['mentions'].to_string()

# fp_mentions_1 = fp_mentions_temp.to_string()

fp_mentions_1 = str(tweets_smi_1['mentions'])

# fp_mentions_1 = fp_mentions_1_temp.to_string()

print('fp_mentions_1 dtypes Mentions 1')
# print(fp_mentions_1.dtypes)
print('---')

tweets_text_mentions_1 = nltk.word_tokenize(fp_mentions_1)

smi1_value_counts_mentions_1_df = pd.value_counts(tweets_text_mentions_1, ascending=False, normalize=True).to_frame()
# smi1_value_counts_mentions_1_df[['item','count']] = pd.DataFrame(smi1_value_counts_mentions_1_df.str.split(' ',1).tolist(), columns = ['item','count'])

print('----')
print('Value Counts Mentions - Frequency 1 HEAD')
print(smi1_value_counts_mentions_1_df.head)
print('----')

print('----')
print('Value Counts Mentions - Frequency 1 DTYPES')
print(smi1_value_counts_mentions_1_df.dtypes)
print('----')




############################################################################################################

## NEED TO DO Hashtag STAS!!!!!!!!!!!!!!

############################################################################################################


# Value Counts All Hashtags   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_hashtags_1a = pd.value_counts(tweets_smi_1['hashtags'], ascending=False, normalize=True)

smi1_value_counts_hashtags_1a = value_counts_hashtags_1a.sort_values(ascending=False)

print('---')
print('value_counts_hashtags 1a')
# print(value_counts_hashtags_1a.head)
print('---')

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Hashtags_1a')
# print(smi1_value_counts_hashtags_1a.describe().head)
print('---')

smi1_value_counts_hashtags_1a_df = pd.DataFrame(value_counts_hashtags_1a, columns =['hashtags_1a'])

smi1_value_counts_hashtags_1a_df.to_csv('4_4_43_109_SMI1_Hashtags_1a_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_hashtags_1a_df.to_excel('4_4_43_109_SMI1_Hashtags_1a_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts')
plt.ioff()
# smi1_value_counts_hashtags.plot(6,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_hashtags_1a[:6].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_109_SMI1_Top_Hashtags_1a_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(30,30))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Pie')
plt.ioff()
# smi1_value_counts_hashtags_1a[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.pie(smi1_value_counts_hashtags_1a[:6], labels=smi1_value_counts_hashtags_1a[:6], colors=colors_blue, startangle=86, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(smi1_value_counts_hashtags_1a, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_4_43_109_SMI1_Top_Hashtags_1a_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(30,30))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Bars')
plt.ioff()
# smi1_value_counts_hashtags_1a[:6].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_109_SMI1_Top_Hashtags_1a_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##########################################################################

# METHOD 1 HASHTAGS

# fp_hashtags_1_temp = tweets_smi_1['hashtags'].astype(str, errors='ignore')
# fp_hashtags_1_temp = tweets_smi_1['hashtags'].to_string()

fp_hashtags_1 = str(tweets_smi_1['hashtags'])

# fp_hashtags_1 = fp_hashtags_1_temp.to_string()

print('fp_hashtags_1 dtypes 1')
# print(fp_hashtags_1.dtypes)
print('---')

# fp_hashtags_1 = fp_hashtags_1_temp

tweets_text_hashtags_1 = nltk.word_tokenize(fp_hashtags_1)

value_counts_hashtags_1 = pd.value_counts(tweets_text_hashtags_1, ascending=False, normalize=True) 

smi1_value_counts_hashtags_1 = value_counts_hashtags_1.sort_values(ascending=False)

# smi1_value_counts_hashtags_1_freq_dist = tweets_text_hashtags_1.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Hashtags 1 - Frequency 1')
# print(smi1_value_counts_hashtags_1.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts hashtags_1')
# print(smi1_value_counts_hashtags_1.describe().head)
print('---')

smi1_value_counts_hashtags_1_df = pd.DataFrame(smi1_value_counts_hashtags_1, columns=['hashtags_frequency'])

smi1_value_counts_hashtags_1_df.to_csv('4_4_43_110_SMI1_Value_Counts_Hashtags_1_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_hashtags_1_df.to_excel('4_4_43_110_SMI1_Value_Counts_Hashtags_1_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts')
plt.ioff()
plt.plot(smi1_value_counts_hashtags_1[:10], alpha=0.9)
plt.xlabel('Hashtags')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_110_SMI1_Top_Hashtags_1_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Pie')
plt.ioff()
smi1_value_counts_hashtags_1[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, explode = explode_pie_6)
plt.legend(smi1_value_counts_hashtags_1, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_110_SMI1_Top_Hashtags_1_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Bars')
plt.ioff()
smi1_value_counts_hashtags_1[:10].plot.bar(alpha=0.9)
plt.xlabel('Hashtags')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_110_SMI1_Top_Hashtags_1_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


######################################################################################################
############################################################################################################

## NEED TO DO LANGUAGE STATS!!!!!!!!!!!!!!

############################################################################################################

# NEED FREQ DIST EMOJIS, IMAGE LINK< NEED TO DO MISSING HASHTAFS MENTIONS !!!! < ETC

############################################################################################################
#######################################################################################################

print('---')
print('Loading Libs 15')
print('---')

## NEED TO DO MISSING MENTIONS AND HASTAGS!!!!

# missing_mentions = pd.DataFrame(missing_mentions)


# quant_stats_smi_tweets_1 = go.Figure(data=[go.Table(header=dict(values=['Tweets by JAMESCHARLES', 'Tweets by JEFFREESTAR', 'Tweets by mannymua733', 'Tweets by MICHELLEPHAN', 'Tweets by NIKKIETUTORIALS', 'Tweets by zoella', 'Tweets by AUDIENCE']),
#                 cells=dict(values=[[number_tweets_by_jamescharles, number_tweets_by_jeffreestar, number_tweets_by_mannymua733, number_tweets_by_michellephan, number_tweets_by_nikkietutorials, number_tweets_by_zoella, 'number_tweets_by_audience']]))])

# quant_stats_smi_tweets_1.show()

# quant_stats_smi_tweets_1.to_csv('4_4_165_SMI1_Quant_Stats_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# quant_stats_smi_tweets_1.to_excel('4_4_165_SMI1_Quant_Stats.xlsx', header=True)

# Plot ## NEED TO DO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets SMIs - Audience')
plt.ioff()
# plt.plot(quant_stats_smi_tweets_1, alpha=0.9)
# plt.imshow(quant_stats_smi_tweets_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_165_SMI1_Quant_Stats_SMI_Tweets_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets SMIs - Audience - Pie')
plt.ioff()
# plt.pie(top_retweets_tweets[:6], labels=top_retweets_tweets, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# quant_stats_smi_tweets_1.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(quant_stats_smi_tweets_1, loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_165_SMI1_Quant_Stats_SMI_Tweets_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets SMIs vs Audience - Bars')
plt.ioff()
# plt.plot.bar(quant_stats_smi_tweets_1)
# quant_stats_smi_tweets_1_df['tweets_about_smi_number'].plot.bar(alpha=0.9)
# ax.bar(tweets_about_percentages_df['tweets_about_smi_item'], tweets_about_percentages_df['tweets_about_smi_number'])
plt.xlabel('SMI / Audience')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_165_SMI1_Quant_Stats_SMI_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

####################################################################################################################################################

# This selects the top 5 highest average points among all Tweets: # NEED TO DO

# Mean ScreenName

# smi1_screenname_mean = statistics.mean(tweets_smi_1['screenName'])
# smi1_screenname_mean

# smi1_screenname_mean.sort_values(by='screenName', ascending=False).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest ScreenName Average Points Among All Tweets:')
# print(smi1_screenname_mean.sort_values(by="screenName').head)
print('--')

# smi1_screenname_mean_sort_values_df = pd.DataFrame(smi1_screenname_mean().sort_values(by="screenName'))

# smi1_screenname_mean_sort_values_df.to_csv('4_4_166_SM1_Screenname_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Average Points - All Tweets')
plt.ioff()
# plt.plot(smi1_screenname_mean_sort_values_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_166_SMI1_Screenname_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenName Average Points - Pie')
plt.ioff()
# plt.pie(smi1_screenname_mean_sort_values_df.most_common(10), labels=screenname_mean_sort_values_df.most_common(10), colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_screenname_mean_sort_values_df, loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_166_SMI1_Screenname_Mean_Sort_Values_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenName Average Points - Bars')
plt.ioff()
# smi1_screenname_mean_sort_values_df[:10].plot.bar(alpha=0.9)
plt.xlabel('ScreenName')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_166_SMI1_Screenname_Mean_Sort_Values_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################

# This selects the top 5 highest average points among all Tweets:

# smi1_favorites_mean().sort_values(by="favorites",ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest Favorites Average Points Among All Tweets:')
# print(smi1_favorites_mean().sort_values(by="favorites",ascending=True).head)
print('---')


# smi1_favorites_mean_sort_values_favorites_df = pd.DataFrame(smi1_favorites_mean().sort_values(by="favorites",ascending=True))

# smi1_favorites_mean_sort_values_favorites_df.to_csv('4_4_167_SMI1_Favorites_Mean_Sort_Values_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_favorites_mean_sort_values_favorites_df.to_excel('4_4_167_SMI1_Favorites_Mean_Sort_Values_Favorites_DF.xlsx', header=True)

# PLOT TABLE plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Average Points')
plt.ioff()
# plt.plot(smi1_favorites_mean_sort_values_favorites_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_167_SMI1_Favorites_Mean_Sort_Values_Favorites_df.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))    ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Average Points - All Tweets - Pie')
plt.ioff()
# plt.pie(smi1_favorites_mean_sort_values_favorites_df.most_common(10), labels=smi1_favorites_mean_sort_values_favorites_df.most_common(10), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_favorites_mean_sort_values_favorites_df, loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_167_SMI1_Favorites_Mean_Sort_Values_Favorites_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Average Points - All Tweets - Bars')
plt.ioff()
# smi1_screenname_mean_sort_values_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Favorites')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_167_SMI1_Favorites_Mean_Sort_Values_Favorites_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################

# This selects the top 5 highest average points among all Tweets:

# smi1_retweets_mean().sort_values(by="retweets",ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest Friends Average Points Amongst All Tweets:')
# print(smi1_retweets_mean().sort_values(by="retweets",ascending=True).head)
print('---')

# smi1_retweets_mean_sort_values_retweets_df = pd.DataFrame(smi1_retweets_mean().sort_values(by="retweets",ascending=True))

# smi1_retweets_mean_sort_values_retweets_df.to_csv('4_4_168_SMI1_Retweets_Mean_Sort_Values_Retweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of Retweets Grouped')
plt.ioff()
# plt.plot(smi1_retweets.describe(), alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_168_SMI1_Retweets_Mean_Sort_Values_Retweets_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO BOX PLOT


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of Retweets Grouped - Pie')
# plt.pie(smi1_retweets.describe(), labels=smi1_retweets.describe(), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_retweets.describe(), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_168_SMI1_Retweets_Mean_Sort_Values_Retweets_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Retweets Average Points Tweets - Bars')
plt.ioff()
# smi1_languages.describe().plot.bar(alpha=0.9)
plt.xlabel('Retweets')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_168_SMI1_Retweets_Mean_Sort_Values_Retweets_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#########################################################################################################################################################

# Number of tweets_words in text

number_of_tweets_words = len(smi1_tweets_text_words_fdist)
number_of_tweets_words

# print('---')
print('Number of tweets_words Analyzed : No Stop Words')
print(number_of_tweets_words)
print('---')

number_of_tweets_words_df = pd.DataFrame([number_of_tweets_words])

number_of_tweets_words_df.to_csv('4_4_169_SMI1_Number_of_Tweets_Words_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# number_of_tweets_words_df.to_excel('4_4_169_SMI1_Number_of_Tweets_Words_DF.xlsx, header=True)

# PLOT TABLE plt.plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Text')
plt.ioff()
plt.plot(number_of_tweets_words_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_169_SMI1_Number_of_Tweets_Words_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO DO BOX PLOT


# Pie

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Text - Pie')
# plt.pie(number_of_tweets_words_df, labels=number_of_tweets_words_df, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(number_of_tweets_words_df, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_4_169_SMI1_Number_of_Tweets_Words_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Text - Bars')
plt.ioff()
number_of_tweets_words_df.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_169_SMI1_Number_of_Tweets_Words_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLES

del number_of_tweets_words
del number_of_tweets_words_df


###################################################################################################################

# STATISTICS DF # NEED TO DO 

# initialize list of Lists 

# quant_stats_1_pairs = [['Mean Favorites', median_favorites, 'Median Retweets', median_retweets, 'Mode Favorites', mode_favorites, 'Mode Retweets', mode_retweets], ['Variance Favorites', variance_favorites, 'Variance Retweets', variance_retweets, 'Population Variance Favorites', pvariance_favorites, 'Population Variance Retweets', pvariance_retweets, 'Standard Deviation Retweets', stdev_retweets, 'Population Standard Deviation Favorites', pstdev_favorites, 'Population Standard Deviation Retweets', pstdev_retweets, 'Skewness Favorites', skewness_favorites, 'Skewness Retweets', skewness_retweets, 'Percentiles Favorites (25, 50, 75)', quantiles_favorites, 'Percentiles Friends (25, 50, 75)', quantiles_retweets, 'Ranges Favorites', ptp_favorites, 'Ranges Retweets', ptp_retweets, 'Correlation Coefficient - Pearson Regression', corr_coef_favs_friends_pearson, 'Linear Regession', r_linar_reg],['Number of Tweets Analyzed', number_tweets, 'Number of Unique Tweets Analyzed', number_unique_tweets, 'Number of tweets_wos # in Text', number_of_tweets_words, 'List Unique Users ReTweeting, Commenting, Engaged', number_unique_engaged_users, 'Number of Users Who Fav', number_unique_tweets_with_favorites, 'Number of Unique Tweets with friends', 'number_unique_retweets_users', 'List Unique Hashtags', 'number_unique_hashtags', 'List Unique Mentions', 'number_unique_mentions', 'List Unique Emojis', 'number_unique_emojis_unicode', 'List Unique Emojis', 'number_unique_emojis_converted', 'List Unique Language', 'number_unique_languages', 'Summary Statistics All Favorites / Desc', 'summ_stats_all_favs_desc', 'Summary Statistics All friends / Desc', 'summ_stats_all_friends_desc']]

# Create the pandas DataFrame 
# quant_stats_measures_1 = pd.DataFrame(quant_stats_1_pairs, columns = ['Measures of Centrality', 'Measures of Variability', 'General User Stats', 'Other Stats']) 

# quant_stats_measures_1.to_csv('4_4_170_SMI1_Quant_Stats_Measures_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# quant_stats_measures_1.to_excel('4_4_170_SMI1_Quant_Stats_Measures.xlsx', header=True)

### NEED TO DO PLOT?????????????????

############################################################################################################

print('---')
print('Loading Libs 15')
print('---')

### FROM tweets_words ABOVE

fdist_location_name = FreqDist(tweets_smi_1['geo'])

fdist_location_name.most_common(10)

print('---')
print('Frequency Distribution of location_name')
# print(fdist_location_name.most_common(10))
print('---')

df_fdist_location_name_df = pd.DataFrame([fdist_location_name])

df_fdist_location_name_df.to_csv('4_4_171_SMI1_fdist_Location_Name_CSV.csv', sep='\t', encoding='utf-8', index=True)
# df_fdist_location_name_df.to_excel('4_4_171_SMI1_fdist_Location_Name.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# NEED TO DO - TABLE PLOT 

# PLOT

# Frequency Distribution Plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Location Name')
plt.ioff()
# df_fdist_location_name_df[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_171_SMI1_Location_Name_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Location Name')
plt.ioff()
# plt.plot(tweets_smi_1['location_name':10], alpha=0.9)
# plt.plot(df_fdist_location_name_df[:10], alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_171_SMI1_df_fdist_Location_Name_df_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Location Name - Pie')
plt.ioff()
# plt.pie(df_fdist_location_name_df[:6], labels=df_fdist_location_name_df[:6], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(df_fdist_location_name_df[:6], loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_4_171_SMI1_df_fdist_Location_Name_df_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(8,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Location Name - Bars')
# df_fdist_location_name_df[:10].plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend(bbox_to_anchor=(1.5, 1), loc='upper left') 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_171_SMI1_df_fdist_Location_Name_df_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLES

del fdist_location_name
del df_fdist_location_name_df

##
############################################################################################################

print('---')
print('Loading Libs 16')
print('---')

### FROM tweets_words ABOVE

fdist_country = FreqDist(tweets_smi_1['geo'])

fdist_country.most_common(10)

print('---')
print('Frequency Distribution of country')
# print(fdist_country.most_common(10))
print('---')

fdist_country_df = pd.DataFrame([fdist_country])

fdist_country_df.to_csv('4_4_171_SMI1_fdist_country_CSV.csv', sep='\t', encoding='utf-8', index=True)
# fdist_country_df.to_excel('4_4_171_SMI1_fdist_country.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# NEED TO DO - TABLE PLOT 

# PLOT

# Frequency Distribution Plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Country')
plt.ioff()
# fdist_country_df[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_171_SMI1_country_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Country')
plt.ioff()
# plt.plot(tweets_smi_1['country':10], alpha=0.9)
# plt.plot(fdist_country_df[:10], alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_171_SMI1_df_fdist_country_df_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Country - Pie')
plt.ioff()
# plt.pie(fdist_country_df[:6], labels=Fdist_country_df[:6], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(fdist_country_df[:6], loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_4_171_SMI1_Fdist_Country_df_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Country - Bars')
# fdist_country_df[:10].plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_171_SMI1_Fdist_Country_df_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLES

del fdist_country
del fdist_country_df

###############################################################################################################

# Summary Statistics of all screenNames          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_screenname_describe = tweets_smi_1['screenName'].describe()

print('---')
print('Summary Statistics of ScreenNames')
# print(smi1_screenname.describe().head)
print('---')

smi1_screenname_describe_df = pd.DataFrame(smi1_screenname_describe)

smi1_screenname_describe_df.to_csv('4_4_172_SMI1_Screenname_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot NEED TO DO

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of ScreenNames')
# plt.plot(smi1_screenname_describe_df.describe())
# plt.plot(smi1_screenname_describe_df[:10], alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_172_SMI1_ScreenName_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie - NEED TO DO

# Bars - NEED TO DO


## DELETE VARIABLES

del smi1_screenname_describe
del smi1_screenname_describe_df

##########################################################################################################

# Summary Statistics of Text          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_text_describe = twetts_smi_1['text'].describe()

print('---')
print('Summary Statistics of Text')
# print(smi1_text.describe().head)
print('---')

# smi1_text_describe_df = pd.DataFrame([smi1_text_describe])

# smi1_text_describe_df.to_csv('4_4_173_SM1_Text_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot NEED TO DO

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of Text')
# plt.plot(smi1_text_describe_df.describe())
# plt.plot(smi1_text_describe_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_173_SMI1_Text_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie - NEED TO DO

# Bars - NEED TO DO

## DELETE VARIABLE

# del smi1_text_describe
# del smi1_text_describe_df

############################################################################################################

# Summary Statistics of Hashtags          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_hashtags_describe = tweets_smi_1['hashtags'].describe()

print('---')
print('Summary Statistics of Hashtags')
# print(smi1_hashtags.describe().head)
print('---')

# smi1_hashtags_describe_df = pd.DataFrame(smi1_hashtags_describe)

# smi1_hashtags_describe_df.to_csv('4_4_174_SMI1_Hashtags_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE ## NEED TO DO 

# plt.plot

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of Hashtags - Grouped')
# plt.plot(smi1_hashtags.describe())
# plt.plot(smi1_hashtags_describe_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_174_SMI1_Hashtags_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie - NEED TO DO

# Bars - NEED TO DO

## DELETE VARIABLE

# del smi1_hashtags_describe_df
# del smi1_hashtags_describe

############################################################################################################

# Summary Statistics of Mentions          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_mentions_describe = tweets_smi_1['mentions'].describe()

# smi1_mentions_describe_df = pd.DataFrame([smi1_mentions_describe])

# smi1_mentions_describe_df.to_csv('4_4_175_SM1_Mentions_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of Mentions - Grouped')
# plt.plot(smi1_mentions.describe())
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_175_SMI1_Mentions_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie - NEED TO DO

# Bars - NEED TO DO

## DELETE VARIABLE

# del smi1_mentions_describe
# del smi1_mentions_describe_df



####################################################################################################################
#####

# METHOD 1 TEXT

fp_text = tweets_smi_1['text'].to_string()

tweets_text_text = nltk.word_tokenize(fp_text)

value_counts_text = pd.value_counts(tweets_text_text, ascending=False, normalize=True) 

smi1_value_counts_text = value_counts_text.sort_values(ascending=False)

# smi1_value_counts_text_freq_dist = tweets_text_text.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts TEXT - Frequency')
# print(smi1_value_counts_text.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - Value Counts TEXT')
print(smi1_value_counts_text.describe().head)
print('---')

smi1_value_counts_text_df = pd.DataFrame(smi1_value_counts_text, columns=['text_frequency'])

smi1_value_counts_text_df.to_csv('4_4_43_121_SMI1_Value_Counts_Text_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_text_df.to_excel('4_4_43_121_SMI1_Value_Counts_Text_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Text Value Counts')
plt.plot(smi1_value_counts_text[:10], alpha=0.9)
plt.xlabel('Text')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_121_SMI1_Top_Text_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Text Value Counts - Pie')
smi1_value_counts_text[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, explode = explode_pie_6)
plt.legend(smi1_value_counts_text, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_121_SMI1_Top_Text_Value_Counts_Plot_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Text Value Counts - Bars')
smi1_value_counts_text[:10].plot.bar(alpha=0.9)
plt.xlabel('Text')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_121_SMI1_Top_Text_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del smi1_value_counts_text
del smi1_value_counts_text_df

##################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Common Tweet Text

df_value_counts_text_df = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True).to_frame()
# df_value_counts_text_df[['item','count']] = pd.DataFrame(df_value_counts_text_df.str.split(' ',1).tolist(), columns = ['item','count'])

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

df_value_counts_text_df.to_csv('4_4_122_1_SMI1_df_Top_Text_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# df_value_counts_text_df.to_excel('4_4_122_1_SMI1_df_Top_Text_and_No_Tweets.xlsx', header=True)

## NEED TO PLOT

# value_counts_text

print('---')
print('Most Common Tweet value_counts_text_df')
# print(df_value_counts_text_df.head)
print('---')

## NEED TO DO FAVS AND Retweets FOR THEM!!!

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Text Value Counts')
# plt.plot(df_value_counts_text_df[:10], alpha=0.9)
plt.xlabel('Text')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_121_SMI1_Most_Common_Text_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Text Value Counts - Pie')
# df_value_counts_text_df[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
# plt.legend(df_value_counts_text_df, loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_43_121_SMI1_Most_Common_Text_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Text Value Counts - Bars')
# df_value_counts_text_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Text')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_121_SMI1_Most_Common_Text_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

# del df_value_counts_text
# del df_value_counts_text_df


####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Common Hashtags

top_hashtags_tweets_df  = pd.value_counts(tweets_smi_1['hashtags'], ascending=False, normalize=True).to_frame()
# top_hashtags_tweets_df[['item','count']] = top_hashtags_tweets_df.str.split(" ", expand=True)

## NEED TO PLOT

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

top_hashtags_tweets_df.to_csv('4_4_43_123_1_SMI1_df_Value_Counts_Hashtags_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# top_hashtags_tweets_df.to_excel('4_4_43_123_1_SMI1_df_Value_Counts_Hashtags_and_No_Tweets.xlsx', header=True)


print('---')
print('---Most Common Hashtags 1 HEAD')
print(top_hashtags_tweets_df.head)
print('---')

print('---')
print('---Most Common Hashtags 1 DTYPES')
print(top_hashtags_tweets_df.dtypes)
print('---')

# TABLE AND FRAME DF NEED TO DO 

# MOST FREQUENT HASHTAGS IN Tweets

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Hashtags')
top_hashtags_tweets_df[:10].plot(alpha=0.9)
plt.xlabel('Most Repeated / Shared / Hashtags')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_123_1_SMI1_10_Most_Repeteaded_Hashtags_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Mentions - Pie')
# plt.pie(top_hashtags_tweets_df[:10], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, alpha=0.9, startangle=90)
# plt.pie(top_hashtags_tweets_df[:10], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(top_hashtags_tweets_df, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_123_1_SMI1_10_Most_Repeteaded_Hashtags_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars

# TOP NUMBERS OF HASHTAGS IN Tweets 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Hashtags - Bars')
top_hashtags_tweets_df[:10].plot.bar(alpha=0.9)
plt.xticks(rotation=50)
plt.xlabel('Hashtags')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_124_2_SMI1_Top_Tweet_Hashtags_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('tweets_smi_1 Text HEAD 1A')
print(tweets_smi_1['text'].head)
# print(tweets_smi_1['text'].dtypes)
print('-----------------------------------------------------------------------')


####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Common Tweet Mentions

top_mentions_tweets_df = pd.value_counts(tweets_smi_1['mentions'], ascending=False, normalize=True).to_frame()
# top_mentions_tweets_df[['item','count']] = top_mentions_tweets_df.str.split(" ", expand=True)

print('---')
print('Most Common Tweet Mentions')
# print(pd.value_counts(tweets_smi_1['mentions']).head)
print('---')

top_mentions_tweets_df.to_csv('4_4_148_SMI1_Top_Mentions_Tweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
#.to_ excel()

# TABLE PLOT NEED TO DO 

# Pie ###### NEED TO DO

# Bars

# TOP NUMBERS OF MENTIONS IN Tweets 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Mentions')
top_mentions_tweets_df[:10].plot(alpha=0.9)
plt.xlabel('Mentions')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_148_SMI1_Top_Tweet_Mentions_Number_Tweets_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Mentions - Pie')
# plt.pie(top_mentions_tweets_df[:10], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, alpha=0.9, startangle=90)
# plt.pie(top_mentions_tweets_df[:10], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(top_mentions_tweets_df, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_148_SMI1_Top_Tweet_Mentions_Number_Tweets_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Mentions - Bars')
top_mentions_tweets_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Mentions')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_148_SMI1_Top_Tweet_Mentions_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Commons Emojis Unicode

top_emojis_unicode_tweets_df = pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True).to_frame()
# top_emojis_unicode_tweets_df[['item','count']] = top_emojis_unicode_tweets_df.str.split(" ", expand=True)

print('---')
print('Most Commons Emojis Unicode')
print(top_emojis_unicode_tweets_df.head)
print('---')


top_emojis_unicode_tweets_df.to_csv('4_4_150_SMI1_Top_emojis_unicode_tweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis')
# plt.plot(top_emojis_unicode_tweets_df[:10], alpha=0.9)
plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_150_SMI1_Top_Tweet_Emojis_Unicode_Number_Tweets_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# TOP NUMBERS OF EMOJIS UNICODE IN Tweets 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis - Pie')
# plt.pie(top_emojis_unicode_tweets_df[:10], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, alpha=0.9, startangle=90)
# plt.pie(top_emojis_unicode_tweets_df[:10], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(top_emojis_unicode_tweets_df, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_150_SMI1_Top_Tweet_Emojis_Unicode_Number_Tweets_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis - Bars')
# top_emojis_unicode_tweets_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_150_SMI1_Top_Tweet_Emojis_Unicode_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################################

## nEED TO DO --------- FAVS AND RTS!!!####################################################################################################################

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Commons Emojis Unicode

top_emojis_unicode_tweets_df = pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True).to_frame()
# top_emojis_unicode_tweets_df[['item','count']] = top_emojis_unicode_tweets_df.str.split(" ", expand=True)

print('---')
print('Most Common Emojis - Unicode')
print(top_emojis_unicode_tweets_df.head)
print('---')

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

top_emojis_unicode_tweets_df.to_csv('4_4_151_SMI1_df_Top_Emojis_Unicode_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# top_emojis_unicode_tweets_df.to_excel('4_4_151_SMI1_df_Top_Emojis_Unicode_and_No_Tweets.xlsx', header=True)


## NEED TO PLOT


# TOP NUMBERS OF EMOJIS CONVERTED IN Tweets 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis')
top_emojis_unicode_tweets_df[:10].plot(alpha=0.9)
plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_151_SMI1_Top_Tweet_Emojis_Unicode_Number_Tweets_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis - Pie')
# plt.pie(top_emojis_unicode_tweets_df[:10], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, alpha=0.9, startangle=90)
# plt.pie(top_emojis_unicode_tweets_df[:10], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(top_emojis_converted_tweets_df, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_151_SMI1_Top_Tweet_Emojis_Unicode_Number_Tweets_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BARS

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis Graphics - Bars')
top_emojis_unicode_tweets_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_151_SMI1_Top_Tweet_Emojis_Unicode_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Commons Emojis Converted

top_emojis_converted_tweets_df = pd.value_counts(tweets_smi_1['emojis_converted'], ascending=False, normalize=True).to_frame()
# top_emojis_converted_tweets_df[['item','count']] = top_emojis_converted_tweets_df.str.split(" ", expand=True)

print('---')
print('Most Common Emojis - Converted')
print(top_emojis_converted_tweets_df.head)
print('---')


# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

top_emojis_converted_tweets_df.to_csv('4_4_151_SMI1_df_Top_Emojis_Converted_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# top_emojis_converted_tweets_df.to_excel('4_4_151_SMI1_df_Top_Emojis_Converted_and_No_Tweets.xlsx', header=True)


## NEED TO PLOT


# TOP NUMBERS OF EMOJIS CONVERTED IN Tweets 

# PLOT


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis')
top_emojis_converted_tweets_df[:10].plot(alpha=0.9)
plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_151_SMI1_Top_Tweet_Emojis_Converted_Number_Tweets_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis - Pie')
# plt.pie(top_emojis_converted_tweets_df[:10], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, alpha=0.9, startangle=90)
# plt.pie(top_emojis_converted_tweets_df[:10], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(top_emojis_converted_tweets_df, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_151_SMI1_Top_Tweet_Emojis_Converted_Number_Tweets_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis - Bars')
top_emojis_converted_tweets_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_151_SMI1_Top_Tweet_Emojis_Converted_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Common Tweet Languages

top_languages_tweets_df = pd.value_counts(tweets_smi_1['language'], ascending=False, normalize=True).to_frame()

## NEED TO PLOT

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

top_languages_tweets_df.to_csv('4_4_156_SMI1_df_Top_Language_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# top_languages_tweets_df.to_excel('4_4_156_SMI1_df_Top_Language_and_No_Tweets.xlsx', header=True)

print('---')
print('Most Common Tweet Languages HEAD')
print(top_languages_tweets_df.head)
print('---')

print('---')
print('Most Common Tweet Languages DTYPES')
print(top_languages_tweets_df.dtypes)
print('---')


## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Languages Used')
top_languages_tweets_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Language')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_156_SMI1_Top_Tweet_Languages_Number_Tweets_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Tweets Languages - Pie')
# plt.pie(top_languages_tweets_df[:10], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, alpha=0.9, startangle=90)
# plt.pie(top_languages_tweets_df[:10], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(top_languages_tweets_df, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_156_SMI1_Value_Counts_Tweets_Language_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars

# TOP NUMBERS OF LANGUAGE IN Tweets 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Languages Used - Bars')
top_languages_tweets_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Language')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_156_SMI1_Top_Tweet_Languages_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################

# PERCENTAGE OF Tweets BY TOP USERS

percentage_tweets_screenname = (tweets_smi_1['screenName'].value_counts(normalize=True)) # * 100)
percentage_tweets_screenname

print('---')
print('Percentage of Tweets by Top Users - ScreenName')
print(percentage_tweets_screenname.head)
print('---')

percentage_tweets_screenname_df = pd.DataFrame(percentage_tweets_screenname)

percentage_tweets_screenname_df.to_csv('4_4_157_SMI1_Percentage_Tweets_Screenname_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets by ScreenName - Pie')
# plt.pie(percentage_tweets_screenname[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentage_tweets_screenname[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90 , explode = explode_pie_6)
plt.legend(percentage_tweets_screenname, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.) 

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_157_SMI1_Percentage_Tweets_ScreenName_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

# PERCENTAGE OF Tweets WITH Retweets

percentage_tweets_retweets = (tweets_smi_1['retweets'].value_counts(normalize=True) * 100)

print('---')
print('Percentage of Tweets with Retweets')
print(percentage_tweets_retweets.head)
print('---')

percentage_tweets_retweets_df = pd.DataFrame(percentage_tweets_retweets)

percentage_tweets_retweets_df.to_csv('4_4_158_SMI1_Percentage_Tweets_Retweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Retweets - Pie')
# plt.pie(percentage_tweets_retweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentage_tweets_retweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.legend(percentage_tweets_retweets[0:], bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.) 

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_158_SMI1_Percentage_Tweets_Retweets_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

# PERCENTAGE OF Tweets WITH HASHTAGS

percentage_tweets_hashtags = (tweets_smi_1['hashtags'].value_counts(normalize=True) * 100)
percentage_tweets_hashtags

print('---')
print('Percentage of Tweets with Hashtags')
# print(percentage_tweets_hashtags.head(1))
print('---')

percentage_tweets_hashtags_df = pd.DataFrame(percentage_tweets_hashtags)

percentage_tweets_hashtags_df.to_csv('4_4_159_SMI1_Percentage_Tweets_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Hashtags - Pie')
# plt.pie(percentage_tweets_hashtags[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentage_tweets_hashtags[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.legend(percentage_tweets_hashtags, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_159_SMI1_Percentage_Tweets_Hashtags_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

percentage_tweets_emojis_unicode = (tweets_smi_1['emojis_unicode'].value_counts(normalize=True) * 100)
percentage_tweets_emojis_unicode

# PERCENTAGE OF Tweets WITH EMOJIS_UNICODE


print('---')
print('Percentage of Tweets with Emojis - Unicode')
# print(percentage_tweets_emojis_unicode.head)
print('---')


## NEED TO PLOT 

percentage_tweets_emojis_unicode_df = pd.DataFrame(percentage_tweets_emojis_unicode)

percentage_tweets_emojis_unicode_df.to_csv('4_4_200_SMI1_Percentage_Tweets_Emojis_Unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Emojis - Pie')
# plt.pie(percentage_tweets_emojis_unicode[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentage_tweets_emojis_unicode[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.legend(percentage_tweets_emojis_unicode, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_200_SMI1_Percentage_Tweets_Emojis_Unicode_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

print('------------------')
print('TEXT HEAD 1B')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')

########################################################################################################

# PERCENTAGE OF Tweets WITH EMOJIS_CONVERTED

percentage_tweets_emojis_converted = (tweets_smi_1['emojis_converted'].value_counts(normalize=True) * 100)
percentage_tweets_emojis_converted

print('---')
print('Percentage of Tweets with Emojis Converted')
# print(percentage_tweets_emojis_converted.head)
print('---')


percentage_tweets_emojis_converted_df = pd.DataFrame(percentage_tweets_emojis_converted)

percentage_tweets_emojis_converted_df.to_csv('4_4_201_SMI1_Percentage_Tweets_Emojis_Converted_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Emojis - Pie')
# plt.pie(percentage_tweets_emojis_converted[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentage_tweets_emojis_converted[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.legend(percentage_tweets_emojis_converted, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_201_SMI1_Percentage_Tweets_Emojis_Converted_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO


########################################################################################################

# PERCENTAGE OF LANGUAGES

percentage_tweets_languages = (tweets_smi_1['language'].value_counts(normalize=True) * 100)
percentage_tweets_languages

print('---')
print('Percentage of Tweets Languages')
# print(percentage_tweets_languages.head)
print('---') 

percentage_tweets_languages_df = pd.DataFrame(percentage_tweets_languages)

percentage_tweets_languages_df.to_csv('4_4_203_SMI1_Percentage_Tweets_Languages_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets Languages - Pie')
# plt.pie(percentages_tweets_languages[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentage_tweets_languages[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.legend(percentage_tweets_languages, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_205_SMI1_Percentage_Tweets_Languages_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO


# PONER QUI :P :PS QUE QUITE PIES 


###############################################################################################################

print('-- NEED TO DO FAVS AND Retweets PER LANGUAGE!!!')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


print('----------')
print('TEXT HEAD 3C')
print(tweets_smi_1['text'].head)
print('-----------------------------------')

###############################################################################################################
#################################################################################################################

# Groupby by ######################################### NEED TO DO NOT WORKING!!!!!!!!

smi1_screenname = tweets_smi_1.groupby('screenName')
smi1_dates = tweets_smi_1.groupby('created')
smi1_created = tweets_smi_1.groupby('created')
smi1_favorites = tweets_smi_1.groupby('favorites')
smi1_retweets = tweets_smi_1.groupby('retweets')
smi1_text = tweets_smi_1.groupby('text')
smi1_hashtags = tweets_smi_1.groupby('hashtags')
smi1_hashtags = tweets_smi_1['hashtags_total']
smi1_mentions = tweets_smi_1.groupby('mentions')
smi1_mentions = tweets_smi_1['mentions_total']
smi1_emojis_unicode = tweets_smi_1.groupby('emojis_unicode')
smi1_emojis_converted = tweets_smi_1.groupby('emojis_converted')
smi1_languages = tweets_smi_1.groupby('language')

# smi1_screenname = pd.groupby(df['screenName'])
# smi1_created = pd.groupby(df['created'])
# smi1_favorites = pd.groupby(df['favorites'])
# smi1_retweets = pd.groupby(df['retweets'])
# smi1_text = pd.groupby(df['text'])
# smi1_hashtags = pd.groupby(df['hashtags'])
# smi1_mentions = pd.groupby(df['mentions'])
# smi1_image_link = pd.groupby(df['image_link'])
# smi1_emojis_unicode = pd.groupby(df['emojis_unicode'])
# smi1_emojis_converted = pd.groupby(df['emojis_converted'])
# smi1_language = pd.groupby(df['language'])

# print('-- grouped terms')

#################################################################################################################
#################################################################################################################

# screenName author_id created	retweets Favorites text	latitude longitude mentions hashtags id	url emojis_unicode emojis_converted image_link	language

###################################################################################################################


# SMIS Processing / DATA ANALYSIS QUANTITATIVE AND STATISTICS

# Read dataset and store into DataFrame
## IMPORTING CREATED AS STR / INT TO LOWER MEMORY USE!!!!!!!!

# Define date as datetime objects

# pd.read_csv(smi_file_4_4, sep='\t', names=['screenName', 'author_id', 'created', 'retweets', 'favorites', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', 'id', 'url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language'], parse_dates=['created'], date_parser=mydateparser)

# tweets_smi_1 = pd.read_csv(smi_file_4_4, sep='\t', encoding='utf-8', parse_dates=[4], infer_datetime_format=False, date_parser=mydateparser, dtype={'screenName': 'str', 'author_id': 'int', 'retweets': 'int', 'favorites': 'int', 'text': 'str', 'latitude': 'str', 'longitude': 'str', 'mentions': 'str', 'hashtags': 'str', 'id': 'int', 'url': 'str', 'emojis_unicode': 'str', 'emojis_converted': 'str', 'image_link': 'str', 'language': 'str'}, header=0)
# tweets_smi_1 = pd.read_csv(smi_file_4_4, sep='\t', encoding='utf-8', parse_dates=['created'], infer_datetime_format=True, dtype={'screenName': 'str', 'author_id': 'int', 'created': int64[d], 'retweets': 'int', 'favorites': 'int', 'text': 'str', 'latitude': 'str', 'longitude': 'str', 'mentions': 'str', 'hashtags': 'str', 'id': 'int', 'url': 'str', 'emojis_unicode': 'str', 'emojis_converted': 'str', 'image_link': 'str', 'language': 'str'}, header=0)
# tweets_smi_1 = pd.read_csv(smi_file_4_4, sep='\t', encoding='utf-8', infer_datetime_format=False, dtype={'screenName': 'str', 'author_id': 'int', 'created': [pd.Timestamp('mydateparser')], 'retweets': 'int', 'favorites': 'int', 'text': 'str', 'latitude': 'str', 'longitude': 'str', 'mentions': 'str', 'hashtags': 'str', 'id': 'int', 'url': 'str', 'emojis_unicode': 'str', 'emojis_converted': 'str', 'image_link': 'str', 'language': 'str'}, header=0)
# tweets_smi_1 = pd.read_csv(smi_file_4_4, sep='\t', encoding='utf-8', parse_dates=True, dtype={'screenName': 'str', 'author_id': 'int', 'retweets': 'int', 'favorites': 'int', 'text': 'str', 'latitude': 'str', 'longitude': 'str', 'mentions': 'str', 'hashtags': 'str', 'id': 'int', 'url': 'str', 'emojis_unicode': 'str', 'emojis_converted': 'str', 'image_link': 'str', 'language': 'str'}, header=0, error_bad_lines=False, warn_bad_lines=False, low_memory=True, memory_map=True, float_precision=None)
# tweets_smi_1 = codecs.open(smi_file_4_4, 'r', 'utf-8')
tweets_smi_1 = pd.read_csv(smi_file_4_4, sep='\t', encoding='utf-8', parse_dates=True, header=0, cache_dates=True, low_memory=True, memory_map=True)
# tweets_smi_1 = pd.read_excel(smi_file_4_4, parse_dates=True, sort=False)
# tweets_smi_1 = csv.reader(smi_file_4_4, delimiter='\t', encoding='utf-8')
# tweets_smi_1 = pd.read_csv(smi_file_4_4, sep='\t', encoding='utf-8', header=0, low_memory=False)
# tweets_smi_1 = pd.DataFrame(dtype={'screenName': 'str', 'author_id': 'int', 'created': pd.Timestamp('x, "%Y-%m-%d %H:%M:%S'), 'retweets': 'int', 'favorites': 'int', 'text': 'str', 'latitude': 'str', 'longitude': 'str', 'mentions': 'str', 'hashtags': 'str', 'id': 'int', 'url': 'str', 'emojis_unicode': 'str', 'emojis_converted': 'str', 'image_link': 'str', 'language': 'str'}, header=0)})
# tweets_smi_1 = pd.read_csv(smi_file_4_4, sep='\t', encoding='utf-8', parse_dates=False, infer_datetime_format=False, dtype={'screenName': 'str', 'author_id': 'int', 'created': 'int64, 'retweets': 'int', 'favorites': 'int', 'text': 'str', 'latitude': 'str', 'longitude': 'str', 'mentions': 'str', 'hashtags': 'str', 'id': 'int', 'url': 'str', 'emojis_unicode': 'str', 'emojis_converted': 'str', 'image_link': 'str', 'language': 'str'}, header=0)
# tweets_smi_1 = pd.read_csv(smi_file_4_4, sep='\t', encoding='utf-8', low_memory=False, dtype=str)

#################################################################################################################
###################################

tweets_smi_1['favorites'] = tweets_smi_1['favorites'].fillna(0)
tweets_smi_1['retweets'] = tweets_smi_1['retweets'].fillna(0)
# tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].fillna(0)
# tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].fillna(0)

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].astype(str, errors='ignore')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].astype(str, errors='ignore')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int32, errors='ignore')
# tweets_smi_1['favorites'] = int(tweets_smi_1['favorites'])
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int32, errors='ignore')
# tweets_smi_1['retweets'] = int(tweets_smi_1['retweets'])
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(np.int64, errors='ignore')
# tweets_smi_1['followers_count'] = int(tweets_smi_1['followers_count'])
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(np.int64, errors='ignore')
# tweets_smi_1['followers_count'] = int(tweets_smi_1['followers_count'])

# tweets_smi_1['created'] = pd.to_datetime(tweets_smi_1['created'])
# tweets_smi_1['created'] = tweets_smi_1['created'].to_datetime()

# FINAL FIXES 

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].to_string()
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].to_string()
# # # tweets_smi_1['location'] = tweets_smi_1['location'].to_string()
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].to_string()
# tweets_smi_1['text'] = tweets_smi_1['text'].to_string()
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].to_string()

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\"', ' ', regex=True)
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\'', ' ', regex=True)
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('nan', 'undefined')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace(',', ' ')

# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('[', '', regex=True)
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace(']', '', regex=True)
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\"', ' ', regex=True)
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\"', '', regex=True)
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\'', '', regex=True)
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('nan', 'undefined')

# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\"', ' ', regex=True)
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\'', ' ', regex=True)
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace(']', ' ', regex=True)
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('[', ' ', regex=True)
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('nan', 'undefined')

# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('nan', 'undefined')

# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('"', ' ', regex=True)
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\'', ' ', regex=True)
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(']', ' ', regex=True)
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('[', ' ', regex=True)
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('@', ' ', regex=True)
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('!', ' ', regex=True)

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace('nan', 'undefined')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace(']', ' ')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace('[', ' ')

# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.replace('nan', 'undefined')

# tweets_smi_1['emojis_unicode'] = emoji.emojize(tweets_smi_1['emojis_unicode'])

tweets_smi_1['text'] = tweets_smi_1['text'].fillna('')
tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].fillna('NONE')
tweets_smi_1['mentions'] = tweets_smi_1['mentions'].fillna('NONE')
tweets_smi_1['geo'] = tweets_smi_1['geo'].fillna('NONE')
tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].fillna('NONE')
tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].fillna('NONE')


# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('NaN', ' ', regex=True)

print('---')
print(tweets_smi_1.head(10))
print(tweets_smi_1.dtypes)
print('---')

print('---')
print('Mentions Head')
print(tweets_smi_1['mentions'].head(20))
print('---')

print('------------------')
print('TEXT HEAD 2B')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------------')


#########################################################################################

# ###############  NEED TO DO 

# tweets_smi_1 = pd.DataFrame(tweets_smi_1)

# tweets_smi_1 = pd.read_excel(wb)
# tweets_smi_1 = pd.read_excel(smi_file_4_4, parse_dates=['created'], sort=False)

# hashtags_total_1 = codecs.open(smi_file_4_4_hashtags_total, 'r', 'utf-8')
# missing_mentions_1 = codecs.open(smi_file_4_4_missing_mentions, 'r', 'utf-8')
# missing_mentions_with_smi_names_1 = codecs.open(smi_file_4_4_missing_mentions_with_smi_names, 'r', 'utf-8')

############## NEED TO DO MISSING EMOJIS

# missing_emojis_unicode_1 = codecs.open(smi_file_4_4_missing_emoji_unicode, 'r', 'utf-8')
# missing_image_link_1 = codecs.open(smi_file_4_4_missing_image_link, 'r', 'utf-8')

# hashtags_total_1 = pd.DataFrame(hashtags_total_1)
# missing_mentions_1 = pd.DataFrame(missing_mentions_1)
# missing_mentions_with_smi_names_1 = pd.DataFrame(missing_mentions_with_smi_names_1)
# missing_emojis_unicode_1 = pd.DataFrame(missing_emojis_unicode_1)
# missing_image_link_1 = pd.DataFrame(missing_image_link_1)

######################################################################################################################################

# ANALYSING THE DATA

# Retweets

#### NEED TO COMPLETE DATA: TAKE OUT MENTIONS, HASTAGS, SUMMARY EMOJI CODES WITH EMOTICONS, 
#### NEED FOLLOWER GROWTH OVER TIME GRAPHICS

# ANALYSING THE DATA

#### NEED TO COMPLETE DATA: TAKE OUT MENTIONS, HASTAGS, SUMMARY EMOJI CODES WITH EMOTICONS, 
#### NEED FOLLOWER GROWTH OVER TIME GRAPHICS

# FIX FORMATING OF PieS

# NEED TO LINK TO TWITTER R DATA AND GET LOCATION INFO

# NEED TO DO SAVE TABLES TO FILES

# CHECK ALL 'NEED TO DO'

###############################################################################################################

# REPLACE NANs in TEXT FIELD DF

tweets_smi_1['text'] = tweets_smi_1['text'].fillna('')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('NaN', '') # regex=True

#################################################################################################################

# Check Data Imported

tweets_shape = tweets_smi_1.shape # View number of rows and columms in a df

print('---')
print('Tweets Shape and Types')
print(tweets_smi_1.shape)
print(tweets_smi_1.dtypes)
print('---')

print('----------')
print('TEXT HEAD C')
print(tweets_smi_1['text'].head)
print('-----------------------------------')

#################################################################################################################
#################################################################################################################
#################################################################################################################

# SETTING COLOR MAPS ## NEED TO DO NOT WORKING 

# plt.rcParams['image.cmap']='PuBu_r'
# plt.set_cmap('PuBu_r')

plt.rcParams['image.cmap']='Blues'
plt.set_cmap('Blues')
plt.rcParams['figure.facecolor']='#6593F5'
plt.rcParams['figure.edgecolor']='white'
plt.interactive(False)
plt.ioff()

# def ioff():
#	matplotlib.interactive(False)
#	uninstall_repl_display_hook()

plt.rcParams['image.cmap']='GnBu'
plt.set_cmap('GnBu')

colors_blue = ['#73C2FB', '#6593F5', '#0F52BA', '#000080', 'blue', 'lightskyblue', 'blue']
explode_pie = (0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1)

# plt.rcParams['image.cmap']='#73C2FB'
# plt.set_cmap('colors_blue')

# figure.max_open_warning

font = FontProperties()
# font.set_family('serif')
font.set_name('Segoe UI Emoji')

# plt.rcParams.update({'font.size': 16})

# plt.rcParams['xtick']=labelsize=14)
# plt.rcParams['ytick']=labelsize=14)

axis_font = {'fontname':'Segoe UI Emoji', 'size': 10}

legend_font = {'fontname':'Segoe UI Emoji', 'size': 10}

sns.set(style='ticks')
# sns.palplot(sns.color_palette('GnBu_d'))
sns.palplot(sns.color_palette('Blues'))

#################################################################################################################
#################################################################################################################
#################################################################################################################


print('------------------')
print('TEXT HEAD 10-00')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')

# Groupby by ######################################### NEED TO DO NOT WORKING!!!!!!!!

# smi1_screenname = tweets_smi_1.groupby('screenName')
# smi1_dates = tweets_smi_1.groupby('created')
# smi1_created = tweets_smi_1.groupby('created')
# smi1_favorites = tweets_smi_1.groupby('favorites')
# smi1_retweets = tweets_smi_1.groupby('retweets')
# smi1_text = tweets_smi_1.groupby('text')
# smi1_hashtags = tweets_smi_1.groupby('hashtags')
# smi1_hashtags = hashtags_total_1
# smi1_mentions = tweets_smi_1.groupby('mentions')
# smi1_mentions = missing_mentions_1
# smi1_emojis_unicode = tweets_smi_1.groupby('emojis_unicode')
# smi1_emojis_converted = tweets_smi_1.groupby('emojis_converted')
# smi1_languages = tweets_smi_1.groupby('language')

# smi1_screenname = pd.groupby(df['screenName'])
# smi1_created = pd.groupby(df['created'])
# smi1_favorites = pd.groupby(df['favorites'])
# smi1_retweets = pd.groupby(df['retweets'])
# smi1_text = pd.groupby(df['text'])
# smi1_hashtags = pd.groupby(df['hashtags'])
# smi1_mentions = pd.groupby(df['mentions'])
# smi1_image_link = pd.groupby(df['image_link'])
# smi1_emojis_unicode = pd.groupby(df['emojis_unicode'])
# smi1_emojis_converted = pd.groupby(df['emojis_converted'])
# smi1_language = pd.groupby(df['language'])

# print('-- grouped terms')


print('------------------')
print('TEXT HEAD 10-02')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')

################################################################################################################
################################################################################################################

number_total_tweets = len(tweets_smi_1['created'])

print('---')
print('Variable number_total_tweets Number Total Tweets')
print(number_total_tweets)
print('---')

number_total_favorites = sum(tweets_smi_1['favorites'])
number_retweets = sum(tweets_smi_1['retweets'])

# Inicialize List of Lists

tweets_numbers_basic = [['number_total_tweets', number_total_tweets], ['Number_total_favorites', number_total_favorites], ['Number_retweets', number_retweets]]

# Create DataFrame

tweets_numbers_basic_df = pd.DataFrame(tweets_numbers_basic, columns =['tweets_by_item_description', 'tweets_by_number_value'])

tweets_numbers_basic_df.to_csv('4_4_37_SMI1_Tweets_Numbers_Basic_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_numbers_basic_df.to_excel('4_4_37_SMI1_Tweets_Numbers_Basic_DF.xlsx', header=True)



# COME MUCHA MEMORIA !!!

# tweets_smi_1['percentage_total_favorites'] = (tweets_smi_1['favorites'] * 100)/number_total_favorites

print('---')
print('Percentage total_favorites Head')
# print(tweets_smi_1['percentage_total_favorites'].head)
print('---')

# tweets_smi_1['percentage_retweets'] = (tweets_smi_1['retweets'] * 100)/number_retweets

print('---')
print('Percentage retweets Head')
# print(tweets_smi_1['percentage_retweets'].head)
print('---')


# XXX NEED TO DO NEED TO FIX NOT WORKING NEED TO ADD FIRNDS TO THESE OPERATIONS

print('---')
print('Percentage friends Head')
# print(tweets_smi_1['percentage_friends'].head)
print('---')

print('------------------')
print('TEXT HEAD 10-02A')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')

#################################################################################################################
#################################################################################################################
#################################################################################################################
#################################################################################################################


# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].to_string()
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].to_string()
# # # tweets_smi_1['location'] = tweets_smi_1['location'].to_string()

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace(',', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace(',', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(',', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace(',', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace(',', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace(',', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(',', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace(',', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace(',', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace(',', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(',', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace(',', '')

# REMOVE EXTRA WHITE SPACES

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('   ', ' ')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('   ', ' ')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('   ', ' ')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('   ', ' ')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('   ', ' ')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('   ', ' ')

# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('   ', ' ')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('  ', ' ')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('  ', ' ')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('  ', ' ')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('  ', ' ')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('  ', ' ')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('  ', ' ')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('  ', ' ')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('  ', ' ')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('  ', ' ')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('  ', ' ')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('  ', ' ')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('  ', ' ')

# EXTRA PUNCTUATION SIGNS 

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\\', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\\', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\\', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\\', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\\', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\\', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\\', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\\', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('!', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('!', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('!', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('!', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\?', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\?', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\?', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\?', '')


# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\.', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\.', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\.', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\.', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\.', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\.', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\.', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\.', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\*', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\*', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\*', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\*', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\*', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\*', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\*', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\*', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('{', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('{', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('{', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('{', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('}', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('}', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('}', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('}', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('^', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('^', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('^', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('^', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace(':', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace(':', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(':', '')
# # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace(':', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace(';', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace(';', '')

# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace(';', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str)

# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str)
# tweets_smi_1['location'] = str(tweets_smi_1['location'])
# # tweets_smi_1['location'] = tweets_smi_1['location'].astype(str)

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('~', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('~', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('~', '')
# # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('~', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('+', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('+', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('+', '')
# # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('+', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('-', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('-', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('-', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('-', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('=', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('=', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('=', '')
# # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('=', '')

# tweets_smi_1['text'] = str(tweets_smi_1['text'])
# tweets_smi_1['hashtags'] = str(tweets_smi_1['hashtags'])
# tweets_smi_1['mentions'] = str(tweets_smi_1['mentions'])

print('------------------')
print('TEXT HEAD MED')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')


# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('_', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('_', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('_', '')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('_', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\)', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\)', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\)', '')
# # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\)', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\(', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\(', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\(', '')
# # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\(', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('<', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('<', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('<', '')
# # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('<', '')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('>', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('>', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('>', '')
# # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('>', '')

# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].to_string()

# tweets_smi_1['missing_country'] = tweets_smi_1['location']  # NEED TO FIX NOT WORKING TEMPORARY VARIABLE TEMP


# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\]', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\[', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('  ', ' ')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\"', '', regex=True)
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\'', '', regex=True)
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('nan', 'undefined')

# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\]', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\[', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('  ', ' ')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\"', '', regex=True)
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\'', '', regex=True)
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('nan', 'undefined')

# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\]', '') # NEED TO FIX NOT WORKING VOY A DEJAR EL TEXTO CON ESTO INFLUYE??[ ] 
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\[', '')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('  ', ' ')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\"', '', regex=True)
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\'', '', regex=True)
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('nan', 'undefined')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('"', '', regex=True)
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\'', '', regex=True)
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(']', '', regex=True)
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('[', '', regex=True)
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('@', '', regex=True)
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('!', '', regex=True)

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace(']', '')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace('[', '')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace('  ', ' ')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace('nan', 'undefined')

##
##
# tweets_smi_1['emojis_unicode'] = emoji.emojize(tweets_smi_1['emojis_unicode'])
##
##

# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.replace('\]', '')
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.replace('\[', '')
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.replace('  ', ' ')
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.replace('nan', 'undefined')

# # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\]', '')
# # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\[', '')
# # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('-', ' ')
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\"', '', regex=True)
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('\'', '', regex=True)
# # # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace('nan', 'undefined')

# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('nan', 'undefined')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(str, errors='ignore')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore')
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(str, errors='ignore')
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(str, errors='ignore')
# # tweets_smi_1['followers'] = tweets_smi_1['followers'].astype(str, errors='ignore')
# # tweets_smi_1['following'] = tweets_smi_1['following'].astype(str, errors='ignore')
# tweets_smi_1['total_tweets'] = tweets_smi_1['total_tweets'].astype(str, errors='ignore')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(str, errors='ignore')
# # tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(str, errors='ignore')
# tweets_smi_1['lists'] = tweets_smi_1['lists'].astype(str, errors='ignore')

# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].str.replace('-', '').astype(str, errors='ignore')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].str.replace('\-', '').astype(str, errors='ignore')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].str.replace('\.0', '').astype(str, errors='ignore')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].str.replace('scott', '').astype(str, errors='ignore')

# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].str.replace('-', '').astype(str, errors='ignore')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].str.replace('\-', '').astype(str, errors='ignore')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].str.replace('\.0', '').astype(str, errors='ignore')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].str.replace('scott', '').astype(str, errors='ignore')

# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].str.replace('-', '').astype(str, errors='ignore')
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].str.replace('\-', '').astype(str, errors='ignore')
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].str.replace('\.0', '').astype(str, errors='ignore')
# # tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].str.replace('scott', '').astype(str, errors='ignore')

# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].str.replace('-', '').astype(str, errors='ignore')
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].str.replace('\-', '').astype(str, errors='ignore')
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].str.replace('\.0', '').astype(str, errors='ignore')
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].str.replace('scott', '').astype(str, errors='ignore')

# # tweets_smi_1['followers'] = tweets_smi_1['followers'].str.replace('-', '').astype(str, errors='ignore')
# # tweets_smi_1['followers'] = tweets_smi_1['followers'].str.replace('\-', '').astype(str, errors='ignore')
# # tweets_smi_1['followers'] = tweets_smi_1['followers'].str.replace('\.0', '').astype(str, errors='ignore')
# # tweets_smi_1['followers'] = tweets_smi_1['followers'].str.replace('scott', '').astype(str, errors='ignore')

# # tweets_smi_1['following'] = tweets_smi_1['following'].str.replace('-', '').astype(str, errors='ignore')
# # tweets_smi_1['following'] = tweets_smi_1['following'].str.replace('\-', '').astype(str, errors='ignore')
# # tweets_smi_1['following'] = tweets_smi_1['following'].str.replace('\.0', '').astype(str, errors='ignore')
# # tweets_smi_1['following'] = tweets_smi_1['following'].str.replace('scott', '').astype(str, errors='ignore')


# tweets_smi_1['total_tweets'] = tweets_smi_1['total_tweets'].str.replace('-', '').astype(str, errors='ignore')
# tweets_smi_1['total_tweets'] = tweets_smi_1['total_tweets'].str.replace('\-', '').astype(str, errors='ignore')
# tweets_smi_1['total_tweets'] = tweets_smi_1['total_tweets'].str.replace('\.0', '').astype(str, errors='ignore')
# tweets_smi_1['total_tweets'] = tweets_smi_1['total_tweets'].str.replace('scott', '').astype(str, errors='ignore')


# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].str.replace('-', '').astype(str, errors='ignore')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].str.replace('\-', '').astype(str, errors='ignore')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].str.replace('\.0', '').astype(str, errors='ignore')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].str.replace('scott', '').astype(str, errors='ignore')

# # tweets_smi_1['retweets'] = tweets_smi_1['retweets'].str.replace('-', '').astype(str, errors='ignore')
# # tweets_smi_1['retweets'] = tweets_smi_1['retweets'].str.replace('\-', '').astype(str, errors='ignore')
# # tweets_smi_1['retweets'] = tweets_smi_1['retweets'].str.replace('\.0', '').astype(str, errors='ignore')
# # tweets_smi_1['retweets'] = tweets_smi_1['retweets'].str.replace('scott', '').astype(str, errors='ignore')

# tweets_smi_1['lists'] = tweets_smi_1['lists'].str.replace('-', '').astype(str, errors='ignore')
# tweets_smi_1['lists'] = tweets_smi_1['lists'].str.replace('\-', '').astype(str, errors='ignore')
# tweets_smi_1['lists'] = tweets_smi_1['lists'].str.replace('\.0', '').astype(str, errors='ignore')
# tweets_smi_1['lists'] = tweets_smi_1['lists'].str.replace('scott', '').astype(str, errors='ignore')


# tweets_smi_1['text'] = tweets_smi_1['text'].to_string()
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].to_string()

# tweets_smi_1['text'] = str(tweets_smi_1['text'])
# tweets_smi_1['emojis_unicode'] = str(tweets_smi_1['emojis_unicode'])
# tweets_smi_1['geo'] = str(tweets_smi_1['geo'])
# tweets_smi_1['emoticons'] = str(tweets_smi_1['emoticons'])

# tweets_smi_1['location'] = str(tweets_smi_1['location'])
# tweets_smi_1['hashtags'] = str(tweets_smi_1['hashtags'])
# tweets_smi_1['mentions'] = str(tweets_smi_1['mentions'])

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore')

# tweets_smi_1['emoticons'] = tweets_smi_1['emoticons'].astype(str, errors='ignore')

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str, errors='ignore')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str, errors='ignore')

#################################################################################################################
#################################################################################################################
###

# UNIVARIATE DATA ANALYS

print('------------------')
print('TEXT HEAD 10-03')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')

##########################################################################################################
#####


plt.close(fig='all')
plt.clf()

##########################################################################################################################
###############################################################################################################


# METHOD 1 MENTIONS_TOTAL

fp_mentions_total = tweets_smi_1['mentions_total'].to_string()

# fp_mentions_total = fp_mentions_total_temp.to_string()

tweets_text_mentions_total = nltk.word_tokenize(fp_mentions_total)

value_counts_mentions_total = pd.value_counts(tweets_text_mentions_total, ascending=False, normalize=True) 

smi1_value_counts_mentions_total = value_counts_mentions_total.sort_values(ascending=False)

# smi1_value_counts_mentions_total_freq_dist = tweets_text_mentions_total.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts mentions_total - Frequency')
# print(smi1_value_counts_mentions_total.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Mentions Total')
print(smi1_value_counts_mentions_total.describe().head)
print('---')

smi1_value_counts_mentions_total_df = pd.DataFrame(smi1_value_counts_mentions_total, columns=['mentions_total_frequency'])

smi1_value_counts_mentions_total_df.to_csv('4_4_43_100_SMI1_Value_Counts_Mentions_Total_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_mentions_total_df.to_excel('4_4_43_100_SMI1_Value_Counts_Mentions_total_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts')
plt.plot(smi1_value_counts_mentions_total[:10], alpha=0.9)
plt.xlabel('Mentions')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Mentions_Total_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))     ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Pie')
smi1_value_counts_mentions_total[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True, subplots=True)
# ax1.pie(explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90, colors=colors_blue)
plt.legend(smi1_value_counts_mentions_total, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_mentions_total_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Bars')
smi1_value_counts_mentions_total[:10].plot.bar(alpha=0.9)
plt.xlabel('Mentions')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_mentions_total_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# List MISSING Unique Mentions ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!


mentions_total_1 = tweets_smi_1['mentions_total']
missing_unique_mentions = mentions_total_1.unique()

missing_number_unique_mentions = len(missing_unique_mentions)
missing_number_unique_mentions

print('---')
print('Missing Unique Number of Mentions')
print(missing_number_unique_mentions)
print('---')

missing_number_unique_mentions_df = pd.DataFrame([missing_number_unique_mentions])

missing_number_unique_mentions_df.to_csv('4_4_43_190_SMI1_Missing_Number_Unique_Mentions_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Mentions')
plt.plot(missing_number_unique_mentions_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
# splt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_190_SMI1_Missing_Number_Unique_Mentions_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Mentions - Bars')
missing_number_unique_mentions_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_190_SMI1_Missing_Number_Unique_Mentions_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# List Unique MISSING Hashtags ######################################

# NEED TO GET HASTAGS AND MENTIONS!!!!!!

missing_unique_hashtags = tweets_smi_1['hashtags_total'].unique()

missing_number_unique_hashtags = len(missing_unique_hashtags)
missing_number_unique_hashtags

print('---')
print('Missing Unique Hashtags')
# print(missing_number_unique_hashtags)
print('---')

missing_number_unique_hashtags_df = pd.DataFrame([missing_number_unique_hashtags])

missing_number_unique_hashtags_df.to_csv('4_4_43_SMI1_Missing_Number_Unique_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Hashtags')
plt.plot(missing_number_unique_hashtags_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_188_SMI1_Missing_Number_Unique_Hashtags_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Hashtags - Bars')
missing_number_unique_hashtags_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_188_SMI1_Missing_Number_Unique_Hashtags_DF_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()




print('-- done quant processing 3 - analysis 1')
print(' -- NEED TO DO : SMIS Processing / DATA ANALYSIS QUANTITATIVE AND STATISTICS - SNA - CLUSTER ANALYSIS')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')  



##########################################################################################################################
##########################################################################################################################
##########################################################################################################################



###################################################################################################
###################################################################################################
###################################################################################################
###################################################################################################
###################################################################################################

# List Total total_favorites ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!

number_total_favorites = tweets_smi_1['favorites'].sum()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('List Total Favorites')
# print(number_total_favorites.head)
print('---')

number_total_favorites_df = pd.DataFrame([number_total_favorites], columns=['number_total_favorites'])

number_total_favorites_df.to_csv('4_4_43_SMI1_Number_Total_Total_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# number_total_favorites_df.to_excel()

number_total_favorites_year = tweets_smi_1.groupby(['year'])['favorites'].sum()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


print('---')
print('List Total total_favorites Year')
# print(number_total_favorites_year.head)
print('---')

number_total_favorites_year_df = pd.DataFrame([number_total_favorites_year], columns=['number_total_favorites_year'])

number_total_favorites_year_df.to_csv('4_4_43_SMI1_Number_Total_Total_Favorites_Year_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# number_total_favorites_df.to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Favorites - Year')
plt.ioff()
number_total_favorites_year_df.plot()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Total_Favorites_Year_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Favorites - Pie')
plt.ioff()
# plt.pie(tweet_info_followers_df['number_total_favorites_df'], labels=number_total_favorites_df)
# plt.pie(number_total_favorites['number_total_favorites_df'], labels=number_total_favorites, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=number_total_favorites, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Total_Favorites_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Favorites - Bars')
number_total_favorites_year_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Total_Favorites_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###################################################################################################

# List Total retweets ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!


number_retweets = tweets_smi_1['retweets'].sum()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


print('---')
print('List Total retweets')
# print(number_retweets.head)
print('---')

number_retweets_df = pd.DataFrame([number_retweets], columns=['number_retweets'])

number_retweets_df.to_csv('4_4_43_SMI1_Number_Total_Total_Retweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# number_retweets_df.to_excel()

number_retweets_year = tweets_smi_1.groupby(['year'])['retweets'].sum()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


print('---')
print('List Total retweets Year')
# print(number_retweets_year.head)
print('---')

number_retweets_year_df = pd.DataFrame([number_retweets_year], columns=['number_retweets_year'])

number_retweets_year_df.to_csv('4_4_43_SMI1_Number_Total_Total_Retweets_Year_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# number_retweets_df.to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Retweets - Year')
plt.ioff()
number_retweets_year_df.plot()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Total_Retweets_Year_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Retweets - Pie')
plt.ioff()
# plt.pie(tweet_info_followers_df['number_retweets_df'], labels=number_retweets_df)
# plt.pie(number_retweets['number_retweets_df'], labels=number_retweets, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=number_retweets, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Total_Retweets_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Retweets - Bars')
number_retweets_year_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Total_Retweets_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#######################################################################################################
#######################################################################################################
#######################################################################################################
#######################################################################################################
#######################################################################################################
#######################################################################################################



print('-- NEED TO DO: SAVE TO CSV AND PRINT TABLES')

# NEED TO PLOT TABLE


#################################################################################################################

# Measures of Correlation Between Pairs of Data

# You�ll often need to examine the relationship between the corresponding elements of two variables in a dataset. Say there are two variables, ?? and ??, with an equal number of elements, ??. Let ??1 from ?? correspond to ??1 from ??, ??2 from ?? to ??2 from ??, and so on. You can then say that there are ?? pairs of corresponding elements: (??1, ??1), (??2, ??2), and so on.

# You�ll see the Lists measures of correlation between pairs of data:

# Positive correlation exists when larger values of ?? correspond to larger values of ?? and vice versa.
# Negative correlation exists when larger values of ?? correspond to smaller values of ?? and vice versa.
# Weak or no correlation exists if there is no such apparent relationship.

# Note: There�s one important thing you should always have in mind when working with correlation among a pair of 
# variables, and that�s that correlation is not a measure or indicator of causation, but only of association!

# The two statistics that measure the correlation between datasets are covariance and the correlation coefficient.

# Covariance

# The sample covariance is a measure that quantifies the strength and direction of a relationship between a pair of 
# variables:

# If the correlation is positive, then the covariance is positive, as well. A stronger relationship corresponds to a 
# higher value of the covariance.
# If the correlation is negative, then the covariance is negative, as well. A stronger relationship corresponds to a 
# lower (or higher absolute) value of the covariance.
# If the correlation is weak, then the covariance is close to zero.



#################################################################################################################

# Number of Tweets Analized

# ids_tweets = tweets_smi_1['text']    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_tweets = len(tweets_smi_1['text'])
number_tweets 

print('---')
print('Number of Tweets')
print(number_tweets)
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT NEED TO DO

# PLOT TABLE plt.plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets')
plt.ioff()
plt.plot(number_tweets)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_35_SMI1_Number_Tweets_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets - Bars')
plt.ioff()
# ([number_tweets]).plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_35_SMI1_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('------------------')
print('TEXT HEAD 10-06')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')

#################################################################################################################
#################################################################################################################
#################################################################################################################
###

# UNIVARIATE DATA ANALYS

print('---')
print('Statistical Summary for Categorical or Text Variables')
# print((tweets_smi_1.describe(include=['O']).T, index=True, index_title='Categorical columns'))
print('---')

# Statistical summary for categorical or string variables will show �count�, �unique�, �top�, and �freq�


# categorical_variables_summary_df = pd.DataFrame((tweets_smi_1.describe(include=['O']).T, index=True, index_title='Categorical columns'))

# categorical_variables_summary_df.to_csv('4_4_36_SMI1_categorical_variables_summary_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# categorical_variables_summary_df.to_excel('4_4_36_SMI1_categorical_variables_summary_DF.xlsx', header=True)

# PLOT TABLE plt.plot ## NEED TO DO


# table_cat_smi_tweets_1 = ff.create_table((tweets_smi_1.describe(include=['O']).T, index=True, index_title='Categorical columns')
# table_cat_smi_tweets_df = pd.DataFrame(table_cat_smi_tweets_1)

# PLOT ## NEED TO DO FIX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Statistical Summary for Categorical or Text Variables')
# plt.plot((tweets_smi_1.describe(include=['O']).T, index=True, index_title='Categorical columns'))
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_36_SMI1_DF_Tweets_smi_Processes_Describe_cat_data_1_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO 


# Bars  ## NEED TO DO - FIX


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Statistical Summary for Categorical or Text Variables - Bars')
# ((tweets_smi_1.describe(include=['O']).T, index=True, index_title='Categorical columns').plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_36_SMI1_DF_Tweets_smi_Processes_Describe_cat_data_1_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('---')
print(main_smi)
print('---')

print('------------------')
print('TEXT HEAD 10-07')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')

####################################################################################################################

# Number of Unique Tweets Analized

 #UNIQUE TEXT

print('Number of Unique Tweets ')

unique_tweets = tweets_smi_1['text'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 
total_tweets = tweets_smi_1['text']

number_unique_tweets = len(unique_tweets)
number_unique_tweets 

print('---')
print('Number Unique Tweets')
print(number_unique_tweets)
print('---')


number_repeated_tweets = number_total_tweets - number_unique_tweets

percentage_tweets_unique = ((number_unique_tweets * 100)/number_total_tweets)

percentage_tweets_repeated = (((number_total_tweets - number_unique_tweets) * 100)/number_total_tweets)

percentage_tweets_repeated = 100 - percentage_tweets_unique

# Inicialize List of Lists

tweets_numbers_item_values = [['Number Repeated Tweets', number_repeated_tweets, percentage_tweets_repeated], ['Number Unique Tweets', number_unique_tweets, percentage_tweets_unique]]

# Create DataFrame

tweets_numbers_item_values_df = pd.DataFrame(tweets_numbers_item_values, columns =['tweets_by_item_description', 'tweets_by_number_value', 'tweets_by_percentage'])

tweets_numbers_item_values_df.to_csv('4_4_37_SMI1_Tweets_Numbers_Item_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_numbers_item_values_df.to_excel('4_4_37_SMI1_Tweets_Numbers_Item_Values_DF.xlsx', header=True)

print('---')
print('Tweets and Values: OJO REVISAR')
print(tweets_numbers_item_values_df.head)
print('---')

# tweets_numbers_item_values_df['tweets_by_number_value'] = np.arange(tweets_numbers_item_values_df['tweets_by_number_value']) ## NEED TO DO FiX

# TABLE ## NEED TO DO

# plot.legend()

# Pie 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('following vs Unique Tweets - Pie')
plt.pie(tweets_numbers_item_values_df['tweets_by_number_value'], colors=colors_blue, labels=tweets_numbers_item_values_df['tweets_by_item_description'], startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweets_numbers_item_values_df['tweets_by_item_description'], bbox_to_anchor=(0.6, 0.6), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_37_SMI1_Total_Unique_SMI_Tweets_PLT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Following vs Unique Tweets - Bars')
tweets_numbers_item_values_df['tweets_by_number_value'].plot.bar(label='tweets_by_item_description')
# ax.bar(x=tweets_numbers_item_values_df['tweets_by_item_description'], y=tweets_numbers_item_values_df['tweets_by_number_value'], alpha=0.9)
# ax.bar(tweets_numbers_item_values_df['tweets_by_item_description'], tweets_numbers_item_values_df['tweets_by_number_value'], alpha=0.9)
plt.xlabel('Repeated Tweets / Following / Unique Tweets')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend(labels=tweets_numbers_item_values_df['tweets_by_item_description']) 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_37_SMI1_Total_Unique_SMI_Tweets_PLT_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################
####################################################################################################
#################################################################################################

print('------------------')
print('TEXT HEAD 10-10')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')


####################################################################################################
#####




####################################################################################################
####################################################################################################
####################################################################################################
####################################################################################################
####################################################################################################
####################################################################################################
####################################################################################################
####################################################################################################



###############################################################################################

# AUDIENCE ANALYSIS


print('AUDIENCE AND ENGAGEMENT STATISTICS')

print('---')
print('SMI and Number of Followers ')
# print(total_followers_smis_df)
print('---')

##### NEED TABLE OF TOTAL USER VS EACH ONE

print('---')
print('Follower Counts vs Followers vs Following')     ## NEED TO DO
print('---------- NEED TO DO')
print('---')


###############################################################################################################
############################################################################################################### 
###############################################################################################################

######################################################################################################
######################################################################################################
######################################################################################################
###############################################################################################################

print('---')
print('Total Tweets Number')
print(number_total_tweets)
print('----')

# total Tweets 103215

# MP 6392   6.17
# 103515  100

# LVIQ 6037   5.83
# 103515  100

# INPC 3849   3.17
# 103515  100

# ANRIGH 2064   1.99
# 103515  100

# GLM 1959   1.89
# 103515  100


#############################################################################################################
#############################################################################################################
#############################################################################################################
#############################################################################################################
#############################################################################################################
#############################################################################################################
#############################################################################################################


###############################################################################################################
###############################################################################################################
###############################################################################################################
###############################################################################################################
#
#                              TEXTUAL ANALYTICS
#
###############################################################################################################
###############################################################################################################

print('---')
print('Loading Libs 20')
print('---')

# Word Frequency Distribution

# TURN COLLUMS TO STRING 

# tweets_smi_1['created'] = pd.to_datetime(tweets_smi_1['created'])
# tweets_smi_1['created'] = tweets_smi_1['created'].to_datetime()
# # tweets_smi_1['followers'] = tweets_smi_1['followers'].to_numeric(, errors='ignore')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].to_numeric(, errors='ignore')
# # tweets_smi_1['retweets'] = tweets_smi_1['retweets'].to_numeric(, errors='ignore')
# tweets_smi_1['id'] = tweets_smi_1['id'].to_numeric(, errors='ignore')

print('---')
print('DataFrame Types')
# print(tweets_smi_1.dtypes)
print('---')


#########################################################

# TURN COLLUMS TO STRING 

#############################################################################

# https://www.strehle.de/tim/weblog/archives/2015/09/03/1569



#######################################################################

# Bars  ######### NEED TO DO!!!!!!!!!!!!!

value_counts_text = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)

# Create DataFrame

value_counts_text_df = pd.DataFrame(value_counts_text, columns =['item', 'word_number_value', 'tweets_words_by_percentage'])
value_counts_text_df

print('---')
print('Tweets_words in Tweets and Values')
print(value_counts_text_df.head)
print('---')

value_counts_text_df.to_csv('4_4_104B_SMI1_Value_Counts_Text_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_text_df.to_excel('4_4_104B_SMI1_Value_Counts_Text_DF.xlxs', header=True)

# top_tweets_words_fdist = pd.DataFrame(tweets_words_fdist.sort_values(ascending=False))

# top_tweets_words_fdist = value_counts_df_tweets_words_fdist.sort_values(ascending=False)  ######## NEED TO PUT FIX SORTING DUPLE

# TABLE PLOT NEED TO DO 

# Bars

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Word Frequency Distribution - Bars')
tweets_smi_1['text'].value_counts()[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4B_104_SMI1_Top_Tweets_Words_Freqdists_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')



##################################################

# PLOTS  ######### NEED TO DO!!!!!!!!!!!!! NOT WORKING

# USE DICTIONARY?????

# value_counts_text = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)
# top_tweets_words_fdist = df_tweets_words_fdist.sort_values(ascending=False)

# value_counts_df_tweets_words_fdist = pd.value_counts(pd.DataFrame(df_tweets_words_fdist), ascending=False, normalize=True)
# top_tweets_words_fdist = pd.DataFrame(value_counts_df_tweets_words_fdist.sort_values(ascending=False))

# top_tweets_words_fdist_f = value_counts_df_tweets_words_fdist.sort_values(ascending=False)

## NEED TO DO SAVE INFO TO CSV!!!!

# top_tweets_words_fdist.to_csv('4_4B_104_SMI1_Top_Tweets_Value_Counts_Words_fdist_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# top_tweets_words_fdist.to_excel('4_4B_104_SMI1_Top_Tweets_Value_Counts_Words_fdist.xlsx', header=True)

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi )
plt.title('Top Words Value Counts')
# top_tweets_words_fdist.plot(6,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
# top_tweets_words_fdist[:6].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4B_104_1_SMI1_Top_Tweets_Words_Value_Counts_fdists_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(30,30))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi )
plt.title('Top Words Value Counts - Pie')
# plt.pie(top_tweets_words_fdist[:6], labels=top_tweets_words_fdist, colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# top_tweets_words_fdist[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(top_tweets_words_fdist, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_4B_104_1_SMI1_Top_Tweets_Words_Value_Counts_fdists_Pie.png', bbox_inches='tight')
plt.close(fig='all') 
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Word Frequency Distribution - Bars')
# top_tweets_words_fdist[:10].plot.bar(alpha=0.9)
# value_counts_df_tweets_words_fdist[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_104B_1_SMI1_Top_Tweets_Words_Value_Counts_fdists_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

## NEED TO DO SCREENNAME STAS!!!!!!!!!!!!!!




############################################################################################################

## NEED TO DO MENTIONS STAS!!!!!!!!!!!!!!

############################################################################################################

# Value Counts All Mentions   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_mentions = pd.value_counts(tweets_smi_1['mentions'], ascending=False, normalize=True)

smi1_value_counts_mentions = value_counts_mentions.sort_values(ascending=False)

print('---')
print('value_counts_mentions A')
# print(value_counts_mentions.head)
print('---')

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Mentions')
# print(smi1_value_counts_mentions.describe().head)
print('---')

smi1_value_counts_mentions_df = pd.DataFrame(value_counts_mentions, columns =['mentions'])

smi1_value_counts_mentions_df.to_csv('4_4_43_107_SMI1_Mentions_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_mentions_df.to_excel('4_4_43_107_SMI1_Mentions_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts')
# smi1_value_counts_mentions.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_mentions[:10].plot(alpha=0.9)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_107_SMI1_Top_Mentions_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Pie')
# plt.pie(smi1_value_counts_mentions, labels=smi1_tweets_text_words_fdist['mentions'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
# smi1_value_counts_mentions[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False) 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_107_SMI1_Top_Mentions_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Bars')
plt.ioff()
smi1_value_counts_mentions[:6].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_107_SMI1_Top_Mentions_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# MENTIONS FREQ DISTRIBUTION

# Calculate frequency distribution

smi1_mentions_fdist = nltk.FreqDist(tweets_smi_1['mentions'])

smi1_mentions_fdist_df = pd.DataFrame([smi1_mentions_fdist])

# Output top 50 tweets_words

# for smi1_mentions, frequency in smi1_mentions_fdist.most_common(10):
#    print(u'{};{}'.format(smi1_mentions, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Frequency Distribution of Mentions 2')
# print('smi1_mentions_fdist_df.head')
print('---')

smi1_mentions_fdist_df.to_csv('4_4_43_108_SMI1_Mentions_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_mentions_fdist_df.to_excel('4_4_43-108_SMI1_Mentions_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution')
# plt.plot(smi1_mentions_fdist[:6], alpha=0.9) 
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_108_SMI1_Mentions_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_mentions_fdist, patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_43_108_SMI1_Mentions_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution - Pie')
plt.ioff()
# smi1_mentions_fdist[:6], labels=top_smi1_mentions_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_mentions_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_mentions_fdist, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_4_43_108_SMI1_Mentions_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_mentions_fdist = smi1_mentions_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution - Bars')
plt.ioff()
# smi1_mentions_fdist[:6].plot.bar(alpha=0.9)
plt.xlabel('Mentions')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_108_SMI1_Mentions_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#####

# METHOD 1 MENTIONS

# fp_mentions_2 = tweets_smi_1['mentions'].to_string()

fp_mentions_2 = str(tweets_smi_1['mentions'])

# fp_mentions_2 = fp_mentions_temp_2.to_string()

tweets_text_mentions_2 = nltk.word_tokenize(fp_mentions_2)

value_counts_mentions = pd.value_counts(tweets_text_mentions_2, ascending=False, normalize=True) 

smi1_value_counts_mentions = value_counts_mentions.sort_values(ascending=False)

# smi1_value_counts_mentions_freq_dist = tweets_text_mentions.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Mentions - Frequency 2')
# print(smi1_value_counts_mentions.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Mentions')
print(smi1_value_counts_mentions.describe().head)
print('---')

smi1_value_counts_mentions_df = pd.DataFrame(smi1_value_counts_mentions, columns=['mention_frequency'])

smi1_value_counts_mentions_df.to_csv('4_4_43_108B_SMI1_Value_Counts_mentions_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_mentions_df.to_excel('4_4_43_108B_SMI1_Value_Counts_mentions_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts')
plt.ioff()
plt.plot(smi1_value_counts_mentions[:10], alpha=0.9)
plt.xlabel('Mentions')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_108B_SMI1_Top_mentions_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Pie')
smi1_value_counts_mentions[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
plt.legend(smi1_value_counts_mentions, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_108B_SMI1_Top_Mentions_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Bars')
plt.ioff()
smi1_value_counts_mentions[:10].plot.bar(alpha=0.9)
plt.xlabel('Mentions')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_108B_SMI1_Top_Mentions_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

## NEED TO DO Hashtag STAS!!!!!!!!!!!!!!

############################################################################################################


# Value Counts All Hashtags   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_hashtags = pd.value_counts(tweets_smi_1['hashtags'], ascending=False, normalize=True)

smi1_value_counts_hashtags = value_counts_hashtags.sort_values(ascending=False)

print('---')
print('value_counts_hashtags')
# print(value_counts_hashtags.head)
print('---')

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Hashtags')
# print(smi1_value_counts_hashtags.describe().head)
print('---')

smi1_value_counts_hashtags_df = pd.DataFrame(value_counts_hashtags, columns =['hashtags'])

smi1_value_counts_hashtags_df.to_csv('4_4_43_109_SMI1_Hashtags_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_hashtags_df.to_excel('4_4_43_109_SMI1_Hashtags_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts')
plt.ioff()
# smi1_value_counts_hashtags.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_hashtags[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_109_SMI1_Top_Hashtags_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(30,30))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Pie')
plt.ioff()
# smi1_value_counts_hashtags[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.pie(smi1_value_counts_hashtags[:6], labels=smi1_value_counts_hashtags[:6], colors=colors_blue, startangle=86, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_hashtags, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_4_43_109_SMI1_Top_Hashtags_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(30,30))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Bars')
plt.ioff()
smi1_value_counts_hashtags[:6].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_109_SMI1_Top_Hashtags_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Hashtags FREQ DISTRIBUTION

# Calculate frequency distribution

smi1_hashtags_fdist = nltk.FreqDist(tweets_smi_1['hashtags'])

# Output top 50 tweets_words

# for smi1_hashtags, frequency in smi1_hashtags_fdist.most_common(10):
#    print(u'{};{}'.format(smi1_hashtags, frequency))
    
# SAVE TO CSV   #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


smi1_hashtags_fdist_df = pd.DataFrame([smi1_hashtags_fdist])

print('---')
print('Frequency Distribution of Hashtags')
print('smi1_hashtags_fdist_df.head')
print('---')

smi1_hashtags_fdist_df.to_csv('4_4_43_110_SMI1_Hashtags_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_hashtags_fdist_df.to_excel('4_4_43_110_SMI1_Hashtags_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution 1')
plt.ioff()
# smi1_hashtags_fdist.plot(10,cumulative=False, alpha=0.9)
# smi1_hashtags_fdist[:10].plot(alpha=0.9)  
# plt.plot(fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_110_1_SMI1_Hashtags_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_hashtags_fdist, patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_110_SMI1_Hashtags_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution - Pie')
plt.ioff()
# smi1_hashtags_fdist[:6], labels=top_smi1_hashtags_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_hashtags_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_hashtags_fdist, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_4_43_110_SMI1_Hashtags_Freq_Dist_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_hashtags_fdist = smi1_hashtags_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution - Bars')
plt.ioff()
# smi1_hashtags_fdist[:10].plot.bar(alpha=0.9)
plt.xlabel('Hashtags')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_110_SMI1_Hashtags_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# METHOD 1 HASHTAGS

# fp_hashtags_temp = tweets_smi_1['hashtags'].to_string()
# fp_hashtags_temp = tweets_smi_1['hashtags'].astype(str, )

fp_hashtags = str(tweets_smi_1['hashtags'])

print('---')
print('fp_hashtags DTYPES')
# print(fp_hashtags.dtypes)
print('---')

tweets_text_hashtags = nltk.word_tokenize(fp_hashtags)

value_counts_hashtags = pd.value_counts(tweets_text_hashtags, ascending=False, normalize=True) 

smi1_value_counts_hashtags = value_counts_hashtags.sort_values(ascending=False)

# smi1_value_counts_hashtags_freq_dist = tweets_text_hashtags.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Hashtags - Frequency')
# print(smi1_value_counts_hashtags.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts hashtags')
# print(smi1_value_counts_hashtags.describe().head)
print('---')

smi1_value_counts_hashtags_df = pd.DataFrame(smi1_value_counts_hashtags, columns=['hashtags_frequency'])

smi1_value_counts_hashtags_df.to_csv('4_4_43_110_SMI1_Value_Counts_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_hashtags_df.to_excel('4_4_43_110_SMI1_Value_Counts_Hashtags_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts')
plt.plot(smi1_value_counts_hashtags[:10], alpha=0.9)
plt.xlabel('Hashtags')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_110_SMI1_Top_Hashtags_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Pie')
smi1_value_counts_hashtags[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(smi1_value_counts_hashtags, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_110_SMI1_Top_Hashtags_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Bars')
smi1_value_counts_hashtags[:10].plot.bar(alpha=0.9)
plt.xlabel('Hashtags')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_110_SMI1_Top_Hashtags_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


######################################################################################################
############################################################################################################

## NEED TO DO Emojis_Unicode STAS!!!!!!!!!!!!!!

############################################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Value Counts All Emojis Unicode   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].encode('unicode-escape')

value_counts_emojis_unicode = pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True)

smi1_value_counts_emojis_unicode = value_counts_emojis_unicode.sort_values(ascending=False)

print('---')
print('value_counts_emojis_unicode')
# print(value_counts_emojis_unicode.head)
print('---')

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Emojis Unicode')
# print(smi1_value_counts_emojis_unicode.describe().head)
print('---')

smi1_value_counts_emojis_unicode_df = pd.DataFrame(value_counts_emojis_unicode, columns =['emojis_unicode'])

smi1_value_counts_emojis_unicode_df.to_csv('4_4_111_SMI1_Emojis_Unicode_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_emojis_unicode_df.to_excel('4_4_111_SMI1_Emojis_Unicode_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
# smi1_value_counts_emojis_unicode.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_emojis_unicode[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend()
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_111_SMI1_Top_Emojis_Unicode_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,5))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
# plt.pie(smi1_value_counts_emojis_unicode[:6], labels=smi1_tweets_text_words_fdist['emojis_unicode'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
smi1_value_counts_emojis_unicode[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(tweets_smi_1, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_111_SMI1_Top_Emojis_Unicode_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True)[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_111_SMI1_Top_Emojis_Unicode_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Emojis Unicode FREQ DISTRIBUTION

# Calculate frequency distribution

smi1_emojis_unicode_fdist = nltk.FreqDist(tweets_smi_1['emojis_unicode'])

# Output top 50 tweets_words

# for smi1_emojis_unicode, frequency in smi1_emojis_unicode_fdist.most_common(10):
#    print(u'{};{}'.format(smi1_emojis_unicode, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


print('---')
print('Frequency Distribution of Emojis Unicode')
# print(smi1_emojis_unicode_fdist.head)
print('---')

smi1_emojis_unicode_fdist_df = pd.DataFrame([smi1_emojis_unicode_fdist])

smi1_emojis_unicode_fdist_df.to_csv('4_4_112_SMI1_Emojis_Unicode_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_emojis_unicode_fdist_df.to_excel('4_4_112_SMI1_Emojis_Unicode_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution 2')
# smi1_emojis_unicode_fdist[:10].plot(cumulative=False, alpha=0.9)  
# smi1_emojis_unicode_fdist[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_112_2_SMI1_Emojis_Unicode_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Box')
# plt.boxplot(smi1_emojis_unicode_fdist[:10], patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_112_SMI1_Emojis_Unicode_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Pie')
# smi1_emojis_unicode_fdist[:6], labels=top_smi1_emojis_unicode_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_emojis_unicode_fdist[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_emojis_unicode_fdist, loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_112_SMI1_Emojis_Unicode_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_emojis_unicode_fdist = smi1_emojis_unicode_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Bars')
# smi1_emojis_unicode_fdist[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_112_SMI1_Emojis_Unicode_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

## NEED TO DO Emojis Converted STAS!!!!!!!!!!!!!!

############################################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Value Counts All Emojis Converted   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_emojis_converted = pd.value_counts(tweets_smi_1['emojis_converted'], ascending=False, normalize=True)

smi1_value_counts_emojis_converted = value_counts_emojis_converted.sort_values(ascending=False)

print('---')
print('value_counts_emojis_converted')
# print(value_counts_emojis_converted.head)
print('---')

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Emojis')
print(smi1_value_counts_emojis_converted.describe().head)
print('---')

smi1_value_counts_emojis_converted_df = pd.DataFrame(value_counts_emojis_converted, columns =['emojis_converted'])

smi1_value_counts_emojis_converted_df.to_csv('4_4AA_111_SMI1_Emojis_Converted_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_emojis_converted_df.to_excel('4_4AA_111_SMI1_Emojis_Converted_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
# smi1_value_counts_emojis_converted.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_emojis_converted[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4AA_111_SMI1_Top_Emojis_Converted_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
# plt.pie(smi1_value_counts_emojis_converted[:6], labels=smi1_tweets_text_words_fdist['emojis_converted'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_emojis_converted[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_emojis_converted, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4AA_111_SMI1_Top_Emojis_Converted_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
# smi1_value_counts_emojis_converted[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4AA_111_SMI1_Top_Emojis_Converted_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Emojis Converted FREQ DISTRIBUTION

smi1_emojis_converted = tweets_smi_1['emojis_converted']

# Calculate frequency distribution
smi1_emojis_converted_fdist = nltk.FreqDist(smi1_emojis_converted)

# Output top 50 tweets_words

# for smi1_emojis_converted, frequency in smi1_emojis_converted_fdist.most_common(10):
#    print(u'{};{}'.format(smi1_emojis_converted, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_emojis_converted_fdist_df = pd.DataFrame(smi1_emojis_converted_fdist)

smi1_emojis_converted_fdist_df = pd.DataFrame([smi1_emojis_converted_fdist])

print('---')
print('Frequency Distribution of Emojis Converted')
# print(smi1_emojis_converted_fdist_df.head)
print('---')

smi1_emojis_converted_fdist_df.to_csv('4_4_112_3_SMI1_Emojis_Converted_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_emojis_converted_fdist_df.to_excel('4_4_112_3_SMI1_Emojis_Converted_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) #plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution 3')
# smi1_emojis_converted_fdist.plot(10,cumulative=False, alpha=0.9) 
# smi1_emojis_converted_fdist[:10].plot(alpha=0.9)  
# plt.plot(fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_112_3_SMI1_Emojis_Converted_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Box')
# plt.boxplot(smi1_emojis_converted_fdist, patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50, fontproperties='Symbola')
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_4_SYMBOLA_TEST_112_3_SMI1_Emojis_Converted_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Pie')
# smi1_emojis_converted_fdist[:6], labels=top_smi1_emojis_converted_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_emojis_converted_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_emojis_converted_fdist, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_112_3_SMI1_Emojis_Converted_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_emojis_converted_fdist = smi1_emojis_converted_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Bars')
# smi1_emojis_converted_fdist[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
# plt.ylabel('counts')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_112_3_SMI1_Emojis_Converted_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

## NEED TO DO LANGUAGE STATS!!!!!!!!!!!!!!

############################################################################################################

# NEED FREQ DIST EMOJIS, IMAGE LINK< NEED TO DO MISSING HASHTAFS MENTIONS !!!! < ETC

############################################################################################################
#######################################################################################################

print('---')
print('Loading Libs 21')
print('---')

## NEED TO DO MISSING MENTIONS AND HASTAGS!!!!

# missing_mentions = pd.DataFrame(missing_mentions)

# quant_stats_smi_tweets_1 = go.Figure(data=[go.Table(header=dict(values=['Tweets by JAMESCHARLES', 'Tweets by JEFFREESTAR', 'Tweets by MANNYMUA733', 'Tweets by MICHELLEPHAN', 'Tweets by NIKKIETUTORIALS', 'Tweets by ZOELLA', 'Tweets by AUDIENCE']),
#                 cells=dict(values=[[number_tweets_by_jamescharles, number_tweets_by_jeffreestar, number_tweets_by_mannymua733, number_tweets_by_michellephan, number_tweets_by_nikkietutorials, number_tweets_by_zoella, 'number_tweets_by_audience']]))])

# quant_stats_smi_tweets_1.show()

# quant_stats_smi_tweets_1.to_csv('4_4_165_SMI1_Quant_Stats_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# quant_stats_smi_tweets_1.to_excel('4_4_165_SMI1_Quant_Stats.xlsx', header=True)

# Plot ## NEED TO DO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets SMIs - Audience')
# plt.plot(quant_stats_smi_tweets_1, alpha=0.9)
# plt.imshow(quant_stats_smi_tweets_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_165_SMI1_Quant_Stats_SMI_Tweets_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets SMIs / Audience - Pie')
# plt.pie(top_followers_tweets[:6], labels=top_followers_tweets, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# quant_stats_smi_tweets_1.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(quant_stats_smi_tweets_1, loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_165_SMI1_Quant_Stats_SMI_Tweets_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets SMIs vs Audience - Bars')
# plt.plot.bar(quant_stats_smi_tweets_1)
# quant_stats_smi_tweets_1_df['tweets_about_smi_number'].plot.bar(alpha=0.9)
# ax.bar(tweets_about_percentages_df['tweets_about_smi_item'], tweets_about_percentages_df['tweets_about_smi_number'])
plt.xlabel('SMI / Audience')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_165_SMI1_Quant_Stats_SMI_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

####################################################################################################################################################

# This selects the top 5 highest average points among Total Tweets: # NEED TO DO

# Mean followers

# smi1_screenname_mean = statistics.mean(tweets_smi_1['screenName'])
# smi1_screenname_mean

# smi1_screenname_mean.sort_values(by='screenName', ascending=False).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest ScreenName Average Points Among Total Tweets:')
# print(smi1_screenname_mean.sort_values(by="screenName').head)
print('--')

# smi1_screenname_mean_sort_values_df = pd.DataFrame(smi1_screenname_mean().sort_values(by="screenName'))

# smi1_screenname_mean_sort_values_df.to_csv('4_4_166_SM1_Screenname_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Average Points - Tweets')
# plt.plot(smi1_screenname_mean_sort_values_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_166_SMI1_Screenname_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenName Average Points - Pie')
# plt.pie(smi1_screenname_mean_sort_values_df.most_common(10), labels=screenname_mean_sort_values_df.most_common(10), colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_screenname_mean_sort_values_df, loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_166_SMI1_Screenname_Mean_Sort_Values_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenName Average Points - Bars')
# smi1_screenname_mean_sort_values_df[:10].plot.bar(alpha=0.9)
plt.xlabel('ScreenName')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_166_SMI1_Screenname_Mean_Sort_Values_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################

# This selects the top 5 highest average points among Total Tweets:

# smi1_total_favorites_mean().sort_values(by="total_favorites",ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest total_favorites Average Points Among Total Tweets:')
# print(smi1_total_favorites_mean().sort_values(by="total_favorites", ascending=True).head)
print('---')


# smi1_total_favorites_mean_sort_values_total_favorites_df = pd.DataFrame(smi1_total_favorites_mean().sort_values(by="total_favorites", ascending=True))

# smi1_total_favorites_mean_sort_values_total_favorites_df.to_csv('4_4_167_SMI1_Total_Favorites_Mean_Sort_Values_Total_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_total_favorites_mean_sort_values_total_favorites_df.to_excel('4_4_167_SMI1_Total_Favorites_Mean_Sort_Values_Total_Favorites_DF.xlsx', header=True)

# PLOT TABLE plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Average Points - Table')
# plt.plot(smi1_total_favorites_mean_sort_values_total_favorites_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_167_SMI1_Total_Favorites_Mean_Sort_Values_Total_Favorites_DF_Table.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Average Points - Pie')
# plt.pie(smi1_total_favorites_mean_sort_values_total_favorites_df.most_common(10), labels=smi1_total_favorites_mean_sort_values_total_favorites_df.most_common(10), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_total_favorites_mean_sort_values_total_favorites_df, loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_167_SMI1_Total_Favorites_Mean_Sort_Values_Total_Favorites_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Average Points - Bars')
# smi1_screenname_mean_sort_values_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Favorites')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_167_SMI1_Total_Favorites_Mean_Sort_Values_Total_Favorites_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################

# This selects the top 5 highest average points among Total Tweets:

# smi1_followers_mean().sort_values(by="followers",ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest Following Average Points Amongst Total Tweets:')
# print(smi1_followers_mean().sort_values(by="followers",ascending=True).head)
print('---')

# smi1_followers_mean_sort_values_followers_df = pd.DataFrame(smi1_followers_mean().sort_values(by="followers",ascending=True))

# smi1_followers_mean_sort_values_followers_df.to_csv('4_4_168_SMI1_Followers_Mean_Sort_Values_Followers_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Followers - Grouped')
# plt.plot(smi1_followers.describe(), alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_168_SMI1_Followers_Mean_Sort_Values_Followers_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO BOX PLOT


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Followers Grouped - Pie')
# plt.pie(smi1_followers.describe(), labels=smi1_followers.describe(), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_followers.describe(), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_168_SMI1_Followers_Mean_Sort_Values_Followers_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Average Points - Bars')
# smi1_followers.describe().plot.bar(alpha=0.9)
plt.xlabel('Followers')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_168_SMI1_Followers_Mean_Sort_Values_Followers_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#########################################################################################################################################################
###################################################################################################################

# STATISTICS DF # NEED TO DO 

# initialize list of Lists 

# quant_stats_1_pairs = [['Mean followers', median_followers, 'Median followers', median_followers, 'Mode followers', mode_followers, 'Mode followers', mode_followers], ['Variance followers', variance_followers, 'Variance followers', variance_followers, 'Population Variance followers', pvariance_followers, 'Population Variance followers', pvariance_followers, 'Standard Deviation followers', stdev_followers, 'Population Standard Deviation followers', pstdev_followers, 'Population Standard Deviation followers', pstdev_followers, 'Skewness followers', skewness_followers, 'Skewness followers', skewness_followers, 'Percentiles followers (25, 50, 75)', quantiles_followers, 'Percentiles Followers (25, 50, 75)', quantiles_followers, 'Ranges followers', ptp_followers, 'Ranges followers', ptp_followers, 'Correlation Coefficient - Pearson Regression', corr_coef_followers_following_pearson, 'Linear Regession', r_linar_reg],['Number of Tweets Analyzed', number_tweets, 'Number of Unique Tweets Analyzed', 
# number_unique_tweets, 'Number of tweets_wos # in Text', number_of_tweets_words, 'List Unique Users ReTweeting, Commenting, Engaged', number_unique_engaged_users, 'Number of Users Who Favorite', number_unique_tweets_with_followers, 'Number of Unique Tweets with Following', 'number_unique_followers_users', 'List Unique Hashtags', 'number_unique_hashtags', 'List Unique Mentions', 'number_unique_mentions', 'List Unique Emojis', 'number_unique_emojis_unicode', 'List Unique Emojis', 'number_unique_emojis_converted', 'List Unique Language', 'number_unique_languages', 'Summary Statistics All Followers / Desc', 'summ_stats_all_followers_desc', 'Summary Statistics All Followers / Desc', 'summ_stats_all_followers_desc']]

# Create the pandas DataFrame 
# quant_stats_measures_1 = pd.DataFrame(quant_stats_1_pairs, columns = ['Measures of Centrality', 'Measures of Variability', 'General User Stats', 'Other Stats']) 

# quant_stats_measures_1.to_csv('4_4_170_SMI1_Quant_Stats_Measures_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# quant_stats_measures_1.to_excel('4_4_170_SMI1_Quant_Stats_Measures.xlsx', header=True)

### NEED TO DO PLOT?????????????????

############################################################################################################
############################################################################################################
#############################################################################################################
#################################################

## NEED TO DO FAVS AND Followers FOR THOSE DATES!!

# _df _df = pd.DataFrame()

# .to_csv('4_4_.csv', sep='\t', encoding='utf-8', index=True)
# excel

####################################################################################################################
####################################################################################################################
####################################################################################################################
########################################################################################################



########################################################################################################
########################################################################################################
###############################################################################################################

print('-- NEED TO DO FAVS AND Followers PER LANGUAGE!!!')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

###############################################################################################################

###############################################################################################################
#########################################################################################
######################################################################################################################################

# ANALYSING THE DATA

# followers

#### NEED TO COMPLETE DATA: TAKE OUT MENTIONS, HASTAGS, SUMMARY EMOJI CODES WITH EMOTICONS, 
#### NEED FOLLOWER GROWTH OVER TIME GRAPHICS

# ANALYSING THE DATA

#### NEED TO COMPLETE DATA: TAKE OUT MENTIONS, HASTAGS, SUMMARY EMOJI CODES WITH EMOTICONS, 
#### NEED FOLLOWER GROWTH OVER TIME GRAPHICS

# FIX FORMATING OF PieS

# NEED TO LINK TO TWITTER R DATA AND GET LOCATION INFO

# NEED TO DO SAVE TABLES TO FILES

# CHECK ALL 'NEED TO DO'

#################################################################################################################
#################################################################################################################
#################################################################################################################


############################################################################################################

# _df _df = pd.DataFrame()
# .to_csv('4_5_.csv', sep='\t', encoding='utf-8', index=True)
# excel

#############################################################################################################
#############################################################################################################
#
# 					SENTENCES ANALYSIS
#
#############################################################################################################
#############################################################################################################

# textblob_sentences = textblob_obj_text_c.sentences

print('-------------------------')
print('TextBlob Sentences Head')
# print(textblob_sentences.head)
print('-------------------------')

 
# Create the pandas DataFrame 
# textblob_sentences_df = pd.DataFrame(textblob_sentences) 

# textblob_sentences_df.to_csv('4_5_201_SMI1_Textblob_Sentences_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# textblob_sentences_df.to_excel('4_5_201_SMI1_Textblob_Sentences.xlsx', header=True)

# textblob_sentences_number = len(textblob_sentences)

print('-------------------------')
print('TextBlob Sentences Number')
# print(textblob_sentences_number)
print('-------------------------')

# Create the pandas DataFrame 
# textblob_sentences_number_df = pd.DataFrame([textblob_sentences_number]) 

# textblob_sentences_number_df.to_csv('4_5_201_SMI1_Textblob_Sentences_Number_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# textblob_sentences_number_df.to_excel('4_5_201_SMI1_Textblob_Sentences_Number.xlsx', header=True)

# tweets_smi_1.to_csv('4_5_201_05_SMI1_tweets_smi_1_SENTIMENTS_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_excel('4_5_201_05_SMI1_tweets_smi_1_SENTIMENTS.xlsx', header=True)

### DELETE VARIABLE

# del textblob_sentences
# del textblob_sentences_df 
# del textblob_sentences_number
# del textblob_sentences_number_df

##########################################################################################################################
##########################################################################################################################
##################################################################################################################
##################################################################################################################


###################################################################################################################
#
# 		        TOPIC MODELLING : LSA Latent Semantic Analysis
#                                                 
###################################################################################################################

# analyticsvidhya.com/blob/2018/10/stewise-guide-topic-modeling-latent-semantic-analysis/


##############################################################################################################

# _df _df = pd.DataFrame()
# .to_csv('4_5_.csv', sep='\t', encoding='utf-8', index=True)
# excel

############################################################################################

# ADD IMAGE LINK FIELD 

# METHOD 1 ######## Need to fix


###################################################################################################
##############################################################################################################################################

# Lexicon Normalization

# Lexicon normalization considers another type of noise in the text. For example, connection, connected, connecting word reduce to a 
# common word "connect". It reduces derivationally related forms of a word to a common root word.

# Stemming

# Stemming is a process of linguistic normalization, which reduces tweets_words to their word root word or chops off the derivational affixes. 
# For example, connection, connected, connecting word reduce to a common word "connect".

# The most common algorithm for stemming English, and one that has repeatedly been shown to be empirically very effective, is Porter’s algorithm
# (Porter 1980). The entire algorithm is too long and intricate to present here, but we will indicate its general nature. Porter’s algorithm consists of 5 phases
# of word reductions, applied sequentially. Within each phase there are various conventions to select rules, such as selecting the rule from each rule
# group that applies to the longest suffix. In the first phase, this convention is used with the Lists rule group:

# (2.1) Rule Example
# SSES → SS caresses → caress
# IES → I ponies → poni
# SS → SS caress → caress
# S → cats → cat


print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')



# POLARITY DISTRIBUTION

# textblob_obj_text_c

def find_polarity_textblob(tweets):
	return TextBlob(tweets).sentiment.polarity
	
tweets_smi_1['textblob_sentiment_polarity'] = tweets_smi_1['text'].apply(find_polarity_textblob)

print('---')
print('TextBlob Sent Polarity Distributions')
print(tweets_smi_1['textblob_sentiment_polarity'].head)
print('---')

tweets_smi_1.to_csv('4_5_200_SMI1_Tweets_SMI_1_With_TBLOBPOLDIST_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_excel('4_5_200_SMI1_Tweets_SMI_1_With_TBLOBPOLDIST.xlsx', header=True)

# DIST PLOT # NEED TO DO

# HIST PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity Distribution TextBlob - Histogram')
plt.ioff()
# sns.distplot(tweets_smi_1['textblob_sentiment_polarity'], colors=colors_blue)
sns.distplot(tweets_smi_1['textblob_sentiment_polarity'])
plt.xlabel('Polarity')
plt.ylabel('Value')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_200_SMI1_TextBLob_Sentiment_Polarity_Distribution_Hist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################################################################################
#
#                      SNA - CLUSTER ANALYSIS #############  NEED TO DO!!!!
#
##############################################################################################################

print('done processing 4')

network_radious = 30

print('MAIN SMI:')
print(main_smi)
print('NETWORK RADIOUSSSSSSSSSSSSSSSSSS')
print(network_radious)
print('----------------------------------------')

##############################################################################################################

print('-- NEED TO DO Favorites AND Followers PER LANGUAGE!!!')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

##############################################################################################################

print('-- done quant processing 3 - analysis 1')
print(' -- NEED TO DO : SMIS Processing / DATA ANALYSIS QUANTITATIVE AND STATISTICS - SNA - CLUSTER ANALYSIS')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


#######################################################################################################################
#######################################################################################################################
#######################################################################################################################

# https://towardsdatascience.com/an-end-to-end-project-on-total_favorites-series-analysis-and-forecasting-with-python-4835e6bf050b

# Visualizing Furniture Sales Time Series Data

# Some distinguishable patterns appear when we plot the data. The total_favorites-series has seasonality pattern, such as sales are 
# always low at the beginning of the year and high at the end of the year. There is always an upward trend within any 
# single year with a couple of low months in the mid of the year. We can also visualize our data using a method called 
# total_favorites-series decomposition that allows us to decompose our total_favorites-series into three distinct components: trend, 
# seasonality, and noise.

print('---')
print('Loading Libs 26')
print('---')

# decomposition = sm.tsa.seasonal_decompose(y, model='additive')
# fig = decomposition.plot(alpha=0.9)
# plt.show()

print('MAIN SMI: NEED TO DO')
print(main_smi)
print('----------------------------------------')

#######################################################################################################################
#######################################################################################################################
#######################################################################################################################
#######################################################################################################################
#######################################################################################################################

print('------------------')
print('TEXT HEAD 2-0')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')

## SELECTED WORDS

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Calculate Frequency Distribution

smi1_tweets_text_words_fdist = nltk.FreqDist(tweets_text_words)

print('---')
print('Word Frequency Distribution - NEED TO DO - FIX KNOW TYPE')
print(smi1_tweets_text_words_fdist)
print('---')

print('---')
print('Word Frequency Distribution - Love')
print(smi1_tweets_text_words_fdist['love'])
print('---')

print('---')
print('Word Frequency Distribution - Hate')
print(smi1_tweets_text_words_fdist['hate'])
print('---')

print('---')
print('Word Frequency Distribution - Thanks')
print(smi1_tweets_text_words_fdist['thanks'])
print('---')

print('---')
print('Word Frequency Distribution - Fuck')
print(smi1_tweets_text_words_fdist['fuck'])
print('---')

print('---')
print('Word Frequency Distribution - Follow')
print(smi1_tweets_text_words_fdist['follow'])
print('---')

print('---')
print('Word Frequency Distribution - Friend')
print(smi1_tweets_text_words_fdist['friend'])
print('---')

print('---')
print('Word Frequency Distribution - Buy')
print(smi1_tweets_text_words_fdist['buy'])
print('---')

print('---')
print('Word Frequency Distribution - Brand')
print(smi1_tweets_text_words_fdist['brand'])
print('---')


word_love = smi1_tweets_text_words_fdist['love']
word_hate = smi1_tweets_text_words_fdist['hate']
word_thanks = smi1_tweets_text_words_fdist['thanks']
word_fuck = smi1_tweets_text_words_fdist['fuck']
word_follow = smi1_tweets_text_words_fdist['follow']
word_friend = smi1_tweets_text_words_fdist['friend']
word_buy = smi1_tweets_text_words_fdist['buy']
word_brand = smi1_tweets_text_words_fdist['brand']

## NEED TO DO PLOTS AND SAVE

# Output top 50 tweets_words

for word, frequency in smi1_tweets_text_words_fdist.most_common(10):
    print(u'{};{}'.format(word, frequency))
#     smi1_tweets_text_words_freq['tweets_text_words'] = pd.DataFrame(smi1_tweets_text_words_fdist.word)
#     smi1_tweets_text_words_freq['tweets_text_words_freq'] = pd.DataFrame(smi1_tweets_text_words_fdist.frequency)


# tweets_text_words_freq = tweets_text_words_fdist.keys()  ### NEED TO DO - FIX FROM ABOVE

print('---')
print('Word Frequency Distribution from List and Counts - Try 1')
# print(smi1_tweets_text_words_freq)  ######## NNED TO DO - NOT WORKING
print(type(smi1_tweets_text_words_fdist))
print('---')

print('---')
print('Number of Words In Text')
print(len(smi1_tweets_text_words_fdist))
print('---')

smi1_tweets_text_words_fdist_df = pd.DataFrame([smi1_tweets_text_words_fdist])

smi1_tweets_text_words_fdist_df.to_csv('4_5_101_SMI1_Word_Freq_Dist_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# tweets_text_words_fdist_df.to_excel('4_5_101_SMI1_Word_Freq_Dist_DF.xlsx', header='frequency_distribution') # Only argument is a string of the output file path


# PLOT TABLE NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Word: Love Frequency Distribution')
plt.ioff()
# word_love.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)   ########### NEED TO FIX -SHOWING FEW
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_101_SMI1_Word_LOVE_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Words Frequency Distribution - Box')
plt.ioff()
# plt.plot(smi1_tweets_text_words_fdist[:10])
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_101_SMI1_Words_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################

# HISTOGRAM PLOT NEED TO DO ## need to change

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Words Frequency Distribution - Histogram')
plt.ioff()
# plt.hist(smi1_tweets_text_words_fdist, labels=smi1_tweets_text_words_fdist, colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_tweets_text_words_fdist[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_101_SMI1_Words_Freq_Dist_PLOT_Hist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_tweets_text_words_fdist = tweets_text_words_fdist.sort(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets Words Frequency Distribution - Bars')
plt.ioff()
# smi1_tweets_text_words_fdist[:10].plot.bar(alpha=0.9)
# plt.bar(smi1_tweets_text_words_fdist[:10], tweets_text_words_fdist, color='#7f3d5f', edgecolor='white', label='words')
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_101_SMI1_Words_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('------------------')
print('TEXT HEAD 2A')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')

####################################################################################################

## METHOD 2 - SEVERAL TRIES

# TO DF - NOT WORKING

# smi1_df_tweets_text_words_fdist1_df = pd.DataFrame(smi1_tweets_text_words_fdist)

print('---')
print('Frequency Distribution of Words DF1')
# print(smi1_df_tweets_text_words_fdist1_df.head(10))
print('---')

#### TRY 2 NOT WORKING

# smi1_tweets_text_words_fdist_list = smi1_tweets_text_words_fdist1_df.str.split()

# smi1_tweets_text_words_freq = ['smi1_tweets_text_words', 'smi1_tweets_text_words_freq']

# for w in smi1_tweets_text_words_fdist_list:
#	smi1_tweets_text_words_freq.append(smi1_tweets_text_words_fdist_list.count(w))
	

print('---')
print('Word Frequency Distribution from List and Counts - Try 2')
# print(smi1_tweets_text_words_freq)
print('---')
print('---')
# print('List\n' + str(smi1_tweets_text_words_freq) + '\n')
print('---')
print('---')
# print('Frequencies\n' + str(smi1_tweets_text_words_freq) + '\n')
print('---')
print('---')
# print('Pairs\n' + str(list(zip(smi1_tweets_text_words_fdist_list, smi1_tweets_text_words_freq)))
print('---')

# TABLE PLOT NEED TO DO 

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tweets Words - Pie')
plt.ioff()
# plt.pie(smi1_tweets_text_words_fdist[:6], labels=smi1_tweets_text_words_fdist, colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_tweets_text_words_fdist[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_words, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_102_SMI1_Tweets_Text_Words_fdist_df_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Words - Bars')
plt.ioff()
# smi1_tweets_text_words_fdist.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_102_SMI1_Tweets_Text_Words_fdist_df_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLE

# del smi1_tweets_text_words_fdist
# del smi1_tweets_text_words_fdist1_df
# del smi1_tweets_text_words_fdist_list

print('------------------')
print('TEXT HEAD 2B')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')

####################### NEED TO FIX



# TUPLE TO DATAFRAME

# tweets_text_words_fdist_df = pd.DataFrame.from_records(tweets_text_words_fdist, columns=['tweets_text_words', 'tweets_text_words_freq'])
# tweets_text_words_fdist_df = pd.DataFrame.from_items(tweets_text_words_fdist)
# tweets_text_words_fdist_df = pd.DataFrame(tweets_text_words_fdist, index=[0])
# tweets_text_words_fdist_df = pd.DataFrame([tweets_text_words_fdist])
# tweets_text_words_fdist_df = pd.DataFrame(list(tweets_text_words_fdist), columns=['tweets_text_words', 'tweets_text_words_freq'], index['tweets_text_words', 'tweets_text_words_freq'])

# tweets_text_words_fdist_df = pd.DataFrame(tweets_text_words_fdist, columns=['tweets_text_words', 'tweets_text_words_freq'])
# a_tweets_text_words_fdist_df = tweets_text_words_fdist_df.pivot('tweets_text_words', 'tweets_text_words_freq')


# pd.DataFrame.from_dict(list(tweets_text_words_fdist.items()), columns=['tweets_words', 'tweets_words_frequency_counts'])
# pd.DataFrame.from_dict(tweets_text_words_fdist, orient='index')

# tweets_text_words_fdist_d_f = list(tweets_text_words_fdist, name='tweets_words_frequency_counts')

# tweets_text_words_fdist_d_f.index.name = 'tweets_words_frequency_counts' 

# tweets_text_words_fdist_df = pd.DataFrame(tweets_text_words_fdist, index=[0])

print('---')
print('Tweets_words Frequency Distribution DataFrame')
# print(tweets_text_words_fdist_df)
print('---')

print('FINISHED PRINTING WORD FREQUENCIES')

############ df_tweets_words_fdist is a tuple!!! NEED TO CHANGE TO DF and PLOT DUPLE!!!!

print('---')
print('DF tweets_words Frequency Distribution - fdist ')
# print(tweets_text_words_fdist_df)
print('---')

print('---')
print('Frequency Distribution of Words')
# print(tweets_text_words_fdist_df.head(10))
print('---')

# tweets_text_words_fdist_df.to_csv('4_5_103_SMI1_Tweets_Text_Words_fdist_df_CSV.csv', sep='\t', encoding='utf-8', index=True)
# tweets_text_words_fdist_df.to_excel('4_5_103_SMI1_Tweets_Text_Words_fdist_df.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# NEED TO DO TABLE PLOT

# PLOT NEED TO DO 

# Box 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Top Words - Box')
plt.ioff()
# tweets_text_words_fdist_df.plotbox() 
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_103_SMI1_Tweets_Text_Words_fdist_df_PLOT_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Top Words - Pie')
plt.ioff()
# plt.pie(tweets_text_words_fdist_df[:6], labels=tweets_text_words_fdist_df, colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# tweets_text_words_fdist_df[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_words, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_103_SMI1_Tweets_Text_Words_fdist_df_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## PLOT 2 TEST ## NEED TO DO FIX NOT WORKING

print('PLOT2 WORD DIST TEST - NEED TO FIX')

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Top Words')
plt.ioff()
# tweets_text_words_fdist_df.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
# tweets_text_words_fdist_df[:10].plot(alpha=0.9)
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_103_SMI1_Tweets_Text_Words_fdist_df_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

## Bars ## NEED TO DO FIX NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Top Words - Bars')
plt.ioff()
# tweets_text_words_fdist_df.plot(10,cumulative=False).bars(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
# tweets_text_words_fdist_df[:10].plot.bars(alpha=0.9)
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_103_SMI1_Tweets_Text_Words_fdist_df_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

print('Box Test')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Word Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(tweets_text_words_fdist_df) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_103_SMI1_Tweets_Text_Words_fdist_df_Box_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLE

# del tweets_text_words_fdist
# del tweets_text_words_fdist_df
# del a_tweets_text_words_fdist_df

print('------------------')
print('TEXT HEAD 2C')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')

#######################################################################

# Bars  ######### NEED TO DO!!!!!!!!!!!!!

print('Bars Test')

value_counts_text = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)

# Create DataFrame

value_counts_text_df = pd.DataFrame(value_counts_text, columns =['item', 'word_number_value', 'tweets_words_by_percentage'])
value_counts_text_df

print('---')
print('Tweets_words in Tweets and Values')
# print(value_counts_text_df.head)
print('---')

value_counts_text_df.to_csv('4_5_104_SMI1_Value_Counts_Text_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_text_df.to_excel('4_5_104_SMI1_Value_Counts_Text_DF.xlxs', header=True)

# top_tweets_words_fdist = tweets_words_fdist.sort_values(ascending=False)

# value_counts_df_tweets_words_fdist = pd.value_counts([value_counts_text], ascending=False, normalize=True)
# top_tweets_words_fdist = value_counts_df_tweets_words_fdist.sort_values(ascending=False)  ######## NEED TO PUT FIX SORTING DUPLE

# TABLE PLOT NEED TO DO 

# Bars

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Word Frequency Distribution - Bars')
plt.ioff()
pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
plt.tight_layout(pad=2)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_104_SMI1_Top_Tweets_Words_Freqdists_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')



print('------------------')
print('TEXT HEAD 2D')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')


## DELETE VARIABLE

del value_counts_text
del value_counts_text_df
# del top_tweets_words_fdist
# del value_counts_df_tweets_words_fdist
# del top_tweets_words_fdist


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# screennames FREQ DISTRIBUTION

smi1_screennames = tweets_smi_1['screenName']

# Calculate frequency distribution
smi1_screennames_fdist = nltk.FreqDist(smi1_screennames)

# Output top 50 tweets_words

for smi1_screennames, frequency in smi1_screennames_fdist.most_common(10):
    print(u'{};{}'.format(smi1_screennames, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_screennames_fdist_df = pd.DataFrame(smi1_screennames_fdist)

smi1_screennames_fdist_df = pd.DataFrame([smi1_screennames_fdist])

print('---')
print('ScreenNames Frequency Distribution B')
print('smi1_screennames_fdist_df.head(10)')
print('---')

smi1_screennames_fdist_df.to_csv('4_5_106_SMI1_Screennames_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_screennames_fdist_df.to_excel('4_5_106_SMI1_Screennames_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames Frequency Distribution 2')
plt.ioff()
# smi1_screennames_fdist.plot(10,cumulative=False, alpha=0.9)  
# smi1_screennames_fdist[:10].plot(alpha=0.9) 
# plt.plot(fdist)
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_106_2_SMI1_Screennames_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames Frequency Distribution - Box')
plt.ioff()
# plt.plot(smi1_screennames_fdist)
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_106_SMI1_ScreenNames_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames Frequency Distribution - Pie')
plt.ioff()
# smi1_screennames_fdist[:6], labels=top_smi1_screennames_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_screennames_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_screennames_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_106_SMI1_ScreenNames_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()




# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_screennames_fdist = smi1_screennames_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Screennames Frequency Distribution - Bars')
plt.ioff()
# smi1_screennames_fdist.plot.bar(alpha=0.9)
plt.xlabel('ScreenNames')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_106_SMI1_ScreenNames_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('---')
print('tweets_smi_1 Text HEAD 2E')
print(tweets_smi_1['text'].head)
# print(tweets_smi_1['text'].dtypes)
print('-----------------------------------------------------------------------')


## DELETE VARIABLE

del smi1_screennames
del smi1_screennames_fdist

############################################################################################################

## NEED TO DO MENTIONS STAS!!!!!!!!!!!!!!

############################################################################################################


# Value Counts All Mentions   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_mentions = pd.value_counts(tweets_smi_1['mentions'], ascending=False, normalize=True)

smi1_value_counts_mentions = value_counts_mentions.sort_values(ascending=False)

print(value_counts_mentions)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Mentions')
print(smi1_value_counts_mentions.describe().head())
print('---')

smi1_value_counts_mentions_df = pd.DataFrame(value_counts_mentions, columns =['mentions'])

smi1_value_counts_mentions_df.to_csv('4_5_107_SMI1_Mentions_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_mentions_df.to_excel('4_5_107_SMI1_Mentions_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts')
plt.ioff()
# smi1_value_counts_mentions.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_mentions[:10].plot(alpha=0.9)
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_107_SMI1_Top_Mentions_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Pie')
plt.ioff()
smi1_value_counts_mentions[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
# plt.legend(smi1_value_counts_mentions, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_107_SMI1_Top_Mentions_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Bars')
plt.ioff()
smi1_value_counts_mentions.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_107_SMI1_Top_Mentions_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# MENTIONS FREQ DISTRIBUTION

smi1_mentions = tweets_smi_1['mentions']

# Calculate frequency distribution
smi1_mentions_fdist = nltk.FreqDist(smi1_mentions)

# Output top 50 tweets_words

for smi1_mentions, frequency in smi1_mentions_fdist.most_common(10):
    print(u'{};{}'.format(smi1_mentions, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_mentions_fdist_df = pd.DataFrame(smi1_mentions_fdist)

smi1_mentions_fdist_df = pd.DataFrame([smi1_mentions_fdist])

print('---')
print('Frequency Distribution of Mentions 3')
print('smi1_mentions_fdist_df.head(10)')
print('---')

smi1_mentions_fdist_df.to_csv('4_5_108_SMI1_Mentions_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_mentions_fdist_df.to_excel('4_5_108_SMI1_Mentions_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution')
plt.ioff()
# smi1_mentions_fdist.plot(10,cumulative=False, alpha=0.9)  
# smi1_mentions_fdist[:10].plot(alpha=0.9)
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_108_SMI1_Mentions_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution - Box')
plt.ioff()
# plt.plot(smi1_mentions_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_108_SMI1_Mentions_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution - Pie')
plt.ioff()
# smi1_mentions_fdist[:6], labels=top_smi1_mentions_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_mentions_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_mentions_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_5_108_SMI1_Mentions_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_mentions_fdist = smi1_mentions_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution - Bars')
plt.ioff()
# smi1_mentions_fdist.plot.bar(alpha=0.9)
plt.xlabel('Mentions')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_108_SMI1_Mentions_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

## NEED TO DO Hashtag STAS!!!!!!!!!!!!!!

############################################################################################################


# Value Counts All Hashtags   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_hashtags = pd.value_counts(tweets_smi_1['hashtags'], ascending=False, normalize=True)

smi1_value_counts_hashtags = value_counts_hashtags.sort_values(ascending=False)

print(value_counts_hashtags)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Hashtags')
print(smi1_value_counts_hashtags.describe().head())
print('---')

smi1_value_counts_hashtags_df = pd.DataFrame(value_counts_hashtags, columns =['hashtags'])

smi1_value_counts_hashtags_df.to_csv('4_5_109_SMI1_Hashtags_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_hashtags_df.to_excel('4_5_109_SMI1_Hashtags_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts')
plt.ioff()
# smi1_value_counts_hashtags.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_hashtags[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_109_SMI1_Top_Hashtags_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Pie')
plt.ioff()
smi1_value_counts_hashtags[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_hashtags, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_5_109_SMI1_Top_Hashtags_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Bars')
plt.ioff()
smi1_value_counts_hashtags[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_109_SMI1_Top_Hashtags_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Hashtags FREQ DISTRIBUTION

smi1_hashtags = tweets_smi_1['hashtags']

# Calculate frequency distribution
smi1_hashtags_fdist = nltk.FreqDist(smi1_hashtags)

# Output top 50 tweets_words

for smi1_hashtags, frequency in smi1_hashtags_fdist.most_common(10):
    print(u'{};{}'.format(smi1_hashtags, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 



# smi1_hashtags_fdist_df = pd.DataFrame(smi1_hashtags_fdist)

smi1_hashtags_fdist_df = pd.DataFrame([smi1_hashtags_fdist])

print('---')
print('Frequency Distribution of Hashtags')
print('smi1_hashtags_fdist_df.head(10)')
print('---')

smi1_hashtags_fdist_df.to_csv('4_5_110_SMI1_Hashtags_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_hashtags_fdist_df.to_excel('4_5_110_SMI1_Hashtags_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution 2')
plt.ioff()
# smi1_hashtags_fdist.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)  
# smi1_hashtags_fdist[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_110_2_SMI1_Hashtags_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_hashtags_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_110_SMI1_Hashtags_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution - Pie')
plt.ioff()
# smi1_hashtags_fdist[:6], labels=top_smi1_hashtags_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_hashtags_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_hashtags_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_5_110_SMI1_Hashtags_Freq_Dist_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_hashtags_fdist = smi1_hashtags_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution - Bars')
plt.ioff()
# smi1_hashtags_fdist.plot.bar(alpha=0.9)
plt.xlabel('Hashtags')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_110_SMI1_Hashtags_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################

## NEED TO DO Emojis_Unicode STAS!!!!!!!!!!!!!!

############################################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Value Counts All Emojis Unicode   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].encode('unicode-escape')

value_counts_emojis_unicode = pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True)

smi1_value_counts_emojis_unicode = value_counts_emojis_unicode.sort_values(ascending=False)

print(value_counts_emojis_unicode.head)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Emojis Unicode')
print(smi1_value_counts_emojis_unicode.describe().head())
print('---')

smi1_value_counts_emojis_unicode_df = pd.DataFrame(value_counts_emojis_unicode, columns =['emojis_unicode'])

smi1_value_counts_emojis_unicode_df.to_csv('4_5_111_SMI1_Emojis_Unicode_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_emojis_unicode_df.to_excel('4_5_111_SMI1_Emojis_Unicode_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
plt.ioff()
# smi1_value_counts_emojis_unicode.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_emojis_unicode[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_111_SMI1_Top_Emojis_Unicode_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
plt.ioff()
smi1_value_counts_emojis_unicode[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_emojis_unicode, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_111_SMI1_Top_Emojis_Unicode_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
plt.ioff()
pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True)[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_111_SMI1_Top_Emojis_Unicode_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Emojis Unicode FREQ DISTRIBUTION

smi1_emojis_unicode = tweets_smi_1['emojis_unicode']

# Calculate frequency distribution
smi1_emojis_unicode_fdist = nltk.FreqDist(smi1_emojis_unicode)

# Output top 50 tweets_words

for smi1_emojis_unicode, frequency in smi1_emojis_unicode_fdist.most_common(10):
    print(u'{};{}'.format(smi1_emojis_unicode, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_emojis_unicode_fdist_df = pd.DataFrame(smi1_emojis_unicode_fdist)

smi1_emojis_unicode_fdist_df = pd.DataFrame([smi1_emojis_unicode_fdist])

print('---')
print('Frequency Distribution of Emojis')
print(smi1_emojis_unicode_fdist_df.head(10))
print('---')

smi1_emojis_unicode_fdist_df.to_csv('4_5_111_SMI1_Emojis_Unicode_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_emojis_unicode_fdist_df.to_excel('4_5_111_SMI1_Emojis_Unicode_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution 4')
plt.ioff()
# smi1_emojis_unicode_fdist.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)  
# smi1_emojis_unicode_fdist[:10].plot(alpha=0.9) 
# plt.plot(fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_111_4_SMI1_Emojis_Unicode_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_emojis_unicode_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_111_SMI1_Emojis_Unicode_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Pie')
plt.ioff()
# smi1_emojis_unicode_fdist[:6], labels=top_smi1_emojis_unicode_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.pie(smi1_emojis_unicode_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_emojis_unicode_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_111_SMI1_Emojis_Unicode_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_emojis_unicode_fdist = smi1_emojis_unicode_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Bars')
plt.ioff()
# smi1_emojis_unicode_fdist.plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_111_SMI1_Emojis_Unicode_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del smi1_emojis_unicode
del smi1_emojis_unicode_fdist
del smi1_emojis_unicode_fdist_df


############################################################################################################

## NEED TO DO Emojis Converted STAS!!!!!!!!!!!!!!

############################################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Value Counts All Emojis Converted   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_emojis_converted = pd.value_counts(tweets_smi_1['emojis_converted'], ascending=False, normalize=True)

smi1_value_counts_emojis_converted = value_counts_emojis_converted.sort_values(ascending=False)

print(value_counts_emojis_converted)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Emojis')
# print(smi1_value_counts_emojis_converted.describe().head())
print('---')

smi1_value_counts_emojis_converted_df = pd.DataFrame(value_counts_emojis_converted, columns =['emojis_converted'])

smi1_value_counts_emojis_converted_df.to_csv('4_5_112_SMI1_Emojis_Converted_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_emojis_converted_df.to_excel('4_5_112_SMI1_Emojis_Converted_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
plt.ioff()
# smi1_value_counts_emojis_converted_df.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_emojis_converted_df[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_112_SMI1_Top_Emojis_Converted_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
plt.ioff()
smi1_value_counts_emojis_converted_df[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
# plt.legend(smi1_value_counts_emojis_converted,_df bbox_to_anchor=(1.05, 1), loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_112_SMI1_Top_Emojis_Converted_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
plt.ioff()
pd.value_counts(tweets_smi_1['emojis_converted'], ascending=False, normalize=True)[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_112_SMI1_Top_Emojis_Converted_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del value_counts_emojis_converted
del smi1_value_counts_emojis_converted
del smi1_value_counts_emojis_converted_df

#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Emojis Converted FREQ DISTRIBUTION

smi1_emojis_converted = tweets_smi_1['emojis_converted']

# Calculate frequency distribution
smi1_emojis_converted_fdist = nltk.FreqDist(smi1_emojis_converted)

# Output top 50 tweets_words

for smi1_emojis_converted, frequency in smi1_emojis_converted_fdist.most_common(10):
    print(u'{};{}'.format(smi1_emojis_converted, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_emojis_converted_fdist_df = pd.DataFrame(smi1_emojis_converted_fdist)

smi1_emojis_converted_fdist_df = pd.DataFrame([smi1_emojis_converted_fdist])

print('---')
print('Frequency Distribution of Emojis')
print(smi1_emojis_converted_fdist_df.head(10))
print('---')

smi1_emojis_converted_fdist_df.to_csv('4_5_112_SMI1_Emojis_Converted_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_emojis_converted_fdist_df.to_excel('4_5_112_SMI1_Emojis_Converted_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution 5')
plt.ioff()
# smi1_emojis_converted_fdist.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)  
# smi1_emojis_converted_fdist[:10].plot(alpha=0.9)  
# plt.plot(fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_112_5_SMI1_Emojis_Converted_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_emojis_converted_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_112_SMI1_Emojis_Converted_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Pie')
plt.ioff()
# smi1_emojis_converted_fdist[:6], labels=top_smi1_emojis_converted_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_emojis_converted_fdist.plot.pie(colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
# plt.legend(smi1_emojis_converted_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.) 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_112_SMI1_Emojis_Converted_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_emojis_converted_fdist = smi1_emojis_converted_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Bars')
plt.ioff()
# smi1_emojis_converted_fdist.plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_112_SMI1_Emojis_Converted_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLE

del smi1_emojis_converted
del smi1_emojis_converted_fdist
del smi1_emojis_converted_fdist_df

###########################################################################################################

### EMOJIS UNICODE STATS

###########################################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Value Counts All Emojis Unicode   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].encode('unicode-escape')

value_counts_emojis_unicode = pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True)

smi1_value_counts_emojis_unicode = value_counts_emojis_unicode.sort_values(ascending=False)

print(value_counts_emojis_unicode)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Emojis Unicode')
print(smi1_value_counts_emojis_unicode.describe().head())
print('---')

smi1_value_counts_emojis_unicode_df = pd.DataFrame(value_counts_emojis_unicode, columns =['emojis_unicode'])

smi1_value_counts_emojis_unicode_df.to_csv('4_5_113_SMI1_Emojis_Unicode_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_emojis_unicode_df.to_excel('4_5_113_SMI1_Emojis_Unicode_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
plt.ioff()
# smi1_value_counts_emojis_unicode.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_emojis_unicode[:10].plot(alpha=0.9)
plt.xticks(rotation=50, fontproperties='Symbola')
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_SYMBOLA_TEST_SMI1_Top_Emojis_Unicode_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
plt.ioff()
# plt.pie(smi1_value_counts_emojis_unicode[:6], labels=smi1_tweets_text_words_fdist['emojis_unicode'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_emojis_unicode[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
# plt.legend(smi1_value_counts_emojis_unicode, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.tight_layout(pad=1)
# plt.show()
plt.savefig('4_5_113_SMI1_Top_Emojis_Unicode_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
plt.ioff()
smi1_value_counts_emojis_unicode[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50, fontproperties='Symbola')
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_SYMBOLA_TEST_SMI1_Top_Emojis_Unicode_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Emojis Graphical FREQ DISTRIBUTION

smi1_emojis_graphical = tweets_smi_1['emojis_unicode']

# Calculate frequency distribution
smi1_emojis_graphical_fdist = nltk.FreqDist(smi1_emojis_graphical)

# Output top 50 tweets_words

for smi1_emojis_graphical, frequency in smi1_emojis_graphical_fdist.most_common(10):
    print(u'{};{}'.format(smi1_emojis_graphical, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_emojis_graphical_fdist_df = pd.DataFrame(smi1_emojis_graphical_fdist)

smi1_emojis_graphical_fdist_df = pd.DataFrame([smi1_emojis_graphical_fdist])

print('---')
print('Frequency Distribution of Emojis Graphical')
print(smi1_emojis_graphical_fdist_df.head(10))
print('---')

smi1_emojis_graphical_fdist_df.to_csv('4_5_113_SMI1_Emojis_Graphical_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_emojis_graphical_fdist_df.to_excel('4_5_113_SMI1_Emojis_Graphical_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution 6')
plt.ioff()
# smi1_emojis_graphical_fdist.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)  
# smi1_emojis_graphical_fdist[:10].plot(alpha=0.9)
plt.xticks(rotation=50, fontproperties='Symbola')
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_6_SYMBOLA_TEST_SMI1_Emojis_Graphical_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_emojis_graphical_fdist)
plt.xticks(rotation=50, fontproperties='Symbola')
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_SYMBOLA_TEST_SMI1_Emojis_Graphical_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Pie')
plt.ioff()
# smi1_emojis_graphical_fdist[:6], labels=top_smi1_emojis_graphical_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_emojis_graphical_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_emojis_graphical_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_113_SMI1_Emojis_Graphical_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_emojis_graphical_fdist = smi1_emojis_graphical_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Bars')
plt.ioff()
# smi1_emojis_graphical_fdist.plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50, fontproperties='Symbola')
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
 
# plt.show()
plt.savefig('4_5_113_SYMBOLA_TEST_SMI1_Emojis_Graphical_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#######
######

###########################################################################################################

### EMOJIS GRAPHICAL STATS

###########################################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Value Counts All Emojis Converted   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].encode('unicode-escape')

value_counts_emojis_converted = pd.value_counts(tweets_smi_1['emojis_converted'], ascending=False, normalize=True)

smi1_value_counts_emojis_converted = value_counts_emojis_converted.sort_values(ascending=False)

print(value_counts_emojis_converted)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Emojis converted')
print(smi1_value_counts_emojis_converted.describe().head())
print('---')

smi1_value_counts_emojis_converted_df = pd.DataFrame(value_counts_emojis_converted, columns =['emojis_converted'])

smi1_value_counts_emojis_converted_df.to_csv('4_5_113_SMI1_Emojis_Converted_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_emojis_converted_df.to_excel('4_5_113_SMI1_Emojis_Converted_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
plt.ioff()
# smi1_value_counts_emojis_converted.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_emojis_converted[:10].plot(alpha=0.9)
plt.xticks(rotation=50, fontproperties='Symbola')
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_SYMBOLA_TEST_SMI1_Top_Emojis_Converted_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
plt.ioff()
# plt.pie(smi1_value_counts_emojis_converted[:6], labels=smi1_tweets_text_words_fdist['emojis_converted'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_emojis_converted[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
# plt.legend(smi1_value_counts_emojis_converted, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.tight_layout(pad=1)
# plt.show()
plt.savefig('4_5_113_SMI1_Top_Emojis_Converted_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
plt.ioff()
# smi1_value_counts_emojis_converted[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_SMI1_Top_Emojis_Converted_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Emojis Graphical FREQ DISTRIBUTION

smi1_emojis_graphical = tweets_smi_1['emojis_converted']

# Calculate frequency distribution
smi1_emojis_graphical_fdist = nltk.FreqDist(smi1_emojis_graphical)

# Output top 50 tweets_words

for smi1_emojis_graphical, frequency in smi1_emojis_graphical_fdist.most_common(10):
    print(u'{};{}'.format(smi1_emojis_graphical, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_emojis_graphical_fdist_df = pd.DataFrame(smi1_emojis_graphical_fdist)

smi1_emojis_graphical_fdist_df = pd.DataFrame([smi1_emojis_graphical_fdist])

print('---')
print('Frequency Distribution of Emojis')
print(smi1_emojis_graphical_fdist_df.head(10))
print('---')

smi1_emojis_graphical_fdist_df.to_csv('4_5_113_SMI1_Emojis_Graphical_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_emojis_graphical_fdist_df.to_excel('4_5_113_SMI1_Emojis_Graphical_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution 7')
plt.ioff()
# smi1_emojis_graphical_fdist.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)  
# smi1_emojis_graphical_fdist[:10].plot(alpha=0.9)
plt.xticks(rotation=50, fontproperties='Symbola')
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_7_SYMBOLA_TEST_SMI1_Emojis_Graphical_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_emojis_graphical_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_SMI1_Emojis_Graphical_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Pie')
plt.ioff()
# smi1_emojis_graphical_fdist[:6], labels=top_smi1_emojis_graphical_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_emojis_graphical_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_emojis_graphical_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_113_SMI1_Emojis_Graphical_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_emojis_graphical_fdist = smi1_emojis_graphical_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Bars')
plt.ioff()
# smi1_emojis_graphical_fdist.plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
 
# plt.show()
plt.savefig('4_5_113_SMI1_Emojis_Graphical_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###########################################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Value Counts All Emojis Converted   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# tweets_smi_1['emojis_graphical'] = tweets_smi_1['emojis_converted'].encode('unicode-escape')

value_counts_emojis_graphical = pd.value_counts(tweets_smi_1['emojis_converted'], ascending=False, normalize=True)

smi1_value_counts_emojis_graphical = value_counts_emojis_graphical.sort_values(ascending=False)

print(value_counts_emojis_graphical)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Emojis Graphical')
print(smi1_value_counts_emojis_graphical.describe().head())
print('---')

smi1_value_counts_emojis_graphical_df = pd.DataFrame(value_counts_emojis_graphical, columns =['emojis_graphical'])

smi1_value_counts_emojis_graphical_df.to_csv('4_5_113_SMI1_Emojis_Graphical_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_emojis_graphical_df.to_excel('4_5_113_SMI1_Emojis_Graphical_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
plt.ioff()
# smi1_value_counts_emojis_graphical.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_emojis_graphical[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_SMI1_Top_Emojis_Graphical_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
plt.ioff()
# plt.pie(smi1_value_counts_emojis_graphical[:6], labels=smi1_tweets_text_words_fdist['emojis_graphical'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_emojis_graphical[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
# plt.legend(smi1_value_counts_emojis_graphical, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.tight_layout(pad=1)
# plt.show()
plt.savefig('4_5_113_SMI1_Top_Emojis_Graphical_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
plt.ioff()
smi1_value_counts_emojis_graphical[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_SMI1_Top_Emojis_Graphical_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Emojis Graphical FREQ DISTRIBUTION

smi1_emojis_graphical = tweets_smi_1['emojis_converted']

# Calculate frequency distribution
smi1_emojis_graphical_fdist = nltk.FreqDist(smi1_emojis_graphical)

# Output top 50 tweets_words

for smi1_emojis_graphical, frequency in smi1_emojis_graphical_fdist.most_common(10):
    print(u'{};{}'.format(smi1_emojis_graphical, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 



# smi1_emojis_graphical_fdist_df = pd.DataFrame(smi1_emojis_graphical_fdist)

smi1_emojis_graphical_fdist_df = pd.DataFrame([smi1_emojis_graphical_fdist])

print('---')
print('Frequency Distribution of Emojis Graphical')
print(smi1_emojis_graphical_fdist_df.head(10))
print('---')

smi1_emojis_graphical_fdist_df.to_csv('4_5_113_SMI1_Emojis_Graphical_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_emojis_graphical_fdist_df.to_excel('4_5_113_SMI1_Emojis_Graphical_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution 8')
plt.ioff()
# smi1_emojis_graphical_fdist.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)  
# smi1_emojis_graphical_fdist[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_8_SMI1_Emojis_Graphical_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_emojis_graphical_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_SMI1_Emojis_Graphical_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Pie')
plt.ioff()
# smi1_emojis_graphical_fdist[:6], labels=top_smi1_emojis_graphical_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_emojis_graphical_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_emojis_graphical_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_113_SMI1_Emojis_Graphical_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_emojis_graphical_fdist = smi1_emojis_graphical_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Bars')
plt.ioff()
# smi1_emojis_graphical_fdist.plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
 
# plt.show()
plt.savefig('4_5_113_SMI1_Emojis_Graphical_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################
############################################################################################################

## NEED TO DO LANGUAGE STAS!!!!!!!!!!!!!!

############################################################################################################


# Value Counts All Languages  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_languages = pd.value_counts(tweets_smi_1['language'], ascending=False, normalize=True)

smi1_value_counts_languages = value_counts_languages.sort_values(ascending=False)


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Languages')
print(smi1_value_counts_languages.describe().head())
print('---')


smi1_value_counts_languages_percentages = (smi1_value_counts_languages * 100)/number_total_tweets

smi1_value_counts_list = [[smi1_value_counts_languages, smi1_value_counts_languages, smi1_value_counts_languages_percentages]]


smi1_value_counts_languages_df = pd.DataFrame(value_counts_languages, columns =['languages', 'languages_count', 'languages_percentage'])

smi1_value_counts_languages_df.to_csv('4_5_160_SMI1_Languages_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_languages_df.to_excel('4_5_160_SMI1_Languages_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Languages Value Counts')
plt.ioff()
# smi1_value_counts_languages.plot(10,cumulative=False)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_languages[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_160_SMI1_Top_Languages_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Languages Value Counts - Pie')
plt.ioff()
smi1_value_counts_languages[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
# plt.legend(smi1_value_counts_languages, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_160_SMI1_Top_Languages_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Languages Value Counts - Bars')
plt.ioff()
smi1_value_counts_languages[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_160_SMI1_Top_Languages_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Languages FREQ DISTRIBUTION

smi1_languages = tweets_smi_1['language']

# Calculate frequency distribution
smi1_languages_fdist = nltk.FreqDist(smi1_languages)

# Output top 50 tweets_words

for smi1_languages, frequency in smi1_languages_fdist.most_common(10):
    print(u'{};{}'.format(smi1_languages, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_languages_fdist_df = pd.DataFrame(smi1_languages_fdist)

smi1_languages_fdist_df = pd.DataFrame([smi1_languages_fdist])

print('---')
print('Frequency Distribution of Languages')
print('smi1_languages_fdist_df.head(10)')
print('---')

smi1_languages_fdist_df.to_csv('4_5_161_SMI1_Languages_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_languages_fdist_df.to_excel('4_5_161_SMI1_Languages_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Languages Frequency Distribution')
plt.ioff()
# smi1_languages_fdist.plot(10,cumulative=False, alpha=0.9)  
# smi1_languages_fdist[:10].plot(alpha=0.9) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_161_SMI1_Languages_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Languages Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_languages_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_161_SMI1_Languages_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Languages Frequency Distribution - Pie')
plt.ioff()
# smi1_languages_fdist[:6], labels=top_smi1_languages_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_languages_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_languages_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_161_SMI1_Languages_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_languages_fdist = smi1_languages_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Languages Frequency Distribution - Bars')
plt.ioff()
# smi1_languages_fdist.plot.bar(alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_161_SMI1_Languages_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

############################################################################################################

# NEED FREQ DIST EMOJIS, IMAGE LINK< NEED TO DO MISSING HASHTAFS MENTIONS !!!! < ETC

############################################################################################################
############################################################################################################

## NEED TO DO MISSING MENTIONS AND HASTAGS!!!!

# missing_mentions = pd.DataFrame(missing_mentions)

print('---')
print('Loading Libs 28')
print('---')

# quant_stats_smi_tweets_1 = go.Figure(data=[go.Table(header=dict(values=['Tweets by JAMESCHARLES', 'Tweets by JEFFREESTAR', 'Tweets by MANNYMUA733', 'Tweets by MICHELLEPHAN', 'Tweets by NIKKIETUTORIALS', 'Tweets by ZOELLA', 'Tweets by AUDIENCE']),
#                 cells=dict(values=[[number_tweets_by_jamescharles, number_tweets_by_jeffreestar, number_tweets_by_mannymua733, number_tweets_by_michellephan, number_tweets_by_nikkietutorials, number_tweets_by_zoella, 'number_tweets_by_audience']]))])

# quant_stats_smi_tweets_1.show()

# quant_stats_smi_tweets_1.to_csv('4_5_165_SMI1_Quant_Stats_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# quant_stats_smi_tweets_1.to_excel('4_5_165_SMI1_Quant_Stats.xlsx', header=True)

# Plot ## NEED TO DO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets SMIs - Audience')
plt.ioff()
# plt.plot(quant_stats_smi_tweets_1, edgecolor='white', label=' ', alpha=0.9)
# plt.imshow(quant_stats_smi_tweets_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
 
# plt.show()
plt.savefig('4_5_165_SMI1_Quant_Stats_SMI_Tweets_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets SMIs Audience - Pie')
plt.ioff()
# plt.pie(top_followers_tweets[:6], labels=top_followers_tweets, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# quant_stats_smi_tweets_1.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(top_followers_tweets, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_165_SMI1_Quant_Stats_SMI_Tweets_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets SMIs vs Audience - Bars')
plt.ioff()
# plt.plot.bar(quant_stats_smi_tweets_1)
# quant_stats_smi_tweets_1_df['tweets_about_smi_number'].plot.bar(alpha=0.9)
# ax.bar(tweets_about_percentages_df['tweets_about_smi_item'], tweets_about_percentages_df['tweets_about_smi_number'])
plt.xlabel('SMI / Audience')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_165_SMI1_Quant_Stats_SMI_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

##################################################

# PLOTS  ######### NEED TO DO!!!!!!!!!!!!! NOT WORKING

top_tweets_words_fdist = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True).to_frame()


## NEED TO DO SAVE INFO TO CSV!!!!

top_tweets_words_fdist.to_csv('4_5_104_SMI1_Top_Tweets_Value_Counts_Words_fdist_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# top_tweets_words_fdist.to_excel('4_5_104_SMI1_Top_Tweets_Value_Counts_Words_fdist.xlsx', header=True)

# TABLE PLOT NEED TO DO 

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Word Frequency Distribution - Bars')
plt.ioff()
top_tweets_words_fdist[:10].plot.bar(alpha=0.9)
# value_counts_df_tweets_words_fdist[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5CC_104_SMI1_Top_Tweets_Words_Value_Counts_fdists_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLE

# del top_tweets_df_fdist
# del value_counts_text



####################################################################################################################################################

# This selects the top 5 highest average points among Total Tweets: # NEED TO DO


# Mean followers

# smi1_screenname_mean = statistics.mean(tweets_smi_1['screenName'])
# smi1_screenname_mean

# smi1_screenname_mean.sort_values(by='screenName', ascending=False).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest ScreenName Average Points - Tweets:')
# print(smi1_screenname_mean.sort_values(by="screenName').head)
print('--')

# smi1_screenname_mean_sort_values_df = pd.DataFrame(smi1_screenname_mean().sort_values(by="screenName'))

# smi1_screenname_mean_sort_values_df.to_csv('4_5_166_SM1_Screenname_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Average Points - Tweets')
plt.ioff()
# plt.plot(smi1_screenname_mean_sort_values_df[:10], color='#6593F5', edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_166_SMI1_Screenname_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenName Average Points - Pie')
plt.ioff()
# plt.pie(smi1_screenname_mean_sort_values_df.most_common(10), labels=screenname_mean_sort_values_df.most_common(10), colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_screenname_mean_sort_values_df[:10], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_166_SMI1_Screenname_Mean_Sort_Values_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenName Average Points - Bars')
plt.ioff()
# smi1_screenname_mean_sort_values_df[:10].plot.bar(alpha=0.9)
plt.xlabel('ScreenName')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_166_SMI1_Screenname_Mean_Sort_Values_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################

# This selects the top 5 highest average points among Total Tweets:

# smi1_total_favorites_mean().sort_values(by='total_favorites',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest total_favorites Average Points Among Total Tweets:')
# print(smi1_total_favorites_mean().sort_values(by='total_favorites',ascending=True).head())
print('---')


# smi1_total_favorites_mean_sort_values_total_favorites_df = pd.DataFrame(smi1_total_favorites_mean().sort_values(by='total_favorites', ascending=True))

# smi1_total_favorites_mean_sort_values_total_favorites_df.to_csv('4_5_167_SMI1_Total_Favorites_Mean_Sort_Values_Total_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_total_favorites_mean_sort_values_total_favorites_df.to_excel('4_5_167_SMI1_Total_Favorites_Mean_Sort_Values_Total_Favorites_DF.xlsx', header=True)

# PLOT TABLE plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Average Points - Tweets')
plt.ioff()
# plt.plot(smi1_total_favorites_mean_sort_values_total_favorites_df[:10], edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_167_SMI1_Total_Favorites_Mean_Sort_Values_Total_Favorites_df_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Average Points - Pie')
plt.ioff()
# plt.pie(smi1_total_favorites_mean_sort_values_total_favorites_df[:10], labels=smi1_total_favorites_mean_sort_values_total_favorites_df.most_common(10), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_total_favorites_mean_sort_values_total_favorites_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_167_SMI1_Total_Favorites_Mean_Sort_Values_Total_Favorites_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Average Points - Bars')
plt.ioff()
# smi1_screenname_mean_sort_values_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_167_SMI1_Total_Favorites_Mean_Sort_Values_Total_Favorites_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################

# This selects the top 5 highest average points among Total Tweets:

# smi1_followers_mean().sort_values(by='followers',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest Followers Average Points Amongst Total Tweets:')
# print(smi1_followers_mean().sort_values(by='followers',ascending=True).head())
print('---')

# smi1_followers_mean_sort_values_followers_df = pd.DataFrame(smi1_followers_mean().sort_values(by='followers',ascending=True))

# smi1_followers_mean_sort_values_followers_df.to_csv('4_5_168_SMI1_Followers_Mean_Sort_Values_Followers_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Followers - Grouped')
plt.ioff()
# plt.plot(smi1_languages.describe(), edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_168_SMI1_Followers_Mean_Sort_Values_Followers_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO Box


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Followers Grouped - Pie')
plt.ioff()
# plt.pie(smi1_languages.describe(), labels=smi1_languages.describe(), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_languages.describe(), bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_168_SMI1_Followers_Mean_Sort_Values_Followers_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Average Points - Bars')
plt.ioff()
# smi1_languages.describe().plot.bar(alpha=0.9)
plt.xlabel('Followers')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_168_SMI1_Followers_Mean_Sort_Values_Followers_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#########################################################################################################################################################

# Number of tweets_words in text

number_of_tweets_words = len(smi1_tweets_text_words_fdist)
number_of_tweets_words

print('---')
print('Number of tweets_words Analyzed : No Stop Words')
print(number_of_tweets_words)
print('---')

number_of_tweets_words_df = pd.DataFrame([number_of_tweets_words])

number_of_tweets_words_df.to_csv('4_5_169_SMI1_Number_of_Tweets_Words_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# number_of_tweets_words_df.to_excel('4_5_169_SMI1_Number_of_Tweets_Words_DF.xlsx, header=True)

# PLOT TABLE plt.plot

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Text')
plt.ioff()
# plt.plot(number_of_tweets_words_df.describe())
# plt.plot(number_of_tweets_words_df, edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_169_SMI1_Number_of_Tweets_Words_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO DO Box


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Text - Pie')
plt.ioff()
# plt.pie(number_of_tweets_words_df, labels=number_of_tweets_words_df, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(number_of_tweets_words_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_5_169_SMI1_Number_of_Tweets_Words_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

###################################################################################################

### FROM tweets_words ABOVE

print('---')
print('Loading Libs 29')
print('---')

fdist_2 = FreqDist(word)
print(fdist_2)

fdist_2.most_common(10)

print('---')
print('Frequency Distribution of Tweets_words - Most Common 10')
print(fdist_2.most_common(10))
print('---')

df_fdist_2_df = pd.DataFrame([fdist_2])

df_fdist_2_df.to_csv('4_5_171_SMI1_Word_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# df_fdist_2_df.to_excel('4_5_171_SMI1_Word_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# NEED TO DO - TABLE PLOT 

# PLOT

# Frequency Distribution Plot

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Frequency Distribution of Words')
plt.ioff()
# fdist_2.plot(10,cumulative=False, alpha=0.9)
# fdist_2[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_171_SMI1_Word_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Word Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(FreqDist(word), edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_171_SMI1_Word_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Word Frequency Distribution - Pie')
plt.ioff()
# plt.pie(FreqDist(word)[:6], labels=FreqDist(word), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(FreqDist(word), bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_5_171_SMI1_Word_Freq_Dist_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

###############################################################################################################


# Summary Statistics of all screenNames          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_screenname.describe().head()

print('---')
print('Summary Statistics of All ScreenNames')
print(smi1_screenname.describe().head())
print('---')

smi1_screenname_describe_df = pd.DataFrame(smi1_screenname.describe())

smi1_screenname_describe_df.to_csv('4_5_172_SMI1_Screenname_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot NEED TO DO

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All ScreenNames')
plt.ioff()
# plt.plot(smi1_hashtags.describe())
# plt.plot(smi1_screenname_describe_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_172_SMI1_ScreenName_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All ScreenNames - Pie')
plt.ioff()
# plt.pie(smi1_hashtags.describe(), colors=colors_blue, labels=tweets_numbers_item_values_df['tweets_by_item_description'], startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweets_numbers_item_values_df['tweets_by_item_description'], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend(smi1_hashtags.describe(), loc=3)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_172_SMI1_ScreenName_Describe_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

##########################################################################################################


# Summary Statistics of all Text          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_text.describe().head()

print('---')
print('Summary Statistics of All Text')
print(smi1_text.describe().head())
print('---')

smi1_text_describe_df = pd.DataFrame(smi1_text.describe())

smi1_text_describe_df.to_csv('4_5_173_SM1_Text_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot NEED TO DO

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Text')
plt.ioff()
# plt.plot(smi1_hashtags.describe())
# plt.plot(smi1_text_describe_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_173_SMI1_Text_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################


# hashtags_total_1

# Summary Statistics of all Hashtags          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_hashtags.describe().head()

print('---')
print('Summary Statistics of All Hashtags')
# print(smi1_hashtags.describe().head())
print('---')

# smi1_hashtags_describe_df = pd.DataFrame([smi1_hashtags.describe()])

# smi1_hashtags_describe_df.to_csv('4_5_174_SMI1_Hashtags_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_hashtags_describe_df.to_excel()

# PLOT TABLE ## NEED TO DO 

# plt.plot

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Mentions - Grouped')
plt.ioff()
# plt.plot(smi1_hashtags.describe(), color='#73C2FB', edgecolor='white', label=' ', alpha=0.9)
# plt.plot(smi1_hashtags_describe_df, edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_174_SMI1_Hashtags_Describe_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################


# Summary Statistics of all Mentions          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_mentions.describe().head()


# smi1_mentions_describe_df = pd.DataFrame(smi1_mentions.describe())

# smi1_mentions_describe_df.to_csv('4_5_175_SM1_mentions_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of all Mentions - Grouped')
plt.ioff()
# plt.plot(smi1_mentions.describe(), edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_175_SMI1_Mentions_Describe_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie - NEED TO DO

# Bars - NEED TO DO


############################################################################################################

# Summary Statistics of all Emojis       ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Summary Statistics of All Emojis')
# print(smi1_emojis_unicode.describe())
print('---')


# smi1_emojis_unicode_describe_df = pd.DataFrame(smi1_emojis_unicode.describe())

# smi1_emojis_unicode_describe_df.to_csv('4_5_176_SM1_Emojis_Unicode_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Emojis - Grouped')
plt.ioff()
# plt.plot(smi1_emojis_unicode_df.describe(), edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_176_SMI1_Emojis_Unicode_Describe_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT

# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################

# Summary Statistics of all Emojis Converted          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_emojis_converted.describe().head()

# smi1_emojis_converted_describe_df = pd.DataFrame(smi1_emojis_converted.describe())

# smi1_emojis_converted_describe_df.to_csv('4_5_177_SMI1_Emojis_Converted_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO TABLE 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Emojis - Grouped')
plt.ioff()
# plt.plot(smi1_emojis_converted_describe_df, edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_177_SMI1_Emojis_Converted_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO


#############################################################################################################

############ NEED TO DO = WHAT ABOUT THE OTHER VARIABLES?????????

# List Unique Hashtags ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!

total_hashtags = tweets_smi_1['hashtags']    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_total_hashtags = len(total_hashtags)
number_total_hashtags

print('---')
print('List Total Hashtags')
print(number_total_hashtags)
print('---')

unique_hashtags = tweets_smi_1['hashtags'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_hashtags = len(unique_hashtags)
number_unique_hashtags

print('---')
print('List Unique Hashtags')
print(number_unique_hashtags)
print('---')


tweets_smi_1['single_tweet'] = pd.to_numeric(tweets_smi_1['single_tweet'], errors='ignore')

number_unique_hashtags_df = pd.DataFrame([number_unique_hashtags])

number_unique_hashtags_df.to_csv('4_5_147_SMI1_Number_Unique_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# number_unique_hashtags_df.to_excel('4_5_147_SMI1_Number_Unique_Hashtags_DF.xlsx', header=True)

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Hashtags')
plt.ioff()
# plt.plot(number_unique_hashtags_df[:10], edgecolor='white', label=' ', alpha=0.9)
plt.plot(number_unique_hashtags_df[:10], label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_147_SMI1_1_Number_Unique_Hashtags_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Hashtags - Pie')
plt.ioff()
# plt.pie(number_unique_hashtags_df, colors=colors_blue, labels=number_unique_hashtags_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(number_unique_hashtags_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_147_SMI1_Number_Unique_Hashtags_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

###############################################################################################################

# List Unique TOTAL Hashtags ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!


hashtags_total_1 = tweets_smi_1['hashtags']
missing_unique_hashtags = hashtags_total_1.unique()

missing_number_unique_mentions = len(missing_unique_hashtags)
missing_number_unique_hashtags

print('---')
print('Missing Unique Hashtags')
# print(missing_number_unique_hashtags)
print('---')

missing_number_unique_hashtags_df = pd.DataFrame([missing_number_unique_hashtags])

missing_number_unique_hashtags_df.to_csv('4_5_148_SMI1_Missing_Number_Unique_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Hashtags')
plt.ioff()
plt.plot(missing_number_unique_hashtags_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_148_SMI1_Missing_Number_Unique_Hashtags_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Hashtags - Pie')
plt.ioff()
# plt.pie(missing_number_unique_hashtags_df, colors=colors_blue, labels=missing_number_unique_hashtags_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(missing_number_unique_hashtags_df, loc=3)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_148_SMI1_Missing_Number_Unique_Hashtags_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

###############################################################################################################

# List Unique Mentions ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!

total_mentions = tweets_smi_1['mentions']   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_total_mentions = len(total_mentions)
number_total_mentions

print('---')
print('Number Total Mentions')
print(number_total_mentions)
print('---')

unique_mentions = tweets_smi_1['mentions'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_mentions = len(unique_mentions)
number_unique_mentions

print('---')
print('Number Unique Mentions')
print(number_unique_mentions)
print('---')

number_unique_mentions_df = pd.DataFrame(['number_unique_mentions'])

number_unique_mentions_df.to_csv('4_5_149_SMI1_Number_Unique_Mentions_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Mentions')
plt.ioff()
# plt.plot(number_unique_mentions_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_149_SMI1_Number_Unique_Mentions_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Mentions - Pie')
plt.ioff()
# plt.pie(number_unique_mentions_df, colors=colors_blue, labels=number_unique_mentions_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(number_unique_mentions_df, loc=3)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_149_SMI1_Missing_Number_Unique_Mentions_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

###############################################################################################################

# List MISSING Unique Mentions ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!



missing_unique_mentions = tweets_smi_1['mentions'].unique()

missing_number_unique_mentions = len(missing_unique_mentions)
missing_number_unique_mentions

print('---')
print('Missing Unique Number of Mentions')
print(missing_number_unique_mentions)
print('---')

missing_number_unique_mentions_df = pd.DataFrame([missing_number_unique_mentions])

missing_number_unique_mentions_df.to_csv('4_5_150_SMI1_Missing_Number_Unique_Mentions_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Mentions')
plt.ioff()
plt.plot(missing_number_unique_mentions_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_150_SMI1_Missing_Number_Unique_Mentions_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Mentions - Pie')
plt.ioff()
# plt.pie(missing_number_unique_mentions_df, colors=colors_blue, labels=missing_number_unique_mentions_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(missing_number_unique_mentions_df, loc=3)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_150_SMI1_Missing_Number_Unique_Mentions_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO




###############################################################################################################

# List Unique Emojis Converted

unique_emojis_converted = tweets_smi_1['emojis_converted'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_emojis_converted = len(unique_emojis_converted)
number_unique_emojis_converted

print('---')
print('Number Unique Emojis Converted')
print(number_unique_emojis_converted)
print('---')

number_unique_emojis_converted_df = pd.DataFrame([number_unique_emojis_converted])

number_unique_emojis_converted_df.to_csv('4_5_153_SMI1_Number_Unique_Emojis_Converted_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Emojis')
plt.ioff()
plt.plot(number_unique_emojis_converted_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_153_SMI1_Number_Unique_Emojis_Converted_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO


#####################################

# initialize list of Lists 
numbers_more_values = [['Values for Hashtags', number_total_hashtags, number_unique_hashtags], ['Values for Mentions', number_total_mentions, number_unique_mentions], ['Values for Emojis', 'number_total_emojis_unicode', 'number_unique_emojis_unicode']] 
 
# Create the pandas DataFrame 
numbers_more_values_df = pd.DataFrame(numbers_more_values, columns = ['values_item', 'number_total_item', 'number_unique_item']) 

numbers_more_values_df.to_csv('4_5_154_SMI1_Numbers_More_Values_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# nnumbers_more_values_df.to_excel('4_5_154_SMI1_Numbers_More_Values.xlsx', header=True)


## DELETE VARIABLE

del numbers_more_values
del numbers_more_values_df

###############################################################################################################

# List Unique Language

unique_languages = tweets_smi_1['language'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_languages = len(unique_languages)
number_unique_languages

print('---')
print('Number Unique Languages')
print(number_unique_languages)
print('---')

number_unique_languages_df = pd.DataFrame([number_unique_languages])

number_unique_languages_df.to_csv('4_5_154_SMI1_Number_Unique_Languages_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Languages')
plt.ioff()
plt.plot(number_unique_languages_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
 
# plt.show()
plt.savefig('4_5_154_SMI1_Number_Unique_Languages_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

# Pie - NEED TO DO

# Bars - NEED TO DO


## DELETE VARIABLE

del number_unique_languages
del number_unique_languages_df

#######################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# DATES WITH MOST Tweets

# This is necessary to show lots of columns in pandas 0.12. 
# Not necessary in pandas 0.13.
# pd.set_option('display.width', 5000) 
# pd.set_option('display.max_columns', 60)

# plt.rcParams['figure.figsize'] = (15, 5)

#####################################################################################################

# Most Common Tweet Date

# METHOD 1

value_counts_date = pd.value_counts(tweets_smi_1['created'], ascending=False, normalize=True)

print('---')
print('Loading Libs 30')
print('---')

def get_counts(sequence):  
	counts = defaultdict(int) # values will initialize to 0  
	for x in sequence:    
		counts[x] += 1  
	return counts


def top_counts(count_dict, n=10):  
	value_key_pairs = [(count, tz) for tz, count in count_dict.items()]  
	value_key_pairs.sort()  
	return value_key_pairs[-n:] 

# counts_created_1 = get_counts(tweets_smi_1['created'])

# top_counts_created_1 = top_counts(counts_created)

print('---')
print('Most Common Tweet Date - 1A')
# print('counts_created_1')
print('---')

##############################################

# METHOD 2

print('---')
print('Loading Libs 31')
print('---')

counts_created_2 = Counter(tweets_smi_1['created'])

print('---')
print('Most Common Tweet Date - 2A')
# print('counts_created_2')
print('---')

###########################################################

### NEED TO PLOT

# SAVE TO CSV   ######################################  NEED TO SAVE DATE ON FIRST COLUMN / SECOND COUNT

value_counts_date.to_csv('4_5_160_SMI1_A_df_Top_Dates_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_date = value_counts_date.to_excel('4_5_160_SMI1_A_df_Top_Dates_and_No_Tweets.xlsx', header=True) # Only argument is a string of the output file path


# value_counts_date

print('---')
print('Value Counts Date')
print(value_counts_date.head)
print('---')

# TABLE PLOT NEED TO DO 

# Pie NEED TO DO

# Bars

# TOP DATES WITH TWEET COUNT

top_dates_tweets = value_counts_date.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Dates Where Users Activity for an SMI - Bars')
plt.ioff()
top_dates_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Dates')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_160_A_SMI1_Top_Tweet_Dates_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################################


## NEED TO DO total_favorites AND Followers FOR THOSE DATES!!

# _df _df = pd.DataFrame()

# .to_csv('4_5_.csv', sep='\t', encoding='utf-8', index=True)
# excel

#####################################################################################################

print('---')
print('Loading Libs 31')
print('---')

# TREEMAPS

# Treemap Plotting

# Use ggplot style

# style.use('ggplot') 

# BY favorites

treemap_favorites = tweets_smi_1.sort_values(by='favorites', ascending=False)

# Find Percentage

treemap_favorites['fav_percentage'] = round(100 * treemap_favorites['favorites'] / sum(treemap_favorites['favorites']), 2)

# Create Treemaps Labels

treemap_favorites['text'] = treemap_favorites['text'] + '(' + treemap_favorites['fav_percentage'].astype('str') + '%)'

print('---')
print('Tree Maps Favs 1')
print(treemap_favorites['fav_percentage'].head(10)) ## NEED TO DO - FIX
print('---')

# Get Axis and Figure

fig, ax = plt.subplots()

# Min and Max Values

mini_favorites = min(treemap_favorites['favorites'])
maxi_favorites = max(treemap_favorites['favorites'])

# Finding Colors for each tile

# norm_favorites = plt.colors.Normalize(vmini=mini_favorites, vmax=maxi_favorites)
# colors = [plt.cmap(norm(value)) for value in treemap_favorites['favorites']]

# Plotting

# squarify.plot(sizes=treemap_favorites['favorites'], label=treemap_favorites['text'], alpha=0.8, color=colors)

# Removing Axis

plt.axis('off')

# Invert Y-Axis

plt.gca().invert_yaxis()     ############## NEED TO FIX

# NEED TABLE AND SAVE TO EXCEL AND CSV - NEED TO DO

# Pie ## NEED TO DO - NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Texts by Favorites - Pie') # fontsize=32
plt.ioff()
# plt.pie(treemap_favorites)
plt.legend(treemap_favorites, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_121_SMI1_10_1_Most_Repeteaded_Tweet_Favorites_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BARS PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Texts by Favorites - Bars') # fontsize=32
plt.ioff()
# treemap_favorites.plot.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_121_SMI1_10_1_Most_Repeteaded_Tweet_Favorites_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Plot


# Pie ## NEED TO DO - NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Texts by Favorites - Pie') # fontsize=32
plt.ioff()
# plt.plot(treemap_favorites)
plt.legend(treemap_favorites, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_121_SMI1_10_1_Most_Repeteaded_Tweet_Favorites_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del treemap_favorites

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Common Tweet Text

value_counts_text = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)

df_value_counts_text = pd.DataFrame([value_counts_text])

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

df_value_counts_text.to_csv('4_5_122_2_SMI1_df_Top_Text_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# df_value_counts_text.to_excel('4_5_122_2_SMI1_df_Top_Text_and_No_Tweets.xlsx', header=True)

## NEED TO PLOT

# value_counts_text

print('---')
print('Most Common Tweet Text 2')
# print(value_counts_text)
print('---')

# MOST FREQUENT TEXT IN Tweets

top_texts_tweets = value_counts_text.sort_values(ascending=False)

print('---')
print('Most Frequent Complete Text in Tweets - Bars')
print(value_counts_text.sort_values(ascending=False))
print('---')

## NEED TO DO total_favorites AND Followers FOR THEM!!!

# NEED TO DO TABLE PLOT

# Pie ## NEED TO DO - NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Content of Text - Pie') # fontsize=32
plt.ioff()
# plt.pie(top_texts_tweets[:10])
plt.legend(top_texts_tweets[:6], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_122_2_SMI1_10_Most_Repeteaded_Tweet_Text_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Content of Text - Bars')
plt.ioff()
top_texts_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Most Repeated / Shared / Text Content')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_122_2_SMI1_10_Most_Repeteaded_Tweet_Text_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Plot


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Content of Text - Pie') # fontsize=32
plt.ioff()
plt.plot(top_texts_tweets[:10])
plt.legend(top_texts_tweets[:6], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_122_2_SMI1_10_Most_Repeteaded_Tweet_Text_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLE

del top_texts_tweets

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Common Hashtags

value_counts_hashtags_df = pd.value_counts(tweets_smi_1['hashtags'], ascending=False, normalize=True).to_frame()

# .rename_axis('unique_values').reset_index(name='counts')

print('---')
print('---Most Common Hashtags 2 DataFrame DTYPES')
print(value_counts_hashtags_df.dtypes)
print('---')

print('---')
print('OJOOOOO ---Most Common Hashtags 2 DataFrame HEAD')
print(value_counts_hashtags_df.head)
print('---')

# value_counts_hashtags_df = pd.DataFrame([value_counts_hashtags])

## NEED TO PLOT

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_hashtags_df.to_csv('4_5_2_123_SMI1_df_Top_Hashtags_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_hashtags_df.to_excel('4_5_123_2_SMI1_df_Top_Hashtags_and_No_Tweets.xlsx', header=True)

print('---')
print('---Most Common Hashtags 2')
# print(pd.value_counts(tweets_smi_1['hashtags'], ascending=False, normalize=True))
print('---')

print('---')
print('---Most Common Hashtags 2HEAD')
print(value_counts_hashtags_df.head)
print('---')

print('---')
print('---Most Common Hashtags 2 DTYPES')
print(value_counts_hashtags_df.dtypes)
print('---')

# TABLE AND FRAME DF NEED TO DO 

# Pie NEED TO DO 

# Bars 

# MOST FREQUENT HASHTAGS IN Tweets

top_hashtags_tweets_df = value_counts_hashtags_df

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Hashtags - Bars')
plt.ioff()
top_hashtags_tweets_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Most Repeated / Shared / Hashtags')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_123_2_SMI1_10_Most_Repeteaded_Hashtags_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### NEED TO PUT total_favorites AND followers!!! NEED TO DO NEED TO FIX XXX

## DELETE VARIABLE

del value_counts_hashtags
del top_hashtags_tweets_df

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/
## NNED TO CHECK IF THIS ONE WORKS VS THE OTHERS VALUE COUNTS !!!!!! that are expanded into frames
###
###
###
########

# Most Common Tweet Mentions

## NEED TO CHECK NEED TO FIX XXX DIDNT EXAMPT RESET INDEX DATAFRAME

top_mentions_tweets_df = pd.value_counts(tweets_smi_1['mentions'], ascending=False, normalize=True).to_frame() 


print('---')
print('Most Common Tweet Mentions 3 HEAD')
print(top_mentions_tweets_df.head)
print('---')

print('---')
print('Most Common Tweet Mentions 3 DTYPES')
print(top_mentions_tweets_df.dtypes)
print('---')


# top_mentions_tweets_df = pd.DataFrame(top_mentions_tweets)

top_mentions_tweets_df.to_csv('4_5_148_3A_SMI1_Top_Mentions_Tweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
#.to_ excel()

# TABLE PLOT NEED TO DO 

# Pie ###### NEED TO DO

# Bars

# TOP NUMBERS OF MENTIONS IN Tweets 



# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Mentions Used - Bars')
plt.ioff()
top_mentions_tweets_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Mentions')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_148_3A_SMI1_Top_Tweet_Mentions_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


############################################################################################

# https://towardsdatascience.com/data-science-with-python-intro-to-loading-and-subsetting-data-with-pandas-9f26895ddd7f

#### TWEETS WITH NO emojis_unicode NOT UNIQUE

# SUBSETS

# Number of Tweets With emojis_unicode  ########### NEED TO FIX

tweets_with_emojis_unicode = tweets_smi_1['emojis_unicode']  ######### NEED TO ADD CONDITION - NOT WORKING


print('---')
print('Tweets With emojis_unicode Info -- SERIES VALUE')
# print(tweets_with_emojis_unicode)
print('---')

tweets_with_emojis_unicode_count = tweets_with_emojis_unicode.count()

print('---')
print('Tweets With emojis_unicode Count')
# print(tweets_with_emojis_unicode_count)
print('---')


tweets_without_emojis_unicode_filter = tweets_smi_1[tweets_smi_1.emojis_unicode == 0]

# tweets_without_emojis_unicode_filter = pd.DataFrame(tweets_without_emojis_unicode_filter)

number_tweets_without_emojis_unicode_filter = len(tweets_without_emojis_unicode_filter)
number_tweets_without_emojis_unicode_filter

print('---')
print('Number of Tweets Without emojis_unicode - FILTER')
print(number_tweets_without_emojis_unicode_filter)
print('---')


percentage_tweets_without_emojis_unicode_filter = ((number_tweets_without_emojis_unicode_filter * 100)/number_total_tweets)
percentage_tweets_without_emojis_unicode_filter

print('---')
print('Percentage of Tweets Without emojis_unicode - Filter')
print(percentage_tweets_without_emojis_unicode_filter)
print('---')

number_tweets_with_emojis_unicode_not_unique = number_total_tweets - number_tweets_without_emojis_unicode_filter
number_tweets_with_emojis_unicode_not_unique

print('---')
print('Number of Tweets With emojis_unicode')
print(number_tweets_with_emojis_unicode_not_unique)
print('---')

percentage_tweets_with_emojis_unicode_not_unique = ((number_tweets_with_emojis_unicode_not_unique * 100)/number_total_tweets)
percentage_tweets_with_emojis_unicode_not_unique

print('---')
print('Percentage of Tweets With emojis_unicode')
print(percentage_tweets_with_emojis_unicode_not_unique)
print('---')

number_tweets_no_emojis_unicode = number_total_tweets - number_tweets_with_emojis_unicode_not_unique

print('---')
print('Number of Tweets Without emojis_unicode')
print(number_tweets_no_emojis_unicode)
print('---')

percentage_tweets_no_emojis_unicode = 100 - percentage_tweets_with_emojis_unicode_not_unique

print('---')
print('Percentage of Tweets Without emojis_unicode')
print(percentage_tweets_no_emojis_unicode)
print('---')

##############

# Inicialize List of Lists TWEETS WITH emojis_unicode NOT UNIQUES emojis_unicode

tweet_info_emojis_unicode_not_unique = [['Tweets With Emojis', number_tweets_with_emojis_unicode_not_unique, percentage_tweets_with_emojis_unicode_not_unique], ['Tweets Without Emojis', number_tweets_without_emojis_unicode_filter, percentage_tweets_without_emojis_unicode_filter]]

# Create DataFrame

tweet_info_emojis_unicode_not_unique_df = pd.DataFrame(tweet_info_emojis_unicode_not_unique, columns =['tweet_info_emojis_unicode_not_unique', 'number_tweet_info_emojis_unicode_not_unique', 'percentage_tweet_info_emojis_unicode_not_unique'])

print('---')
print('Tweet Info emojis_unicode NOT UNIQUE Information')
# print(tweet_info_emojis_unicode_not_unique_df.head)
print('---')

tweet_info_emojis_unicode_not_unique_df.to_csv('4_4_43_38_SMI1_Tweet_Info_Emojis_Unicode_Not_Unique_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_emojis_unicode_not_unique_df.to_excel('4_4_43_38_SMI1_Tweet_Info_Emojis_Unicode_Not_Unique_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets With Emojis Not Unique - Pie')
# plt.pie(tweet_info_emojis_unicode_df['number_tweet_info_emojis_unicode'], labels=tweet_info_emojis_unicode_df['tweet_info_emojis_unicode'])
plt.pie(tweet_info_emojis_unicode_not_unique_df['number_tweet_info_emojis_unicode_not_unique'], labels=tweet_info_emojis_unicode_not_unique_df['tweet_info_emojis_unicode_not_unique'], colors=colors_blue, startangle=80, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweet_info_emojis_unicode_not_unique_df['tweet_info_emojis_unicode_not_unique'], bbox_to_anchor=(1.05, 1.05), loc='upper right', borderaxespad=0.) # bbox_to_anchor=(1.05, 1), 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_38_SMI1_Tweet_Info_Emojis_Unicode_Not_Unique_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Unicode Counts Not Unique - Bars')
tweet_info_emojis_unicode_not_unique_df['number_tweet_info_emojis_unicode_not_unique'].plot.bar(alpha=0.9)
# ax.bar(tweet_info_emojis_unicode_not_unique_df['tweet_info_emojis_unicode_not_unique'], tweet_info_emojis_unicode_not_unique_df['number_tweet_info_emojis_unicode_not_unique'])
plt.xticks(rotation=50)
plt.xlabel('Tweets With Emojis, Tweets With No Emojis')
plt.ylabel('Count')
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_38_SMI1_Tweet_Info_Emojis_Unicode_Not_Unique_df_Counts_Bars_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# List Unique Emojis Unicode


unique_emojis_unicode = tweets_smi_1['emojis_unicode'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_emojis_unicode = len(unique_emojis_unicode)
number_unique_emojis_unicode

# unique_emojis_unicode = emoji.emojize(unique_emojis_unicode)

# NEED TO DO CHANGE UNICODE TO EMOJI GRAPHICAL

print('---')
print('Number Unique Emojis Unicode')
print(number_unique_emojis_unicode)
print('---')

number_unique_emojis_unicode_df = pd.DataFrame([number_unique_emojis_unicode])

number_unique_emojis_unicode_df.to_csv('4_4_43_191_SMI1_Number_Unique_Emojis_Unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Emojis')
plt.plot(number_unique_emojis_unicode_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_191_SMI1_Number_Unique_Emojis_Unicode_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Emojis - Bars')
# plt.bar(number_unique_emojis_unicode_df)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_191_SMI1_Number_Unique_Emojis_Unicode_DF_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################################################################
###################################################################################################
#################################################################################################

### XXX NEED TO FIX NOT WORKING 

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


# METHOD 1 GEO

# fp_location = tweets_smi_1['location'].to_string()

# fp_location = fp_location_temp.to_string()

# fp_location = tweets_smi_1['location'].astype(str, errors='ignore')


fp_location = str(tweets_smi_1['geo'])

# fp_location = fp_location.to_string()

print('fp_location dtypes')
# print(fp_location.dtypes)
print('---')

tweets_text_location = nltk.word_tokenize(fp_location)


total_number_location = len(tweets_text_location)
smi1_total_number_location_df = pd.DataFrame([total_number_location], columns=['total_number_location'])

smi1_total_number_location_df.to_csv('4_4_43_100_SMI1_GEO_Total_Number_Location_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_total_number_location_df.to_excel('4_4_43_100_SMI1_GEO_Total_Number_Location_DF.xlsx', header=True)

value_counts_location = pd.value_counts(tweets_text_location, ascending=False, normalize=True) 

smi1_value_counts_location = value_counts_location.sort_values(ascending=False)

# smi1_value_counts_location_freq_dist = tweets_text_location.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Location - Frequency')
print(smi1_value_counts_location.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts location')
print(smi1_value_counts_location.describe().head)
print('---')

smi1_value_counts_location_df = pd.DataFrame(smi1_value_counts_location, columns=['location_frequency'])


print('---')
print('OJO  XXXX smi1_value_counts_location_df location_frequency')
print(smi1_value_counts_location_df['location_frequency'].head)
print('---')


smi1_value_counts_location_df.to_csv('4_4_43_100_SMI1_GEO_Value_Counts_Location_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_location_df.to_excel('4_4_43_100_SMI1_GEO_Value_Counts_Location_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Locations Value Counts')
plt.plot(smi1_value_counts_location[:10], alpha=0.9)
plt.xlabel('Location')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_100_SMI1_GEO_Top_Location_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))     ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Locations Value Counts - Pie')
smi1_value_counts_location[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(smi1_value_counts_location, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_100_SMI1_GEO_Top_Location_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Locations Value Counts - Bars')
smi1_value_counts_location[:10].plot.bar(alpha=0.9)
plt.xlabel('Location')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_100_SMI1_GEO_Top_location_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###############################################################################################################
#####

# METHOD 1 MISSING COUNTRY

print('OJO CAMBIE MISSING_COUNTRY POR GEO !!!! ')

# fp_missing_country = tweets_smi_1['missing_country'].to_string()

# fp_missing_country = fp_missing_country.to_string()

# fp_missing_country = fp_missing_country_temp.to_string()

# fp_missing_country = tweets_smi_1['missing_country'].astype(str, errors='ignore')


#### fp_missing_country = str(tweets_smi_1['missing_country']) 

fp_missing_country = str(tweets_smi_1['geo'])


print('fp_missing_country dtypes')
# print(fp_missing_country.dtypes)
print('---')


tweets_text_missing_country = nltk.word_tokenize(fp_missing_country)

value_counts_missing_country = pd.value_counts(tweets_text_missing_country, ascending=False, normalize=True) 

smi1_value_counts_missing_country = value_counts_missing_country.sort_values(ascending=False)

# smi1_value_counts_missing_country_freq_dist = tweets_text_missing_country.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts missing_country - Frequency')
print(smi1_value_counts_missing_country.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts missing_country NEED TO DOOOOOOOOOOOOOOOOOOOOOO')
print(smi1_value_counts_missing_country.describe().head)
print('---')

smi1_value_counts_missing_country_df = pd.DataFrame(smi1_value_counts_missing_country, columns=['missing_country_frequency'])

smi1_value_counts_missing_country_df.to_csv('4_4_43_100_SMI1_Value_Counts_Missing_Country_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_missing_country_df.to_excel('4_4_43_100_SMI1_Value_Counts_Missing_Country_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Country Value Counts')
plt.plot(smi1_value_counts_missing_country[:10], alpha=0.9)
plt.xlabel('Country')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Missing_Country_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top M Country Value Counts - Pie')
smi1_value_counts_missing_country[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(smi1_value_counts_missing_country, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Missing_Country_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Country Value Counts - Bars')
smi1_value_counts_missing_country[:10].plot.bar(alpha=0.9)
plt.xlabel('Country')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Missing_Country_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################################################################

# METHOD 1 EMOJIS UNICODE

# fp_emojis_unicode = tweets_smi_1['emojis_unicode'].to_string()

# fp_emojis_unicode = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore')

# fp_emojis_unicode = fp_emojis_unicode_temp.to_string()


fp_emojis_unicode = str(tweets_smi_1['emojis_unicode'])

# fp_emojis_unicode = fp_emojis_unicode_temp.to_string()

print('fp_emojis_unicode dtypes')
# print(fp_emojis_unicode.dtypes)
print('---')

# tweets_text_emojis_unicode = nltk.word_tokenize(fp_emojis_unicode)

# value_counts_emojis_unicode = pd.value_counts(tweets_text_emojis_unicode, ascending=False, normalize=True) 

smi1_value_counts_emojis_unicode_df = pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True).to_frame()


print('----')
print('Value Counts emojis_unicode - Frequency 1 HEAD')
print(smi1_value_counts_emojis_unicode_df.head)
print('----')


print('---')
print('Summary Statistics - All Value Counts emojis_unicode OJO REVISAR!!!!! NEED TO FIX NEED TO DO')
# print(smi1_value_counts_emojis_unicode_df.describe().head)
print('---')


smi1_value_counts_emojis_unicode_df.to_csv('4_4_43_100_SMI1_Value_Counts_Emojis_Unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_emojis_unicode_df.to_excel('4_4_43_100_SMI1_Value_Counts_Emojis_Unicode_DF.xlsx', header=True)

# smi1_value_counts_emojis_unicode_df['emojis_unicode'] = smi1_value_counts_emojis_unicode_df['emojis_unicode'].apply(lambda x: x.re.sub('\\\\', '\'))
# smi1_value_counts_emojis_unicode_df = smi1_value_counts_emojis_unicode_df.replace('\\\\', '\')
# smi1_value_counts_emojis_unicode_df = re.sub('\\\\', '\', smi1_value_counts_emojis_unicode_df)

# smi1_value_counts_emojis_unicode_df['emojis_unicode'] = smi1_value_counts_emojis_unicode_df['emojis_unicode'].str.replace(r'\\\\U', r'\U')

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT # XXX NEED TO FIX NOT WORKING 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
# plt.plot(smi1_value_counts_emojis_unicode_df[:10], alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_EMOJIS_Unicode_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie # XXX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True)[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(smi1_value_counts_emojis_unicode, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_EMOJIS_Unicode_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True)[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Emojis_Unicode_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Commons Emojis Unicode

top_emojis_unicode_tweets_df = pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True).to_frame()


value_counts_emojis_unicode_df = pd.DataFrame(value_counts_emojis_unicode)

print('---')
print('Most Common Emojis Unicode 3 HEAD')
print(top_emojis_unicode_tweets_df.head)
print('---')

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

top_emojis_unicode_tweets_df.to_csv('4_5_149_3_SMI1_df_Top_Emojis_Unicode_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# top_emojis_unicode_tweets_df.to_excel('4_5_149_3_SMI1_df_Top_Emojis_Unicode_and_No_Tweets.xlsx', header=True)

# TOP NUMBERS OF EMOJIS UNICODE IN Tweets 


# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis')
plt.ioff()
# plt.plot(top_emojis_unicode_tweets_df[:10], alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50, fontproperties='Symbola')
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_149_3_SYMBOLA_TEST_SMI1_Top_Tweet_Emojis_Unicode_Number_Tweets_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis - Pie')
plt.ioff()
# plt.pie(top_emojis_unicode_tweets_df[:10], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.pie(top_emojis_unicode_tweets_df[:10], autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.legend(top_emojis_unicode_tweets_df[:10], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_149_3_SMI1_Top_Tweet_Emojis_Unicode_Number_Tweets_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis - Bars')
plt.ioff()
top_emojis_unicode_tweets_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50, fontproperties='Symbola')
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_149_3_SYMBOLA_TEST_SMI1_Top_Tweet_Emojis_Unicode_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLE

del value_counts_emojis_unicode
del value_counts_emojis_unicode_df
# del top_emojis_unicode_tweets
del top_emojis_unicode_tweets_df

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Common Tweet Languages

value_counts_language = pd.value_counts(tweets_smi_1['language'], ascending=False, normalize=True)

## NEED TO PLOT

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_language.to_csv('4_5_3_155_SMI1_df_Top_Language_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_language.to_excel('4_5_155_3_SMI1_df_Top_Language_and_No_Tweets.xlsx', header=True)

value_counts_language

print('---')
print('Most Common Tweet Languages 3')
# print(value_counts_language)
print('---')

value_counts_language_df = pd.DataFrame(value_counts_language)


## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Value Counts Tweets Languages - Pie')
plt.ioff()
# plt.pie(value_counts_language[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(value_counts_language[:6], autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(value_counts_language, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_155_3_SMI1_Value_Counts_Language_Tweets_Language_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars

# TOP NUMBERS OF LANGUAGE IN Tweets 

top_languages_tweets = value_counts_language.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Languages Used - Bars')
plt.ioff()
top_languages_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_155_3_SMI1_Top_Tweet_Languages_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################

# PERCENTAGE OF Tweets BY TOP USERS

percentage_tweets_screenname = (tweets_smi_1['screenName'].value_counts(normalize=True) * 100)
percentage_tweets_screenname

print('---')
print('Percentage of Tweets by Top Users - ScreenName 3')
# print(percentage_tweets_screenname)
print('---')

percentage_tweets_screenname_df = pd.DataFrame(percentage_tweets_screenname)

percentage_tweets_screenname_df.to_csv('4_5_157_3_SMI1_Percentage_Tweets_Screenname_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets by ScreenName - Pie')
plt.ioff()
# plt.pie(percentage_tweets_screenname[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentage_tweets_screenname[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentage_tweets_screenname, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_157_3_SMI1_Percentage_Tweets_ScreenName_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

# PERCENTAGE OF Tweets WITH followers

percentage_tweets_followers = (tweets_smi_1['followers'].value_counts(normalize=True) * 100)

print('---')
print('Percentage of Tweets with Followers ')
# print(percentage_tweets_followers)
print('---')

percentage_tweets_followers_df = pd.DataFrame(percentage_tweets_followers)

percentage_tweets_followers_df.to_csv('4_5_158_3_SMI1_Percentage_Tweets_Followers_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Followers - Pie')
plt.ioff()
# plt.pie(percentage_tweets_followers[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentage_tweets_followers[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentage_tweets_followers, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_158_3_SMI1_Percentage_Tweets_Followers_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

# PERCENTAGE OF Tweets WITH HASHTAGS

percentage_tweets_hashtags = (tweets_smi_1['hashtags'].value_counts(normalize=True) * 100)
percentage_tweets_hashtags

print('---')
print('Percentage of Tweets with Hashtags 3')
# print(percentage_tweets_hashtags)
print('---')

percentage_tweets_hashtags_df = pd.DataFrame(percentage_tweets_hashtags)

percentage_tweets_hashtags_df.to_csv('4_5_159_3_SMI1_Percentage_Tweets_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Hashtags - Pie')
plt.ioff()
# plt.pie(percentage_tweets_hashtags[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentage_tweets_hashtags[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentage_tweets_hashtags, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()
# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_159_3_SMI1_Percentage_Tweets_Hashtags_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

percentage_tweets_screenname = (tweets_smi_1['screenName'].value_counts(normalize=True) * 100)
percentage_tweets_screenname

# PERCENTAGE OF Tweets WITH EMOJIS_UNICODE


print('---')
print('Percentage of Tweets with Emojis - Unicode 3')
# print(percentage_tweets_emojis_unicode)
print('---')


## NEED TO PLOT 

percentage_tweets_emojis_unicode_df = pd.DataFrame(percentage_tweets_emojis_unicode)

percentage_tweets_emojis_unicode_df.to_csv('4_5_160_3_SMI1_Percentage_Tweets_Emojis_Unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Emojis - Pie')
plt.ioff()
# plt.pie(percentage_tweets_emojis_unicode[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentage_tweets_emojis_unicode[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentage_tweets_emojis_unicode, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_160_3_SMI1_Percentage_Tweets_Emojis_Unicode_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

# PERCENTAGE OF Tweets WITH EMOJIS_CONVERTED

percentage_tweets_emojis_converted = (tweets_smi_1['emojis_converted'].value_counts(normalize=True) * 100)
percentage_tweets_emojis_converted

print('---')
print('Percentage of Tweets with Emojis Converted 3')
# print(percentage_tweets_emojis_converted)
print('---')


percentage_tweets_emojis_converted_df = pd.DataFrame(percentage_tweets_emojis_converted)

percentage_tweets_emojis_converted_df.to_csv('4_5_161_3_SMI1_Percentage_Tweets_Emojis_Converted_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Emojis - Pie')
plt.ioff()
# plt.pie(percentage_tweets_emojis_converted[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentage_tweets_emojis_converted[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentage_tweets_emojis_converted, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_161_3_SMI1_Percentage_Tweets_Emojis_Converted_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO


########################################################################################################

# PERCENTAGE OF LANGUAGES

percentage_tweets_languages = (tweets_smi_1['language'].value_counts(normalize=True) * 100)
percentage_tweets_languages

print('---')
print('Percentage of Tweets Languages')
# print(percentage_tweets_languages)
print('---') 

percentage_tweets_languages_df = pd.DataFrame(percentage_tweets_languages)

percentage_tweets_languages_df.to_csv('4_5_163_SMI1_Percentage_Tweets_Languages_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# percentage_tweets_languages_df.to_excel()

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets Languages - Pie')
plt.ioff()
# plt.pie(percentages_tweets_languages[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentage_tweets_languages[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentage_tweets_languages, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_165_SMI1_Percentage_Tweets_Languages_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO


############################################################################################################

# https://matplotlib.org/3.1.1/gallery/pie_and_polar_chafollowers/pie_and_donut_labels.html#sphx-glr-gallery-pie-and-polar-chafollowers-pie-and-donut-labels-py
# https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplt.pie.html

##############################################################################################################

# Pie : PERCENTAGE OF total_favorites / Top

percentages_total_favorites_tweets = (tweets_smi_1['favorites'].value_counts(normalize=True) * 100)

print('--')
print('Percentage of Favorite Tweets')
# print(percentages_total_favorites_tweets)
print('--')

percentages_total_favorites_tweets_df = pd.DataFrame(percentages_total_favorites_tweets)

percentages_total_favorites_tweets_df.to_csv('4_5_165A_SMI1_Percentages_Total_Favorites_Tweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# to_excel()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Favorites - Pie')
plt.ioff()
# plt.pie(percentages_total_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.pie(percentages_total_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.legend(percentages_total_favorites_tweets, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_165A_SMI1_Percentages_Total_Favorites_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

####################################################################################################################

# https://plot.ly/python/pie-chafollowers/

# Pie : PERCENTAGE OF total_favorites / Top

percentages_total_favorites_tweets = (tweets_smi_1['favorites'].value_counts(normalize=True) * 100) ## XXX NEED TO FIX NOT WORKING PUSE SOLO FAVORITOS NO TOTLA FAVORITOS

print('--')
print('Percentage of total_favorites - Top')
# print(smi1_total_favorites.size().sort_values(ascending=False))
print('--')

percentages_total_favorites_tweets_df = pd.DataFrame(percentages_total_favorites_tweets)

percentages_total_favorites_tweets_df.to_csv('4_5_167_SMI1_Percentages_Total_Favorites_Tweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# to_excel()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Favorites - Pie')
plt.ioff()
# plt.pie(percentages_total_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.pie(percentages_total_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.legend(percentages_total_favorites_tweets, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_167_SMI1_Percentage_Total_Favorites_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO


print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

########################################################################################################

# Bars

# HASTAGS

number_of_hashtags_in_tweets = tweets_smi_1['hashtags'].count()

# NEED TO GROUP

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Hashtags / Time - Bars')
plt.ioff()
# plt.plot(created, number_of_hashtags_in_tweets, label='linear')
# number_of_hashtags_in_tweets.sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Count')
ax.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_178_SMI1_Hashtags_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


smi1_total_hashtags_size_sort_values_df = pd.DataFrame([number_of_hashtags_in_tweets])

smi1_total_hashtags_size_sort_values_df.to_csv('4_5_178_SMI1_Total_Hashtags_Size_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

########################################################################################################
########################################################################################################

# HASHTAGS PLOTS BAR

# HASHTAGS

number_of_hashtags_in_tweets = tweets_smi_1['hashtags'].value_counts()

# NEED TO GROUP!!!!

# Plot the data ## NEED TO FIX 

# TABLE PLOT NEED TO DO 
# Bars NEED TO DO

# Bars

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Hashtags / Time - Bars')
plt.ioff()
# plt.plot(created, number_of_hashtags_in_tweets, label='linear')
# number_of_hashtags_in_tweets.sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Hashtags')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_179_SMI1_Number_Hashtags_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()
plt.clf()


number_of_hashtags_in_tweets = pd.DataFrame(number_of_hashtags_in_tweets, columns=['number_of_hashtags_in_tweets'])

number_of_hashtags_in_tweets.to_csv('4_5_179_SMI1_Number_of_Hashtags_in_Tweets_CSV.csv')
# .to_excel()


########################################################################################################

# MENTIONS PLOTS BAR

# MENTIONS

number_of_mentions_in_tweets = tweets_smi_1['mentions'].value_counts()

# NEED TO GROPU!!!!

# Plot the data ## NEED TO FIX 

# TABLE PLOT NEED TO DO 
# Bars NEED TO DO

# Bars

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Mentions / Time - Bars')
plt.ioff()
# plt.plot(created, number_of_mentions_in_tweets, label='linear')
# number_of_mentions_in_tweets.sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Mentions')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_179_SMI1_Number_Hashtags_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()
plt.clf()


number_of_hashtags_in_tweets = pd.DataFrame(number_of_hashtags_in_tweets, columns=['number_of_hashtags_in_tweets'])

number_of_hashtags_in_tweets.to_csv('4_5_179_SMI1_Number_of_Hashtags_in_Tweets_CSV.csv')
# .to_excel()

########################################################################################################

print('---')
print('Most Common Tweet tweets_smi_1 HEAD')
print(tweets_smi_1.head)
print('---')

print('---')
print('Most Common Tweet tweets_smi_1 DTYPES')
print(tweets_smi_1.dtypes)
print('---')


print('---')
print('Most Common Tweet tweets_followers HEAD')
print(tweets_smi_1['followers'].head)
print('---')

print('---')
print('Most Common Tweet tweets_following HEAD')
print(tweets_smi_1['following'].head)
print('---')

# LINE PLOTS

# Numer of Followers / favorites


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Numer of Followers / Favorites')
plt.ioff()

# Plot with differently-colored markers.
plt.plot(tweets_smi_1['year'], tweets_smi_1['followers'], 'b-', label='followers')
plt.plot(tweets_smi_1['year'], tweets_smi_1['favorites'], 'r-', label='favorites')

# Create legend.
plt.legend(loc='upper left')
plt.xlabel('Year')
plt.ylabel('Followers / Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_180_SMI1_Number_Followers_Favorites_Time_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Numer of Followers / retweets


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Numer of Followers / Retweets')
plt.ioff()

# Plot with differently-colored markers.
plt.plot(tweets_smi_1['year'], tweets_smi_1['followers'], 'b-', label='followers')
plt.plot(tweets_smi_1['year'], tweets_smi_1['retweets'], 'r-', label='retweets')

# Create legend.
plt.legend(loc='upper left')
plt.xlabel('Year')
plt.ylabel('Followers / Retweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_180_1_SMI1_Number_Followers_Retweets_Time_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################

# Bars

# Number of Followers of Tweets


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Followers - Bars')
plt.ioff()
# plt.plot(tweets_smi_1['year'], smi1_followers, label='linear')
# smi1_followers.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Followers')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
ax.grid(True)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_182_SMI1_Number_Followers_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################


# Bars

# Most Commom Languages 


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Languages - Bars')
plt.ioff()
# plt.plot(tweets_smi_1['year'], smi1_languages, label='linear')
# smi1_languages.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_183_SMI1_Language_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

# Summary Statistics of all Dates       ## NEED TO FIX AND PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_created_describe = tweets_smi_1['created'].describe()
smi1_created_describe

print('---')
print('Summary Statistics of all Dates')
print(smi1_created.describe().head())
print('---')

smi1_created_describe_df = pd.DataFrame(smi1_created_describe)

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

smi1_created_describe.to_csv('4_5_193_SM1_Created_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_created_describe.to_excel('4_5_193_SM1_Created_Describe_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# plt.plot

# PLOT


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Dates - Grouped')
plt.ioff()
# plt.plot(smi1_created.describe())
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_193_SM1_Created_Describe_DF_g_1.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###############################################################################################
###############################################################################################
###############################################################################################


###############################################################################################################

# https://towardsdatascience.com/data-science-with-python-intro-to-loading-and-subsetting-data-with-pandas-9f26895ddd7f

# SUBSETS

# Number of Users With Tweets with Friends  ###### NEED TO FIX AND DO Followers

print('AUDIENCE AND ENGAGEMENT STATISTICS')


users_tweets_with_friends = tweets_smi_1[['screenName', 'is_friend']]

users_unique_tweets_with_friends = users_tweets_with_friends['is_friend'].unique() ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

users_number_unique_tweets_with_friends = len(users_unique_tweets_with_friends)
users_number_unique_tweets_with_friends


print('---')
print('Number of Unique Usernames of Tweets With Friends')
# print(users_number_unique_tweets_with_friends)
print('---')

users_percentage_unique_tweets_with_friends = ((users_number_unique_tweets_with_friends * 100)/main_smi_no_followers)
users_percentage_unique_tweets_with_friends

print('---')
print('Percentage of Unique Usernames of Tweets With Friends')
# print(users_percentage_unique_tweets_with_friends)
print('---')


# List Unique Users Tweeting with friends

engaged_users_with_friends = tweets_smi_1[(tweets_smi_1['screenName'] == main_smi_1)]

unique_engaged_users_with_friends = engaged_users_with_friends['screenName'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_engaged_users_with_friends = len(unique_engaged_users_with_friends)
number_unique_engaged_users_with_friends

print('---')
print('List Unique Users Tweeting _with_friends')
# print(number_unique_engaged_users_with_friends)
print('---')

percentage_unique_engaged_users_with_friends = ((number_unique_engaged_users_with_friends * 100)/main_smi_no_followers)
percentage_unique_engaged_users_with_friends

print('---')
print('Percentage Unique Users Commenting, With Friends')
print(percentage_unique_engaged_users_with_friends)
print('---')

number_not_engaged_users_with_friends = main_smi_no_followers - number_unique_engaged_users_with_friends
number_not_engaged_users_with_friends

print('---')
print('List Unique Followers NOT Tweeting _with_friends')
print(number_not_engaged_users_with_friends)
print('---')


percentage_not_engaged_users_with_friends = 100 - percentage_unique_engaged_users_with_friends
percentage_not_engaged_users_with_friends

print('---')
print('Percentage Followers NOT Tweeting _with_friends')
print(percentage_not_engaged_users_with_friends)
print('---')


############ 2975  ### NEED TO DO FIX!!!!! NOT WORKING

print('------------- NEED TO DO - FIX BELOW')

# Inicialize List of Lists

engaged_users_items_with_friends = [['Users Who Tweet with friends', number_unique_engaged_users_with_friends, percentage_unique_engaged_users_with_friends], ['Users Not Tweeting with friends', number_not_engaged_users_with_friends, percentage_not_engaged_users_with_friends]]

# Create DataFrame

engaged_users_with_friends_df = pd.DataFrame(engaged_users_items_with_friends, columns =['engagement_description_with_friends', 'engagement_number_value_with_friends', 'engagement_users_percentage_with_friends'])

print('---')
print('Engaged Users: Who Tweeted --- NEED TO FIX')
print(engaged_users_with_friends_df)
print('---')

engaged_users_with_friends_df.to_csv('4_4_75_SMI1_df_Engaged_Users_with_Friends_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# engaged_users_with_friends_df.to_excel('4_4_75_SMI1_df_Engaged_Users_with_Friends.xlsx', header=True)

# Inicialize List of Lists

engaged_users_items_perct_with_friends = [['Users Who Tweet with friends', percentage_unique_engaged_users_with_friends], ['Users Not Tweeting with friends', percentage_not_engaged_users_with_friends]]

# Create DataFrame

engaged_users_df_perct_with_friends = pd.DataFrame(engaged_users_items_perct_with_friends, columns =['engagement_description_perct_with_friends', 'engagement_users_percentage_perct_with_friends'])

print('---')
print('Engaged Users: Who Tweeted --- NEED TO FIX')
print(engaged_users_df_perct_with_friends)
print('---')

# PLOT TABLE NEED TO DO!!!!!!!!!

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Engaged Users with Friends - Pie')
plt.ioff()
plt.pie(engaged_users_df_perct_with_friends['engagement_users_percentage_perct_with_friends'], labels=engaged_users_df_perct_with_friends['engagement_description_perct_with_friends'], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=engaged_users_df_perct_with_friends['engagement_description_perct_with_friends'], loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_75_SMI1_Engaged_Users_DF_with_Friends_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Engaged Users Who Tweet - Bars')
plt.ioff()
# engaged_users_df_with_friends[:10].plot.bar(alpha=0.9)
engaged_users_df_perct_with_friends.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
plt.xlabel('ScreenName')
plt.ylabel('Count')
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_75_SMI1_Engaged_Users_DF_with_Friends_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


###############################################################################################


######################################################################################################
######################################################################################################
######################################################################################################

# USER ANALYSIS - Followers Friends

# https://tutswiki.com/pandas-cookbook/chapter2/

# TOP USERS WHO TWEET (COMMENT ABOUT AN SMI) WITH TWEET COUNT

# Top Tweets Count Users

users_who_tweet = pd.value_counts(tweets_smi_1['screenName'], ascending=False, normalize=True)

# TOP NUMBERS OF USERS IN Tweets 

users_who_tweet_and_tweet_value_sort = users_who_tweet.sort_values(ascending=False)
top_users_who_tweet_and_tweet_value_counts = users_who_tweet_and_tweet_value_sort[10:]

top_users_who_tweet_and_tweet_value_counts_df = pd.DataFrame(top_users_who_tweet_and_tweet_value_counts)

# SAVE TO CSV   ######################################  NEED TO SAVE USERNAMES ON FIRST COLUMN / SECOND IS COUNT

top_users_who_tweet_and_tweet_value_counts_df.to_csv('4_4_61_SMI1_df_Top_Users_Who_Tweet_and_Tweet_Value_Counts_3_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# top_users_who_tweet_and_tweet_value_counts_df.to_excel('4_4_61_SMI1_Top_Users_Who_Tweet_and_Tweet_Value_Counts_3.xlsx', header=True)

# value_counts_users
# df_value_counts_users

print('---')
print('Top Users Who Tweet and Tweet Value Count')
# print(top_users_who_tweet_and_tweet_value_counts_df.head)
print('---')

print('---')
print('Top Users Who Tweet and Tweet Value Info')
print(top_users_who_tweet_and_tweet_value_counts_df.info)
print('---')

print('---')
print('Top Users Who Tweet and Tweet Value D Types')
print(top_users_who_tweet_and_tweet_value_counts_df.dtypes)
print('---')

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Users Who Tweet - Pie')
plt.ioff()
tweets_smi_1['screenName'].value_counts(normalize=True)[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweets_smi_1['screenName'], loc='upper right', borderaxespad=0.) 
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_61_SMI1_Top_Users_Who_Tweet_and_Tweet_Value_Counts_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NORMALIZED

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Users Who Tweet - Bars Normalized')
plt.ioff()
tweets_smi_1['screenName'].value_counts(normalize=True)[:10].plot.bar(x=tweets_smi_1['screenName'], alpha=0.9)
plt.xlabel('ScreenName')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_61_SMI1_Top_Users_Who_Tweet_and_Tweet_Value_Counts_Bars_Normalized.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Users Who Tweet - Bars')
plt.ioff()
top_users_who_tweet_and_tweet_value_counts_df[:10].plot.bar(alpha=0.9)
plt.xlabel('ScreenName')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_61_SMI1_Top_Users_Who_Tweet_and_Tweet_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

###############################################################################################################

print('---')
print('Total Tweets Number')
print(number_total_tweets)
print('----')

# total Tweets 103215

# MP 6392   6.17
# 103515  100

# LVIQ 6037   5.83
# 103515  100

# INPC 3849   3.17
# 103515  100

# ANRIGH 2064   1.99
# 103515  100

# GLM 1959   1.89
# 103515  100

number_top_users_who_tweet_and_tweet_value_counts_df = top_users_who_tweet_and_tweet_value_counts_df[:10]

percentage_top_users_who_tweet_and_tweet_value_counts_df = ((number_top_users_who_tweet_and_tweet_value_counts_df * 100)/number_total_tweets)
percentage_top_users_who_tweet_and_tweet_value_counts_df

print('---')
print('Top Tweets Number Value Counts Percentages')
# print(percentage_top_users_who_tweet_and_tweet_value_counts_df)
print('---')

######## NEED TO DO - COUNT AND PERCENTAGE OF ALL Tweets NOT IN THE TOP 5 ALSO their Followers and reteweets and percentage!!!!!!!!!!!

top_users_list = [['Top Users Who Tweet', number_top_users_who_tweet_and_tweet_value_counts_df, percentage_top_users_who_tweet_and_tweet_value_counts_df]]

# Create the pandas DataFrame 
top_users_df = pd.DataFrame(top_users_list, columns = ['top_users_screenname', 'top_users_tweet_count', 'top_users_tweet_percentage']) 


print('---')
print('Top Users DF - Tweet Count and Percentage')
# print(top_users_df.head)
print('---')

top_users_df.to_csv('4_4_62_SMI1_Top_Users_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# top_users_df.to_excel('4_4_62_SMI1_Top_Users_DF.xlsx', header=True)

# TABLE PLOT NEED TO DO 

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Users Who Tweet - Pie')
plt.ioff()
# plt.pie(top_users_df['count'], labels=top_users_df['description'], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
tweets_smi_1['screenName'].value_counts()[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(labels=tweets_smi_1['screenName'], bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.) 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_62_SMI1_Top_Users_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Users Who Tweet - Bars')
plt.ioff()
tweets_smi_1['screenName'].value_counts()[:6].plot.bar(x=tweets_smi_1['screenName'], alpha=0.9)
plt.xlabel('ScreenName')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_62_SMI1_Top_Users_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Users Who Tweet - Pie')
plt.ioff()
# plt.pie(top_users_df['count'], labels=top_users_df['description'], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
tweets_smi_1['screenName'].value_counts()[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweets_smi_1['screenName'], loc='upper right', borderaxespad=0.) 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_62_SMI1_Top_Users_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')

# Bars

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Users Who Tweet - Bars')
plt.ioff()
top_users_who_tweet_and_tweet_value_counts_df[:6].plot.bar(alpha=0.9)
# plt.xlabel(tweets_smi_1['screenName'])
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_62_SMI1_Top_Users_Bars_A.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#############################################################################################################

# FOR THE TOP USERS : Followers AND Friends

print('NEEDDDDDDDDDDDDD TO PLOT TOP FRIENDS AND FOLLOWERSSSSSSSSSSS')
print('NEEDDDDDDDDDDDDD TO PLOT TOP FRIENDS AND FOLLOWERSSSSSSSSSSS')
print('NEEDDDDDDDDDDDDD TO PLOT TOP FRIENDS AND FOLLOWERSSSSSSSSSSS')

####  NEED PERCENTAGE OF TWEETS THAT THE TOP USERS REPRESENT AND PUE PLOT AND HOW MUCH THE REST

# Plot Bars Total Users vs Engaged vs Followers vs Retweet ## NEED TO DO!!!


# ENGAGED USERS Followers - Friends - COUNT AND PERCENTAGE ## NEED TO DO!!!!!!!!!


#########  NEED TO CHANGE - TAKEN FROM ABOVE

## NEED TO MAKE DF OF THIS!!!!

# initialize list of Lists 

########## NEED TO PUT PERCENTAGES PER TOP USERS!!!! AND PERCENTAGES OF Followers AND Friends TABLE

# USER ANALYSIS - Followers Friends

# https://tutswiki.com/pandas-cookbook/chapter2/

# TOP USERS WHO TWEET (COMMENT ABOUT AN SMI) WITH Followers AND Friends

# Top Tweets Count Users

users_who_tweet = pd.value_counts(tweets_smi_1['screenName'], ascending=False, normalize=True)

users_who_tweet_followers_friends = users_who_tweet

# TOP NUMBERS OF USERS IN Tweets 

users_who_tweet_followers_friends_and_tweet_value_sort = users_who_tweet_followers_friends.sort_values(ascending=False)
top_users_who_tweet_followers_friends_and_tweet_value_counts = users_who_tweet_followers_friends_and_tweet_value_sort[10:]

top_users_who_tweet_followers_friends_and_tweet_value_counts_df = pd.DataFrame(top_users_who_tweet_followers_friends_and_tweet_value_counts)

# SAVE TO CSV   ######################################  NEED TO SAVE USERNAMES ON FIRST COLUMN / SECOND IS COUNT

top_users_who_tweet_followers_friends_and_tweet_value_counts_df.to_csv('4_4_61_SMI1_df_Top_Users_Who_Tweet_followers_friends_and_Tweet_Value_Counts_3_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# top_users_who_tweet_followers_friends_and_tweet_value_counts_df.to_excel('4_4_61_SMI1_Top_Users_Who_Tweet_followers_friends_and_Tweet_Value_Counts_3.xlsx', header=True)

# value_counts_users
# df_value_counts_users

print('---')
print('Top Users Who Tweet and Followers Friends Count')
# print(top_users_who_tweet_followers_friends_and_tweet_value_counts_df)
print('---')

print('---')
print('Top Users Who Tweet and Followers Friends Info')
print(top_users_who_tweet_followers_friends_and_tweet_value_counts_df.info)
print('---')

print('---')
print('Top Users Who Tweet and Followers Friends D Types')
print(top_users_who_tweet_followers_friends_and_tweet_value_counts_df.dtypes)
print('---')

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Users Who Tweet Followers and Friends - Pie')
plt.ioff()
tweets_smi_1['screenName'].value_counts(normalize=True)[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(labels=tweets_smi_1['screenName'], bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.) 
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_61_SMI1_Top_users_who_tweet_Followers_Friends_and_Tweet_Value_Counts_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NORMALIZED

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Users Who Tweet Followers and Friends - Bar Normalized')
plt.ioff()
tweets_smi_1['screenName'].value_counts(normalize=True)[:10].plot.bar(x=tweets_smi_1['screenName'], alpha=0.9)
plt.xlabel('screenName')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_61_SMI1_Top_users_who_tweet_followers_friends_and_Tweet_Value_Counts_Bars_Normalized.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Users Who Tweet Followers and Friends - Bars')
plt.ioff()
top_users_who_tweet_followers_friends_and_tweet_value_counts_df[:10].plot.bar(alpha=0.9)
plt.xlabel('ScreenName')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_61_SMI1_Top_users_who_tweet_followers_friends_and_Tweet_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###########################################################################################################
#############################################################################################################
##########################################################################################################################
##########################################################################################################################
#########################################################################################################################

# PLOT BARS - MULTIPLE - Tweets ABOUT AND BY SMI ## NEED TO DO - FIX 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

r1 = np.arange(len(tweets_about_percentages_df['tweets_about_smi_number']))
r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES // NEED TO CHANGE

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Users Who Tweet vs Followers / Friends / Users - Multiple Bars')
plt.ioff()

plt.bar(r1, tweets_about_percentages_df['tweets_about_smi_number'], color='#73C2FB', edgecolor='white', label='Tweets About', alpha=0.9)
plt.bar(r2, tweets_by_percentages_df['number_tweets_by'], color='blue', edgecolor='white', label='Tweets By Author', alpha=0.9)

# tweets_about_percentages_df['tweets_about_smi_number'].plot.bar(alpha=0.9)
# ax.bar(tweets_about_percentages_df['tweets_about_smi_item'], tweets_about_percentages_df['tweets_about_smi_number'])
# tweets_by_percentages_df['number_tweets_by'].plot.bar(alpha=0.9)
# ax.bar(x + (2 * barWidth), tweets_by_percentages_df['tweets_by_smi'], tweets_by_percentages_df['number_tweets_by'])
# ax.bar(x + (2 * barWidth), tweets_by_percentages_df['tweets_by_smi'], tweets_by_percentages_df['number_tweets_by'])

plt.xticks(rotation=50)
plt.xlabel('Users Who Tweet / Followers / Friends / Total Users')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_63_SMI1_Bars_Chart_Users_Tweets_Followers_Friends_PLT_BARS.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################################################################################################################

# MULTIVARIATE PLOTS

# BOX SEABORN

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Multivariate Analysis - Box')
plt.ioff()
# tweets_smi_1.plot.box() 
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_64_SMI1_All_Multivariate_Box_Plot.png', bbox_inches='tight')
plt.close(fig='all')


# STAKED

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Multivariate Analysis - Staked')
plt.ioff()
# tweets_smi_1.plot.bar(stacked=True) 
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_64_SMI1_All_Multivariate_Stacked_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###############################################################################################################
###############################################################################################################
#
#     				  USE PACKAGE CORPUS - NEED TO DO 
#
###############################################################################################################

# https://towardsdatascience.com/practical-statistics-visualization-with-python-plotly-770e96e35067

print('---')
print('Loading Libs 33')
print('---')

# USING CUFFLNKS

##############################################################################################################
#
#                                SNA - CLUSTER ANALYSIS #############  NEED TO DO!!!!
#
##########################################################################################################################

print('done processing 4')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

###############################################################################################################

print('-- NEED TO DO FAVS AND Followers PER LANGUAGE!!!')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

###############################################################################################################

print('-- done quant processing 3 - analysis 1')
print(' -- NEED TO DO : SMIS Processing / DATA ANALYSIS QUANTITATIVE AND STATISTICS - SNA - CLUSTER ANALYSIS')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


#######################################################################################################################
#######################################################################################################################
#######################################################################################################################

# https://towardsdatascience.com/an-end-to-end-project-on-total_favorites-series-analysis-and-forecasting-with-python-4835e6bf050b

# Visualizing Furniture Sales Time Series Data

# Some distinguishable patterns appear when we plot the data. The total_favorites-series has seasonality pattern, such as sales are 
# always low at the beginning of the year and high at the end of the year. There is always an upward trend within any 
# single year with a couple of low months in the mid of the year. We can also visualize our data using a method called 
# total_favorites-series decomposition that allows us to decompose our total_favorites-series into three distinct components: trend, 
# seasonality, and noise.

# NEED TO DO FIGURE !!!! NEED TO FIX 

# decomposition = sm.tsa.seasonal_decompose(y, model='additive')
# fig = decomposition.plot(alpha=0.9)
# plt.show()

print('MAIN SMI: NEED TO DO')
print(main_smi)
print('----------------------------------------')

#######################################################################################################################
#######################################################################################################################
########################################################################################################################
#
#				TEXTUAL ANALYTICS
#
#######################################################################################################################
#######################################################################################################################

### NOT WORKING NEED TO DO


######################################################################################################

## SELECTED WORDS

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Calculate Frequency Distribution

smi1_tweets_text_words_fdist = nltk.FreqDist(tweets_text_words)

print('---')
print('Word Frequency Distribution - NEED TO DO - FIX KNOW TYPE')
print(smi1_tweets_text_words_fdist)
print('---')

print('---')
print('Word Frequency Distribution - Love')
print(smi1_tweets_text_words_fdist['love'])
print('---')

print('---')
print('Word Frequency Distribution - Hate')
print(smi1_tweets_text_words_fdist['hate'])
print('---')

print('---')
print('Word Frequency Distribution - Thanks')
print(smi1_tweets_text_words_fdist['thanks'])
print('---')

print('---')
print('Word Frequency Distribution - Fuck')
print(smi1_tweets_text_words_fdist['fuck'])
print('---')

print('---')
print('Word Frequency Distribution - Follow')
print(smi1_tweets_text_words_fdist['follow'])
print('---')

print('---')
print('Word Frequency Distribution - Friend')
print(smi1_tweets_text_words_fdist['friend'])
print('---')

print('---')
print('Word Frequency Distribution - Buy')
print(smi1_tweets_text_words_fdist['buy'])
print('---')

print('---')
print('Word Frequency Distribution - Brand')
print(smi1_tweets_text_words_fdist['brand'])
print('---')


word_love = smi1_tweets_text_words_fdist['love']
word_hate = smi1_tweets_text_words_fdist['hate']
word_thanks = smi1_tweets_text_words_fdist['thanks']
word_fuck = smi1_tweets_text_words_fdist['fuck']
word_follow = smi1_tweets_text_words_fdist['follow']
word_friend = smi1_tweets_text_words_fdist['friend']
word_buy = smi1_tweets_text_words_fdist['buy']
word_brand = smi1_tweets_text_words_fdist['brand']

## NEED TO DO PLOTS AND SAVE

# Output top 50 tweets_words

for word, frequency in smi1_tweets_text_words_fdist.most_common(10):
    print(u'{};{}'.format(word, frequency))
#     smi1_tweets_text_words_freq['tweets_text_words'] = pd.DataFrame(smi1_tweets_text_words_fdist.word)
#     smi1_tweets_text_words_freq['tweets_text_words_freq'] = pd.DataFrame(smi1_tweets_text_words_fdist.frequency)


# tweets_text_words_freq = tweets_text_words_fdist.keys()  ### NEED TO DO - FIX FROM ABOVE

print('---')
print('Word Frequency Distribution from List and Counts - Try 1')
# print(smi1_tweets_text_words_freq)  ######## NNED TO DO - NOT WORKING
print(type(smi1_tweets_text_words_fdist))
print('---')

print('---')
print('Number of Words In Text')
print(len(smi1_tweets_text_words_fdist))
print('---')

smi1_tweets_text_words_fdist_df = pd.DataFrame([smi1_tweets_text_words_fdist])

smi1_tweets_text_words_fdist_df.to_csv('4_5A_101_SMI1_Word_Freq_Dist_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# tweets_text_words_fdist_df.to_excel('4_5A_101_SMI1_Word_Freq_Dist_DF.xlsx', header='frequency_distribution') # Only argument is a string of the output file path


# PLOT TABLE NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Words Frequency Distribution')
plt.ioff()
smi1_tweets_text_words_fdist.plot(10,cumulative=False, alpha=0.9) 
# smi1_tweets_text_words_fdist[:10].plot(alpha=0.9)  ########### NEED TO FIX -SHOWING FEW
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_101_SMI1_Words_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Words Frequency Distribution - Box')
plt.ioff()
# plt.plot(smi1_tweets_text_words_fdist[:10])
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_101_SMI1_Words_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################

# HISTOGRAM PLOT NEED TO DO ## need to change

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))    ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Words Frequency Distribution - Histogram')
plt.ioff()
# plt.hist(smi1_tweets_text_words_fdist, labels=smi1_tweets_text_words_fdist, colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_tweets_text_words_fdist[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_101_SMI1_Words_Freq_Dist_PLOT_Hist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOTS  ######### NEED TO DO!!!!!!!!!!!!!

# top_tweets_text_words_fdist = tweets_text_words_fdist.sort(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets Words Frequency Distribution - Bars')
plt.ioff()
# smi1_tweets_text_words_fdist[:6].plot.bar(alpha=0.9)
# plt.bar(smi1_tweets_text_words_fdist[:6], tweets_text_words_fdist, color='#7f3d5f', edgecolor='white', label='words')
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_101_SMI1_Words_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################

## METHOD 2 - SEVERAL TRIES

# TO DF - NOT WORKING

# smi1_df_tweets_text_words_fdist = pd.DataFrame(smi1_tweets_text_words_fdist)

print('---')
print('Frequency Distribution of Words DF')
# print(smi1_df_tweets_text_words_fdist.head(10))
print('---')

#### TRY 2 NOT WORKING

# smi1_tweets_text_words_fdist_list = smi1_tweets_text_words_fdist.str.split()

# smi1_tweets_text_words_freq = ['smi1_tweets_text_words', 'smi1_tweets_text_words_freq']

# for w in smi1_tweets_text_words_fdist_list:
#	smi1_tweets_text_words_freq.append(smi1_tweets_text_words_fdist_list.count(w))
	

print('---')
print('Word Frequency Distribution from List and Counts - Try 2')
# print(smi1_tweets_text_words_freq)
print('---')
print('---')
# print('List\n' + str(smi1_tweets_text_words_freq) + '\n')
print('---')
print('---')
# print('Frequencies\n' + str(smi1_tweets_text_words_freq) + '\n')
print('---')
print('---')
# print('Pairs\n' + str(list(zip(smi1_tweets_text_words_fdist_list, smi1_tweets_text_words_freq)))
print('---')

# TABLE PLOT NEED TO DO 

# PIE PLOT NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tweets Words - Pie')
plt.ioff()
# plt.pie(smi1_tweets_text_words_fdist[:6], labels=smi1_tweets_text_words_fdist, colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_tweets_text_words_fdist[:6].plot(kind='pie', colors='#73C2FB', startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_words, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_102_SMI1_Tweets_Text_Words_fdist_df_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Words - Bars')
plt.ioff()
# smi1_tweets_text_words_fdist.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_102_SMI1_Tweets_Text_Words_fdist_df_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################### NEED TO FIX

# TUPLE TO DATAFRAME

# tweets_text_words_fdist_df = pd.DataFrame.from_records(tweets_text_words_fdist, columns=['tweets_text_words', 'tweets_text_words_freq'])
# tweets_text_words_fdist_df = pd.DataFrame.from_items(tweets_text_words_fdist)
# tweets_text_words_fdist_df = pd.DataFrame(tweets_text_words_fdist, index=[0])
# tweets_text_words_fdist_df = pd.DataFrame([tweets_text_words_fdist])
# tweets_text_words_fdist_df = pd.DataFrame(list(tweets_text_words_fdist), columns=['tweets_text_words', 'tweets_text_words_freq'], index['tweets_text_words', 'tweets_text_words_freq'])

# tweets_text_words_fdist_df = pd.DataFrame(tweets_text_words_fdist, columns=['tweets_text_words', 'tweets_text_words_freq'])
# a_tweets_text_words_fdist_df = tweets_text_words_fdist_df.pivot('tweets_text_words', 'tweets_text_words_freq')


# pd.DataFrame.from_dict(list(tweets_text_words_fdist.items()), columns=['tweets_words', 'tweets_words_frequency_counts'])
# pd.DataFrame.from_dict(tweets_text_words_fdist, orient='index')

# tweets_text_words_fdist_d_f = list(tweets_text_words_fdist, name='tweets_words_frequency_counts')

# tweets_text_words_fdist_d_f.index.name = 'tweets_words_frequency_counts' 

# tweets_text_words_fdist_df = pd.DataFrame(tweets_text_words_fdist, index=[0])

print('---')
print('Tweets_words Frequency Distribution DataFrame')
# print(tweets_text_words_fdist_df)
print('---')

print('FINISHED PRINTING WORD FREQUENCIES')

############ df_tweets_words_fdist is a tuple!!! NEED TO CHANGE TO DF and PLOT DUPLE!!!!


print('---')
print('DF tweets_words Frequency Distribution - fdist ')
# print(tweets_text_words_fdist_df)
print('---')

print('---')
print('Frequency Distribution of tweets_words')
# print(tweets_text_words_fdist_df.head(10))
print('---')

# tweets_text_words_fdist_df.to_csv('4_5A_103_SMI1_Tweets_Text_Words_fdist_df_CSV.csv', sep=';', encoding='utf-8', index=True)
# tweets_text_words_fdist_df.to_excel('4_5A_103_SMI1_Tweets_Text_Words_fdist_df.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# NEED TO DO TABLE PLOT

# PLOT NEED TO DO 

# BOX PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution - Box')
plt.ioff()
# tweets_text_words_fdist_df.plotbox() 
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_103_SMI1_Tweets_Text_Words_fdist_df_PLOT_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution - Pie')
plt.ioff()
# plt.pie(tweets_text_words_fdist_df[:6], labels=tweets_text_words_fdist_df, colors='#73C2FB',startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# tweets_text_words_fdist_df[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_words, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_103_SMI1_Tweets_Text_Words_fdist_df_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## PLOT 2 TEST ## NEED TO DO FIX NOT WORKING

print('PLOT2 WORD DIST TEST - NEED TO FIX')

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Words')
plt.ioff()
# tweets_text_words_fdist_df.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
# tweets_text_words_fdist_df[:10].plot(alpha=0.9)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_103_SMI1_Tweets_Text_Words_fdist_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT NEED TO DO

## BAR PLOT ## NEED TO DO FIX NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Words - Bars')
plt.ioff()
# tweets_text_words_fdist_df[:6].plot.bars(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_103_SMI1_Tweets_Text_Words_fdist_df_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

print('Box Plot Test')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Word Frequency Distribution - Box')
plt.ioff()
# plt.plot(tweets_text_words_fdist_df) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_103_SMI1_Tweets_Text_Words_fdist_df_Box_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#######################################################################

# BAR PLOTS  ######### NEED TO DO!!!!!!!!!!!!!

print('Bar Plot Test')

value_counts_text = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)

# Create DataFrame

value_counts_text_df = pd.DataFrame(value_counts_text, columns =['item', 'word_number_value', 'tweets_words_by_percentage'])
value_counts_text_df

print('---')
print('Tweets_words in Tweets and Values')
# print(value_counts_text_df)
print('---')

value_counts_text_df.to_csv('4_5A_104_SMI1_Value_Counts_Text_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# value_counts_text_df.to_excel('4_5A_104_SMI1_Value_Counts_Text_DF.xlxs', header=True)

# top_tweets_words_fdist = tweets_words_fdist.sort_values(ascending=False)

# value_counts_df_tweets_words_fdist = pd.value_counts([value_counts_text], ascending=False, normalize=True)
# top_tweets_words_fdist = value_counts_df_tweets_words_fdist.sort_values(ascending=False)  ######## NEED TO PUT FIX SORTING DUPLE

# TABLE PLOT NEED TO DO 

# BAR PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Word Frequency Distribution - Bars')
plt.ioff()
pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
plt.tight_layout(pad=2)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_104_SMI1_Top_Tweets_Words_Freqdists_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

##################################################
############################################################################################################

## NEED TO DO Hashtag STAS!!!!!!!!!!!!!!

############################################################################################################
#######################################################################################
############################################################################################################

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

############################################################################################################

# NEED FREQ DIST EMOJIS, IMAGE LINK< NEED TO DO MISSING HASHTAFS MENTIONS !!!! < ETC

#################################################################################################################

# Mode Favorites

mode_favorites = statistics.mode(tweets_smi_1['favorites'])

print('---')
print('Mode Favorites')
print(statistics.mode(tweets_smi_1['favorites']))
print('---')

# mode_favorites_df = pd.DataFrame([mode_favorites], columns=['mode_favorites'])

# mode_favorites_df.to_csv('4_4_6_SMI1_Mode_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# mode_favorites_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mode Favorites - Box')
plt.ioff()
# plt.boxplot(statistics.mode(tweets_smi_1['favorites']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_6_SMI1_Mode_Favorites_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mode Favorites - Bars')
plt.ioff()
# mode_favorites_df.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_6_SMI1_Mode_Favorites_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf() 

#################################################################################################################


# Mode Retweets

# mode_retweets = statistics.mode(tweets_smi_1['retweets'])
# mode_retweets

print('---')
print('Mode Retweets')
# print(statistics.mode(tweets_smi_1['retweets']))
print('---')

# mode_retweets_df = pd.DataFrame([mode_retweets], columns=['mode_retweets'])

# mode_retweets_df.to_csv('4_4_7_SMI1_Mode_Retweets_CSV.csv', sep='\t', encoding='utf-8', index=True)
# mode_retweets_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mode Retweets - Box')
plt.ioff()
# plt.boxplot(statistics.mode(tweets_smi_1['retweets']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_7_SMI1_Mode_Retweets_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mode Retweets - Bars')
plt.ioff()
# mode_retweets_df.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_7_SMI1_Mode_Retweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

######################################################################################################################################

# https://realpython.com/python-statistics/

# DESCRIPTIVE STATISTICS / # Measures of Central Tendency

###  PERCENTAGE ORIG FORMULAS FOR PIE PLOT: %1.1f%% 


# ANALYSING THE DATA

# followers

#### NEED TO COMPLETE DATA: TAKE OUT MENTIONS, HASTAGS, SUMMARY EMOJI CODES WITH EMOTICONS, 
#### NEED FOLLOWER GROWTH OVER TIME GRAPHICS

# ANALYSING THE DATA

#### NEED TO COMPLETE DATA: TAKE OUT MENTIONS, HASTAGS, SUMMARY EMOJI CODES WITH EMOTICONS, 
#### NEED FOLLOWER GROWTH OVER TIME GRAPHICS

# FIX FORMATING OF PIE CHAfollowers

# NEED TO LINK TO TWITTER R DATA AND GET LOCATION INFO

# NEED TO DO SAVE TABLES TO FILES

# CHECK ALL 'NEED TO DO'



print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


######################################################################################################################

# GRAPH NETWORK OF PEOPLE AND MENTIONS # NEED TO DO!!!!

# Find the neighbours of a node
	
######################################################################################################################
##################################################################################################################

# Scatter Plot Faceted on Two Variables

#################################################################################################################

print('---')
print('Loading Libs 40')
print('---')


# screenName author_id created Followers favorites Text latitude longitude mentions hashtags id url emojis_unicode emojis_converted image_link language

tweets_smi_1_numeric = pd.DataFrame(tweets_smi_1)
# del tweets_smi_1_numeric['screenName']
# df.drop(['column_nameA', 'column_nameB'], axis=1, inplace=True)
# del tweets_smi_1_numeric['screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', 'url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language']

# tweets_smi_1_numeric.drop('screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language', axis=1, inplace=True)

# tweets_smi_1_numeric.drop('screenName', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('text', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('latitude', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('longitude', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('mentions', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('hashtags', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('url', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('emojis_unicode', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('emojis_converted', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('image_link', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('language', axis=1, inplace=True)

# tweets_smi_1_numeric.drop(['screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', 'url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language'], axis=1, inplace=True)
# tweets_smi_1_numeric = tweets_smi_1[['author_id', 'created', 'followers', 'favorites', 'id']]

# Create the default pairplot

# PLOT  # NEED TO DO NOT WORKING !!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Pair Plot of SMI Numeric Data')
plt.ioff()
# sns.pairplot(tweets_smi_1_numeric)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_197_SMI1_Pair_Plot_Numeric.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('creating plots')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


###################################################################################################################

# http://seaborn.pydata.org/tutorial/relational.html

# Visualizing Statistical Relationships # NEED TO DO 

# Statistical analysis is a process of understanding how variables in a dataset relate to each other and how those relationships depend on other variables. Visualization can be a core component of this process because, when data are visualized properly, the human visual system can see trends and patterns that indicate a relationship.
# We will discuss three seaborn functions in this tutorial. The one we will use most is relplot(). This is a figure-level function for visualizing statistical relationships using two common approaches: scatter plots and line plots. relplot() combines a FacetGrid with one of two axes-level functions:
# scatterplot() (with kind="scatter"; the default)
# lineplot() (with kind="line')
# As we will see, these functions can be quite illuminating because they use simple and easily-understood representations of data that can nevertheless represent complex dataset structures. They can do so because they plot two-dimensional graphics that can be enhanced by mapping up to three additional variables using the semantics of hue, size, and style.

# Relating variables with scatter plots

# The scatter plot is a mainstay of statistical visualization. It depicts the joint distribution of two variables using a cloud of points, where each point represents an observation in the dataset. This depiction allows the eye to infer a substantial amount of information about whether there is any meaningful relationship between them.
# There are several ways to draw a scatter plot in seaborn. The most basic, which should be used when both variables 
# are numeric, is the scatterplot() function. In the categorical visualization tutorial, we will see specialized tools 
# for using scatterplots to visualize categorical data. The scatterplot() is the default kind in relplot() (it can also 
# be forced by setting kind="scatter'):

# SCATTER PLOT Favorites

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(6,6))
plt.suptitle(main_smi, y=1.0)
plt.title('Scatter Plot Relating Followers / Favorites')
plt.ioff()
# sns.relplot(x='followers', y='total_favorites', data=tweets_smi_1)
plt.xlabel('Followers')
plt.ylabel('Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_198_SMI1_SB_Scatter_Plot_Rel_Total_Favorites_Followers_Numeric_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# SCATTER PLOT retweets

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(6,6))
plt.suptitle(main_smi, y=1.0)
plt.title('Scatter Plot Relating Followers / Retweets')
plt.ioff()
# sns.relplot(x='followers', y='retweets', data=tweets_smi_1)
plt.xlabel('Followers')
plt.ylabel('Retweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_198_SMI1_SB_Scatter_Plot_Rel_Total_Retweets_Followers_Numeric_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#####################

# In the simplest invocation, both functions draw a scatterplot of two variables, x and y, and then fit the regression model 
# y ~ x and plot the resulting regression line and a 95% confidence interval for that regression:

# SCATTER PLOT REG favorites

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Regression Followers / Favorites 95% Conf. Int. Scatter')
plt.ioff()
# sns.regplot(x='followers', y='total_favorites', data=tweets_smi_1)
plt.xlabel('Followers')
plt.ylabel('Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_198_SMI1_SB_Scatter_Plot_Reg_Total_Favorites_Followers_REG_PLOT_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT LM

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Regression Followers / Favorites 95% Conf. Int. Scatter')
plt.ioff()
# sns.lmplot(x='followers', y='total_favorites', data=tweets_smi_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_198_SMI1_SB_Scatter_Plot_Reg_Total_Favorites_Followers_LM_PLOT_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# SCATTER PLOT REG retweets

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Regression Followers - Retweets: 95% Conf. Int. Scatter')
plt.ioff()
# sns.regplot(x='followers', y='retweets', data=tweets_smi_1)
plt.xlabel('Followers')
plt.ylabel('Retweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_198_2_SMI1_SB_Scatter_Plot_Reg_Total_Retweets_Followers_REG_PLOT_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT LM 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Regression Followers - Retweets: 95% Conf. Int. Scatter')
plt.ioff()
# sns.lmplot(x='followers', y='retweets', data=tweets_smi_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_198_3_SMI1_SB_Scatter_Plot_Reg_Total_Retweets_Followers_LM_PLOT_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('done - using seaborn')

#################################################################################

# _df _df = pd.DataFrame()
# .to_csv('4_5A_.csv', sep=';', encoding='utf-8', index=True)
# excel

###########################################################################################################

# https://www.datacamp.com/community/tutorials/wordcloud-python

# WORDCLOUD 

# SMI_WordCloud_1 = WordCloud(background_color="white",stoptweets_words=stoptweets_words,width=800, height=400, colors=colors_blue).generate(' '.join(data))
SMI_WordCloud_1 = WordCloud(background_color='white').generate(' '.join(tweets_text_words))

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet WordCloud Visualization')
plt.ioff()
plt.imshow(SMI_WordCloud_1, interpolation='bilinear')
plt.axis('off')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# plt.show()
plt.savefig('4_5A_199_SMI1_WordCloud_SB_1.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

################################################################################################################
#
#				TEXTUAL ANALYTICS - TEXT ANALYSIS
#
################################################################################################################
################################################################################################################

# TURN COLLUMS TO STRING 

# TEXTUAL ANALYSICS

# https://www.strehle.de/tim/weblog/archives/2015/09/03/1569

# WORD FREQUENCY DISTRIBUTION IN TEXT OF Tweets


print('---')
print('Loading Libs 37')
print('---')

# TEXT BIGRAMS

# input_file = sys.argv[1]

# fp_text = tweets_smi_1['text'].astype(str, errors='ignore')
# fp_text['tweet_text_fp_text'] = pd.DataFrame(tweets_smi_1['text'].astype(str, errors='ignore'))
# fp_text = tweets_smi_1.text.astype(str, errors='ignore')

fp_text_temp = tweets_smi_1['text']
fp_text = fp_text_temp.to_string()
fp_text_c = fp_text ### OJO QIE ESTA SIN ARREGLAR EL C

print('---')
print('DataFrame Types fp_text')
# print(fp_text.dtypes)
print('---')

# fp_text = pd.DataFrame(tweets_smi_1['text'].astype('str'))
# fp_text = pd.DataFrame(StringIO(tweets_smi_1['text']))

# input_file = sys.argv[1]

# fp_text = pd.DataFrame(tweets_smi_1['text'].astype('str'))
# fp_text = StringIO(tweets_smi_1['text'])

# fp_text = pd.read_csv(StringIO(smi_file_4_4_text_only, 'r', 'utf-8'))
# fp_text = pd.read_csv(smi_file_4_4_text_only, sep=';', encoding='utf-8', parse_dates=True, header=0, low_memory=False)# 
# fp_text = codecs.open(smi_file_4_4_text_only, 'r', 'utf-8')
# fp_text = pd.DataFrame(tweets_smi_1['text'].astype('str'))
# fp_text = np.to_string(fp_text)

# fp_text = pd.DataFrame(fp_text)

# fp_text = open(smi_file_4_4_text_only, encoding='utf-8')
# f_text = fp_text.read() # As bytes

# data_f = fp_text.read() # As bytes

# f_text = fp_text

# f_text = data_f.decode('utf-8') # Unicode not bytes

print('---')
# print(f_text)
print('---')

# fp_text = f_text

print('---')
print('Tweets Text First 10')
print(tweets_smi_1['text'].head(10))
print('---')

#######################################################################################

# CORRECT SPELLING

# tweets_smi_1

# tweets_smi_1.parse() #Parse the article
# ('punkt')   #1 total_favorites download of the sentence tokenizer
# tweets_smi_1.nlp() # Keyword extraction wrapper

textblob_obj_text_c = TextBlob(fp_text) ## OJO QUE SI ES EL CORREGIDO O NO

#########   textblob_obj_text_c = textblob_obj_text.correct() ## NEED TO CHECK HOW IT WORKS!!!!
# textblob_obj_text_c = textblob_obj_text

textblob_obj_text_c_df = pd.DataFrame(textblob_obj_text_c)

print('--')
print('textblob_obj_text_C_DF TYPE:')
# print(textblob_obj_text_c)
print('--')

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

# textblob_obj_text_c_df.to_csv('4_5A_184_SMI1_Text_Obj_C_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# textblob_obj_text_c_df.to_excel('4_5A_184_SMI1_Text_Obj_C_DF.xlsx', header=True)

# fp_text_c = textblob_obj_text_c.to_string()

# fp_text_c = textblob_obj_text_c

#######################################################################################

# tweets_text_words = nltk.word_tokenize(pd.to_string(fp_text_c))
# tweets_text_words = nltk.word_tokenize(fp_text_c['tweet_text_fp_text_c'])
tweets_text_words = nltk.word_tokenize(fp_text_c)
tweets_text_words_df = pd.DataFrame(tweets_text_words)

# tweets_text_words = nltk.word_tokenize((tweets_smi_1['text']).pd.to_string())
# tweets_text_words = tweets_smi_1['text']).nltk.word_tokenize()

print('--')
print('Tokenized text_words')
print(tweets_text_words_df.head(10))
print('--')

print('--')
print('Tokenized text_words Shape')
print(tweets_text_words_df.shape)
print('--')

print('--')
print('Tokenized text_words Info')
print(tweets_text_words_df.info)
print('--')

# Remove single-character tokens (mostly punctuation) ######## NEED TO DO FIX 
# tweets_text_words = [word for word in tweets_text_words if len(word) > 1]

# Remove numbers ######## NEED TO DO FIX
# tweets_text_words = [word for word in tweets_text_words if not word.isnumeric()]

# Lowercase all tweets_words (default_stoptweets_words are lowercase too) ######## NEED TO DO FIX
# tweets_text_words = [word.lower() for word in tweets_text_words]

# Stemming tweets_words seems to make matters worse, disabled
# stemmer = nltk.stem.snowball.SnowballStemmer('english')
# tweets_text_words = [stemmer.stem(word) for word in tweets_text_words]

# Remove stoptweets_words          ################################################################
# tweets_text_words = [word for word in tweets_text_words if word not in stoptweets_words]

# print('removed stoptweets_words')

##################################################################################################################

# FINDING N-GRAMS TEXT

# N-Grams refer to n combination of words in a sentence. For instance, for a sentence "I love watching football", some 2-grams would 
# be (I love), (love watching) and (watching football). N-Grams can play a cricual role in Text classification. 

for ngram_text in textblob_obj_text_c.ngrams(2):
	print('-------------------------')
	print('N-Grams text: 2')
	print(ngram_text)
	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_text = pd.DataFrame([str(ngram_text)])

ngram_text.to_csv('4_5A_200_SMI1_ngram_Text_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
ngram_text.to_csv('4_5A_200_SMI1_ngram_Text_TEXT.txt', sep=';', encoding='utf-8', index=False, header=True)

####


for ngram_trigrams_text in textblob_obj_text_c.ngrams(3):
	print('-------------------------')
	print('N-Grams text: 3')
#	print(ngram_trigrams_text)
#	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_trigrams_text = pd.DataFrame(ngram_trigrams_text)

ngram_trigrams_text.to_csv('4_5A_200_SMI1_ngram_Trigrams_Text_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
ngram_trigrams_text.to_csv('4_5A_200_SMI1_ngram_Trigrams_Text_TEXT.txt', sep='\t', encoding='utf-8', index=False, header=True)


####

# VISUALIZATION OF triGRAMS

# Create a list of Lists containing trigrams in tweets

trigrams_text_terms = list(nltk.trigrams(fp_text))

trigrams_text = list(itertools.chain(*trigrams_text_terms))

# Create counter of words in trigrams

# trigrams_text_counts = collections.Counter(trigrams_text)

trigrams_text_counts = pd.value_counts(trigrams_text, ascending=False, normalize=True)

trigrams_text_counts = trigrams_text_counts.sort_values(ascending=False)

trigrams_text_counts = trigrams_text_counts.apply(lambda x: x.str.split(' '))

print('---')
print('trigrams_text_counts DF SEPERATED ')
print(trigrams_text_counts.head)
print('---')

# trigram_text_df = pd.DataFrame(trigrams_text_counts, columns=['trigrams_text', 'trigrams_counts'])

trigram_text_df = pd.DataFrame([str(trigrams_text_counts)])

trigram_text_df.to_csv('4_5A_200_SMI1_Trigram_Text_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# trigram_text_df.to_excel('4_5A_200_SMI1_Trigram_Text_DF.xlsx', header=True)

########################################################################################################
########################################################################################################
########################################################################################################

def ngrams_wrapper(sent):
	yield list(nltk.ngrams(sent, 2))

raw_text = fp_text_c

sentences_text = nltk.sent_tokenize(raw_text)

tokenized_text = map(nltk.tokenize, sentences_text)

print('---')
print('Tokenized text')
# print(tokenized_text)
print('---')

bigrams_text = []
for sentence_text in sentences_text:
	sequence_text = word_tokenize(sentence_text)
	bigrams_text.extend(list(ngrams(sequence_text, 2)))

freq_dist_text = nltk.FreqDist(bigrams_text)
prob_dist_text = nltk.MLEProbDist(freq_dist_text)
number_of_bigrams_text = freq_dist_text.N()

print('---')
print('freq_dist text')
# print(freq_dist_text)
print('---')

print('---')
print('prob_dist text')
# print(prob_dist_text)
print('---')

print('---')
print('number_of_bigrams text')
print(number_of_bigrams_text)
print('---')

freq_dist_text_df = pd.DataFrame([freq_dist_text], columns=['freq_dist_text'])

freq_dist_text_df.to_csv('4_5A_201_SMI1_Freq_Dist_Text_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# freq_dist_text_df.to_excel('4_5A_201_SMI1_Freq_Dist_Text_DF.xlsx', index=True, header=True)

prob_dist_text_df = pd.DataFrame([prob_dist_text])

prob_dist_text_df.to_csv('4_5A_201_SMI1_Prob_Dist_Text_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# prob_dist_text_DF.to_excel('4_5A_201_SMI1_Prob_Dist_Text_DF.xlsx', index=True, header=True)

number_of_bigrams_text_df = pd.DataFrame([number_of_bigrams_text], columns=['number_of_bigrams_text'])

number_of_bigrams_text_df.to_csv('4_5A_201_SMI1_Number_of_Bigrams_Text_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# number_of_bigrams_text_df.to_excel('4_5A_201_SMI1_Number_of_Bigrams_Text_DF.xlsx', index=True, header=True)


######################################################################################################################
############################################################################################################

# WORD FREQUENCY HASHTAGS


# HASHTAGS BIGRAMS

fp_hashtags_temp = tweets_smi_1['hashtags']
fp_hashtags = fp_hashtags_temp.to_string()
fp_hashtags_c = fp_hashtags ### OJO QIE ESTA SIN ARREGLAR EL C

print('---')
print('DataFrame Types fp_hashtags')
# print(fp_hashtags.dtypes)
print('---')


# data_f = fp_hashtags.read() # As bytes

# f_hashtags = fp_hashtags

# f_hashtags = data_f.decode('utf-8') # Unicode not bytes

print('---')
# print(f_hashtags)
print('---')

# fp_hashtags = f_hashtags

print('---')
print('Tweets hashtags First 10')
print(tweets_smi_1['hashtags'].head(10))
print('---')

#######################################################################################

# CORRECT SPELLING

textblob_obj_hashtags_c = TextBlob(fp_hashtags) ## OJO QUE SI ES EL CORREGIDO O NO

#########   textblob_obj_hashtags_c = textblob_obj_hashtags.correct() ## NEED TO CHECK HOW IT WORKS!!!!
# textblob_obj_hashtags_c = textblob_obj_hashtags

textblob_obj_hashtags_c_df = pd.DataFrame(textblob_obj_hashtags_c)

print('--')
print('textblob_obj_hashtags_C_DF TYPE:')
# print(textblob_obj_hashtags_c)
print('--')

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

# textblob_obj_hashtags_c_df.to_csv('4_5A_184_SMI1_Hashtags_Obj_C_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# textblob_obj_hashtags_c_df.to_excel('4_5A_184_SMI1_Hashtags_Obj_C_DF.xlsx', header=True)

# fp_hashtags_c = textblob_obj_hashtags_c.to_string()

# fp_hashtags_c = textblob_obj_hashtags_c

#######################################################################################

# tweets_hashtags_words = nltk.word_tokenize(pd.to_string(fp_hashtags_c))
# tweets_hashtags_words = nltk.word_tokenize(fp_hashtags_c['tweet_hashtags_fp_hashtags_c'])
tweets_hashtags_words = nltk.word_tokenize(fp_hashtags_c)
tweets_hashtags_words_df = pd.DataFrame(tweets_hashtags_words)

# tweets_hashtags_words = nltk.word_tokenize((tweets_smi_1['hashtags']).pd.to_string())
# tweets_hashtags_words = tweets_smi_1['hashtags']).nltk.word_tokenize()

print('--')
print('Tokenized hashtags_words')
print(tweets_hashtags_words_df.head(10))
print('--')

print('--')
print('Tokenized hashtags_words Shape')
print(tweets_hashtags_words_df.shape)
print('--')

print('--')
print('Tokenized hashtags_words Info')
print(tweets_hashtags_words_df.info)
print('--')

# Remove single-character tokens (mostly punctuation) ######## NEED TO DO FIX 
# tweets_hashtags_words = [word for word in tweets_hashtags_words if len(word) > 1]

# Remove numbers ######## NEED TO DO FIX
# tweets_hashtags_words = [word for word in tweets_hashtags_words if not word.isnumeric()]

# Lowercase all tweets_words (default_stoptweets_words are lowercase too) ######## NEED TO DO FIX
# tweets_hashtags_words = [word.lower() for word in tweets_hashtags_words]

# Stemming tweets_words seems to make matters worse, disabled
# stemmer = nltk.stem.snowball.SnowballStemmer('english')
# tweets_hashtags_words = [stemmer.stem(word) for word in tweets_hashtags_words]

# Remove stoptweets_words          ################################################################
# tweets_hashtags_words = [word for word in tweets_hashtags_words if word not in stoptweets_words]

# print('removed stoptweets_words')

##################################################################################################################

# FINDING N-GRAMS

# N-Grams refer to n combination of words in a sentence. For instance, for a sentence "I love watching football", some 2-grams would 
# be (I love), (love watching) and (watching football). N-Grams can play a cricual role in Text classification. 

for ngram_hashtags in textblob_obj_hashtags_c.ngrams(2):
#	print('-------------------------')
	print('N-Grams hashtags: 2')
#	print(ngram_hashtags)
#	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_hashtags = pd.DataFrame(ngram_hashtags, columns=['ngran_hashtags'])

ngram_hashtags.to_csv('4_5A_200_SMI1_ngram_Hashtags_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
ngram_hashtags.to_csv('4_5A_200_SMI1_ngram_Hashtags_TEXT.txt', sep=';', encoding='utf-8', index=False, header=True)


########################################################################################################

def ngrams_wrapper(sent):
	yield list(nltk.ngrams(sent, 2))

raw_hashtags = fp_hashtags_c

sentences_hashtags = nltk.sent_tokenize(raw_hashtags)

tokenized_hashtags = map(nltk.tokenize, sentences_hashtags)

# print('---')
print('Tokenized hashtags')
# print(tokenized_hashtags)
print('---')

bigrams_hashtags = []
for sentence_hashtags in sentences_hashtags:
	sequence_hashtags = word_tokenize(sentence_hashtags)
	bigrams_hashtags.extend(list(ngrams(sequence_hashtags, 2)))

freq_dist_hashtags = nltk.FreqDist(bigrams_hashtags)
prob_dist_hashtags = nltk.MLEProbDist(freq_dist_hashtags)
number_of_bigrams_hashtags = freq_dist_hashtags.N()

# print('---')
print('freq_dist hashtags')
# print(freq_dist_hashtags)
print('---')

# print('---')
print('prob_dist hashtags')
# print(prob_dist_hashtags)
print('---')

# print('---')
print('number_of_bigrams hashtags')
print(number_of_bigrams_hashtags)
print('---')

# tokenized_hashtags_df = pd.DataFrame([tokenized_hashtags])

# tokenized_hashtags_df.to_csv('4_5A_201_SMI1_tokenized_hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# tokenized_hashtags_df.to_excel('4_5A_201_SMI1_tokenized_hashtags_DF.xlsx', index=True, header=True)

freq_dist_hashtags_df = pd.DataFrame([freq_dist_hashtags], columns=['freq_dist_hashtags'])

freq_dist_hashtags_df.to_csv('4_5A_201_SMI1_freq_dist_hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# freq_dist_hashtags_df.to_excel('4_5A_201_SMI1_freq_dist_hashtags_DF.xlsx', index=True, header=True)

prob_dist_hashtags_df = pd.DataFrame([prob_dist_hashtags])

prob_dist_hashtags_df.to_csv('4_5A_201_SMI1_prob_dist_hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# prob_dist_hashtags_DF.to_excel('4_5A_201_SMI1_prob_dist_hashtags_DF.xlsx', index=True, header=True)

number_of_bigrams_hashtags_df = pd.DataFrame([number_of_bigrams_hashtags], columns=['number_of_bigrams_hashtags'])

number_of_bigrams_hashtags_df.to_csv('4_5A_201_SMI1_number_of_bigrams_hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# number_of_bigrams_hashtags_df.to_excel('4_5A_201_SMI1_number_of_bigrams_hashtags_DF.xlsx', index=True, header=True)



############################################################################################################

# WORD FREQUENCY DISTRIBUTION IN Mentions OF Tweets


# BIGRAMS MENTIONS

# fp_mentions = tweets_smi_1['mentions'].astype(str, errors='ignore')
# fp_mentions['tweet_mentions_fp_mentions'] = pd.DataFrame(tweets_smi_1['mentions'].astype(str, errors='ignore'))
# fp_mentions = tweets_smi_1.mentions.astype(str, errors='ignore')

fp_mentions_temp = tweets_smi_1['mentions']

# fp_mentions = fp_mentions_temp.to_string()

fp_hashtags = str(tweets_smi_1['hashtags'])

fp_mentions_c = fp_mentions ### OJO QIE ESTA SIN ARREGLAR EL C

# print('---')
print('DataFrame Types fp_mentions')
# print(fp_mentions.dtypes)
print('---')

# f_mentions = fp_mentions

# f_mentions = data_f.decode('utf-8') # Unicode not bytes

# print('---')
# print(f_mentions)
print('---')

# fp_mentions = f_mentions

# print('---')
print('Tweets mentions First 10')
print(tweets_smi_1['mentions'].head(10))
print('---')

#######################################################################################

# CORRECT SPELLING

# tweets_smi_1

textblob_obj_mentions_c = TextBlob(fp_mentions) ## OJO QUE SI ES EL CORREGIDO O NO

#########   textblob_obj_mentions_c = textblob_obj_mentions.correct() ## NEED TO CHECK HOW IT WORKS!!!!
# textblob_obj_mentions_c = textblob_obj_mentions

textblob_obj_mentions_c_df = pd.DataFrame(textblob_obj_mentions_c)

# print('--')
print('textblob_obj_mentions_C_DF TYPE:')
# print(textblob_obj_mentions_c)
print('--')

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

textblob_obj_mentions_c_df.to_csv('4_5A_184_SMI1_mentions_Obj_C_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# textblob_obj_mentions_c_df.to_excel('4_5A_184_SMI1_mentions_Obj_C_DF.xlsx', header=True)

# fp_mentions_c = textblob_obj_mentions_c.to_string()

# fp_mentions_c = textblob_obj_mentions_c

#######################################################################################

# tweets_mentions_words = nltk.word_tokenize(pd.to_string(fp_mentions_c))
# tweets_mentions_words = nltk.word_tokenize(fp_mentions_c['tweet_mentions_fp_mentions_c'])
tweets_mentions_words = nltk.word_tokenize(fp_mentions_c)
tweets_mentions_words_df = pd.DataFrame(tweets_mentions_words)

# tweets_mentions_words = nltk.word_tokenize((tweets_smi_1['mentions']).pd.to_string())
# tweets_mentions_words = tweets_smi_1['mentions']).nltk.word_tokenize()

# print('--')
print('Tokenized mentions_words')
print(tweets_mentions_words_df.head(10))
print('--')

# print('--')
print('Tokenized mentions_words Shape')
print(tweets_mentions_words_df.shape)
print('--')

# print('--')
print('Tokenized mentions_words Info')
print(tweets_mentions_words_df.info)
print('--')

# Remove single-character tokens (mostly punctuation) ######## NEED TO DO FIX 
# tweets_mentions_words = [word for word in tweets_mentions_words if len(word) > 1]

# Remove numbers ######## NEED TO DO FIX
# tweets_mentions_words = [word for word in tweets_mentions_words if not word.isnumeric()]

# Lowercase all tweets_words (default_stoptweets_words are lowercase too) ######## NEED TO DO FIX
# tweets_mentions_words = [word.lower() for word in tweets_mentions_words]

# Stemming tweets_words seems to make matters worse, disabled
# stemmer = nltk.stem.snowball.SnowballStemmer('english')
# tweets_mentions_words = [stemmer.stem(word) for word in tweets_mentions_words]

# Remove stoptweets_words          ################################################################
# tweets_mentions_words = [word for word in tweets_mentions_words if word not in stoptweets_words]

# print('removed stoptweets_words')

##########################################################################################################
##########################################################################################################
##########################################################################################################

# FINDING N-GRAMS

# N-Grams refer to n combination of words in a sentence. For instance, for a sentence "I love watching football", some 2-grams would 
# be (I love), (love watching) and (watching football). N-Grams can play a cricual role in Text classification. 

for ngram_mentions in textblob_obj_mentions_c.ngrams(2):
#	print('-------------------------')
	print('N-Grams mentions: 2')
	print(ngram_mentions)
#	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_mentions_df = pd.DataFrame(ngram_mentions, columns=['ngran_mentions'])

ngram_mentions_df.to_csv('4_5A_200_SMI1_ngram_Mentions_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
ngram_mentions_df.to_csv('4_5A_200_SMI1_ngram_Mentions_TEXT.txt', sep=';', encoding='utf-8', index=False, header=True)

## DELETE VARIABLE

del ngram_mentions
del ngram_mentions_df


########################################################################################################

def ngrams_wrapper(sent):
	yield list(nltk.ngrams(sent, 2))

raw_mentions = fp_mentions_c

sentences_mentions = nltk.sent_tokenize(raw_mentions)

tokenized_mentions = map(nltk.tokenize, sentences_mentions)

# print('---')
print('Tokenized mentions')
# print(tokenized_mentions)
print('---')

bigrams_mentions = []
for sentence_mentions in sentences_mentions:
	sequence_mentions = word_tokenize(sentence_mentions)
	bigrams_mentions.extend(list(ngrams(sequence_mentions, 2)))

freq_dist_mentions = nltk.FreqDist(bigrams_mentions)
prob_dist_mentions = nltk.MLEProbDist(freq_dist_mentions)
number_of_bigrams_mentions = freq_dist_mentions.N()

# print('---')
print('freq_dist mentions')
# print(freq_dist_mentions)
print('---')

# print('---')
print('prob_dist mentions')
# print(prob_dist_mentions)
print('---')

print('---')
print('number_of_bigrams mentions')
print(number_of_bigrams_mentions)
print('---')

# tokenized_mentions_df = pd.DataFrame([tokenized_mentions])

# tokenized_mentions_df.to_csv('4_5A_201_SMI1_tokenized_mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# tokenized_mentions_df.to_excel('4_5A_201_SMI1_tokenized_mentions_DF.xlsx', index=True, header=True)

freq_dist_mentions_df = pd.DataFrame([freq_dist_mentions], columns=['freq_dist_mentions'])

freq_dist_mentions_df.to_csv('4_5A_201_SMI1_freq_dist_mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# freq_dist_mentions_df.to_excel('4_5A_201_SMI1_freq_dist_mentions_DF.xlsx', index=True, header=True)

prob_dist_mentions_df = pd.DataFrame([prob_dist_mentions])

prob_dist_mentions_df.to_csv('4_5A_201_SMI1_prob_dist_mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# prob_dist_mentions_DF.to_excel('4_5A_201_SMI1_prob_dist_mentions_DF.xlsx', index=True, header=True)

number_of_bigrams_mentions_df = pd.DataFrame([number_of_bigrams_mentions], columns=['number_of_bigrams_mentions'])

number_of_bigrams_mentions_df.to_csv('4_5A_201_SMI1_number_of_bigrams_mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# number_of_bigrams_mentions_df.to_excel('4_5A_201_SMI1_number_of_bigrams_mentions_DF.xlsx', index=True, header=True)



############################################################################################################

# WORD FREQUENCY DISTRIBUTION IN emojis_unicode OF Tweets


# BIGRAMS emojis_unicode

# fp_emojis_unicode = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore')
# fp_emojis_unicode['tweet_emojis_unicode_fp_emojis_unicode'] = pd.DataFrame(tweets_smi_1['emojis_unicode'].astype(str, errors='ignore'))
# fp_emojis_unicode = tweets_smi_1.emojis_unicode.astype(str, errors='ignore')

fp_emojis_unicode_temp = tweets_smi_1['emojis_unicode']
fp_emojis_unicode = fp_emojis_unicode_temp.to_string()
fp_emojis_unicode_c = fp_emojis_unicode ### OJO QIE ESTA SIN ARREGLAR EL C

# print('---')
print('DataFrame Types fp_emojis_unicode')
# print(fp_emojis_unicode.dtypes)
print('---')

# fp_emojis_unicode = pd.DataFrame(tweets_smi_1['emojis_unicode'].astype('str'))
# fp_emojis_unicode = pd.DataFrame(StringIO(tweets_smi_1['emojis_unicode']))

# input_file = sys.argv[1]

# fp_emojis_unicode = pd.DataFrame(tweets_smi_1['emojis_unicode'].astype('str'))
# fp_emojis_unicode = StringIO(tweets_smi_1['emojis_unicode'])

# fp_emojis_unicode = pd.read_csv(StringIO(smi_file_4_4_emojis_unicode_only, 'r', 'utf-8', memory_map=True))
# fp_emojis_unicode = pd.read_csv(smi_file_4_4_emojis_unicode_only, sep=';', encoding='utf-8', parse_dates=True, header=0, low_memory=False)# 
# fp_emojis_unicode = codecs.open(smi_file_4_4_emojis_unicode_only, 'r', 'utf-8')
# fp_emojis_unicode = pd.DataFrame(tweets_smi_1['emojis_unicode'].astype('str'))
# fp_emojis_unicode = np.to_string(fp_emojis_unicode)

# fp_emojis_unicode = pd.DataFrame(fp_emojis_unicode)

# fp_emojis_unicode = open(smi_file_4_4_emojis_unicode_only, encoding='utf-8')
# f_emojis_unicode = fp_emojis_unicode.read() # As bytes

# data_f = fp_emojis_unicode.read() # As bytes

# f_emojis_unicode = fp_emojis_unicode

# f_emojis_unicode = data_f.decode('utf-8') # Unicode not bytes

print('---')
# print(f_emojis_unicode)
print('---')

# fp_emojis_unicode = f_emojis_unicode

print('---')
print('Tweets emojis_unicode First 10')
print(tweets_smi_1['emojis_unicode'].head(10))
print('---')

#######################################################################################

# CORRECT SPELLING

# tweets_smi_1

textblob_obj_emojis_unicode_c = TextBlob(fp_emojis_unicode) ## OJO QUE SI ES EL CORREGIDO O NO

#########   textblob_obj_emojis_unicode_c = textblob_obj_emojis_unicode.correct() ## NEED TO CHECK HOW IT WORKS!!!!
# textblob_obj_emojis_unicode_c = textblob_obj_emojis_unicode

textblob_obj_emojis_unicode_c_df = pd.DataFrame(textblob_obj_emojis_unicode_c)

print('--')
print('textblob_obj_emojis_unicode_C_DF TYPE:')
# print(textblob_obj_emojis_unicode_c)
print('--')

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

textblob_obj_emojis_unicode_c_df.to_csv('4_5A_184_SMI1_Emojis_Unicode_Obj_C_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# textblob_obj_emojis_unicode_c_df.to_excel('4_5A_184_SMI1_Emojis_Unicode_Obj_C_DF.xlsx', header=True)

# fp_emojis_unicode_c = textblob_obj_emojis_unicode_c.to_string()

# fp_emojis_unicode_c = textblob_obj_emojis_unicode_c

#######################################################################################

# tweets_emojis_unicode_words = nltk.word_tokenize(pd.to_string(fp_emojis_unicode_c))
# tweets_emojis_unicode_words = nltk.word_tokenize(fp_emojis_unicode_c['tweet_emojis_unicode_fp_emojis_unicode_c'])
tweets_emojis_unicode_words = nltk.word_tokenize(fp_emojis_unicode_c)
tweets_emojis_unicode_words_df = pd.DataFrame(tweets_emojis_unicode_words)

# tweets_emojis_unicode_words = nltk.word_tokenize((tweets_smi_1['emojis_unicode']).pd.to_string())
# tweets_emojis_unicode_words = tweets_smi_1['emojis_unicode']).nltk.word_tokenize()

print('--')
print('Tokenized emojis_unicode_words')
print(tweets_emojis_unicode_words_df.head(10))
print('--')

print('--')
print('Tokenized emojis_unicode_words Shape')
print(tweets_emojis_unicode_words_df.shape)
print('--')

print('--')
print('Tokenized emojis_unicode_words Info')
print(tweets_emojis_unicode_words_df.info)
print('--')

# Remove single-character tokens (mostly punctuation) ######## NEED TO DO FIX 
# tweets_emojis_unicode_words = [word for word in tweets_emojis_unicode_words if len(word) > 1]

# Remove numbers ######## NEED TO DO FIX
# tweets_emojis_unicode_words = [word for word in tweets_emojis_unicode_words if not word.isnumeric()]

# Lowercase all tweets_words (default_stoptweets_words are lowercase too) ######## NEED TO DO FIX
# tweets_emojis_unicode_words = [word.lower() for word in tweets_emojis_unicode_words]

# Stemming tweets_words seems to make matters worse, disabled
# stemmer = nltk.stem.snowball.SnowballStemmer('english')
# tweets_emojis_unicode_words = [stemmer.stem(word) for word in tweets_emojis_unicode_words]

# Remove stoptweets_words          ################################################################
# tweets_emojis_unicode_words = [word for word in tweets_emojis_unicode_words if word not in stoptweets_words]

# print('removed stoptweets_words')

##################################################################################################################

# FINDING N-GRAMS

# N-Grams refer to n combination of words in a sentence. For instance, for a sentence "I love watching football", some 2-grams would 
# be (I love), (love watching) and (watching football). N-Grams can play a cricual role in Text classification. 

for ngram_emojis_unicode in textblob_obj_emojis_unicode_c.ngrams(2):
	print('-------------------------')
	print('N-Grams emojis_unicode: 2')
	print(ngram_emojis_unicode)
	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_emojis_unicode = pd.DataFrame(ngram_emojis_unicode, columns=['ngran_emojis_unicode'])

ngram_emojis_unicode.to_csv('4_5A_200_SMI1_ngram_emojis_unicode_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
ngram_emojis_unicode.to_csv('4_5A_200_SMI1_ngram_emojis_unicode_TEXT.txt', sep=';', encoding='utf-8', index=False, header=True)




#####

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Ngrams Emojis')
plt.ioff()
ngram_emojis_unicode_df[:10].plot(alpha=0.9)
plt.xlabel('Ngram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_1_201_SMI1_Top_Ngram_Emojis_unicode_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Ngrams Emojis - Pie')
plt.ioff()
ngram_emojis_unicode_df[:7].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
# plt.legend(ngram_emojis_unicode_df['value_counts'], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_1_201_SMI1_Top_Ngram_Emojis_unicode_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Ngrams Emoji - Bars')
plt.ioff()
ngram_emojis_unicode_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Ngram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_1_201_SMI1_Top_Ngram_Emojis_unicode_Bars.png', bbox_inches='tight')

## DELETE VARIABLES

del ngram_emojis_unicode
del ngram_emojis_unicode_df

########################################################################################################

def ngrams_wrapper(sent):
	yield list(nltk.ngrams(sent, 2))

raw_emojis_unicode = fp_emojis_unicode_c

sentences_emojis_unicode = nltk.sent_tokenize(raw_emojis_unicode)

tokenized_emojis_unicode = map(nltk.tokenize, sentences_emojis_unicode)

print('---')
print('Tokenized emojis_unicode')
# print(tokenized_emojis_unicode)
print('---')

bigrams_emojis_unicode = []
for sentence_emojis_unicode in sentences_emojis_unicode:
	sequence_emojis_unicode = word_tokenize(sentence_emojis_unicode)
	bigrams_emojis_unicode.extend(list(ngrams(sequence_emojis_unicode, 2)))

freq_dist_emojis_unicode = nltk.FreqDist(bigrams_emojis_unicode)
prob_dist_emojis_unicode = nltk.MLEProbDist(freq_dist_emojis_unicode)
number_of_bigrams_emojis_unicode = freq_dist_emojis_unicode.N()

print('---')
print('freq_dist emojis_unicode')
# print(freq_dist_emojis_unicode)
print('---')

print('---')
print('prob_dist emojis_unicode')
# print(prob_dist_emojis_unicode)
print('---')

print('---')
print('number_of_bigrams emojis_unicode')
print(number_of_bigrams_emojis_unicode)
print('---')

# tokenized_emojis_unicode_df = pd.DataFrame([tokenized_emojis_unicode])

# tokenized_emojis_unicode_df.to_csv('4_5A_201_SMI1_tokenized_emojis_unicode_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# tokenized_emojis_unicode_df.to_excel('4_5A_201_SMI1_tokenized_emojis_unicode_DF.xlsx', index=True, header=True)

freq_dist_emojis_unicode_df = pd.DataFrame([freq_dist_emojis_unicode], columns=['freq_dist_emojis_unicode'])

freq_dist_emojis_unicode_df.to_csv('4_5A_201_SMI1_freq_dist_emojis_unicode_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# freq_dist_emojis_unicode_df.to_excel('4_5A_201_SMI1_freq_dist_emojis_unicode_DF.xlsx', index=True, header=True)

prob_dist_emojis_unicode_df = pd.DataFrame([prob_dist_emojis_unicode])

prob_dist_emojis_unicode_df.to_csv('4_5A_201_SMI1_prob_dist_emojis_unicode_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# prob_dist_emojis_unicode_DF.to_excel('4_5A_201_SMI1_prob_dist_emojis_unicode_DF.xlsx', index=True, header=True)

number_of_bigrams_emojis_unicode_df = pd.DataFrame([number_of_bigrams_emojis_unicode], columns=['number_of_bigrams_emojis_unicode'])

number_of_bigrams_emojis_unicode_df.to_csv('4_5A_201_SMI1_number_of_bigrams_emojis_unicode_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# number_of_bigrams_emojis_unicode_df.to_excel('4_5A_201_SMI1_number_of_bigrams_emojis_unicode_DF.xlsx', index=True, header=True)


############################################################################################################

# WORD FREQUENCY DISTRIBUTION IN emojis_converted OF Tweets


# BIGRAMS emojis_converted


# fp_emojis_converted = tweets_smi_1['emojis_converted'].astype(str, errors='ignore')
# fp_emojis_converted['tweet_emojis_converted_fp_emojis_converted'] = pd.DataFrame(tweets_smi_1['emojis_converted'].astype(str, errors='ignore'))
# fp_emojis_converted = tweets_smi_1.emojis_converted.astype(str, errors='ignore')

fp_emojis_converted_temp = tweets_smi_1['emojis_converted']
fp_emojis_converted = fp_emojis_converted_temp.to_string()
fp_emojis_converted_c = fp_emojis_converted ### OJO QIE ESTA SIN ARREGLAR EL C

print('---')
print('DataFrame Types fp_emojis_converted')
# print(fp_emojis_converted.dtypes)
print('---')

# fp_emojis_converted = pd.DataFrame(tweets_smi_1['emojis_converted'].astype('str'))
# fp_emojis_converted = pd.DataFrame(StringIO(tweets_smi_1['emojis_converted']))

# input_file = sys.argv[1]

# fp_emojis_converted = pd.DataFrame(tweets_smi_1['emojis_converted'].astype('str'))
# fp_emojis_converted = StringIO(tweets_smi_1['emojis_converted'])

# fp_emojis_converted = pd.read_csv(StringIO(smi_file_4_4_emojis_converted_only, 'r', 'utf-8'))
# fp_emojis_converted = pd.read_csv(smi_file_4_4_emojis_converted_only, sep=';', encoding='utf-8', parse_dates=True, header=0, low_memory=False)# 
# fp_emojis_converted = codecs.open(smi_file_4_4_emojis_converted_only, 'r', 'utf-8')
# fp_emojis_converted = pd.DataFrame(tweets_smi_1['emojis_converted'].astype('str'))
# fp_emojis_converted = np.to_string(fp_emojis_converted)

# fp_emojis_converted = pd.DataFrame(fp_emojis_converted)

# fp_emojis_converted = open(smi_file_4_4_emojis_converted_only, encoding='utf-8')
# f_emojis_converted = fp_emojis_converted.read() # As bytes

# data_f = fp_emojis_converted.read() # As bytes

# f_emojis_converted = fp_emojis_converted

# f_emojis_converted = data_f.decode('utf-8') # Unicode not bytes

print('---')
# print(f_emojis_converted)
print('---')

# fp_emojis_converted = f_emojis_converted

print('---')
print('Tweets emojis_converted First 10')
print(tweets_smi_1['emojis_converted'].head(10))
print('---')

#######################################################################################

# CORRECT SPELLING

# tweets_smi_1

textblob_obj_emojis_converted_c = TextBlob(fp_emojis_converted) ## OJO QUE SI ES EL CORREGIDO O NO

#########   textblob_obj_emojis_converted_c = textblob_obj_emojis_converted.correct() ## NEED TO CHECK HOW IT WORKS!!!!
# textblob_obj_emojis_converted_c = textblob_obj_emojis_converted

textblob_obj_emojis_converted_c_df = pd.DataFrame(textblob_obj_emojis_converted_c)

print('--')
print('textblob_obj_emojis_converted_C_DF TYPE:')
# print(textblob_obj_emojis_converted_c)
print('--')

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

# textblob_obj_emojis_converted_c_df.to_csv('4_5A_184_SMI1_Emojis_Converted_Obj_C_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# textblob_obj_emojis_converted_c_df.to_excel('4_5A_184_SMI1_Emojis_Converted_Obj_C_DF.xlsx', header=True)

# fp_emojis_converted_c = textblob_obj_emojis_converted_c.to_string()

# fp_emojis_converted_c = textblob_obj_emojis_converted_c

## DELETE VARIABLE

del textblob_obj_emojis_converted_c
del textblob_obj_emojis_converted_c_df

#######################################################################################

# tweets_emojis_converted_words = nltk.word_tokenize(pd.to_string(fp_emojis_converted_c))
# tweets_emojis_converted_words = nltk.word_tokenize(fp_emojis_converted_c['tweet_emojis_converted_fp_emojis_converted_c'])
tweets_emojis_converted_words = nltk.word_tokenize(fp_emojis_converted_c)
tweets_emojis_converted_words_df = pd.DataFrame(tweets_emojis_converted_words)

# tweets_emojis_converted_words = nltk.word_tokenize((tweets_smi_1['emojis_converted']).pd.to_string())
# tweets_emojis_converted_words = tweets_smi_1['emojis_converted']).nltk.word_tokenize()

print('--')
print('Tokenized emojis_converted_words')
print(tweets_emojis_converted_words_df.head(10))
print('--')

print('--')
print('Tokenized emojis_converted_words Shape')
print(tweets_emojis_converted_words_df.shape)
print('--')

print('--')
print('Tokenized emojis_converted_words Info')
print(tweets_emojis_converted_words_df.info)
print('--')

# Remove single-character tokens (mostly punctuation) ######## NEED TO DO FIX 
# tweets_emojis_converted_words = [word for word in tweets_emojis_converted_words if len(word) > 1]

# Remove numbers ######## NEED TO DO FIX
# tweets_emojis_converted_words = [word for word in tweets_emojis_converted_words if not word.isnumeric()]

# Lowercase all tweets_words (default_stoptweets_words are lowercase too) ######## NEED TO DO FIX
# tweets_emojis_converted_words = [word.lower() for word in tweets_emojis_converted_words]

# Stemming tweets_words seems to make matters worse, disabled
# stemmer = nltk.stem.snowball.SnowballStemmer('english')
# tweets_emojis_converted_words = [stemmer.stem(word) for word in tweets_emojis_converted_words]

# Remove stoptweets_words          ################################################################
# tweets_emojis_converted_words = [word for word in tweets_emojis_converted_words if word not in stoptweets_words]

# print('removed stoptweets_words')

##################################################################################################################

# FINDING N-GRAMS

# XXX NEED TO FIX NOT WORKING NEED TO DO 

# N-Grams refer to n combination of words in a sentence. For instance, for a sentence "I love watching football", some 2-grams would 
# be (I love), (love watching) and (watching football). N-Grams can play a cricual role in Text classification. 


for ngram_emojis_converted in textblob_obj_emojis_converted_c.ngrams(2):
	print('-------------------------')
	print('N-Grams emojis_converted: 2')
	print(ngram_emojis_converted)
	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!


ngram_emojis_converted = pd.value_counts(ngram_emojis_converted, ascending=False, normalize=True)

ngram_emojis_converted = ngram_emojis_converted.sort_values(ascending=False)

ngram_emojis_converted_df = pd.DataFrame([ngram_emojis_converted])

ngram_emojis_converted_df.to_csv('4_5A_200_SMI1_Ngram_Emojis_Converted_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
ngram_emojis_converted_df.to_csv('4_5A_200_SMI1_Ngram_Emojis_Converted_TEXT.txt', sep=';', encoding='utf-8', index=False, header=True)



#####

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Ngrams Emojis')
plt.ioff()
ngram_emojis_converted_df[:10].plot(alpha=0.9)
plt.xlabel('Ngram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_1_201_SMI1_Top_Ngram_Emojis_Converted_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Ngrams Emojis - Pie')
plt.ioff()
ngram_emojis_converted_df[:7].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
# plt.legend(ngram_emojis_converted_df['value_counts'], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_1_201_SMI1_Top_Ngram_Emojis_Converted_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Ngrams Emoji - Bars')
plt.ioff()
ngram_emojis_converted_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Ngram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_1_201_SMI1_Top_Ngram_Emojis_Converted_Bars.png', bbox_inches='tight')

## DELETE VARIABLES

del ngram_emojis_converted
del ngram_emojis_converted_df

########################################################################################################

## XXX NEED TO DO NEED TO FIX NOT WORKING NEED GRAPSH !!!!!!

def ngrams_wrapper(sent):
	yield list(nltk.ngrams(sent, 2))

raw_emojis_converted = fp_emojis_converted_c

sentences_emojis_converted = nltk.sent_tokenize(raw_emojis_converted)

tokenized_emojis_converted = map(nltk.tokenize, sentences_emojis_converted)

print('---')
print('Tokenized emojis_converted')
# print(tokenized_emojis_converted)
print('---')

bigrams_emojis_converted = []
for sentence_emojis_converted in sentences_emojis_converted:
	sequence_emojis_converted = word_tokenize(sentence_emojis_converted)
	bigrams_emojis_converted.extend(list(ngrams(sequence_emojis_converted, 2)))

freq_dist_emojis_converted = nltk.FreqDist(bigrams_emojis_converted)
prob_dist_emojis_converted = nltk.MLEProbDist(freq_dist_emojis_converted)
number_of_bigrams_emojis_converted = freq_dist_emojis_converted.N()

print('---')
print('freq_dist emojis_converted')
print(freq_dist_emojis_converted)
print('---')

print('---')
print('prob_dist emojis_converted')
print(prob_dist_emojis_converted)
print('---')

print('---')
print('number_of_bigrams emojis_converted')
print(number_of_bigrams_emojis_converted)
print('---')

# tokenized_emojis_converted_df = pd.DataFrame([tokenized_emojis_converted])

# tokenized_emojis_converted_df.to_csv('4_5A_201_SMI1_tokenized_emojis_converted_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# tokenized_emojis_converted_df.to_excel('4_5A_201_SMI1_Tokenized_Emojis_Converted_DF.xlsx', index=True, header=True)

freq_dist_emojis_converted_df = pd.DataFrame([freq_dist_emojis_converted], columns=['freq_dist_emojis_converted'])

freq_dist_emojis_converted_df.to_csv('4_5A_201_SMI1_freq_dist_emojis_converted_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# freq_dist_emojis_converted_df.to_excel('4_5A_201_SMI1_freq_dist_emojis_converted_DF.xlsx', index=True, header=True)

prob_dist_emojis_converted_df = pd.DataFrame([prob_dist_emojis_converted])

prob_dist_emojis_converted_df.to_csv('4_5A_201_SMI1_prob_dist_emojis_converted_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# prob_dist_emojis_converted_DF.to_excel('4_5A_201_SMI1_prob_dist_emojis_converted_DF.xlsx', index=True, header=True)

number_of_bigrams_emojis_converted_df = pd.DataFrame([number_of_bigrams_emojis_converted], columns=['number_of_bigrams_emojis_converted'])

number_of_bigrams_emojis_converted_df.to_csv('4_5A_201_SMI1_Number_of_Bigrams_Emojis_Converted_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# number_of_bigrams_emojis_converted_df.to_excel('4_5A_201_SMI1_Number_of_Bigrams_Emojis_Converted_DF.xlsx', index=True, header=True)


## DELETE VARIABLE

del sentences_emojis_converted
del raw_emojis_converted
del freq_dist_emojis_converted
del freq_dist_emojis_converted_df
del prob_dist_emojis_converted
del prob_dist_emojis_converted_df
del number_of_bigrams_emojis_converted
del number_of_bigrams_emojis_converted_df
# del tokenized_emojis_converted
# del tokenized_emojis_converted_df

############################################################################################################
############################################################################################################
#############################################################################################################

value_counts_bigram_hashtags = pd.value_counts(bigrams_hashtags, ascending=False, normalize=True) 

value_counts_bigram_hashtags = value_counts_bigram_hashtags.sort_values(ascending=False)

value_counts_bigram_hashtags_df = pd.DataFrame(value_counts_bigram_hashtags, columns=['value_counts_bigrams_hashtags'])

value_counts_bigram_hashtags_df.to_csv('4_5A_1_201_SMI1_value_counts_bigram_hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# value_counts_bigram_hashtags_df.to_excel('4_5A_1_201_SMI1_value_counts_bigram_hashtags_DF.xlsx', index=True, header=True)

print('---')
print('value_counts_bigram_hashtags_df info')
print(value_counts_bigram_hashtags_df.info)
print('---')

print('---')
print('value_counts_bigram_hashtags_df shape')
print(value_counts_bigram_hashtags_df.shape)
print('---')

# CREATE SEPERATE BIGRAMS DATAFRAMES 

# value_counts_bigram_hashtags_df = value_counts_bigram_hashtags_df.astype(str, errors='ignore')

# seperate_value_counts_bigram_hashtags = [value_counts_bigram_hashtags_df[:0], value_counts_bigram_hashtags_df[:1]]

# value_counts_bigram_hashtags_df = value_counts_bigram_hashtags_df['value_counts_bigrams'].apply(list)

# seperate_value_counts_bigram_hashtags_df = pd.DataFrame.from_items(value_counts_bigram_hashtags, columns=['items_counts_bigrams', 'number_counts_bigrams'])
# seperate_value_counts_bigram_hashtags_df[['value_bigrams_hashtags', 'value_counts_bigrams_hashtags']] = pd.DataFrame(value_counts_bigram_hashtags_df['value_counts_bigrams'].tolist(),index=value_counts_bigram_hashtags_df)
# seperate_value_counts_bigram_hashtags_df = seperate_value_counts_bigram_hashtags_df.join(value_counts_bigram_hashtags_df_temp)
# seperate_value_counts_bigram_hashtags_df.to_csv('4_5A_1_201_SMI1_seperate_value_counts_bigram_hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# seperate_value_counts_bigram_hashtags_df.to_excel('4_5A_1_201_SMI1_seperate_value_counts_bigram_hashtags_DF.xlsx', index=True, header=True)

print('---')
print('seperate_value_counts_bigram_hashtags_df head')
# print(seperate_value_counts_bigram_hashtags_df.head)
print('---')

print('---')
print('value_counts_bigram_hashtags_df info')
print(value_counts_bigram_hashtags_df.info)
print('---')

print('---')
print('value_counts_bigram_hashtags_df shape')
print(value_counts_bigram_hashtags_df.shape)
print('---')

#####

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Hashtags Value Counts')
plt.ioff()
value_counts_bigram_hashtags_df[:10].plot(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_1_201_SMI1_Top_Bigram_Value_Counts_Bigram_Hashtags_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Hashtags Value Counts - Pie')
plt.ioff()
# value_counts_bigram_hashtags_df[:7].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['hashtags'], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_1_201_SMI1_Top_Value_Counts_Bigram_Hashtags_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Hashtags Value Counts - Bars')
plt.ioff()
value_counts_bigram_hashtags_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_1_201_SMI1_Top_Value_Counts_Bigram_Hashtags_Bars.png', bbox_inches='tight')


## DELETE VARIABLE

del value_counts_bigram_hashtags
del value_counts_bigram_hashtags_df

#############################################################################################################
#############################################################################################################

value_counts_bigram_mentions = pd.value_counts(bigrams_mentions, ascending=False, normalize=True) 

value_counts_bigram_mentions = value_counts_bigram_mentions.sort_values(ascending=False)

value_counts_bigram_mentions_df = pd.DataFrame(value_counts_bigram_mentions, columns=['value_counts_bigrams_mentions'])

value_counts_bigram_mentions_df.to_csv('4_5A_1_201_SMI1_Value_Counts_Bigram_Mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# value_counts_bigram_mentions_df.to_excel('4_5A_1_201_SMI1_Value_Counts_Bigram_Mentions_DF.xlsx', index=True, header=True)

print('---')
print('value_counts_bigram_mentions_df info')
print(value_counts_bigram_mentions_df.info)
print('---')

print('---')
print('value_counts_bigram_mentions_df shape')
print(value_counts_bigram_mentions_df.shape)
print('---')

# CREATE SEPERATE BIGRAMS DATAFRAMES 

# value_counts_bigram_mentions_df = value_counts_bigram_mentions_df.astype(str, errors='ignore')

# seperate_value_counts_bigram_mentions = [value_counts_bigram_mentions_df[:0], value_counts_bigram_mentions_df[:1]]

# value_counts_bigram_mentions_df = value_counts_bigram_mentions_df['value_counts_bigrams'].apply(list)

# seperate_value_counts_bigram_mentions_df = pd.DataFrame.from_items(value_counts_bigram_mentions, columns=['items_counts_bigrams', 'number_counts_bigrams'])
# seperate_value_counts_bigram_mentions_df[['value_bigrams_mentions', 'value_counts_bigrams_mentions']] = pd.DataFrame(value_counts_bigram_mentions_df['value_counts_bigrams'].tolist(),index=value_counts_bigram_mentions_df)
# seperate_value_counts_bigram_mentions_df = seperate_value_counts_bigram_mentions_df.join(value_counts_bigram_mentions_df_temp)
# seperate_value_counts_bigram_mentions_df.to_csv('4_5A_1_201_SMI1_seperate_value_counts_bigram_mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# seperate_value_counts_bigram_mentions_df.to_excel('4_5A_1_201_SMI1_seperate_value_counts_bigram_mentions_DF.xlsx', index=True, header=True)

print('---')
print('seperate_value_counts_bigram_mentions_df head')
# print(seperate_value_counts_bigram_mentions_df.head)
print('---')

print('---')
print('value_counts_bigram_mentions_df info')
print(value_counts_bigram_mentions_df.info)
print('---')

print('---')
print('value_counts_bigram_mentions_df shape')
print(value_counts_bigram_mentions_df.shape)
print('---')

#####

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Mentions Value Counts')
plt.ioff()
value_counts_bigram_mentions[:10].plot(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_1_201_SMI1_Top_bigram_value_counts_bigram_mentions_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Mentions Value Counts - Pie')
plt.ioff()
# value_counts_bigram_mentions[:7].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['mentions'], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_1_201_SMI1_Top_Value_Counts_Bigram_Mentions_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Mentions Value Counts - Bars')
plt.ioff()
value_counts_bigram_mentions[:10].plot.bar(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_1_201_SMI1_Top_Value_Counts_Bigram_Mentions_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#############################################################################################################
#############################################################################################################

value_counts_bigram_emojis_converted = pd.value_counts(bigrams_emojis_converted, ascending=False, normalize=True) 

value_counts_bigram_emojis_converted = value_counts_bigram_emojis_converted.sort_values(ascending=False)

value_counts_bigram_emojis_converted_df = pd.DataFrame(value_counts_bigram_emojis_converted, columns=['value_counts_bigrams_emojis_converted'])

value_counts_bigram_emojis_converted_df.to_csv('4_5A_201_SMI1_value_counts_bigram_emojis_converted_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# value_counts_bigram_emojis_converted_df.to_excel('4_5A_201_SMI1_value_counts_bigram_emojis_converted_DF.xlsx', index=True, header=True)

print('---')
print('value_counts_bigram_emojis_converted_df info')
print(value_counts_bigram_emojis_converted_df.info)
print('---')

print('---')
print('value_counts_bigram_emojis_converted_df shape')
print(value_counts_bigram_emojis_converted_df.shape)
print('---')

# CREATE SEPERATE BIGRAMS DATAFRAMES 

# value_counts_bigram_emojis_converted_df = value_counts_bigram_emojis_converted_df.astype(str, errors='ignore')

# seperate_value_counts_bigram_emojis_converted = [value_counts_bigram_emojis_converted_df[:0], value_counts_bigram_emojis_converted_df[:1]]

# value_counts_bigram_emojis_converted_df = value_counts_bigram_emojis_converted_df['value_counts_bigrams'].apply(list)

# seperate_value_counts_bigram_emojis_converted_df = pd.DataFrame.from_items(value_counts_bigram_emojis_converted, columns=['items_counts_bigrams', 'number_counts_bigrams'])
# seperate_value_counts_bigram_emojis_converted_df[['value_bigrams_emojis_converted', 'value_counts_bigrams_emojis_converted']] = pd.DataFrame(value_counts_bigram_emojis_converted_df['value_counts_bigrams'].tolist(),index=value_counts_bigram_emojis_converted_df)
# seperate_value_counts_bigram_emojis_converted_df = seperate_value_counts_bigram_emojis_converted_df.join(value_counts_bigram_emojis_converted_df_temp)
# seperate_value_counts_bigram_emojis_converted_df.to_csv('4_5A_201_SMI1_seperate_value_counts_bigram_emojis_converted_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# seperate_value_counts_bigram_emojis_converted_df.to_excel('4_5A_201_SMI1_seperate_value_counts_bigram_emojis_converted_DF.xlsx', index=True, header=True)

print('---')
print('seperate_value_counts_bigram_emojis_converted_df head')
# print(seperate_value_counts_bigram_emojis_converted_df.head)
print('---')

print('---')
print('value_counts_bigram_emojis_converted_df info')
print(value_counts_bigram_emojis_converted_df.info)
print('---')

print('---')
print('value_counts_bigram_emojis_converted_df shape')
print(value_counts_bigram_emojis_converted_df.shape)
print('---')

#####

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Emojis Value Counts')
plt.ioff()
value_counts_bigram_emojis_converted[:10].plot(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Bigram_Value_Counts_Bigram_Emojis_Converted_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Emojis Value Counts - Pie')
plt.ioff()
# value_counts_bigram_emojis_converted[:7].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['emojis_converted'], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Value_Counts_Bigram_Emojis_Converted_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Emojis Value Counts - Bars')
plt.ioff()
value_counts_bigram_emojis_converted[:10].plot.bar(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_value_counts_bigram_emojis_converted_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#############################################################################################################

# tidytextmining.com/ngrams.html

# USING BIGRAMS TO GIVE CONTEXT TO SENTIMENT ANALYSIS / NEED TO CHANGE THIS ONE IF R NOT PYTHON!!!!

# bigrams_separated %>%
#	filter(word == 'not') %>%
#	count(word1, word2, sort=True)

# AFINN <- get_sentiments('afinn')

# not_words <- bigrams_seperated %>%
#	filter(word1 == 'not') %.%
# 	inner_join(AFINN, by = c(word2 = 'word')) %>%
#	count(word2, value, sort=True)

#############################################################################################################
#############################################################################################################
#############################################################################################################
#############################################################################################################
#############################################################################################################
#############################################################################################################

# developer.ibm.com/technologies/artificial-intelligence/articles/cc-patterns-artificial-intelligence-part2

###################################################################################################################
#
#		SENTIMENT ANALYSIS: USING TEXTBLOB
#
###################################################################################################################

# The SENTIMENT property returns a nameduple of the form sentiment(polarity, subjectivity). The polarity score is a 
# float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective
# and 1.0 is very subjective.


# returns the sentiment of text
# by returning a value between -1.0 and 1.0

textblob_obj_text_polarity = textblob_obj_text_c.sentiment.polarity
textblob_obj_text_subjectivity = textblob_obj_text_c.sentiment.subjectivity

print('---')
print('TextBlob Polarity:')
print(textblob_obj_text_polarity)

if textblob_obj_text_polarity == 0:
  print('The Text is neutral')
elif textblob_obj_text_polarity > 0.75:
  print('The Text is very positive') 
elif textblob_obj_text_polarity > 0.50:
  print('The Text is positive')
elif textblob_obj_text_polarity > 0:
  print('The Text is somewhat positive')
elif textblob_obj_text_polarity > -0.25:
  print('The Text is somewhat negative') 
elif textblob_obj_text_polarity > -0.50:
  print('The Text is negative')
else:
  print('The Text is very negative')
  
print('---')

print('TextBlob Subjectivity:')
print(textblob_obj_text_subjectivity)

if textblob_obj_text_subjectivity == 0:
  print('The Text is extremely subjective')
elif textblob_obj_text_subjectivity > 0.75:
  print('The Text is very objective')
elif textblob_obj_text_subjectivity > 0.50:
  print('The Text is objective')
elif textblob_obj_text_subjectivity > 0.25:
  print('The Text is subjective')
else:
  print('The Text is very subjective')

print('---')


textblob_obj_text_positiveness = 1 - textblob_obj_text_polarity
# textblob_obj_text_subjectivity = 1 - textblob_obj_text_subjectivity

# initialize list of Lists 
textblob_obj_text_sentiments = [['textblob_obj_text_polarity', textblob_obj_text_polarity], ['textblob_obj_text_subjectivity', textblob_obj_text_subjectivity], ['textblob_obj_text_positiveness', textblob_obj_text_positiveness]] 
 
# Create the pandas DataFrame 
textblob_obj_text_sentiments_df = pd.DataFrame(textblob_obj_text_sentiments, columns = ['textblob_obj_text_sentiment_item', 'textblob_obj_text_sentiment_value']) 

textblob_obj_text_sentiments_df.to_csv('4_5A_200_SMI1_Textblob_Obj_Text_Sentiments_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# textblob_obj_text_sentiments_df.to_excel('4_5A_200_SMI1_Textblob_Obj_Text_Sentiments.xlsx', header=True)

# PLOT TABLE # NEED TO DO 

# Sentiment Plot

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
plt.figure(figsize=(6,6))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity - TextBlob')
plt.ioff()
textblob_obj_text_sentiments_df.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_200_SMI1_Textblob_Obj_Text_Sentiments_df_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity TextBlob - Pie')
plt.ioff()
plt.pie(textblob_obj_text_sentiments_df['textblob_obj_text_sentiment_value'], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, radius = 0.6, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.legend(textblob_obj_text_sentiments_df, bbox_to_anchor=(1., 1), loc=1, borderaxespad=0.)
# plt.legend()
# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_200_SMI1_Textblob_Obj_Text_Sentiments_df_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOT # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity / Subjectivity TextBlob - Bars')
plt.ioff()
textblob_obj_text_sentiments_df.plot.bar(alpha=0.9)
plt.xlabel('Sentiment Polarity / Subjectivity / Positiveness')
plt.ylabel('Value')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_200_SMI1_Textblob_Obj_Text_Sentiments_df_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


######################################################################################################################

# SENTENCES ANALYSIS

textblob_sentences = textblob_obj_text_c.sentences

print('-------------------------')
print('TextBlob Sentences Head - NOT WORKINGGGGGG')
# print(textblob_sentences[:10])
print('-------------------------')

 
# Create the pandas DataFrame 
textblob_sentences_df = pd.DataFrame(textblob_sentences) 

textblob_sentences_df.to_csv('4_5A_201_SMI1_Textblob_Sentences_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# textblob_sentences_df.to_excel('4_5A_201_SMI1_Textblob_Sentences.xlsx', header=True)

textblob_sentences_number = len(textblob_sentences)

print('-------------------------')
print('TextBlob Sentenes Number')
# print(textblob_sentences_number)
print('-------------------------')

# Create the pandas DataFrame 
# textblob_sentences_number_df = pd.DataFrame(textblob_sentences_number) 

# textblob_sentences_number_df.to_csv('4_5A_201_SMI1_Textblob_Sentences_Number_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# textblob_sentences_number_df.to_excel('4_5A_201_SMI1_Textblob_Sentences_Number.xlsx', header=True)

###################################################################################################################
#
# 	 			 TEXT CLASSIFICATION
#                                                 
###################################################################################################################
	
	
# WITH TEXTBLOB - BASIC CLASSIFICATION

textblob_train_data = [
	('fucking love it', 'positive'),	
	('fucking great', 'positive'),
	('fucking amazing', 'positive'),
	('fucking kidding', 'negative'),
	('fucking bad', 'negative')
]

textblob_test_data = [
	('fucking love it', 'positive'),	
	('fucking great', 'positive'),
	('fucking amazing', 'positive'),
	('fucking kidding', 'negative'),
	('fucking bad', 'negative')
]

###########################################################

print('---')
print('Loading Libs 42')
print('---')

# NAIVE BAYES CLASSIFIER

from textblob.classifiers import NaiveBayesClassifier

textblob_classifier = NaiveBayesClassifier(textblob_train_data)

textblob_test_phrase_1 = 'This lipstick is fucking amazing'
textblob_test_phrase_2 = 'This lipstick is fucking waste of money'

print('-------------------------')
print('TextBlob NaiveBayes Classifier')
print(textblob_test_phrase_1)
print('is:')
print(textblob_classifier.classify(textblob_test_phrase_1))
print('-------------------------')

print('-------------------------')
print('TextBlob NaiveBayes Classifier')
print(textblob_test_phrase_2)
print('is:')
print(textblob_classifier.classify(textblob_test_phrase_2))
print('-------------------------')


# NEED TO FINISHHHHHHHHHHHHHHHHHHHHHHHHHHH


######################################################################################################################
######################################################################################################################

# SENTIMENT PER TWEET XXX NEED TO FIX NOT WORKING 

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str)
tweets_smi_1['text'] = tweets_smi_1['text'].to_string()

for tweet in tweets_smi_1['text']:
	tweet_textblob = TextBlob(tweet)
	# tweets_smi_1['textblob_obj_text_polarity'] = tweet_textblob.sentiment.polarity
	# tweets_smi_1['textblob_obj_text_subjectivity'] = tweet_textblob.sentiment.subjectivity
	tweets_smi_1['textblob_obj_text_polarity'] = tweet_textblob.apply(lambda x: TextBlob(x).sentiment.polarity)
	tweets_smi_1['textblob_obj_text_subjectivity'] = tweet_textblob.apply(lambda x: TextBlob(x).sentiment.subjectivity)
	

# tweets_smi_1['textblob_obj_text_polarity'] = TextBlob(tweets_smi_1['text'].to_string()).sentiment.polarity
# tweets_smi_1['textblob_obj_text_subjectivity'] = TextBlob(tweets_smi_1['text'].to_string()).sentiment.subjectivity


# MOST POSITIVE TWEETS

# most_positive_tweets_text_textblob = tweets_smi_1['textblob_obj_text_polarity'].where('textblob_obj_text_polarity' == 1)
# most_positive_tweets_text_textblob = pd.DataFrame(tweets_smi_1['textblob_obj_text_polarity' == 1])

# tweets_main_smi_1 = tweets_smi_1[(tweets_smi_1['screenName'] == main_smi_1)]

most_positive_tweets_text_textblob = tweets_smi_1[tweets_smi_1.textblob_obj_text_polarity == '1']

print('-------------------------')
print('Most Positive Tweets Text Head')
print(most_positive_tweets_text_textblob[:10])
print('-------------------------')

# MOST NEGATIVE TWEETS

# most_negative_tweets_text_textblob = tweets_smi_1['textblob_obj_text_polarity' == '-1']

# tweets_smi_1 = tweets_smi_1[(tweets_smi_1['screenName'] == main_smi_1)]

most_negative_tweets_text_textblob = tweets_smi_1[tweets_smi_1.textblob_obj_text_polarity == '-1']

print('-------------------------')
print('Most Negative Tweets Text Head')
print(most_negative_tweets_text_textblob[:10])
print('-------------------------')

# most_positive_tweets_text_textblob
# most_negative_tweets_text_textblob

# SAVE DATAFRAME TO CSV 


tweets_smi_1.to_csv('1_6_5A_SENT_SMI1_DF_Tweets_Processes_1_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
tweets_smi_1.to_csv('1_6_5A_SENT_SMI1_DF_Tweets_Processes_1.txt', sep=';', encoding='utf-8', index=False, header=True)

print('MAIN SMI: Done Initial TextBlob')
print(main_smi)
print('-------------------------')



##################################################################################################################
#
#                                       USING NLTK ##### NEED TO DO !!!!!
#
###################################################################################################################

print('---')
print('Loading Libs 43')
print('---')


#############################################################################################################

# POLARITY DISTRIBUTION

# textblob_obj_text_c


def find_polarity_textblob(tweets):
	yield TextBlob(tweets).sentiment.polarity
	
tweets_smi_1['textblob_sentiment_polarity'] = tweets_smi_1['text'].apply(find_polarity_textblob)

print('---')
print('TextBlob Sentiment Polarity Distributions')
print(tweets_smi_1['textblob_sentiment_polarity'].head)
print('---')

textblob_sentiment_polarity_df = tweets_smi_1['textblob_sentiment_polarity']

textblob_sentiment_polarity_df.to_csv('4_5A_200_SMI1_Textblob_Sentiment_Polarity_df_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# textblob_sentiment_polarity_df.to_excel('4_5A_200_SMI1_Textblob_Sentiment_Polarity_df.xlsx', header=True)

# DIST PLOT # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity Distribution TextBlob - Histogram')
plt.ioff()
# tweets_smi_1['textblob_sentiment_polarity'].plot.bar(alpha=0.9)
plt.xlabel('Sentiment Polarity')
plt.ylabel('Value')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_200_SMI1_TextBLob_Sentiment_Polarity_Distribution_Hist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##########################################################################################################################

# Word Tokenization

# Word tokenizer breaks Text paragraph into tweets_words.

tokenized_tweets_words = nltk.tokenize.word_tokenize(tweets_smi_1['text'].to_string())
# print(tokenized_tweets_words.head)

# tokenized_tweets_words = mosestokenizer.MosesTokenizer(tweets_smi_1['text'])

# tokenized_tweets_words.to_csv('4_5A_212_SMI1_Tokenized_Tweets_Words_CSV.csv', sep=';', encoding='utf-8', index=True)
# tokenized_tweets_words.to_excel('4_5A_212_SMI1_Tokenized_Tweets_Words.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Words')
plt.ioff()
# tokenized_tweets_words.plot(10,cumulative=False)
# sns.distplot(tokenized_tweets_words)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_212_SMI1_Freq_Dist_Tokenized_Tweets_Words.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Words - Pie')
plt.ioff()
# plt.pie(tokenized_tweets_words[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(tokenized_tweets_words, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_212_SMI1_Freq_Dist_Tokenized_Tweets_Words_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Words - Bars')
plt.ioff()
# tokenized_tweets_words[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_212_SMI1_Freq_Dist_Tokenized_Tweets_Words_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#########################################################################################################################################################

# Stoptweets_words

# Stoptweets_words considered as noise in the text. Text may contain stop tweets_words such as is, am, are, this, a, an, the, etc.
# In NLTK for removing stoptweets_words, you need to create a list of stoptweets_words and filter out your list of tokens from these tweets_words.

# NEED TO DO - NOT WORKING!!!!!!!!!!!

# stop_tweets_words = nltk.corpus.stoptweets_words.tweets_words('english')

# stop_tweets_words = stoptweets_words.tweets_words('english')

print('---')
print('Stop tweets_words NOT WORKING NEED TO FIX')
# print(stop_tweets_words)
print('---')

# filtered_sent=[]
# for w in tokenized_tweets_words:
#    if w not in stop_tweets_words:
#        filtered_sent.append(w)
# print("Tokenized Sentence:", tokenized_sent)
# print("Filterd Sentence:", filtered_sent)

# tokenized_sent.to_csv('4_5A_213_SMI1_Tokenized_Sent_No_Stoptweets_words_CSV.csv', sep=';', encoding='utf-8', index=True)
# tokenized_sent.to_excel('4_5A_213_SMI1_Tokenized_Sent_No_Stoptweets_words.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# PLOT TOKENIZED SENT - 1 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentiment')
plt.ioff()
# tokenized_sent.plot(10,cumulative=False, alpha=0.9)
# tokenized_sent[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_213_SMI1_Freq_Dist_Tokenized_Sent.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentiment - Pie')
plt.ioff()
# plt.pie(tokenized_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.pie(tokenized_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(tokenized_sent, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_213_SMI1_Freq_Dist_Tokenized_Sent_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO

############################################################################

# tokenized_sent.to_csv('4_5A_214_SMI1_Tokenized_sent_CSV.csv', sep=';', encoding='utf-8', index=True)
# tokenized_sent.to_excel('4_5A_214_SMI1_Tokenized_sent.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# PLOT SENTIMENT OR SENTENCES????????? - 2

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Filtered Sentiment')
plt.ioff()
# filtered_sent.plot(10,cumulative=False)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_214_SMI1_Tokenized_Sent.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Filtered Sentiment - Pie')
plt.ioff()
# plt.pie(filtered_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.pie(filtered_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(filtered_sent, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()
# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_214_SMI1_Freq_Dist_Filtered_Sent_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO


############################################################################################################
#######################################################################################################
############################################################################################################
#
#			NEED TO DO !!! - NOT WORKING !!!!
#
############################################################################################################
#######################################################################################################
############################################################################################################

#################################################################################

# List Total number_hashtags ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!


tweets_smi_1['number_total_hashtags'] = tweets_smi_1['number_total_hashtags'].astype(np.int32, errors='ignore')

count_total_number_hashtags = tweets_smi_1['number_total_hashtags'].sum()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


print('---')
print('List Total number_hashtags')
print(count_total_number_hashtags)
print('---')

count_total_number_hashtags_df = pd.DataFrame([count_total_number_hashtags], columns=['count_total_number_hashtags'])

count_total_number_hashtags_df.to_csv('4_4_43_SMI1_Count_Total_Number_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# count_total_number_hashtags_df.to_excel()

count_total_number_hashtags_year = tweets_smi_1.groupby(['year'])['number_total_hashtags'].sum()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


print('---')
print('List Total number_hashtags Year')
print(count_total_number_hashtags_year)
print('---')

count_total_number_hashtags_year_df = pd.DataFrame([count_total_number_hashtags_year], columns=['count_total_number_hashtags_year'])

count_total_number_hashtags_year_df.to_csv('4_4_43_SMI1_Count_Total_Number_Hashtags_Year_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# count_total_number_hashtags_df.to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Hashtags - Year')
plt.ioff()
plt.plot(count_total_number_hashtags_year)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_SMI1_Count_Total_Number_Hashtags_Year_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Number Hashtags - Pie')
plt.ioff()
plt.pie(tweets_smi_1.groupby(['year'])['number_total_hashtags'].sum(), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=count_total_number_hashtags, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_SMI1_Count_Total_Number_Hashtags_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Number Hashtags - Bars')
plt.ioff()
count_total_number_hashtags_year.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_SMI1_Count_Total_Number_Hashtags_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################

# List Total number_mentions ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!

number_total_number_mentions = tweets_smi_1['number_total_mentions'].sum()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('List Total number_mentions')
# print(number_total_number_mentions.head)
print('---')

number_total_number_mentions_df = pd.DataFrame([number_total_number_mentions], columns=['number_total_number_mentions'])

number_total_number_mentions_df.to_csv('4_4_43_SMI1_Number_Total_Number_Mentions_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# number_total_number_mentions_df.to_excel()

number_total_number_mentions_year = tweets_smi_1.groupby(['year'])['number_total_mentions'].sum()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


print('---')
print('List Total number_mentions Year')
# print(number_total_number_mentions_year.head)
print('---')

number_total_number_mentions_year_df = pd.DataFrame([number_total_number_mentions_year], columns=['number_total_number_mentions_year'])

number_total_number_mentions_year_df.to_csv('4_4_43_SMI1_Number_Total_Number_Mentions_Year_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# number_total_number_mentions_df.to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Number Mentions - Year')
plt.ioff()
plt.plot(number_total_number_mentions_year_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Number_Mentions_Year_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Number Mentions - Pie')
plt.ioff()
# plt.pie(tweet_info_retweets_df['number_total_number_mentions_df'], labels=number_total_number_mentions_df)
# plt.pie(number_total_number_mentions['number_total_number_mentions_df'], labels=number_total_number_mentions, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=number_total_number_mentions, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Number_Mentions_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Number Mentions - Bars')
plt.ioff()
number_total_number_mentions_year_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Number_Mentions_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################################################

# This selects the top 5 highest average points among Total Tweets:

# smi1_total_favorites_mean().sort_values(by='total_favorites', ascending=True).head  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest total_favorites Average Points Among Total Tweets:')
# print(smi1_total_favorites_mean().sort_values(by='total_favorites',ascending=True).head)
print('---')


# smi1_total_favorites_mean_sort_values_total_favorites_df = pd.DataFrame(smi1_total_favorites_mean().sort_values(by='total_favorites',ascending=True))

# smi1_total_favorites_mean_sort_values_total_favorites_df.to_csv('4_5A_167_SMI1_Total_Favorites_Mean_Sort_Values_Total_Favorites_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# smi1_total_favorites_mean_sort_values_total_favorites_df.to_excel('4_5A_167_SMI1_Total_Favorites_Mean_Sort_Values_Total_Favorites_DF.xlsx', header=True)

# PLOT plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Favorites Average Points')
plt.ioff()
# plt.plot(smi1_total_favorites_mean_sort_values_total_favorites_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_167_SMI1_Total_Favorites_Mean_Sort_Values_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Favorites Average Points - Pie')
plt.ioff()
# plt.pie(smi1_total_favorites_mean_sort_values_total_favorites_df.most_common(10), labels=smi1_total_favorites_mean_sort_values_total_favorites_df.most_common(10), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_total_favorites_mean_sort_values_total_favorites_df[:6], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_167_SMI1_Total_Favorites_Mean_Sort_Values_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# BAR PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Favorites Average Points - Bars')
plt.ioff()
# smi1_total_favorites_mean_sort_values_retweets_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_167_SMI1_Total_Favorites_Mean_Sort_Values_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##
###################################################################################



# This selects the top 5 highest average points among Total Tweets:

# smi1_retweets_mean().sort_values(by='retweets',ascending=True).head  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest retweets Average Points Among Total Tweets:')
# print(smi1_retweets_mean().sort_values(by='retweets',ascending=True).head)
print('---')


# smi1_retweets_mean_sort_values_retweets_df = pd.DataFrame(smi1_otal_retweets_mean().sort_values(by='retweets',ascending=True))

# smi1_retweets_mean_sort_values_retweets_df.to_csv('4_5A_167_SMI1_Total_Retweets_Mean_Sort_Values_total_Retweetss_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# smi1_retweets_mean_sort_values_retweets_df.to_excel('4_5A_167_SMI1_Total_Retweets_Mean_Sort_Values_total_Retweets_DF.xlsx', header=True)

# PLOT plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Retweets Average Points')
plt.ioff()
# plt.plot(smi1_retweets_mean_sort_values_retweets_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_167_4_SMI1_Total_Retweets_Mean_Sort_Values_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Retweets Average Points - Pie')
plt.ioff()
# plt.pie(smi1_retweets_mean_sort_values_retweets_df.most_common(10), labels=smi1_retweets_mean_sort_values_retweets_df.most_common(10), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_retweets_mean_sort_values_retweets_df[:6], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_167_4_SMI1_Total_Retweets_Mean_Sort_Values_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# BAR PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Retweets Average Points - Bars')
plt.ioff()
# smi1_retweets_mean_sort_values_retweets_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Retweets')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_167_4_SMI1_Total_Retweets_Mean_Sort_Values_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

# This selects the top 5 highest average points among Total Tweets:

# smi1_followers_mean.sort_values(by='followers',ascending=True).head  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest Followers Average Points Amongst Total Tweets:')
# print(smi1_followers_mean.sort_values(by='followers',ascending=True).head)
print('---')

# smi1_followers_mean_sort_values_followers_df = pd.DataFrame(smi1_followers_mean().sort_values(by='followers',ascending=True))

# smi1_followers_mean_sort_values_followers_df.to_csv('4_5A_168_SMI1_Followers_Mean_Sort_Values_Followers_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Followers - Grouped')
plt.ioff()
# plt.plot(smi1_followers_mean.describe())
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_168_SMI1_Followers_Mean_Sort_Values_Followers_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO BOX PLOT


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Followers Grouped - Pie')
plt.ioff()
# plt.pie(smi1_followers_mean.describe(), labels=smi1_languages.describe(), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_followers_mean.describe(), bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_168_SMI1_followers_Mean_Sort_Values_Followers_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# BAR PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Followers Average Points Among Total Tweets - Bars')
plt.ioff()
# smi1_followers_mean.describe().plot.bar(alpha=0.9)
plt.xlabel('followers')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_168_SMI1_followers_Mean_Sort_Values_followers_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#########################################################################################################################################################

# Number of tweets_words in text

number_of_tweets_words = len(smi1_tweets_text_words_fdist)
number_of_tweets_words

print('---')
print('Number of tweets_words Analyzed : No Stop Words')
print(number_of_tweets_words)
print('---')

number_of_tweets_words_df = pd.DataFrame([number_of_tweets_words])

number_of_tweets_words_df.to_csv('4_5A_169_SMI1_Number_of_Tweets_Words_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# number_of_tweets_words_df.to_excel('4_5A_169_SMI1_Number_of_Tweets_Words_DF.xlsx, header=True)

# PLOT TABLE plt.plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Text')
plt.ioff()
# plt.plot(number_of_tweets_words_df.describe(), alpha=0.9)
# plt.plot(number_of_tweets_words_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_169_SMI1_Number_of_Tweets_Words_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO DO BOX PLOT


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Text - Pie')
plt.ioff()
# plt.pie(number_of_tweets_words_df[:6], labels=number_of_tweets_words_df, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(number_of_tweets_words_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_169_SMI1_Number_of_Tweets_Words_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO


###################################################################################################################

# STATISTICS DF # NEED TO DO 

# initialize list of Lists 

# quant_stats_1_pairs = [['Mean followers', median_followers, 'Median followers', median_followers, 'Mode followers', mode_followers, 'Mode followers', mode_followers], ['Variance followers', variance_followers, 'Variance followers', variance_followers, 'Population Variance followers', pvariance_followers, 'Population Variance followers', pvariance_followers, 'Standard Deviation followers', stdev_followers, 'Population Standard Deviation followers', pstdev_followers, 'Population Standard Deviation followers', pstdev_followers, 'Skewness followers', skewness_followers, 'Skewness followers', skewness_followers, 'Percentiles followers (25, 50, 75)', quantiles_followers, 'Percentiles Followers (25, 50, 75)', quantiles_followers, 'Ranges followers', ptp_followers, 'Ranges followers', ptp_followers, 'Correlation Coefficient - Pearson Regression', corr_coef_total_favorites_followers_pearson, 'Linear Regession', r_linar_reg],['Number of Tweets Analyzed', number_tweets, 'Number of Unique Tweets Analyzed', number_unique_tweets, 'Number of tweets_words in Text', number_of_tweets_words, 'List Unique Followers ReTweeting, Commenting, Engaged', number_unique_engaged_users, 'Number of Users Who  Are Followers', number_unique_tweets_with_followers, 'Number of Unique Tweets with followers', 'number_unique_followers_users', 'List Unique Hashtags', 'number_unique_hashtags', 'List Unique Mentions', 'number_unique_mentions', 'List Unique Emojis Unicode', 'number_unique_emojis_unicode', 'List Unique Emojis Converted', 'number_unique_emojis_converted', 'List Unique Language', 'number_unique_languages', 'Summary Statistics All total_favorites / Desc', 'summ_stats_all_total_favorites_desc', 'Summary Statistics All Followers / Desc', 'summ_stats_all_followers_desc']]

# Create the pandas DataFrame 
# quant_stats_measures_1 = pd.DataFrame(quant_stats_1_pairs, columns = ['Measures of Centrality', 'Measures of Variability', 'General User Stats', 'Other Stats']) 

# quant_stats_measures_1.to_csv('4_5A_170_SMI1_Quant_Stats_Measures_Followers_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# quant_stats_measures_1.to_excel('4_5A_170_SMI1_Quant_Stats_Measures_Followers.xlsx', header=True)

### NEED TO DO PLOT?????????????????

############################################################################################################

############################################################################################################

print('---')
print('Loading Libs 44')
print('---')

### FROM tweets_words ABOVE

fdist_2 = FreqDist(word)
# print(fdist_2)

fdist_2.most_common(10)

print('---')
print('Frequency Distribution of Tweets_words - Most Common 10')
print(fdist_2.most_common(10))
print('---')

df_fdist_2_df = pd.DataFrame([fdist_2])

df_fdist_2_df.to_csv('4_5A_171_SMI1_Word_Freq_Dist_CSV.csv', sep=';', encoding='utf-8', index=True)
# df_fdist_2_df.to_excel('4_5A_171_SMI1_Word_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# NEED TO DO - TABLE PLOT 

# PLOT

# Frequency Distribution Plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Frequency Distribution of Words')
plt.ioff()
# fdist_2[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_171_SMI1_Word_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Word Frequency Distribution - Box')
plt.ioff()
# plt.plot(FreqDist(word))
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_171_SMI1_Word_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Word Frequency Distribution - Pie')
plt.ioff()
# plt.pie(FreqDist(word)[:6], labels=FreqDist(word), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(FreqDist(word), bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_171_SMI1_Word_Freq_Dist_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

###############################################################################################################


# Summary Statistics of all screenNames          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_screenname = tweets_smi_1['screenName'].describe()

print('---')
print('Summary Statistics of All ScreenNames')
print(tweets_smi_1['screenName'].describe().head)
print('---')

smi1_screenname_describe_df = pd.DataFrame(smi1_screenname)

smi1_screenname_describe_df.to_csv('4_5A_172_SMI1_Screenname_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot NEED TO DO

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All ScreenNames')
plt.ioff()
plt.plot(tweets_smi_1['hashtags'].describe())
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_172_SMI1_ScreenName_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# PIE PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All ScreenNames - Pie')
plt.ioff()
# plt.pie(tweets_smi_1['hashtags'].describe(), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweets_smi_1['hashtags'].describe(), bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)
# plt.legend(smi1_hashtags, loc=3)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_172_SMI1_ScreenName_Describe_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

##########################################################################################################

# Summary Statistics of all Text          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_text = tweets_smi_1['text'].describe()

print('---')
print('Summary Statistics of All Text')
print(smi1_text.describe().head)
print('---')

smi1_text_describe_df = pd.DataFrame(smi1_text)

smi1_text_describe_df.to_csv('4_5A_173_SM1_Text_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot NEED TO DO

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Text')
plt.ioff()
# plt.plot(smi1_hashtags.describe())
# plt.plot(smi1_text_describe_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_173_SMI1_Text_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO

############################################################################################################
############################################################################################################

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO


########################################################################################################

# PERCENTAGE OF Tweets WITH followers

percentage_tweets_followers = (tweets_smi_1['followers'].value_counts(normalize=True) * 100)

print('---')
print('Percentage of Tweets with Followers ')
# print(percentage_tweets_followers)
print('---')

percentage_tweets_followers_df = pd.DataFrame(percentage_tweets_followers)

percentage_tweets_followers_df.to_csv('4_5A_158_SMI1_Percentage_Tweets_followers_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Followers - Pie')
plt.ioff()
# plt.pie(percentage_tweets_followers[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.pie(percentage_tweets_followers[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(percentage_tweets_followers, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5A_158_SMI1_Percentage_Tweets_Followers_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO

########################################################################################################
########################################################################################################

# PLOT PERCENTAGES MEASURES total_favorites, followers, MENTIONS, HASHTAGS, EMOJIS, IMAGE_LINKLANGUAGES   ### NEED TO DO

# List of List  ########## NEED TO DO DATAFRAME

percentages_of_measures_df = pd.DataFrame(percentages_of_measures)

print('---')
print('Percentage of Measures')
# print('percentages_of_measures')
print('---')


percentages_of_measures_df.to.csv('4_5A_164_SMI1_Percentages_of_Measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentages of Measures - Pie')
plt.ioff()
# plt.pie(percentages_total_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentages_of_measures_df[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(percentages_of_measures_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_164_SMI1_Percentages_of_Measures_df_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO

################################################ NEED TO DO TABLE WITH COUNTS AND PERCENTAGES OF THE ABOVE!!!!!!

# _df _df = pd.DataFrame()

# .to_csv('4_5A_.csv', sep=';', encoding='utf-8', index=True)
# excel

############################################################################################################

# https://matplotlib.org/3.1.1/gallery/pie_and_polar_chafollowers/pie_and_donut_labels.html#sphx-glr-gallery-pie-and-polar-chafollowers-pie-and-donut-labels-py
# https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplt.pie.html

##############################################################################################################

# XXX TIME FAVORITES TOTAL FAVORITES FIX 

# PIE CHART : PERCENTAGE OF total_favorites / Top

percentages_total_favorites_tweets = tweets_smi_1['favorites'].size().sort_values(ascending=False)

print('--')
print('Percentage of total_favorites Tweets')
# print(percentages_total_favorites_tweets)
print('--')

percentages_total_favorites_tweets_df = pd.DataFrame(percentages_total_favorites_tweets)

percentages_total_favorites_tweets_df.to_csv('4_5A_165_SMI1_Percentages_Total_Favorites_Tweets_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# to_excel()

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Favorites - Pie')
plt.ioff()
# plt.pie(percentages_total_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentages_total_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(percentages_total_favorites_tweets, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_165_SMI1_Percentages_Total_Favorites_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

####################################################################################################################

# https://plot.ly/python/pie-chafollowers/

# PIE CHART : PERCENTAGE OF Followers / Top

percentages_followers_tweets = tweets_smi_1['followers'].size().sort_values(ascending=False)


print('--')
print('Percentage of Followers - Top')
# print(smi1_followers.size().sort_values(ascending=False))
print('--')

percentages_followers_tweets_df = pd.DataFrame(percentages_followers_tweets)

percentages_followers_tweets_df.to_csv('4_5A_167_SMI1_Percentages_Followers_Tweets_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# to_excel()

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Followers - Pie')
plt.ioff()
# plt.pie(percentages_followers_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentages_followers_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(percentages_followers_tweets, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_167_SMI1_Percentage_followers_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO


####################################################################################################################
########################################################################################################
########################################################################################################
########################################################################################################

# BAR PLOTS

# Prepare the data

tweets_lists = tweets_smi_1['lists']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Lists / Time - Bars')
plt.ioff()
plt.plot(created, tweets_lists, label='linear')
# smi1_lists.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_176_SMI1_lists_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


########################################################################################################

# BAR PLOTS

# followers


# Prepare the data
tweets_followers = tweets_smi_1.loc['followers']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Followers / Time - Bars')
plt.ioff()
plt.plot(created,  tweets_followers, label='linear')
# tweets_followers.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_177_SMI1_Followers_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

########################################################################################################
########################################################################################################

# LINE PLOTS

# Number of Followers / total_favorites

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Followers / Favorites')
plt.ioff()

# Plot with differently-colored markers.
plt.plot(created, tweets_followers, 'b-', label='followers')
plt.plot(created, total_tweets_total_favorites, 'r-', label='total_favorites')

# Create legend.
# plt.legend(loc='upper left')
plt.xlabel('Year')
plt.ylabel('Followers / Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_180_SMI1_Followers_VS_Total_Favorites_Time_Line_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################################################################

# LINE PLOTS

# Number of Followers / retweets

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Followers / Retweets')
plt.ioff()

# Plot with differently-colored markers.
plt.plot(created, tweets_followers, 'b-', label='followers')
plt.plot(created, total_tweets_retweets, 'r-', label='retweets')

# Create legend.
# plt.legend(loc='upper left')
plt.xlabel('Year')
plt.ylabel('Followers / Retweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_180_SMI1_Followers_VS_Total_Retweets_Time_Line_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################
####################################################################################################################


# # https://www.datacamp.com/community/tutorials/wordcloud-python

# BAR PLOT

# Number of Followers of Tweets

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Followers - Bars')
plt.ioff()
smi1_followers.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Followers')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
ax.grid(True)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_182_SMI1_Number_Followers_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################


###############################################################################################################
#
#                        TIME SERIES ###################### NEED TO DO!!!!!!!!!!!
#
###############################################################################################################

# SNS PAIR PLOTS

# MULTIVARIABLE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Correlations Between Variable / Years')
plt.ioff()
sns.pairplot(tweets_smi_1, x_vars = ['favorites', 'retweets', 'is_quote', 'is_retweet', 'is_retweet', 'quote_count', 'reply_count', 'followers_count', 'friends_count', 'is_friend', 'is_follower', 'network_weight', 'number_total_hashtags', 'number_total_mentions', 'number_total_emojis_unicode'], y_vars = ['favorites', 'retweets', 'is_quote', 'is_retweet', 'is_retweet', 'quote_count', 'reply_count', 'followers_count', 'friends_count', 'is_friend', 'is_follower', 'network_weight', 'number_total_hashtags', 'number_total_mentions', 'number_total_emojis_unicode'], hue='year', kind='scatter')
# ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Time_Series_All_Tweets_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('----------')
print('TEXT HEAD D')
print(tweets_smi_1['text'].head)
print('-----------------------------------')

#########################################################################

# DIMENSIONALITY REDUCTION

# In order 

#########################################################################

sns.set()

# TIME SERIES 

# total_favorites_created_df = tweets_smi_1['created']

# total_favorites_created_df.month = pd.to_datetime(total_favorites_created_df.month)

# total_favorites_created_df.set_index('month', inplace=True)

## 22/09/2014 08:36:00

# tweets_smi_1['created'] = pd.to_datetime(tweets_smi_1['created'])

# TWEETS OVER TIME

print('NEED TWEETS OVER TIME HEREEEEEEEEEEEEEEEEEEEEEE')

# ALL TWEETS OVER TIME

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Time Series: All Tweets - Year')
plt.ioff()
tweets_smi_1.groupby(['created']).sum(['single_tweet']).plot(alpha=0.9)
ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Time_Series_All_Tweets_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# SMI TWEETS PLOT NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Time Series: All Tweets - Year')
plt.ioff()
tweets_smi_1.groupby(['created'])['total_tweets'].plot(alpha=0.9)
ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Time_Series_TOTAL_Tweets_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()
 
# FAVORITES PLOT NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Time Series: All Favorites - Year')
plt.ioff()
# tweets_smi_1['favorites'].sum().plot_date(alpha=0.9)
tweets_smi_1.groupby(['created']).sum(['favorites']).plot(alpha=0.9)
ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Time_Series_All_Favorites_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# RETWEETS PLOT NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Time Series: All Retweets - Year')
plt.ioff()
# tweets_smi_1['favorites'].sum().plot_date(alpha=0.9)
tweets_smi_1.groupby(['created']).sum(['retweets']).plot(alpha=0.9)
ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Time_Series_All_Retweets_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# FOLLOWERS PLOT NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Time Series: All Retweets - Year')
plt.ioff()
# tweets_smi_1['favorites'].sum().plot_date(alpha=0.9)
tweets_smi_1.groupby(['screenName' == main_smi]).sum(['followers_count']).plot(alpha=0.9)
ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Time_Series_MAIN_SMI_Followers_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

######################################################################################
# https://towardsdatascience.com/an-end-to-end-project-on-total_favorites-series-analysis-and-forecasting-with-python-4835e6bf050b
# https://pythonplot.com/

# TWEETS YEAR CUM SUM 

smi1_year_tweets_counts = tweets_smi_1.groupby('year')['single_tweet'].count()

smi1_year_tweets_counts_df = pd.DataFrame([smi1_year_tweets_counts])

smi1_year_tweets_counts_df.to_csv('4_5_185_SMI1_Year_Tweets_Counts_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_year_tweets_counts_df.to_excel('4_5_185_SMI1_Year_Tweets_Counts_DF.xlsx', header='frequency_distribution') # Only argument is a string of the output file path


# PLOT TABLE NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets Counts per Year')
plt.ioff()
# tweets_smi_1.set_index('created')['single_tweet']
# smi1_year_tweets_counts.set_indexbar('created').plot(cumulative=False, color='#6593F5', edgecolor='white', label=' ', alpha=0.9) 
smi1_year_tweets_counts.plot(alpha=0.9)  ########### NEED TO FIX -SHOWING FEW
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_185_SMI1_Tweets_Counts_Cum_Sum_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets Counts / Year - Cum Sum')
plt.ioff()
# tweets_smi_1.set_index('created')['single_tweet']
# smi1_year_tweets_counts.set_indexbar('created').plot(kind='bar', edgecolor='white', label=' ', alpha=0.9)
smi1_year_tweets_counts.plot(alpha=0.9)  ########### NEED TO FIX -SHOWING FEW
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_185_SMI1_Tweets_counts_cum_sum_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###########

# FAVORITES CUM SUM YEAR 

smi1_year_favorites_counts = tweets_smi_1.groupby('year')['favorites'].count()

smi1_year_favorites_counts_df = pd.DataFrame([smi1_year_favorites_counts])

smi1_year_tweets_counts_df.to_csv('4_5_185_SMI1_Year_Tweets_Counts_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_year_tweets_counts_df.to_excel('4_5_185_SMI1_Year_Tweets_Counts_DF.xlsx', header='frequency_distribution') # Only argument is a string of the output file path


# BARS PLOT Tweets OVER TIME NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites Over Time - Cum Sum - Bars')
plt.ioff()
# smi1_year_favorites_counts_df.plot(kind='bar', edgecolor='white', label=' ', colors=colors_blue, alpha=0.9)
tweets_smi_1.groupby('year')['favorites'].count().plot(kind='bar', edgecolor='white', label=' ', colors=colors_blue, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Favorites_Time_Cum_Sum_Year_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###########

# retweets CUM SUM YEAR 

smi1_year_retweets_counts = tweets_smi_1.groupby('year')['retweets'].count()

smi1_year_retweets_counts_df = pd.DataFrame([smi1_year_retweets_counts])

smi1_year_tweets_counts_df.to_csv('4_5_185_SMI1_Year_tweets_counts_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_year_tweets_counts_df.to_excel('4_5_185_SMI1_Year_tweets_counts_DF.xlsx', header='frequency_distribution') # Only argument is a string of the output file path


# BARS PLOT Tweets OVER TIME NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Retweets / Time Cum. Sum. - Bars')
plt.ioff()
smi1_year_retweets_counts_df.plot(kind='bar', edgecolor='white', label=' ', alpha=0.9)
tweets_smi_1.groupby('year')['retweets'].count().plot(kind='bar', edgecolor='white', label=' ', colors=colors_blue, alpha=0.9) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Retweets_Time_Cum_Sum_Year_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('----------')
print('TEXT HEAD B')
print(tweets_smi_1['text'].head)
print('-----------------------------------')



#############################################################################################

# BARS PLOT Tweets OVER TIME NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets Over Time')
plt.ioff()
smi1_year_tweets_counts.plot(kind='bar', edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Tweets_Time_All_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT Favorites OVER TIME NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['favorites'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Favorites_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites Over Time - Bars')
plt.ioff()
tweets_smi_1.set_index('created')['favorites'].plot(kind='bar', edgecolor='white', label=' ', alpha=0.9) # color='#73C2FB',
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Favorites_Time_All_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################

# Retweets OVER TIME

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Retweets Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['retweets'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_185_SMI1_Retweets_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Retweets Over Time')
plt.ioff()
# tweets_smi_1.set_indexbar('created')['retweets'].plot(kind='bar', edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Retweets_Time_All_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Favorites / Retweets OVER TIME #################################### NEED TO DO!!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# color='#6593F5', #73C2FB

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites / Retweets Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['favorites'].plot(color='lightskyblue', alpha=0.9)
tweets_smi_1.set_index('created')['retweets'].plot(color='blue', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_186_SMI1_Favorites_Retweets_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# plt.rcdefaults()                 
fig, ax = plt.subplots()
plt.ioff()

# #73C2FB', '#6593F5'

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites / Retweets Over Time - Bars')
plt.ioff()
tweets_smi_1.set_index('created')['favorites'].plot(kind='bar', color='#73C2FB', edgecolor='white', label=' ', alpha=0.9)
tweets_smi_1.set_index('created')['retweets'].plot(kind='bar', color='#6593F5', edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_186_SMI1_Favorites_Retweets_Time_All_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Tweets Favorites / Retweets OVER TIME #################################### NEED TO DO!!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets / Favorites / Retweets Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['single_tweet'].plot(color='lightskyblue', alpha=0.9)
tweets_smi_1.set_index('created')['favorites'].plot(color='blue', alpha=0.9)
tweets_smi_1.set_index('created')['retweets'].plot(color='purple', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_186_SMI1_Tweets_Favorites_Retweets_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets / Favorites / Retweets Over Time - Bars')
plt.ioff()
tweets_smi_1.set_index('created')['single_tweet'].plot(kind='bar', color='#73C2FB', edgecolor='white', label=' ', alpha=0.9)
tweets_smi_1.set_index('created')['favorites'].plot(kind='bar', color='#6593F5', edgecolor='white', label=' ', alpha=0.9)
tweets_smi_1.set_index('created')['retweets'].plot(kind='bar', color='blue', edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_186_SMI1_Tweets_Favorites_Retweets_Time_All_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##########################################################################################

# PLOT Favorites / Retweets OVER TIME #################################### NEED TO DO!!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Followers / Following / Favorites Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['followers'].plot(color='blue', alpha=0.9)
tweets_smi_1.set_index('created')['favorites'].plot(color='lightskyblue', alpha=0.9)
tweets_smi_1.set_index('created')['following'].plot(color='purple', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_186_SMI1_Followers_Following_Favorites_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('----------')
print('TEXT HEAD DE')
print(tweets_smi_1['text'].head)
print('-----------------------------------')

#######################################################################################################################

# https://towardsdatascience.com/an-end-to-end-project-on-total_favorites-series-analysis-and-forecasting-with-python-4835e6bf050b
# https://pythonplot.com/

# PLOT Mentions OVER TIME NEED TO DO ## NEED TO BE ABLE TO SPLIT MENTIONS AND COUNT THEM / ALSO GRPOUP MONTHS AND YEARS

def count_items_list(x):
	for x in list:
		count_items = x + 1
	yield emoji

tweets_smi_1['tweet_mentions_number'] = tweets_smi_1['mentions'].str.len()
# tweets_smi_1['tweet_mentions_number'] = tweets_smi_1['tweet_mentions_number'].fillna(0)

print('---')
print('Mentions Head')
print(tweets_smi_1['mentions'].head(20))
print('---')

print('---')
print('Number Mentions Head')
print(tweets_smi_1['tweet_mentions_number'].head(20))
print('---')

tweets_smi_1['number_mentions'] = sum(tweets_smi_1['tweet_mentions_number'])
tweets_smi_1['number_mentions']


print('---')
print('Number Mentions Head')
print(tweets_smi_1['number_mentions'].head)
print('---')

##### tweets_smi_1.to_csv('4_5_187_SMI1_DF_CSV.csv', sep='\t', encoding='utf-8', index=True) # MAKES HUGE FILE =(
# tweets_smi_1.to_excel('4_5_187_SMI1_DF_CSV.csv', header=True)

## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Total Mentions Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['number_mentions'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_187_SMI1_Total_Mentions_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Total Mentions Over Time - Bars')
plt.ioff()
tweets_smi_1.set_index('created')['number_mentions'].plot(kind='bar', edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_187_SMI1_Total_Mentions_Time_All_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###################################################

# SUMM OF MENTIONS - METHOD 2

# tweets_dates_1['number_total_mentions'] = tweets_smi_1.groupby('created').sum()
# tweets_dates_1['number_total_mentions']

tweets_smi_1['number_total_mentions'] = len(tweets_smi_1['mentions'])
tweets_smi_1['number_total_mentions']

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Total Mentions Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['number_total_mentions'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_187_SMI1_Number_Total_Mentions_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Total Mentions Over Time - Bars')
plt.ioff()
tweets_smi_1.set_index('created')['number_total_mentions'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_187_SMI1_Number_Total_Mentions_Time_All_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PLOT Hashtags OVER TIME NEED TO DO ## NEED TO BE ABLE TO SPLIT MENTIONS AND COUNT THEM / ALSO GRPOUP MONTHS AND YEARS

## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['number_total_hashtags'] = len(tweets_smi_1['hashtags'])
tweets_smi_1['number_total_hashtags']

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Total Hashtags Over Time')
plt.ioff()
# tweets_smi_1.set_index('created')['number_total_hashtags'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_188_SMI1_Total_Hashtags_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Total Mentions / Hashtags OVER TIME #################################### NEED TO DO!!!!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Total Mentions / Hashtags Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['number_total_mentions'].plot(alpha=0.9)
tweets_smi_1.set_index('created')['number_total_hashtags'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_189_SMI1_Total_Mentions_Hashtags_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

# https://towardsdatascience.com/an-end-to-end-project-on-total_favorites-series-analysis-and-forecasting-with-python-4835e6bf050b
# https://pythonplot.com/

# PLOT Emojis_converted OVER TIME NEED TO DO ## NEED TO BE ABLE TO SPLIT MENTIONS AND COUNT THEM / ALSO GRPOUP MONTHS AND YEARS

## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['number_total_emojis_converted'] = len(tweets_smi_1['emojis_converted'])
tweets_smi_1['number_total_emojis_converted']

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Total Emojis_converted Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['number_total_emojis_converted'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_190_SMI1_Total_Emojis_converted_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################

# PLOT Languages OVER TIME NEED TO DO ## NEED TO BE ABLE TO SPLIT MENTIONS AND COUNT THEM / ALSO GRPOUP MONTHS AND YEARS

## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['number_total_screenName'] = len(tweets_smi_1['screenName'])
tweets_smi_1['number_total_screenName']

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Total screeNames Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['number_total_screenName'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_191_SMI1_Total_screenNames_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


################################################################

# PLOT Languages OVER TIME NEED TO DO ## NEED TO BE ABLE TO SPLIT MENTIONS AND COUNT THEM / ALSO GRPOUP MONTHS AND YEARS


## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['number_total_language'] = len(tweets_smi_1['language'])
tweets_smi_1['number_total_language']

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Total Languages Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['number_total_language'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_191_SMI1_Total_Languages_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Emojis / Languages OVER TIME #################################### NEED TO DO!!!!!!!!!!

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Total Emojis / Languages Over Time')
plt.ioff()
# tweets_smi_1.set_index('created')['number_total_emojis'].plot(alpha=0.9)
# tweets_smi_1.set_index('created')['number_total_language'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_192_SMI1_Total_Emojis_Languages_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### NEED TO DO FOR SMI VS AUDIENCE!!!!!!!!!!!!!

############################################################################################################
############################################################################################################

# This selects the Top 5 highest average points among all Tweets:

# smi1_created.mean().sort_values(by='created',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 highest Created average points - Tweets:')
# print('smi1_created.mean().sort_values(by='created',ascending=True).head()')
print('---')

# XXX 

# smi1_created_mean_sort_values_created = pd.DataFrame(smi1_created.mean().sort_values(by='created',ascending=True))

# smi1_created_mean_sort_values_created.to_csv('4_5_194_SMI1_Created_Mean_Sort_Values_Created_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_created_mean_sort_values_created.to_excel('4_5_194_SMI1_Created_Mean_Sort_Values_Created_CSV.csv', sep='\t', encoding='utf-8', index=True)


################################################################################

# Stratification Plot

# Another way to get more information out of a dataset is to divide it into smaller, more uniform subsets, and analyze each of these �strata� on its own. We will create a new HouseAge column, then partition the data into HouseAge strata, and construct side-by-side boxplots of the sale price within each stratum.

# tweets_smi_1.set['YearP'] = 2020 - tweets_smi_1.set['created']

# tweets_smi_1.set["YearGrp"] = pd.cut(tweets_smi_1.set.YearP, [2005, 2010, 2015, 2020]) # Create age strata based on these cut points

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Stratification Plot for Changes in Favorites / Year')
plt.ioff()
# sns.boxplot(x="year", y='favorites', data='tweets_smi_1')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_196_SMI1_Strats_Favorites_Year.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################################################################################################################

# Stratification Plot

# Another way to get more information out of a dataset is to divide it into smaller, more uniform subsets, and analyze each of these �strata� on its own. We will create a new HouseAge column, then partition the data into HouseAge strata, and construct side-by-side boxplots of the sale price within each stratum.

# tweets_smi_1.set['year'] = 2020 - tweets_smi_1.set['year']
# tweets_smi_1.set["YearGrp"] = pd.cut(tweets_smi_1.set.YearP, [2005, 2010, 2015, 2020]) # Create age strata based on these cut points

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Stratification Plot for Changes in Retweets / Year - Box')
plt.ioff()
# ns.boxplot(x="year", y='retweets', data='tweets_smi_1')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_196_SMI1_Strats_Retweets_Time_Box_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('------------------')
print('TEXT HEAD 1C')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')

###############################################################################################################
###############################################################################################################
#
#                               TEXTUAL ANALYTICS
#
###############################################################################################################
###############################################################################################################

print('---')
print('Loading Libs 46')
print('---')

# Word Frequency Distribution


# TURN COLLUMS TO STRING 

# tweets_smi_1['screenName'] = tweets_smi_1['screenName'].pd.to_string()
# tweets_smi_1['author_id'] = tweets_smi_1['author_id'].to_numeric(, errors='ignore')
# tweets_smi_1['created'] = tweets_smi_1['created'].to_datetime()
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].to_numeric(, errors='ignore')
# tweets_smi_1['favorites'] = tweets_smi_1['favorites'].to_numeric(, errors='ignore')
# tweets_smi_1['text'] = tweets_smi_1['text'].to_string()
# tweets_smi_1['latitude'] = tweets_smi_1['latitude'].to_string()      ########################## NEED TO CHECK PLACES OR GEO LOCATION!!!!!!
# tweets_smi_1['longitude'] = tweets_smi_1['longitude'].to_numeric(, errors='ignore')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].to_string()
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].to_string()
# tweets_smi_1['id'] = tweets_smi_1['id'].to_numeric(, errors='ignore')
# tweets_smi_1['url'] = tweets_smi_1['url'].to_string()
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].to_string()
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].to_string()
# tweets_smi_1['image_link'] = tweets_smi_1['image_link'].to_string()
# tweets_smi_1['language'] = tweets_smi_1['language'].to_string()

print('---')
print('DataFrame Types')
# print(tweets_smi_1.dtypes)
print('---')

print('---')
print('DataFrame Types')
# print(tweets_smi_1.dtypes)
print('---')


# tweets_smi_1['screenName'].pd.astype('str').dtypes
# tweets_smi_1['created'] = tweets_smi_1['created'].to_datetime()
# tweets_smi_1['text'].astype('str').dtypes
# tweets_smi_1['latitude'] = tweets_smi_1['latitude'].to_string()      ########################## NEED TO CHECK PLACES OR GEO LOCATION!!!!!!
# tweets_smi_1['longitude'] = tweets_smi_1['longitude'].to_numeric(, errors='ignore')
# tweets_smi_1['hashtags'].pd.astype('str').dtypes
# tweets_smi_1['mentions'].pd.astype('str').dtypes
# tweets_smi_1['url'].pd.astype('str').dtypes
# tweets_smi_1['emojis_unicode'].pd.astype('str').dtypes
# tweets_smi_1['emojis_converted'].astype('str').dtypes
# tweets_smi_1['image_link'].pd.astype('str').dtypes
# tweets_smi_1['language'].pd.astype('str').dtypes

#########################################################

# TURN COLLUMS TO STRING 

# TEXTUAL ANALYSICS

# https://www.strehle.de/tim/weblog/archives/2015/09/03/1569

# WORD FREQUENCY DISTRIBUTION IN TEXT OF Tweets


# fp_text = tweets_smi_1['text'].astype(str, errors='ignore')
# fp_text['tweet_text_fp_text'] = pd.DataFrame(tweets_smi_1['text'].astype(str, errors='ignore'))
# fp_text = tweets_smi_1.text.astype(str, errors='ignore')

fp_text_temp = tweets_smi_1['text']
fp_text = fp_text_temp.to_string()
fp_text_c = fp_text ### OJO QIE ESTA SIN ARREGLAR EL C

print('---')
print('DataFrame Types fp_text')
# print(fp_text.dtypes)
print('---')

# f_text = fp_text

# f_text = data_f.decode('utf-8') # Unicode not bytes

print('---')
# print(f_text)
print('---')

# fp_text = f_text

print('---')
print('Tweets Text First 10')
print(tweets_smi_1['text'].head(10))
print('---')

#######################################################################################

# CORRECT SPELLING


textblob_obj_text_c = TextBlob(fp_text) ## OJO QUE SI ES EL CORREGIDO O NO

#########   textblob_obj_text_c = textblob_obj_text.correct() ## NEED TO CHECK HOW IT WORKS!!!!
# textblob_obj_text_c = textblob_obj_text

textblob_obj_text_c_df = pd.DataFrame(textblob_obj_text_c)

print('--')
print('textblob_obj_text_C_DF TYPE:')
# print(textblob_obj_text_c)
print('--')

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

# textblob_obj_text_c_df.to_csv('4_5_184_SMI1_Textblob_Cbj_C_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# textblob_obj_text_c_df.to_excel('4_5_184_SMI1_Textblob_Cbj_C_DF.xlsx', header=True)

# fp_text_c = textblob_obj_text_c.to_string()

# fp_text_c = textblob_obj_text_c

#######################################################################################

# tweets_text_words = nltk.word_tokenize(pd.to_string(fp_text_c))
# tweets_text_words = nltk.word_tokenize(fp_text_c['tweet_text_fp_text_c'])
tweets_text_words = nltk.word_tokenize(fp_text_c)
tweets_text_words_df = pd.DataFrame(tweets_text_words)

# tweets_text_words = nltk.word_tokenize((tweets_smi_1['text']).pd.to_string())
# tweets_text_words = tweets_smi_1['text']).nltk.word_tokenize()

print('--')
print('Tokenized tweets_words')
print(tweets_text_words_df.head(10))
print('--')


print('--')
print('Tokenized tweets_words Shape')
print(tweets_text_words_df.shape)
print('--')

print('--')
print('Tokenized tweets_words Info')
print(tweets_text_words_df.info)
print('--')

# Remove single-character tokens (mostly punctuation) ######## NEED TO DO FIX 
# tweets_text_words = [word for word in tweets_text_words if len(word) > 1]

# Remove numbers ######## NEED TO DO FIX
# tweets_text_words = [word for word in tweets_text_words if not word.isnumeric()]

# Lowercase all tweets_words (default_stoptweets_words are lowercase too) ######## NEED TO DO FIX
# tweets_text_words = [word.lower() for word in tweets_text_words]

# Stemming tweets_words seems to make matters worse, disabled
# stemmer = nltk.stem.snowball.SnowballStemmer('english')
# tweets_text_words = [stemmer.stem(word) for word in tweets_text_words]

# Remove stoptweets_words          ################################################################
# tweets_text_words = [word for word in tweets_text_words if word not in stoptweets_words]

# print('removed stoptweets_words')


##################################################################################################################

# FINDING N-GRAMS

# N-Grams refer to n combination of words in a sentence. For instance, for a sentence "I love watching football", some 2-grams would 
# be (I love), (love watching) and (watching football). N-Grams can play a cricual role in Text classification. 

for ngram_bigrams_text in textblob_obj_text_c.ngrams(2):
#	print('-------------------------')
	print('N-Grams text: 2')
#	print(ngram_bigrams_text)
#	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_bigrams_text = pd.DataFrame(ngram_bigrams_text)

ngram_bigrams_text.to_csv('4_5_210_SMI1_Ngram_Bigrams_Text_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# ngram_bigrams_text.to_csv('4_5_210_SMI1_Ngram_Bigrams_Text_TEXT.txt', sep='\t', encoding='utf-8', index=False, header=True)

########################################################################################################

# earthdatascience.og/courses/earth-analysis-python/using-apis-natural-language-processing-twitter/calculate-tweet-word-bigrams-networks-in-python/

# VISUALIZATION OF BIGRAMS

# Create a list of Lists containing bigrams in tweets

bigrams_text_terms = list(bigrams(fp_text))

bigrams_text = list(itertools.chain(*bigrams_text_terms))

# Create counter of words in bigrams

# bigrams_text_counts = collections.Counter(bigrams_text)

bigrams_text_counts = pd.value_counts(bigrams_text, ascending=False, normalize=True)

bigrams_text_counts = bigrams_text_counts.sort_values(ascending=False)

bigrams_text_counts = bigrams_text_counts.astype(str, errors='ignore').apply(lambda x: x.str.split(' '))

print('---')
print('bigrams_text_counts DF SEPERATED ')
print(bigrams_text_counts.head)
print('---')

print('---')
print('bigrams_text_counts DF SEPERATED ')
print(bigrams_text_counts.dtypes)
print('---')

print('---')
print('bigrams_text_counts DF SEPERATED ')
print(bigrams_text_counts.shape)
print('---')

# bigram_text_df = pd.DataFrame(bigrams_text_counts, columns=['bigrams_text', 'bigrams_counts'])
bigram_text_df = pd.DataFrame([bigrams_text_counts])

bigram_text_df.to_csv('4_5_210_SMI1_Bigram_Text_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# bigram_text_df.to_excel('4_5_210_SMI1_Bigram_Text_df_DF.xlsx', header=True)


#######################################################################################################

# developer.ibm.com/technologies/artificial-intelligence/articles/cc-patterns-artificial-intelligence-part2/

# def countngrams(inputfp, frequencies, order, buffersize=1024):
# 	'''Read the Text content of a file and keep a running count of how oftern each bigram (sequence of two) characters appears.
# 
# 	Arguments:
# 		input_fp -- fine pointer with input text
# 		frequencies -- mapping from each bigram to its counted frequency
# 		buffer_size -- incremental quantity of Text to be read at a total_favorites, in bytes (1024 if not otherwise specified)
# 
# 	Returns:
#	nothing
# 	'''
# 	# Read the first chunk of text, and set all letters to lowercase
# 	# Text = input_fp.read(buffer_size).lower()
# 	text = input_fp
# 	# Loop over the file while there is Text to read
# 	While text:
# 		# This step is needed to collapse rins of space characters into one
# 		text = ' '.join(text.str.split())
# 		spans = TOKENIZER.span_tokenize(text)
# 		tokens = (text[begin : end] for (begin, end) in spans)
# 		for bigram in ngrams(tokens, order):
# 			# Increment the count for the bigram. Automatically handles any bigram not seen before. 
# 			# The join expression turns 2-character string
# 			frequencies[''.join(bigram)] += 1
# 		# Read the next chunk of text, and set all letters to lowercase
# 		# Text = input_fp.read(buffer_size).lower()
# 		text = input_fp
# 
# 	yield
#	
######################################################################################################################
############################################################################################################

# WORD FREQUENCY DISTRIBUTION IN Hashtags OF Tweets

fp_hashtags_temp = tweets_smi_1['hashtags']
fp_hashtags = fp_hashtags_temp.to_string()
fp_hashtags_c = fp_hashtags ### OJO QUE ESTA SIN ARREGLAR EL C

print('---')
print('DataFrame Types fp_hashtags')
# print(fp_hashtags.dtypes)
print('---')


# fp_hashtags = pd.DataFrame(fp_hashtags)

# fp_hashtags = open(smi_file_4_4_hashtags_only, encoding='utf-8')
# f_hashtags = fp_hashtags.read() # As bytes

# data_f = fp_hashtags.read() # As bytes

# f_hashtags = fp_hashtags

# f_hashtags = data_f.decode('utf-8') # Unicode not bytes

print('---')
# print(f_hashtags)
print('---')

# fp_hashtags = f_hashtags

print('---')
print('Tweets hashtags First 10')
print(tweets_smi_1['hashtags'].head(10))
print('---')


#################################################################################

# CORRECT SPELLING


hashtagsblob_obj_hashtags_c = TextBlob(fp_hashtags) ## OJO QUE SI ES EL CORREGIDO O NO

#########   hashtagsblob_obj_hashtags_c = hashtagsblob_obj_hashtags.correct() ## NEED TO CHECK HOW IT WORKS!!!!
# hashtagsblob_obj_hashtags_c = hashtagsblob_obj_hashtags

hashtagsblob_obj_hashtags_c_df = pd.DataFrame(hashtagsblob_obj_hashtags_c)

print('--')
print('hashtagsblob_obj_hashtags_C_DF TYPE:')
# print(hashtagsblob_obj_hashtags_c)
print('--')

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

hashtagsblob_obj_hashtags_c_df.to_csv('4_5_184_SMI1_hashtagsblob_Cbj_C_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# hashtagsblob_obj_hashtags_c_df.to_excel('4_5_184_SMI1_hashtagsblob_Cbj_C_DF.xlsx', header=True)

# fp_hashtags_c = hashtagsblob_obj_hashtags_c.to_string()

# fp_hashtags_c = hashtagsblob_obj_hashtags_c

# tweets_hashtags_words = nltk.word_tokenize(pd.to_string(fp_hashtags_c))
# tweets_hashtags_words = nltk.word_tokenize(fp_hashtags_c['tweet_hashtags_fp_hashtags_c'])
tweets_hashtags_words = nltk.word_tokenize(fp_hashtags_c)
tweets_hashtags_words_df = pd.DataFrame(tweets_hashtags_words)

# tweets_hashtags_words = nltk.word_tokenize((tweets_smi_1['hashtags']).pd.to_string())
# tweets_hashtags_words = tweets_smi_1['hashtags']).nltk.word_tokenize()

print('--')
print('Tokenized tweets_words')
print(tweets_hashtags_words_df.head(10))
print('--')

print('--')
print('Tokenized tweets_words Shape')
print(tweets_hashtags_words_df.shape)
print('--')

print('--')
print('Tokenized tweets_words Info')
print(tweets_hashtags_words_df.info)
print('--')


# Remove stoptweets_words          ################################################################
# tweets_hashtags_words = [word for word in tweets_hashtags_words if word not in stoptweets_words]

# print('removed stoptweets_words')


# FINDING N-GRAMS

# N-Grams refer to n combination of words in a sentence. For instance, for a sentence "I love watching football", some 2-grams would 
# be (I love), (love watching) and (watching football). N-Grams can play a cricual role in hashtags classification. 

for ngram_hashtags in hashtagsblob_obj_hashtags_c.ngrams(2):
#	print('-------------------------')
	print('N-Grams hashtags: 2')
#	print(ngram_hashtags)
#	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_hashtags = pd.DataFrame(ngram_hashtags)

ngram_hashtags.to_csv('4_5_210_SMI1_ngram_hashtags_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# ngram_hashtags.to_csv('4_5_210_SMI1_ngram_hashtags_hashtags.txt', sep='\t', encoding='utf-8', index=False, header=True)


# earthdatascience.og/courses/earth-analysis-python/using-apis-natural-language-processing-twitter/calculate-tweet-word-bigrams-networks-in-python/

# VISUALIZATION OF BIGRAMS

bigrams_hashtags = list(itertools.chain(*fp_hashtags))

# Create counter of words in bigrams

bigrams_hashtags_counts = collections.Counter(bigrams_hashtags)

# bigrams_hashtags_counts = bigrams_hashtags.value_counts(bigrams_hashtags)

bigram_hashtags_df = pd.DataFrame(bigrams_hashtags_counts, columns=['bigrams_hashtags', 'count'])

bigram_hashtags_df.to_csv('4_5_210_SMI1_bigram_hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# bigram_hashtags_df.to_excel('4_5_210_SMI1_bigram_hashtags_df_DF.xlsx', header=True)


############################################################################################################

# WORD FREQUENCY DISTRIBUTION IN mentions OF Tweets

print('---')
print('WORD FREQUENCY DISTRIBUTION IN mentions OF Tweets 1')
print('---')


fp_mentions_temp = tweets_smi_1['mentions']
fp_mentions = fp_mentions_temp.to_string()
fp_mentions_c = fp_mentions ### OJO QIE ESTA SIN ARREGLAR EL C

print('---')
print('DataFrame Types fp_mentions')
# print(fp_mentions.dtypes)
print('---')

print('---')
# print(fp_mentions)
print('---')

# fp_mentions = f_mentions

print('---')
print('Tweets mentions First 10')
print(tweets_smi_1['mentions'].head(10))
print('---')


mentionsblob_obj_mentions_c = TextBlob(fp_mentions) ## OJO QUE SI ES EL CORREGIDO O NO

mentionsblob_obj_mentions_c_df = pd.DataFrame(mentionsblob_obj_mentions_c)

print('--')
print('mentionsblob_obj_mentions_C_DF TYPE:')
# print(mentionsblob_obj_mentions_c)
print('--')

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

# mentionsblob_obj_mentions_c_df.to_csv('4_5_184_SMI1_mentionsblob_Cbj_C_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# mentionsblob_obj_mentions_c_df.to_excel('4_5_184_SMI1_mentionsblob_Cbj_C_DF.xlsx', header=True)

tweets_mentions_words = nltk.word_tokenize(fp_mentions_c)
tweets_mentions_words_df = pd.DataFrame(tweets_mentions_words)

print('--')
print('Tokenized tweets_words')
print(tweets_mentions_words_df.head(10))
print('--')

# print('--')
print('Tokenized tweets_words Shape')
print(tweets_mentions_words_df.shape)
print('--')

# print('--')
print('Tokenized tweets_words Info')
print(tweets_mentions_words_df.info)
print('--')


# FINDING N-GRAMS

# N-Grams refer to n combination of words in a sentence. For instance, for a sentence "I love watching football", some 2-grams would 
# be (I love), (love watching) and (watching football). N-Grams can play a cricual role in mentions classification. 

for ngram_mentions in mentionsblob_obj_mentions_c.ngrams(2):
#	print('-------------------------')
	print('N-Grams mentions: 2')
#	print(ngram_mentions)
#	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_mentions = pd.DataFrame(ngram_mentions)

ngram_mentions.to_csv('4_5_210_SMI1_ngram_mentions_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# ngram_mentions.to_csv('4_5_210_SMI1_ngram_mentions_mentions.txt', sep='\t', encoding='utf-8', index=False, header=True)


# earthdatascience.og/courses/earth-analysis-python/using-apis-natural-language-processing-twitter/calculate-tweet-word-bigrams-networks-in-python/

# VISUALIZATION OF BIGRAMS

bigrams_mentions = list(itertools.chain(*fp_mentions))

# Create counter of words in bigrams

bigrams_mentions_counts = collections.Counter(bigrams_mentions)

# bigrams_mentions_counts = bigrams_mentions.value_counts(bigrams_mentions)

bigram_mentions_df = pd.DataFrame(bigrams_mentions_counts, columns=['bigrams_mentions', 'count'])

bigram_mentions_df.to_csv('4_5_210_SMI1_bigram_mentions_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# bigram_mentions_df.to_excel('4_5_210_SMI1_bigram_mentions_df_DF.xlsx', header=True)


############################################################################################################

# WORD FREQUENCY DISTRIBUTION IN emojis_unicode OF Tweets

fp_emojis_unicode_temp = tweets_smi_1['emojis_unicode']
fp_emojis_unicode = fp_emojis_unicode_temp.to_string()
fp_emojis_unicode_c = fp_emojis_unicode ### OJO QUE ESTA SIN ARREGLAR EL C

print('---')
print('DataFrame Types fp_emojis_unicode')
# print(fp_emojis_unicode.dtypes)
print('---')

# fp_emojis_unicode = pd.DataFrame(tweets_smi_1['emojis_unicode'].astype('str'))
# fp_emojis_unicode = pd.DataFrame(StringIO(tweets_smi_1['emojis_unicode']))

# fp_emojis_unicode = pd.DataFrame(fp_emojis_unicode)


print('---')
print('Tweets emojis_unicode First 10')
print(tweets_smi_1['emojis_unicode'].head(10))
print('---')

emojis_unicodeblob_obj_emojis_unicode_c = TextBlob(fp_emojis_unicode) ## OJO QUE SI ES EL CORREGIDO O NO

emojis_unicodeblob_obj_emojis_unicode_c_df = pd.DataFrame(emojis_unicodeblob_obj_emojis_unicode_c)

print('--')
print('emojis_unicodeblob_obj_emojis_unicode_C_DF TYPE:')
# print(emojis_unicodeblob_obj_emojis_unicode_c)
print('--')

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

emojis_unicodeblob_obj_emojis_unicode_c_df.to_csv('4_5_184_SMI1_emojis_unicodeblob_Cbj_C_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# emojis_unicodeblob_obj_emojis_unicode_c_df.to_excel('4_5_184_SMI1_emojis_unicodeblob_Cbj_C_DF.xlsx', header=True)

tweets_emojis_unicode_words = nltk.word_tokenize(fp_emojis_unicode_c)
tweets_emojis_unicode_words_df = pd.DataFrame(tweets_emojis_unicode_words)

print('--')
print('Tokenized tweets_words')
print(tweets_emojis_unicode_words_df.head(10))
print('--')


print('--')
print('Tokenized tweets_words Shape')
print(tweets_emojis_unicode_words_df.shape)
print('--')

print('--')
print('Tokenized tweets_words Info')
print(tweets_emojis_unicode_words_df.info)
print('--')


# FINDING N-GRAMS

# N-Grams refer to n combination of words in a sentence. For instance, for a sentence "I love watching football", some 2-grams would 
# be (I love), (love watching) and (watching football). N-Grams can play a cricual role in emojis_unicode classification. 

for ngram_emojis_unicode in emojis_unicodeblob_obj_emojis_unicode_c.ngrams(2):
#	print('-------------------------')
	print('N-Grams emojis_unicode: 2')
	print(ngram_emojis_unicode)
#	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_emojis_unicode = pd.DataFrame(ngram_emojis_unicode)

ngram_emojis_unicode.to_csv('4_5_210_SMI1_ngram_emojis_unicode_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# ngram_emojis_unicode.to_csv('4_5_210_SMI1_ngram_emojis_unicode_emojis_unicode.txt', sep='\t', encoding='utf-8', index=False, header=True)


# earthdatascience.og/courses/earth-analysis-python/using-apis-natural-language-processing-twitter/calculate-tweet-word-bigrams-networks-in-python/

# VISUALIZATION OF BIGRAMS

bigrams_emojis_unicode = list(itertools.chain(*fp_emojis_unicode))

# Create counter of words in bigrams

bigrams_emojis_unicode_counts = collections.Counter(bigrams_emojis_unicode)

# bigrams_emojis_unicode_counts = bigrams_emojis_unicode.value_counts(bigrams_emojis_unicode)

bigram_emojis_unicode_df = pd.DataFrame(bigrams_emojis_unicode_counts, columns=['bigrams_emojis_unicode', 'count'])

bigram_emojis_unicode_df.to_csv('4_5_210_SMI1_bigram_emojis_unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# bigram_emojis_unicode_df.to_excel('4_5_210_SMI1_bigram_emojis_unicode_df_DF.xlsx', header=True)


############################################################################################################

# WORD FREQUENCY DISTRIBUTION IN emojis_converted OF Tweets

# fp_emojis_converted = tweets_smi_1['emojis_converted'].astype(str, errors='ignore')
# fp_emojis_converted['tweet_emojis_converted_fp_emojis_converted'] = pd.DataFrame(tweets_smi_1['emojis_converted'].astype(str, errors='ignore'))
# fp_emojis_converted = tweets_smi_1.emojis_converted.astype(str, errors='ignore')

fp_emojis_converted_temp = tweets_smi_1['emojis_converted']
fp_emojis_converted = fp_emojis_converted_temp.to_string()
fp_emojis_converted_c = fp_emojis_converted ### OJO QUE ESTA SIN ARREGLAR EL C

print('---')
print('DataFrame Types fp_emojis_converted')
# print(fp_emojis_converted.dtypes)
print('---')

# fp_emojis_converted = pd.DataFrame(tweets_smi_1['emojis_converted'].astype('str'))
# fp_emojis_converted = pd.DataFrame(StringIO(tweets_smi_1['emojis_converted']))

# fp_emojis_converted = pd.DataFrame(fp_emojis_converted)

# fp_emojis_converted = open(smi_file_4_4_emojis_converted_only, encoding='utf-8')
# f_emojis_converted = fp_emojis_converted.read() # As bytes

# data_f = fp_emojis_converted.read() # As bytes

# f_emojis_converted = fp_emojis_converted

# f_emojis_converted = data_f.decode('utf-8') # Unicode not bytes

# print('---')
# print(f_emojis_converted)
print('---')

# fp_emojis_converted = f_emojis_converted

# print('---')
print('Tweets emojis_converted First 10')
print(tweets_smi_1['emojis_converted'].head(10))
print('---')

emojis_convertedblob_obj_emojis_converted_c = TextBlob(fp_emojis_converted) ## OJO QUE SI ES EL CORREGIDO O NO

#########   emojis_convertedblob_obj_emojis_converted_c = emojis_convertedblob_obj_emojis_converted.correct() ## NEED TO CHECK HOW IT WORKS!!!!
# emojis_convertedblob_obj_emojis_converted_c = emojis_convertedblob_obj_emojis_converted

emojis_convertedblob_obj_emojis_converted_c_df = pd.DataFrame(emojis_convertedblob_obj_emojis_converted_c)

print('--')
print('emojis_convertedblob_obj_emojis_converted_C_DF TYPE:')
# print(emojis_convertedblob_obj_emojis_converted_c)
print('--')

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

emojis_convertedblob_obj_emojis_converted_c_df.to_csv('4_5_184_SMI1_Emojis_Convertedblob_Cbj_C_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# emojis_convertedblob_obj_emojis_converted_c_df.to_excel('4_5_184_SMI1_Emojis_Convertedblob_Cbj_C_DF.xlsx', header=True)

# fp_emojis_converted_c = emojis_convertedblob_obj_emojis_converted_c.to_string()

# fp_emojis_converted_c = emojis_convertedblob_obj_emojis_converted_c

# tweets_emojis_converted_words = nltk.word_tokenize(pd.to_string(fp_emojis_converted_c))
# tweets_emojis_converted_words = nltk.word_tokenize(fp_emojis_converted_c['tweet_emojis_converted_fp_emojis_converted_c'])
tweets_emojis_converted_words = nltk.word_tokenize(fp_emojis_converted_c)
tweets_emojis_converted_words_df = pd.DataFrame(tweets_emojis_converted_words)

# tweets_emojis_converted_words = nltk.word_tokenize((tweets_smi_1['emojis_converted']).pd.to_string())
# tweets_emojis_converted_words = tweets_smi_1['emojis_converted']).nltk.word_tokenize()

# print('--')
print('Tokenized tweets_words')
print(tweets_emojis_converted_words_df.head(10))
print('--')

# print('--')
print('Tokenized tweets_words Shape')
print(tweets_emojis_converted_words_df.shape)
print('--')

# print('--')
print('Tokenized tweets_words Info')
print(tweets_emojis_converted_words_df.info)
print('--')

# Remove single-character tokens (mostly punctuation) ######## NEED TO DO FIX 
# tweets_emojis_converted_words = [word for word in tweets_emojis_converted_words if len(word) > 1]

# Remove numbers ######## NEED TO DO FIX
# tweets_emojis_converted_words = [word for word in tweets_emojis_converted_words if not word.isnumeric()]

# Lowercase all tweets_words (default_stoptweets_words are lowercase too) ######## NEED TO DO FIX
# tweets_emojis_converted_words = [word.lower() for word in tweets_emojis_converted_words]

# Stemming tweets_words seems to make matters worse, disabled
# stemmer = nltk.stem.snowball.SnowballStemmer('english')
# tweets_emojis_converted_words = [stemmer.stem(word) for word in tweets_emojis_converted_words]

# Remove stoptweets_words          ################################################################
# tweets_emojis_converted_words = [word for word in tweets_emojis_converted_words if word not in stoptweets_words]

# print('removed stoptweets_words')


# FINDING N-GRAMS

# N-Grams refer to n combination of words in a sentence. For instance, for a sentence "I love watching football", some 2-grams would 
# be (I love), (love watching) and (watching football). N-Grams can play a cricual role in emojis_converted classification. 

for ngram_emojis_converted in emojis_convertedblob_obj_emojis_converted_c.ngrams(2):
#	print('-------------------------')
	print('N-Grams emojis_converted: 2')
#	print(ngram_emojis_converted)
#	print('-------------------------')
	
# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_emojis_converted = pd.DataFrame(ngram_emojis_converted)

ngram_emojis_converted.to_csv('4_5_210_SMI1_ngram_emojis_converted_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# ngram_emojis_converted.to_csv('4_5_210_SMI1_ngram_emojis_converted_emojis_converted.txt', sep='\t', encoding='utf-8', index=False, header=True)


# earthdatascience.og/courses/earth-analysis-python/using-apis-natural-language-processing-twitter/calculate-tweet-word-bigrams-networks-in-python/

# VISUALIZATION OF BIGRAMS

bigrams_emojis_converted = list(itertools.chain(*fp_emojis_converted))

# Create counter of words in bigrams

bigrams_emojis_converted_counts = collections.Counter(bigrams_emojis_converted)

# bigrams_emojis_converted_counts = bigrams_emojis_converted.value_counts(bigrams_emojis_converted)

bigram_emojis_converted_df = pd.DataFrame(bigrams_emojis_converted_counts, columns=['bigrams_emojis_converted'])

bigram_emojis_converted_df.to_csv('4_5_210_SMI1_bigram_emojis_converted_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# bigram_emojis_converted_df.to_excel('4_5_210_SMI1_bigram_emojis_converted_df_DF.xlsx', header=True)


######################################################################################################################
######################################################################################################################
######################################################################################################################

# Bars

# Number of Tweets / Date

# Prepare the data

# created = tweets_smi_1.loc['created']
# tweets_numbers = tweets_smi_1.loc['total_tweets']

created = tweets_smi_1['created']
tweets_numbers = tweets_smi_1['total_tweets']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Total Tweets / Time - Bars')
plt.ioff()
plt.plot(created, tweets_numbers, label='linear')
# tweets_numbers.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_215_SMI1_Total_Tweets_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


########################################################################################################

# Bars

# Favorites

# Prepare the data

tweets_favs = tweets_smi_1['favorites']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Favorites / Time - Bars')
plt.ioff()
plt.plot(created, tweets_favs, label='linear')
plt.ioff()
# tweets_favs.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_216_SMI1_Favorites_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


########################################################################################################

# Bars

# Retweets

# Prepare the data
tweets_rts = tweets_smi_1['retweets']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Retweets / Time - Bars')
plt.ioff()
# plt.plot(created, tweets_rts, label='linear')
# tweets_rts.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_217_SMI1_Retweets_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

########################################################################################################

# Bars

# HASTAGS

number_of_hashtags_in_tweets = tweets_smi_1['hashtags']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Hashtags / Time - Bars')
plt.ioff()
# plt.plot(created, number_of_hashtags_in_tweets, label='linear')
# number_of_hashtags_in_tweets.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
# plt.ylabel('Count')
# ax.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_218_SMI1_Hashtags_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


smi1_favorites.size_sort_values_df = pd.DataFrame(smi1_favorites.size().sort_values(ascending=False))

smi1_favorites.size_sort_values_df.to_csv('4_4_218_SMI1_favorites.size_sort_values_df_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

########################################################################################################

# MENTIONS PLOTS BAR

# MENTIONS

number_of_mentions_in_tweets = tweets_smi_1['mentions'] # tweets_smi_1.loc['mentions']


# Plot the data ## NEED TO FIX 

# TABLE PLOT NEED TO DO 

# Bars NEED TO DO

# Bars

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Mentions / Time - Bars')
plt.ioff()
# number_of_mentions_in_tweets.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
# plt.ylabel('Number of Mentions')
plt.plot(created[:10], number_of_mentions_in_tweets[:10], label='linear')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_219_SMI1_Mentions_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


number_of_mentions_in_tweets = pd.DataFrame([number_of_mentions_in_tweets], columns=['number_of_mentions_in_tweets'])

number_of_mentions_in_tweets.to_csv('4_4_219_SMI1_Number_of_Mentions_in_Tweets_CSV.csv')
# .to_excel()


########################################################################################################

# Bars

# Number of Friends/ Date

# Prepare the data
created = tweets_smi_1['created']
friends_numbers = tweets_smi_1['friends_count']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Friends / Time - Bars')
plt.ioff()
plt.plot(created, friends_numbers, label='linear')
# friends_numbers.sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_215_SMI1_Friends_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################################################################

# Bars

# Favorites / Date

# Prepare the data
created = tweets_smi_1['created']
favorites_numbers = tweets_smi_1['favorites']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Favorites / Time - Bars')
plt.ioff()
plt.plot(created, favorites_numbers, label='linear')
# favorites_numbers.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_215_SMI1_Favorites_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################################################################

# LINE PLOTS

# Numer of Retweets / Favorites

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Numer of Retweets / Favorites')
plt.ioff()
# Plot with differently-colored markers.
plt.plot(created, tweets_rts, 'b-', label='Retweets', alpha=0.9)
plt.plot(created, tweets_favs, 'r-', label='Favorites', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# Create legend
plt.legend(loc='upper left')
plt.xlabel('Year')
# plt.ylabel('Retweets / Favorites')
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_220_SMI1_Retweets_VS_Favorites_Time_Line_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# # https://www.datacamp.com/community/tutorials/wordcloud-python

# Pie NEED TO DO

# Bars

# Number of Favorites of Tweets

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Favorites - Bars')
plt.ioff()
smi1_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_220_SMI1_Number_Favorites_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


########################################################################################################

# # https://www.datacamp.com/community/tutorials/wordcloud-python  ## NEED TO DO PLOT 2 VARIABLE!!!!!!!!

# Bars
 
# Number of Favorites / Retweets of Tweets

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Favorites / Retweets - Bars')
plt.ioff()
smi1_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Favs / Retweets')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_221_SMI1_Number_Favorites_Retweets_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################################

# Bars

# Number of Retweets of Tweets

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Retweets - Bars')
plt.ioff()
smi1_retweets.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Retweets')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# ax.grid(True)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_222_SMI1_Number_Retweets_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################################

# Bars

# Most Commom Languages 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Languages - Bars')
plt.ioff()
smi1_languages.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_223_SMI1_Language_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###############################################################################################################
#
#                       CLUSTER ANALYSIS AND TIME SERIES ###################### NEED TO DO!!!!!!!!!!!
#
###############################################################################################################

sns.set()

# XXX 

# TIME SERIES 

total_favorites_created_df = tweets_smi_1[['created','favorites','retweets','single_tweet']].copy

# total_favorites_created_df.month = pd.to_datetime(total_favorites_created_df.month)

# total_favorites_created_df.set_index('month', inplace=True)

# PLOT NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Time Series: Created')
plt.ioff()
(tweets_smi_1['created'], tweets_smi_1['favorites']).plot(alpha=0.9)
(tweets_smi_1['created'], tweets_smi_1['retweets']).plot(alpha=0.9)
(tweets_smi_1['created'], tweets_smi_1['single_tweet']).plot(alpha=0.9)
plt.xlabel('Year')
plt.ylabel('Counts')
ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_225_SMI1_Time_Series_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#######################################################################################################

# https://towardsdatascience.com/an-end-to-end-project-on-total_favorites-series-analysis-and-forecasting-with-python-4835e6bf050b
# https://pythonplot.com/

# PLOT Favorites OVER TIME NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favs Over Time : All Tweets')
plt.ioff()
tweets_smi_1.set_index('created')['favorites'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_226_SMI1_Favorites_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Retweets OVER TIME

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Retweets Over Time : All Tweets')
plt.ioff()
tweets_smi_1.set_index('created')['retweets'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_227_SMI1_Retweets_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Favorites / Retweets OVER TIME #################################### NEED TO DO!!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favs / Retweets Over Time : All Tweets')
plt.ioff()
tweets_smi_1.set_index('created')['favorites'].plot(color='#73C2FB', alpha=0.9)
tweets_smi_1.set_index('created')['retweets'].plot(color='blue', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_228_SMI1_Favorites_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### NEED TO DO FOR SMI VS AUDIENCE!!!!!!!!!!!!!

############################################################################################################

# FIRST AND LAST DATES

smi1_first_date = tweets_smi_1['created'].min()

print('---')
print('Firt Date')
print(tweets_smi_1['created'].min())
print('---')


# initialize list of Lists 
smi1_tweet_date_ranges = [['First Date', smi1_first_date], ['Last Date', smi1_last_date]] 
 
# Create the pandas DataFrame 
smi1_tweet_date_ranges_df = pd.DataFrame(textblob_sentiments, columns = ['date_item', 'sentiment_polarity', 'sentiment_positiveness']) 

smi1_tweet_date_ranges_df.to_csv('4_5_229_SMI1_Tweet_Date_Ranges_df_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# smi1_tweet_date_ranges_df.to_excel('4_5_229_SMI1_Tweet_Date_ranges_df.xlsx', header=True)


# PLOT TABLE # NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Date Ranges')
plt.ioff()
smi1_tweet_date_ranges_df.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_229_SMI1_Tweet_Date_Ranges_df_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Date Ranges - Pie')
plt.ioff()
plt.pie(smi1_tweet_date_ranges_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.legend(smi1_tweet_date_ranges_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_229_SMI1_Tweet_Date_Ranges_df_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Date Ranges - Bars')
plt.ioff()
textblob_sentiment_df.plot.bar(alpha=0.9)
plt.xlabel('Date')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5_229_SMI1_Tweet_Date_Ranges_df_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Summary Statistics of all Dates   ## NEED TO FIX AND PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_created.describe()
smi1_created.describe().head()

print('---')
print('Summary Statistics of all Dates')
# print(smi1_created.describe().head)
print('---')

# smi1_created_describe_df = pd.DataFrame([smi1_created.describe()])

# smi1_created_describe_df.to_csv('4_4_229_SMI1_Created_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE NEED TO DO 

# plt.plot

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics Dates - Grouped')
plt.ioff()
# plt.plot(smi1_created.describe())
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_229_SMI1_DF_Tweets_Processes_Describe_Created_g_1.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLE

del smi1_tweet_date_ranges
# del smi1_created_describe
# del smi1_created_describe_df

############################################################################################################
############################################################################################################

# This selects the Top 5 highest average points among all Tweets:

smi1_created.mean().sort_values(by="created",ascending=True)  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 highest Created average points among all Tweets:')
print('smi1_created.mean().sort_values(by="created",ascending=True).head()')
print('---')


# smi1_created_mean_sort_values_created = pd.DataFrame(smi1_created.mean().sort_values(by="created",ascending=True))

# smi1_created_mean_sort_values_created.to_csv('4_4_230_SMI1_Created_Mean_Sort_Values_Created_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

######################################################################################

# SCATTERPLOT FACETED ON ONE VARIABLE / LANGUAGE - NEED TO DO 

## SCATTERPLOT FAV TIME LANGUAGE METHOD 1 - 1

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favs / Time / Language - Scatter')
plt.ioff()
# plt.scatter(scipy.stats.pearsonr(tweets_smi_1['favorites'], tweets_smi_1['retweets']), alpha=0.9)
plt.xlabel('Favorites / Time')
plt.ylabel('Language')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_230_SMI1_Scatterplot_Favorites_Time_Language_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


### SCATTERPLOT RETWEETS TIME LANGUAGE METHOD 1 -2 MEED TO DO
 
# XXX NEED TO FIX NOT WORKING VARUABLE MEZCLADAS 

#### SCATTERPLOT - Method 2 FAVORITES

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Retweets / Time / Language - Scatter Faceted')
plt.ioff()
# plt.scatter(scipy.stats.pearsonr(tweets_smi_1['retweets'], tweets_smi_1['language']), alpha=0.9)
plt.xlabel('Retweets / Time')
plt.ylabel('Language')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_230_SMI1_Scatterplot_Facetonevar_Retweets_Time_Language_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### SCATTERPLOT METHOD 2 RETWEETS

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Retweets / Time / Language - Scatter Faceted')
plt.ioff()
scatterplot_facetonevar_rts_total_favorites = figure_factory.create_facet_grid(df=tweets_smi_1, x='created', y='retweets', facet_col='language')
plt.xlabel('Retweets / Time ')
plt.ylabel('Language')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_230_SMI1_Scatterplot_Facetonevar_Retweets_Time_Language_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


################################################################################

# Seaborn visualization library

sns.set(color_codes=True)

# Stratification Plot

# Another way to get more information out of a dataset is to divide it into smaller, more uniform subsets, and analyze each of these �strata� on its own. We will create a new HouseAge column, then partition the data into HouseAge strata, and construct side-by-side boxplots of the sale price within each stratum.

tweets_smi_1.set['YearP'] = 2020 - tweets_smi_1.set['created']
tweets_smi_1.set["YearGrp"] = pd.cut(tweets_smi_1.set.YearP, [2005, 2010, 2015, 2020]) # Create age strata based on these cut points

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Stratification Plot for Changes in Favorites / Year')
plt.ioff()
sns.boxplot(x="year", y="favorites", data=tweets_smi_1.set)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_231_SMI1_Strats_Favorites_Year.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################################################################################################################


# Stratification Plot

# Another way to get more information out of a dataset is to divide it into smaller, more uniform subsets, and analyze each of these �strata� on its own. We will create a new HouseAge column, then partition the data into HouseAge strata, and construct side-by-side boxplots of the sale price within each stratum.

# tweets_smi_1.set['YearP'] = 2020 - tweets_smi_1.set['created']
# tweets_smi_1.set["YearGrp"] = pd.cut(tweets_smi_1.set.YearP, [2005, 2010, 2015, 2020]) # Create age strata based on these cut points

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Changes in Retweets / Year - Box')
plt.ioff()
sns.boxplot(x="YearGrp", y="retweets", data=tweets_smi_1.set)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_232_SMI1_Strats_rts_Time_Box_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################################################################################################################


# Scatter Plot Faceted on Two Variables


#################################################################################################################

# Seaborn visualization library

# screenName author_id created RetweetsFavorites Text latitude longitude Mentions hashtags id url emojis_unicode emojis_converted image_link language

tweets_smi_1_numeric = pd.DataFrame(tweets_smi_1)
# del tweets_smi_1_numeric['screenName']
# df.drop(['column_nameA', 'column_nameB'], axis=1, inplace=True)
# del tweets_smi_1_numeric['screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', 'url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language']

# tweets_smi_1_numeric.drop('screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language', axis=1, inplace=True)

tweets_smi_1_numeric.drop('screenName', axis=1, inplace=True)
tweets_smi_1_numeric.drop('text', axis=1, inplace=True)
tweets_smi_1_numeric.drop('latitude', axis=1, inplace=True)
tweets_smi_1_numeric.drop('longitude', axis=1, inplace=True)
tweets_smi_1_numeric.drop('mentions', axis=1, inplace=True)
tweets_smi_1_numeric.drop('hashtags', axis=1, inplace=True)
tweets_smi_1_numeric.drop('url', axis=1, inplace=True)
tweets_smi_1_numeric.drop('emojis_unicode', axis=1, inplace=True)
tweets_smi_1_numeric.drop('emojis_converted', axis=1, inplace=True)
tweets_smi_1_numeric.drop('image_link', axis=1, inplace=True)
tweets_smi_1_numeric.drop('language', axis=1, inplace=True)

# tweets_smi_1_numeric.drop(['screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', 'url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language'], axis=1, inplace=True)
# tweets_smi_1_numeric = tweets_smi_1[['author_id', 'created', 'retweets', 'favorites', 'id']]

# Create the default pairplot

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Pair Plot of SMI Numeric Data')
plt.ioff()
# sns.pairplot(tweets_smi_1_numeric)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_233_SMI1_Pair_Plot_Numeric.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('creating plots')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


###################################################################################################################

# http://seaborn.pydata.org/tutorial/relational.html

# Visualizing statistical relationships

# Statistical analysis is a process of understanding how variables in a dataset relate to each other and how those relationships depend on other variables. Visualization can be a core component of this process because, when data are visualized properly, the human visual system can see trends and patterns that indicate a relationship.
# We will discuss three seaborn functions in this tutorial. The one we will use most is relplot(). This is a figure-level function for visualizing statistical relationships using two common approaches: scatter plots and line plots. relplot() combines a FacetGrid with one of two axes-level functions:
# scatterplot() (with kind="scatter"; the default)
# lineplot() (with kind="line')
# As we will see, these functions can be quite illuminating because they use simple and easily-understood representations of data that can nevertheless represent complex dataset structures. They can do so because they plot two-dimensional graphics that can be enhanced by mapping up to three additional variables using the semantics of hue, size, and style.

# Relating variables with scatter plots

# The scatter plot is a mainstay of statistical visualization. It depicts the joint distribution of two variables using a cloud of points, where each point represents an observation in the dataset. This depiction allows the eye to infer a substantial amount of information about whether there is any meaningful relationship between them.
# There are several ways to draw a scatter plot in seaborn. The most basic, which should be used when both variables 
# are numeric, is the scatterplot() function. In the categorical visualization tutorial, we will see specialized tools 
# for using scatterplots to visualize categorical data. The scatterplot() is the default kind in relplot() (it can also 
# be forced by setting kind="scatter'):

# SCATTER PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationship Retweets / Favorites - ScatterPlot')
plt.ioff()
sns.relplot(x="retweets", y="favorites", data=tweets_smi_1)
plt.xlabel('Retweets')
plt.ylabel('Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_234_SMI1_SB_Scatter_Plot_Rel_Favorites_Retweets_Numeric_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#####################

# In the simplest invocation, both functions draw a scatterplot of two variables, x and y, and then fit the regression model 
# y x and plot the resulting regression line and a 95% confidence interval for that regression:

# SCATTER PLOT REG

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Regression Retweets / Favorites: 95% Conf. Int. - Scatter')
plt.ioff()
sns.regplot(x="retweets", y="favorites", data=tweets_smi_1)
plt.xlabel('Retweets')
plt.ylabel('Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_235_SMI1_SB_Reg_Favorites_Retweets_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT LM

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Regression Retweets/Favorites: 95% Conf. Int. - Scatter')
plt.ioff()
sns.lmplot(x="retweets", y="favorites", data=tweets_smi_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_236_SMI1_SB_Reg_Favorites_Retweets_LM_PLOT_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('done - using seaborn')

#################################################################################

# _df _df = pd.DataFrame()
# .to_csv('4_4_.csv', sep='\t', encoding='utf-8', index=True)
# excel

##################################################################################################################

# Scatter Plot Faceted on Two Variables

#################################################################################################################

# Seaborn visualization library

sns.set(color_codes=True)

# screenName author_id created Retweets Favorites Text latitude longitude mentions hashtags id url emojis_unicode emojis_converted image_link language

tweets_smi_1_numeric = pd.DataFrame(tweets_smi_1)
# del tweets_smi_1_numeric['screenName']
# df.drop(['column_nameA', 'column_nameB'], axis=1, inplace=True)
# del tweets_smi_1_numeric['screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', 'url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language']

# tweets_smi_1_numeric.drop('screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language', axis=1, inplace=True)

# tweets_smi_1_numeric.drop(['screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', 'url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language'], axis=1, inplace=True)
# tweets_smi_1_numeric = tweets_smi_1[['author_id', 'created', 'retweets', 'favorites', 'id']]

# Create the default pairplot

# PLOT  # NEED TO DO NOT WORKING !!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Pair Plot of SMI Numeric Data')
plt.ioff()
# sns.pairplot(tweets_smi_1_numeric)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_197_SMI1_Pair_Plot_Numeric.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('creating plots')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


###################################################################################################################

# http://seaborn.pydata.org/tutorial/relational.html

# Visualizing Statistical Relationships # NEED TO DO 

# Statistical analysis is a process of understanding how variables in a dataset relate to each other and how those relationships depend on other variables. Visualization can be a core component of this process because, when data are visualized properly, the human visual system can see trends and patterns that indicate a relationship.
# We will discuss three seaborn functions in this tutorial. The one we will use most is relplot(). This is a figure-level function for visualizing statistical relationships using two common approaches: scatter plots and line plots. relplot() combines a FacetGrid with one of two axes-level functions:
# scatterplot() (with kind="scatter"; the default)
# lineplot() (with kind="line')
# As we will see, these functions can be quite illuminating because they use simple and easily-understood representations of data that can nevertheless represent complex dataset structures. They can do so because they plot two-dimensional graphics that can be enhanced by mapping up to three additional variables using the semantics of hue, size, and style.

# Relating variables with scatter plots

# The scatter plot is a mainstay of statistical visualization. It depicts the joint distribution of two variables using a cloud of points, where each point represents an observation in the dataset. This depiction allows the eye to infer a substantial amount of information about whether there is any meaningful relationship between them.
# There are several ways to draw a scatter plot in seaborn. The most basic, which should be used when both variables 
# are numeric, is the scatterplot() function. In the categorical visualization tutorial, we will see specialized tools 
# for using scatterplots to visualize categorical data. The scatterplot() is the default kind in relplot() (it can also 
# be forced by setting kind="scatter'):

# SCATTER PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Retweets / Favorites - Scatter')
plt.ioff()
sns.relplot(x='retweets', y='favorites', data=tweets_smi_1)
plt.xlabel('Retweets')
plt.ylabel('Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_198_SMI1_Rel_Favorites_Retweets_Numeric_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#####################

# In the simplest invocation, both functions draw a scatterplot of two variables, x and y, and then fit the regression model 
# y ~ x and plot the resulting regression line and a 95% confidence interval for that regression:

# SCATTER PLOT REG

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Regression Retweets / Favs: 95% Conf Int - Scatter')
plt.ioff()
sns.regplot(x='retweets', y='favorites', data=tweets_smi_1)
plt.xlabel('Retweets')
plt.ylabel('Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_198_SMI1_Reg_Favorites_Retweets_REG_PLOT_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT LM

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Regression Retweets/Favorited: 95% Conf Int - Scatter')
plt.ioff()
sns.lmplot(x='retweets', y='favorites', data=tweets_smi_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_198_SMI1_Reg_Favorites_Retweets_LM_PLOT_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('done - using seaborn')

tweets_smi_1.to_csv('4_5_201_03_SMI1_tweets_smi_1_SENTIMENTS_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_excel('4_5_201_03_SMI1_tweets_smi_1_SENTIMENTS.xlsx', header=True)

#################################################################################

# _df _df = pd.DataFrame()
# .to_csv('4_5_.csv', sep='\t', encoding='utf-8', index=True)
# excel

###########################################################################################################

# https://www.datacamp.com/community/tutorials/wordcloud-python

# WORDCLOUD 

# SMI_WordCloud_1 = WordCloud(background_color="white",stoptweets_words=stoptweets_words,width=800, height=400).generate(' '.join(data))
SMI_WordCloud_1 = WordCloud(background_color='white').generate(' '.join(tweets_text_words))

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet WordCloud Visualization')
plt.ioff()
plt.imshow(SMI_WordCloud_1, interpolation='bilinear')
plt.axis('off')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3) 
# plt.show()
plt.savefig('4_5_199_SMI1_WordCloud_SB_1.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################################################################################
#
#		           SENTIMENT ANALYSIS: USING TEXTBLOB
#          
###################################################################################################################

# The SENTIMENT property returns a nameduple of the form sentiment(polarity, subjectivity). The polarity score is a 
# float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective
# and 1.0 is very subjective.


# returns the sentiment of text
# by returning a value between -1.0 and 1.0

# textblob_polarity = textblob_obj_text_c.sentiment.polarity
# textblob_subjectivity = textblob_obj_text_c.sentiment.subjectivity

textblob_polarity = textblob_obj_text_c.apply(lambda tweet: TextBlob(tweet).sentiment.polarity)
textblob_subjectivity = textblob_obj_text_c.apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)

print('---')
print('TextBlob Polarity:')
print(textblob_polarity)

if textblob_polarity == 0:
  print('The Text is neutral')
elif textblob_polarity > 0.75:
  print('The Text is very positive') 
elif textblob_polarity > 0.50:
  print('The Text is positive')
elif textblob_polarity > 0:
  print('The Text is somewhat positive')
elif textblob_polarity > -0.25:
  print('The Text is somewhat negative') 
elif textblob_polarity > -0.50:
  print('The Text is negative')
else:
  print('The Text is very negative')
  
print('---')

print('TextBlob Subjectivity:')
print(textblob_subjectivity)

if textblob_subjectivity == 0:
  print('The Text is extremely subjective')
elif textblob_subjectivity > 0.75:
  print('The Text is very objective')
elif textblob_subjectivity > 0.50:
  print('The Text is objective')
elif textblob_subjectivity > 0.25:
  print('The Text is subjective')
else:
  print('The Text is very subjective')

print('---')

# Create the pandas DataFrame 
textblob_sentiment_df = pd.DataFrame(textblob_obj_text_c.sentiment) 
# textblob_sentiment_df = textblob_sentiment_df.style.applymap(color_negative_red)

textblob_sentiment_df.to_csv('4_5_200_SMI1_Textblob_Sentiment_df_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# textblob_sentiment_df.to_excel('4_5_200_SMI1_Textblob_Sentiment_df.xlsx', header=True)

textblob_positiveness = 1 - textblob_polarity
textblob_obj_text_cectivity = 1 - textblob_subjectivity

# initialize list of Lists 
textblob_sentiments = [['Sentiment Polarity', textblob_polarity, textblob_positiveness]] 
 
# Create the pandas DataFrame 
textblob_sentiments_df = pd.DataFrame(textblob_sentiments, columns = ['sentiment_item', 'sentiment_polarity', 'sentiment_positiveness']) 

# textblob_sentiments_df = textblob_sentiments_df.style.applymap(color_negative_red)

textblob_sentiments_df.to_csv('4_5_200_SMI1_Textblob_Sentiments_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# textblob_sentiments_df.to_excel('4_5_200_SMI1_Textblob_Sentiments.xlsx', header=True)


# PLOT TABLE # NEED TO DO 

# Sentiment Plot

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity - TextBlob')
# textblob_polarity.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_200_SMI1_TextBlob_Sentiment_Polarity_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity TextBlob - Pie')
# plt.pie(textblob_polarity, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.legend(textblob_polarity, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_200_SMI1_TextBLob_Sentiment_Polarity_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity / Subjectivity TextBlob - Bars')
textblob_sentiment_df.plot.bar(alpha=0.9)
plt.xlabel('Sentiment Polarity / Subjectivity')
plt.ylabel('Value')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_200_SMI1_TextBLob_Sentiment_Polarity_Subjectivity_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##################################################################################################################
#
#                       SENTIMENT DF - TEXTBLOB -  USING NLTK ##### NEED TO DO !!!!!
#
###################################################################################################################
######################################################################################################################

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore')
tweets_smi_1['text'] = tweets_smi_1['text'].to_string()

print('-------------------------')
print('Text type HEAD')
print(tweets_smi_1['text'].head)
print('-------------------------')

print('-------------------------')
print('Text Dtype')
print(tweets_smi_1['text'].dtype)
print('-------------------------')

def get_pol(tweets):
	for tweet in tweets:
		tweets_textblob = Textblob(tweets)
		tweets_smi_1['tweets_textblob_polarity'] = tweets_textblob.sentiment.polarity
		tweets_smi_1['tweets_textblob_subjectivity'] = tweets_textblob.sentiment.subjectivity
	yield tweets_smi_1
		
# tweets_smi_1['textblob_sentiment_polarity'] = tweets_smi_1['text'].apply(lambda x: TextBlob(x).sentiment.polarity)
# tweets_smi_1['textblob_sentiment_subjectivity'] = tweets_smi_1['text'].apply(lambda x: TextBlob(x).sentiment.subjectivity)

# tweets_smi_1['textblob_sentiment_polarity'] = str(tweets_smi_1['textblob_sentiment_polarity'])
# tweets_smi_1['textblob_sentiment_polarity'] = str(tweets_smi_1['textblob_sentiment_polarity'])

get_pol(tweets_smi_1['text'])

print('-------------------------')
print('tweets_smi_1 textblob_sentiment_polarity 0 ')
print(tweets_smi_1['textblob_sentiment_polarity'].head(20))
print('-------------------------')

print('-------------------------')
print('tweets_smi_1 textblob_sentiment_polarity DTYPES 0 ')
print(tweets_smi_1['textblob_sentiment_polarity'].dtypes)
print('-------------------------')

# tweets_smi_1['textblob_sentiment_polarity'] = tweets_smi_1['textblob_sentiment_polarity'].astype(np.int32, errors='ignore')
# tweets_smi_1['textblob_sentiment_polarity'] = tweets_smi_1['textblob_sentiment_polarity'].astype(np.int32, errors='ignore')
# tweets_smi_1['textblob_sentiment_polarity'] = int(tweets_smi_1['textblob_sentiment_polarity']) 
# tweets_smi_1['textblob_sentiment_polarity'] = int(tweets_smi_1['textblob_sentiment_polarity']) 

print('-------------------------')
print('tweets_smi_1 textblob_sentiment_polarity 1')
print(tweets_smi_1['textblob_sentiment_polarity'].head(20))
print('-------------------------')

print('-------------------------')
print('tweets_smi_1 textblob_sentiment_polarity DTYPES 1')
print(tweets_smi_1['textblob_sentiment_polarity'].dtypes)
print('-------------------------')

print('-------------------------')
print('tweets_smi_1 textblob_sentiment_subjectivity')
print(tweets_smi_1['textblob_sentiment_subjectivity'].head(20))
print('-------------------------')

print('-------------------------')
print('tweets_smi_1 textblob_sentiment_subjectivity DTYPES')
print(tweets_smi_1['textblob_sentiment_subjectivity'].dtypes)
print('-------------------------')


print('------------------')
print('TEXT HEAD 2C')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')



# NOT WORKING!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

tweets_smi_1.to_csv('4_5_201_10_SMI1_tweets_smi_1_WITH_SENTIMENTS_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_excel('4_5_201_10_SMI1_tweets_smi_1_WITH_SENTIMENTS.xlsx', header=True)


# SENTIMENT POLARITY OVER TIME

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity Over Time')
# tweets_smi_1.set_index('created')['textblob_sentiment_polarity'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_185_SMI1_Sentiment_Polarity_Tweets_Time.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity Over Time - Bars')
# tweets_smi_1.set_index('created')['textblob_sentiment_polarity'].plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_185_SMI1_Sentiment_Polarity_Tweets_Time_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Subjectivity Over Time')
tweets_smi_1.set_index('created')['textblob_sentiment_subjectivity'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_185_SMI1_Sentiment_Subjectivity_Tweets_Time.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BARS

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Subjectivity Over Time - Bars')
tweets_smi_1.set_index('created')['textblob_sentiment_subjectivity'].plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_185_SMI1_Sentiment_Subjectivity_Tweets_Time_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Polarity / Subjectivity Over Time')
# tweets_smi_1.set_index('created')['textblob_sentiment_polarity'].plot(alpha=0.9)
# tweets_smi_1.set_index('created')['textblob_sentiment_subjectivity'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_186_SMI1_Polarity_Subjectivitys_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PLOT BARS - MULTIPLE - Tweets Followers AND Friends NOT UNIQUE 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

# '#73C2FB', '#6593F5',

r1 = np.arange(len(tweet_info_followers_not_unique_df))
r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Polarity / Subjectivity Over Time - Bars')
plt.bar(r1, tweets_smi_1.set_index('created')['textblob_sentiment_polarity'], color='#73C2FB', edgecolor='white', label='polarity', alpha=0.9)
plt.bar(r2, tweets_smi_1.set_index('created')['textblob_sentiment_subjectivity'], color='blue', edgecolor='white', label='subjectivity', alpha=0.9)
plt.xticks(rotation=50)
plt.xlabel('Users with Followers, Users without Followers, Users with Friends, Users without Friends')
plt.ylabel('Count')
plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True)
# plt.show()
plt.savefig('4_4_40_SMI1_Tweet_Sentiment_Polarity_Subjectivity_Time_df_Bar_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################################################################
################################################################################################
################################################################################################

# MOST POSITIVE TWEETS

positive_tweets_textblob = tweets_smi_1[(tweets_smi_1['textblob_sentiment_polarity'] == '1')]
most_positive_tweets_textblob = positive_tweets_textblob.value_counts(ascending=False)

print('-------------------------')
print('Most Positive Tweets Head')
print(most_positive_tweets_textblob[:10])
print('-------------------------')

print('-------------------------')
print('Most Positive Tweets DTYPES')
print(most_positive_tweets_textblob.dtypes)
print('-------------------------')

number_most_positive_tweets_textblob = len(most_positive_tweets_textblob)

# number_most_positive_tweets_textblob = most_positive_tweets_textblob['textblob_sentiment_polarity'].cumsum()

print('-------------------------')
print('Most Positive Tweets Len')
print(number_most_positive_tweets_textblob)
print('-------------------------')

most_positive_tweets_textblob.to_csv('4_5_201_10_SMI1_Most_Positive_Tweets_Textblob_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# most_positive_tweets_textblob.to_excel('4_5_201_10_SMI1_Most_Positive_Tweets_Textblob.xlsx', header=True)


# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Positive Tweets Value Counts')
most_positive_tweets_textblob.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Positive_Tweets_Textblob_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Positive Tweets Value Counts - Bars')
most_positive_tweets_textblob.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Positive_Tweets_Textblob_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# MOST NEGATIVE TWEETS

negative_tweets_textblob = tweets_smi_1[(tweets_smi_1['textblob_sentiment_polarity'] == '-1')]
most_negative_tweets_textblob = negative_tweets_textblob.value_counts(ascending=False)

print('-------------------------')
print('Most Negative Tweets Head')
print(most_negative_tweets_textblob[:10])
print('-------------------------')

print('-------------------------')
print('Most Negative Tweets DTYPES')
print(most_negative_tweets_textblob.dtypes)
print('-------------------------')

number_most_negative_tweets_textblob = len(most_negative_tweets_textblob)

# number_most_negative_tweets_textblob = most_negative_tweets_textblob['textblob_sentiment_polarity'].cumsum()

print('-------------------------')
print('Most Negative Tweets Len')
print(number_most_negative_tweets_textblob)
print('-------------------------')


most_negative_tweets_textblob.to_csv('4_5_201_10_SMI1_Most_Negative_Tweets_Textblob_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# most_negative_tweets_textblob.to_excel('4_5_201_10_SMI1_Most_Negative_Tweets_Textblob.xlsx', header=True)

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Negative Tweets Value Counts')
most_negative_tweets_textblob.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Negative_Tweets_Textblob_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Negative Tweets Value Counts - Bars')
most_negative_tweets_textblob.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Negative_Tweets_Textblob_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


################################################################################################

# MOST subjective TWEETS

subjective_tweets_textblob = tweets_smi_1[(tweets_smi_1['textblob_sentiment_subjectivity'] == '1')]
most_subjective_tweets_textblob = subjective_tweets_textblob.value_counts(ascending=False)

print('-------------------------')
print('Most subjective Tweets Head')
print(most_subjective_tweets_textblob[:10])
print('-------------------------')

print('-------------------------')
print('Most subjective Tweets DTYPES')
print(most_subjective_tweets_textblob.dtypes)
print('-------------------------')

number_most_subjective_tweets_textblob = len(most_subjective_tweets_textblob)

# number_most_subjective_tweets_textblob = most_subjective_tweets_textblob['textblob_sentiment_subjectivity'].cumsum()

print('-------------------------')
print('Most subjective Tweets Len')
print(number_most_subjective_tweets_textblob)
print('-------------------------')

most_subjective_tweets_textblob.to_csv('4_5_201_10_SMI1_Most_Subjective_Tweets_Textblob_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# most_subjective_tweets_textblob.to_excel('4_5_201_10_SMI1_Most_Subjective_Tweets_Textblob.xlsx', header=True)


# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Subjective Tweets Value Counts')
most_subjective_tweets_textblob.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Subjective_Tweets_Textblob_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Subjective Tweets Value Counts - Bars')
most_subjective_tweets_textblob.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Subjective_Tweets_Textblob_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# MOST subjective TWEETS

subjective_tweets_textblob = tweets_smi_1[(tweets_smi_1['textblob_sentiment_subjectivity'] == '-1')]
most_subjective_tweets_textblob = subjective_tweets_textblob.value_counts(ascending=False)

print('-------------------------')
print('Most subjective Tweets Head')
print(most_subjective_tweets_textblob[:10])
print('-------------------------')

print('-------------------------')
print('Most subjective Tweets DTYPES')
print(most_subjective_tweets_textblob.dtypes)
print('-------------------------')

number_most_subjective_tweets_textblob = len(most_subjective_tweets_textblob)

# number_most_subjective_tweets_textblob = most_subjective_tweets_textblob['textblob_sentiment_subjectivity'].cumsum()

print('-------------------------')
print('Most subjective Tweets Len')
print(number_most_subjective_tweets_textblob)
print('-------------------------')


most_subjective_tweets_textblob.to_csv('4_5_201_10_SMI1_most_subjective_tweets_textblob_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# most_subjective_tweets_textblob.to_excel('4_5_201_10_SMI1_most_subjective_tweets_textblob.xlsx', header=True)

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Subjective Tweets - Value Counts')
most_subjective_tweets_textblob.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Subjective_Tweets_Textblob_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Subjective Tweets - Value Counts - Bars')
most_subjective_tweets_textblob.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Subjective_Tweets_Textblob_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()
######################################################################################################################

# SENTENCES ANALYSIS

textblob_sentences = textblob_obj_text_c.sentences

print('-------------------------')
print('TextBlob Sentences Head')
# print(textblob_sentences.head)
print('-------------------------')

 
# Create the pandas DataFrame 
textblob_sentences_df = pd.DataFrame(textblob_sentences) 

textblob_sentences_df.to_csv('4_5_201_SMI1_Textblob_Sentences_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# textblob_sentences_df.to_excel('4_5_201_SMI1_Textblob_Sentences.xlsx', header=True)

textblob_sentences_number = len(textblob_sentences)

print('-------------------------')
print('TextBlob Sentences Number')
print(textblob_sentences_number)
print('-------------------------')

# Create the pandas DataFrame 
textblob_sentences_number_df = pd.DataFrame([textblob_sentences_number]) 

textblob_sentences_number_df.to_csv('4_5_201_SMI1_Textblob_Sentences_Number_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# textblob_sentences_number_df.to_excel('4_5_201_SMI1_Textblob_Sentences_Number.xlsx', header=True)

tweets_smi_1.to_csv('4_5_201_05_SMI1_tweets_smi_1_SENTIMENTS_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_excel('4_5_201_05_SMI1_tweets_smi_1_SENTIMENTS.xlsx', header=True)


#################################################################################################################
#################################################################################################################


##################################################################################################
##################################################################################################
#
# 			SOCIAL NETWORK ANALYSIS AND GRAPHS SNA 
#
##################################################################################################
##################################################################################################

print('-- STARTING NETWORK GRAPHS -----------------')



#################################################################################################################

# Check Data Imported

tweets_shape = tweets_smi_1.shape # View number of rows and columms in a df

print('---')
print('Tweets Shape and Types')
print(tweets_smi_1.shape)
print(tweets_smi_1.dtypes)
print('---')

#################################################################################################################
#################################################################################################################
#################################################################################################################
####


network_radious = 100

print('---')
print('NETWORK RADIOUS')
print(network_radious)
print('---')





##############################################################################################################
#
#                                SNA - CLUSTER ANALYSIS #############  NEED TO DO!!!!
#
###################################################################s#######################################################

tweets_smi_1_n = tweets_smi_1[tweets_smi_1.network_weight >= 19000000]

# tweets_smi_1_n = tweets_smi_1_n.set_index('network_weigth')

# .reset_index(name='value_counts_bigrams_text_counts')

tweets_smi_1_n.reset_index()
tweets_smi_1_n.set_index('created')

print('77777777777777777777777---')
print('Tweets smi_1_n')
# print(tweets_smi_1_n.head)
print(tweets_smi_1_n.dtypes)
print('77777777777777777777777777---')

# tweets_smi_1_n.set_index('screenName', 'mentions_total_tuple', inplace=True)
# tweets_smi_1_n.set_index('screenName', 'mentions_total_tuple', inplace=True)

g_mentions_1 = nx.MultiDiGraph()
# g_mentions = nx.contracted_nodes(g_mentions_1) # TAKING TOO LONG =(

g_mentions = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'mentions_tuple')

# g_mentions.add_weighted_edges_from(tweets_smi_1_n['mentions_tuple'])
g_mentions.add_nodes_from('screenName')


# for names in tweets_smi_1_n['screenName']:
#	graph_mentions.add_nodes_from(tweets_smi_1_n['screenName'])
#	graph_mentions.add_edges_from(tweets_smi_1_n['mentions_total'])	

# graph_mentions.add_nodes_from(tweets_smi_1_n['screenName'])
# graph_mentions.add_edges_from(nbunch=tweets_smi_1_n['mentions_total_tuple'])	


# graph_mentions.add_edges_from(tweets_smi_1_n['mentions_total_tuple'])

# graph_mentions = nx.from_pandas_edgelist(tweets_smi_1_n['screenName'], tweets_smi_1_n['mentions_total'], ['network_weight'])
# graph_mentions = nx.from_pandas_edgelist(tweets_smi_1_n, source='screenName', target='mentions_total_tuple', edge_attr='network_weight')
# graph_mentions.add_edge(tweets_smi_1_n['mentions'])

graph_mentions_number_of_nodes = int(g_mentions.number_of_nodes())
graph_mentions_number_of_edges = int(g_mentions.number_of_edges())
graph_mentions_list_of_all_nodes = list(g_mentions.nodes())
graph_mentions_list_of_all_edges = list(g_mentions.edges())

graph_mentions_degree_of_all_nodes = 'x' # dict(g_mentions.edges(data = True))
graph_mentions_all_neighbours_main_SMI1 = 'x' # list(g_mentions.neighbours('michellephan'))

graph_mentions_total_number_of_self_loops = int(g_mentions.number_of_selfloops())

print('Total Number of Nodes : ', int(g_mentions.number_of_nodes()))
print('Total Number of Edges : ', int(g_mentions.number_of_edges()))
# print('List of All Nodes : ', list(g_mentions.nodes()))
# print('List of All Edges : ', list(g_mentions.edges()))

# print('Degree for All Nodes : ', dict(g_mentions.edges(data = True)))
# print('List All Nodes That Go in a Single Step from node main SMI : ', list(g_mentions.neighbours('michellephan')))

print('Total Number of Self-Loops : ', int(g_mentions.number_of_selfloops()))
print('List All Nodes with Self-Loops : ', list(g_mentions.nodes_with_selfloops()))

# NODE SIZE

node_size = tweets_smi_1['network_weight']

# node_size = [0.0005 * nx.get_node_attributes(g_mentions, 'network_weight')[v] for v in g_mentions]
# node_size = [0.0005 * nx.get_node_attributes('mentions', 'network_weight')[v] for v in g_mentions]

################

# MENTIONS NETWORK kamada_kawai_layout

# node_size='node_size',

# kamada_kawai_layout

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Network - Kamada Kawai Layout')
nx.draw_kamada_kawai(g_mentions, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=18)
# nx.draw_networkx_edge_labels(g_mentions, pos=nx.fruchterman_reingold_layout(g_mentions), rotate=True)  # edge_labels='mentions_total_tuple', pos='mentions_total_tuple', , label_pos=0.5, pos=1, font_color='#9DC6D8', alpha=0.6, font_size=12, bbox=None, ax=None, **kwds

# draw_networkx_labels(graph_mentions)
nx.draw_networkx_edge_labels(g_mentions, pos=nx.fruchterman_reingold_layout(g_mentions))
# plt.xlabel('Mentions')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Mentions_Network_kamada_kawai_layout_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del g_mentions
del g_mentions_1

##############################################

# changed graph type on top 

##############################################


# MENTIONS NETWORK GRAPH ring_of_cliques

g_mentions_rg = nx.ring_of_cliques(6, 100)

g_mentions_rg = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'mentions')
g_mentions_rg.add_nodes_from('screenName')


# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Network - Ring of Cliques') 
nx.draw(g_mentions_rg, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
# strategy_saturation_largest_first(g_mentions_rg)
# draw_networkx_labels(graph_mentions)
# draw_networkx_edge_labels(graph_mentions, pos=nx.fruchterman_reingold_layout(g_mentions))
# plt.xlabel('Mentions')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Mentions_Network_ring_of_cliques_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLES

del g_mentions_rg

##############################################

# MENTIONS NETWORK GRAPH margulis_gabber_galil_graph

g_mentions_mg = nx.margulis_gabber_galil_graph(6)

g_mentions_mg = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'mentions')
g_mentions_mg.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Network - Margulis Gabber Galil')


# pos_mg = graphviz_layout(g_mentions_mg, prog='twopi')

pos_mg = nx.fruchterman_reingold_layout(g_mentions_mg)
# pos_mg = nx.circular_layout(g_mentions_mg)

nx.draw(g_mentions_mg, pos_mg, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_mentions_mg, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_mentions_mg)
# draw_networkx_edge_labels(g_mentions_mg, pos=nx.fruchterman_reingold_layout(g_mentions))
# plt.xlabel('Mentions')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Mentions_Network_margulis_gabber_galil_graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLES

del g_mentions_mg
del pos_mg

##############################################

# MENTIONS NETWORK GRAPH balanced tree

g_mentions_bt = nx.balanced_tree(6, 6)

g_mentions_bt = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'mentions')
g_mentions_bt.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Network - Circular Tree')


# pos_bt = graphviz_layout(g_mentions_bt, prog='twopi')

pos_bt = nx.fruchterman_reingold_layout(g_mentions_bt)
# pos_bt = nx.circular_layout(g_mentions_bt)

nx.draw(g_mentions_bt, pos_bt, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_mentions_bt, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_mentions_bt)
# draw_networkx_edge_labels(g_mentions_bt, pos=nx.fruchterman_reingold_layout(g_mentions))
# plt.xlabel('Mentions')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Mentions_Network_Circular_Tree_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLES

del g_mentions_bt
del pos_bt

##############################################

# MENTIONS NETWORK GRAPH Spring

g_mentions_sl = nx.MultiDiGraph()

g_mentions_sl = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'mentions')
g_mentions_sl.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Network - Spring Layout')


# pos_sl = graphviz_layout(g_mentions_sl, prog='twopi')

# pos_sl = nx.fruchterman_reingold_layout(g_mentions_sl)
pos_sl = nx.circular_layout(g_mentions_sl)

nx.spring_layout(g_mentions_sl)
nx.draw(g_mentions_sl, pos_sl, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_mentions_sl, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_mentions_sl)
# draw_networkx_edge_labels(g_mentions_sl, pos=nx.fruchterman_reingold_layout(g_mentions))
# plt.xlabel('Mentions')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Mentions_Network_Spring_Layout_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLES

del g_mentions_sl
del pos_sl

##############################################

# dorogovtsev_goltsev_mendes_graph graph

g_mentions_gm = nx.dorogovtsev_goltsev_mendes_graph(6)

g_mentions_gm = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'mentions')
g_mentions_gm.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Network - Dorogovtsev Goltsev Mendes')


# pos_gm = graphviz_layout(g_mentions_gm, prog='twopi')

pos_gm = nx.fruchterman_reingold_layout(g_mentions_gm)
# pos_gm = nx.circular_layout(g_mentions_gm)

nx.draw(g_mentions_gm, pos_gm, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_mentions_gm, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_mentions_gm)
# draw_networkx_edge_labels(g_mentions_gm, pos=nx.fruchterman_reingold_layout(g_mentions))
# plt.xlabel('Mentions')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Mentions_Network_Dorogovtsev_Goltsev_Mendes_graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLES

del g_mentions_gm
del pos_gm

##############################################

# MENTIONS NETWORK GRAPH krackhardt_kite_graph

g_mentions_kk = nx.krackhardt_kite_graph()

g_mentions_kk = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'mentions')
g_mentions_kk.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Network - Krackhardt Kite Graph')

# pos_kk = graphviz_layout(g_mentions_kk, prog='twopi')

pos_kk = nx.fruchterman_reingold_layout(g_mentions_kk)
pos_kk = nx.circular_layout(g_mentions_kk)

nx.draw(g_mentions_kk, pos_kk, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_mentions_kk, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_mentions_kk)
# draw_networkx_edge_labels(g_mentions_kk, pos=nx.fruchterman_reingold_layout(g_mentions))
# plt.xlabel('Mentions')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Mentions_Network_Krackhardt_Kite_Graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# DELETE VARIABLES

del g_mentions_kk
del pos_kk

###################################################


# MENTIONS NETWORK GRAPH PATH

g_mentions_pg = nx.path_graph(6)

g_mentions_pg = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'mentions_tuple')
g_mentions_pg.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Network - Path')

# balanced_tree(

# pos_pg = graphviz_layout(g_mentions_pg, prog='twopi')

pos_pg = nx.fruchterman_reingold_layout(g_mentions_pg)

# pos_pg = nx.circular_layout(g_mentions_pg)

nx.draw(g_mentions_pg, pos_pg, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_mentions_pg, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_mentions_pg)
# draw_networkx_edge_labels(g_mentions_pg, pos=nx.fruchterman_reingold_layout(g_mentions))
# plt.xlabel('Mentions')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Mentions_Network_Path_Graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLES

del g_mentions_pg
del pos_pg

####################################################################################################
# python-graph-gallery.com/320-basic-network-from-pandas-data-frame/
# datacamp.com/community/tutorials/social-networ-analysis-python

tweets_smi_1_n.set_index('created')


print('-----------')
print('tweets_smi_1 dtypes')
print(tweets_smi_1.dtypes)
print('-----------')

number_total_tweets = len(tweets_smi_1_n['created'])

### 

# DETECTING COMMUNITY LOUVAIN

# tweets_smi_1_n.set_index('screenName', 'mentions', inplace=True)

G_community_louvain_screenname_mentions = nx.MultiDiGraph()

# Create Connections between nodes

# smi1_matrix_mentions

G_community_louvain_screenname_mentions = nx.from_pandas_edgelist(tweets_smi_1_n, 'mentions_tuple', 'screenName', ['network_weight'])
G_community_louvain_screenname_mentions.add_nodes_from('screenName')

# G_community_louvain_screenname_mentions = nx.from_pandas_edgelist(smi1_matrix_mentions, 'screenName', 'mentions', ['network_weight'], edge_attr=True)


# CREATE NETWORK community_louvain_screenname_mentions

G_community_louvain_screenname_mentions = nx.erdos_renyi_graph(100,0.01)


# CREATE BEST PARTITION 

G_community_louvain_screenname_mentions_partition = community_louvain.best_partition(G_community_louvain_screenname_mentions)


# GET NETWORK STATISTICS

G_community_louvain_screenname_mentions_nodes_number = len(G_community_louvain_screenname_mentions.nodes())

print('---')
print('G_community_louvain_screenname_mentions_nodes_number:')
print(G_community_louvain_screenname_mentions_nodes_number)
print('---')

G_community_louvain_screenname_mentions_edges_number = len(G_community_louvain_screenname_mentions.edges())

print('---')
print('G_community_louvain_screenname_mentions_edges_number:')
print(G_community_louvain_screenname_mentions_edges_number)
print('---')

G_community_louvain_screenname_mentions_average_clustering = nx.average_clustering(G_community_louvain_screenname_mentions)

print('---')
print('G_community_louvain_screenname_mentions_average_clustering:')
print(G_community_louvain_screenname_mentions_average_clustering)
print('---')


# G_community_louvain_screenname_mentions_eccentricity = nx.eccentricity(G_community_louvain_screenname_mentions)

print('---')
print('G_community_louvain_screenname_mentions_eccentricity:')
# print(G_community_louvain_screenname_mentions_eccentricity)
print('---')

G_community_louvain_screenname_mentions_density = nx.density(G_community_louvain_screenname_mentions)

print('---')
print('G_community_louvain_screenname_mentions_density:')
# print(G_community_louvain_screenname_mentions_density)
print('---')

# initialize list of Lists 
community_louvain_screenname_mentions_network_numbers = [['G_community_louvain_screenname_mentions_nodes_number', G_community_louvain_screenname_mentions_nodes_number], ['G_community_louvain_screenname_mentions_edges_number', G_community_louvain_screenname_mentions_edges_number], ['G_community_louvain_screenname_mentions_average_clustering', G_community_louvain_screenname_mentions_average_clustering], ['G_community_louvain_screenname_mentions_eccentricity', 'G_community_louvain_screenname_mentions_eccentricity'], ['G_community_louvain_screenname_mentions_density', 'G_community_louvain_screenname_mentions_density']]
 
# Create the pandas DataFrame 
community_louvain_screenname_mentions_network_numbers_df = pd.DataFrame(community_louvain_screenname_mentions_network_numbers, columns = ['community_louvain_screenname_mentions_network_numbers_item', 'community_louvain_screenname_mentions_network_numbers_value']) 

community_louvain_screenname_mentions_network_numbers_df.to_csv('4_5A_180_SMI1_Community_Louvain_Screenname_Mentions_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# community_louvain_screenname_mentions_network_numbers_df.to_excel('4_5A_180_SMI1_community_louvain_screenname_mentions_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_community_louvain_screenname_mentions_betweenness_centrality = nx.betweenness_centrality(G_community_louvain_screenname_mentions)

print('---')
print('G_community_louvain_screenname_mentions_betweenness_centrality:')
# print(G_community_louvain_screenname_mentions_betweenness_centrality)
print('---')

# Closeness Centrality

# G_community_louvain_screenname_mentions_closeness_centrality = nx.closeness_centrality(G_community_louvain_screenname_mentions)

print('---')
print('G_community_louvain_screenname_mentions_closeness_centrality:')
# print(G_community_louvain_screenname_mentions_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_community_louvain_screenname_mentions_eigenvector_centrality = nx.eigenvector_centrality(G_community_louvain_screenname_mentions)

print('---')
print('G_community_louvain_screenname_mentions_eigenvector_centrality:')
# print(G_community_louvain_screenname_mentions_eigenvector_centrality)
print('---')

# initialize list of Lists 
community_louvain_screenname_mentions_network_measures = [['G_community_louvain_screenname_mentions_betweenness_centrality', 'G_community_louvain_screenname_mentions_betweenness_centrality'], ['G_community_louvain_screenname_mentions_closeness_centrality', 'G_community_louvain_screenname_mentions_closeness_centrality'], ['G_community_louvain_screenname_mentions_eigenvector_centrality', 'G_community_louvain_screenname_mentions_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# community_louvain_screenname_mentions_network_measures_df = pd.DataFrame(community_louvain_screenname_mentions_network_measures, columns = ['community_louvain_screenname_mentions_network_measures_item', 'community_louvain_screenname_mentions_network_measures_value']) 

# community_louvain_screenname_mentions_network_measures_df.to_csv('4_5A_180_SMI1_community_louvain_screenname_mentions_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# community_louvain_screenname_mentions_network_measures_df.to_excel('4_5A_180_SMI1_community_louvain_screenname_mentions_network_measures_DF.xlsx', header=True)

# NETWORK community_louvain_screenname_mentions

G_community_louvain_screenname_mentions_network_info = nx.info(G_community_louvain_screenname_mentions)

# Create the pandas DataFrame 
# community_louvain_screenname_mentions_network_info_df = pd.DataFrame(G_community_louvain_screenname_mentions_network_info, columns = ['G_community_louvain_screenname_mentions_network_info']) 

# community_louvain_screenname_mentions_network_info_df.to_csv('4_5A_180_SMI1_community_louvain_screenname_mentions_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# community_louvain_screenname_mentions_network_info_df.to_excel('4_5A_180_SMI1_Community_Louvain_Screenname_Mentions_Network_Info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('community_louvain_screenname_mentions_network INFO')
print(G_community_louvain_screenname_mentions_network_info)
print('---')


# PLOT NETWORK GRAPH

# layout_community_louvain_screenname_mentions = nx.random_layout(G_community_louvain_screenname_mentions, iterations=50)
G_community_louvain_screenname_mentions_network_size = float(len(set(G_community_louvain_screenname_mentions_partition.values())))
# nx.random_layout

G_community_louvain_screenname_mentions_network_pos = nx.spring_layout(G_community_louvain_screenname_mentions)
count = 0.

for com in set(G_community_louvain_screenname_mentions_partition.values()):
	G_community_louvain_screenname_mentions_network_count = count + 1.
	list_nodes = [nodes for nodes in G_community_louvain_screenname_mentions_partition.keys() if G_community_louvain_screenname_mentions_partition[nodes] == com]
	nx.draw_networkx_nodes(G_community_louvain_screenname_mentions, G_community_louvain_screenname_mentions_network_pos, list_nodes, node_size=20, node_color = str(G_community_louvain_screenname_mentions_network_count / G_community_louvain_screenname_mentions_network_size))

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Mentions - Louvain Network')
# nx.draw(G_community_louvain_screenname_mentions, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
# nx.draw(G_community_louvain_screenname_mentions, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
# edge_labels_community_louvain_screenname_mentions = nx.get_edge_attributes(G_community_louvain_screenname_mentions, tweets_smi_1_n['screenName']) # , tweets_smi_1_n['mentions']
nx.draw(G_community_louvain_screenname_mentions, G_community_louvain_screenname_mentions_network_pos, with_labels=True, node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9)
# draw_networkx_edge_labels(G_screenname_mentions, G_community_louvain_screenname_mentions_network_pos)
plt.xlabel('')
plt.ylabel('')
# plt.legend(G_community_louvain_screenname_mentions) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_Louvain_Community_Louvain_Screenname_Mentions_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('---')
print('Done Graph Network 1')
print('---')


## DELETE VARIABLE

del G_community_louvain_screenname_mentions_network_info
del G_community_louvain_screenname_mentions
del community_louvain_screenname_mentions_network_measures
del community_louvain_screenname_mentions_network_measures_df
del community_louvain_screenname_mentions_network_numbers
del community_louvain_screenname_mentions_network_numbers_df

######################################################################################################


# CREATE NETWORK SCREENNAME_MENTIONS


# G_screenname_mentions = nx.MultiDiGraph()

G_screenname_mentions_1 = nx.MultiDiGraph()
# G_screenname_mentions = nx.contracted_nodes(G_screenname_mentions_1)


# Create Connections between nodes

G_screenname_mentions = nx.from_pandas_edgelist(tweets_smi_1_n, 'mentions_tuple', 'screenName', ['network_weight'])

# G_screenname_mentions = G_screenname_mentions.add_edges_from(G_screenname_mentions.edges())
# G_screenname_mentions = G_screenname_mentions.add_nodes_from(G_screenname_mentions.nodes())
# G_screenname_mentions = nx.from_pandas_edgelist(smi1_matrix_mentions, 'screenName', 'mentions', ['network_weight'], edge_attr=True)


# GET NETWORK STATISTICS

G_screenname_mentions_nodes_number = len(G_screenname_mentions.nodes())

print('---')
print('G_screenname_mentions_nodes_number:')
# print(G_screenname_mentions_nodes_number)
print('---')

G_screenname_mentions_edges_number = len(G_screenname_mentions.edges())

print('---')
print('G_screenname_mentions_edges_number:')
print(G_screenname_mentions_edges_number)
print('---')

# G_screenname_mentions_average_clustering = nx.average_clustering(G_screenname_mentions)

print('---')
print('G_screenname_mentions_average_clustering:')
# print(G_screenname_mentions_average_clustering)
print('---')


# G_screenname_mentions_eccentricity = nx.eccentricity(G_screenname_mentions)

print('---')
print('G_screenname_mentions_eccentricity:')
# print(G_screenname_mentions_eccentricity)
print('---')

G_screenname_mentions_density = nx.density(G_screenname_mentions)

print('---')
print('G_screenname_mentions_density:')
# print(G_screenname_mentions_density)
print('---')

# initialize list of Lists 
screenname_mentions_network_numbers = [['G_screenname_mentions_nodes_number', G_screenname_mentions_nodes_number], ['G_screenname_mentions_edges_number', G_screenname_mentions_edges_number], ['G_screenname_mentions_average_clustering', 'G_screenname_mentions_average_clustering'], ['G_screenname_mentions_eccentricity', 'G_screenname_mentions_eccentricity'], ['G_screenname_mentions_density', 'G_screenname_mentions_density']]
 
# Create the pandas DataFrame 
screenname_mentions_network_numbers_df = pd.DataFrame(screenname_mentions_network_numbers, columns = ['screenname_mentions_network_numbers_item', 'screenname_mentions_network_numbers_value']) 

screenname_mentions_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Mentions_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_mentions_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Mentions_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_mentions_betweenness_centrality = nx.betweenness_centrality(G_screenname_mentions)

print('---')
print('G_screenname_mentions_betweenness_centrality:')
# print(G_screenname_mentions_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_mentions_closeness_centrality = nx.closeness_centrality(G_screenname_mentions)

print('---')
print('G_screenname_mentions_closeness_centrality:')
# print(G_screenname_mentions_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_mentions_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_mentions)

print('---')
print('G_screenname_mentions_eigenvector_centrality:')
# print(G_screenname_mentions_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_mentions_network_measures = [['G_screenname_mentions_betweenness_centrality', 'G_screenname_mentions_betweenness_centrality'], ['G_screenname_mentions_closeness_centrality', 'G_screenname_mentions_closeness_centrality'], ['G_screenname_mentions_eigenvector_centrality', 'G_screenname_mentions_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_mentions_network_measures_df = pd.DataFrame(screenname_mentions_network_measures, columns = ['screenname_mentions_network_measures_item', 'screenname_mentions_network_measures_value']) 

# screenname_mentions_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Mentions_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_mentions_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Mentions_network_measures_DF.xlsx', header=True)

# NETWORK SCREENNAME_MENTIONS

G_screenname_mentions_network_info = nx.info(G_screenname_mentions)

# Create the pandas DataFrame 
# screenname_mentions_network_info_df = pd.DataFrame(G_screenname_mentions_network_info, columns = ['G_screenname_mentions_network_info']) 

# screenname_mentions_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Mentions_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_mentions_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Mentions_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_mentions_network INFO')
print(G_screenname_mentions_network_info)
print('---')

# PLOT NETWORK GRAPH

# RANDOM LAYOUT 

# random_layout_screenname_mentions = nx.random_layout(G_screenname_mentions, iterations=50)
# mentions_size = [G_screenname_mentions.degree(mentions) * 80 for mentions in mentions]

nx.random_layout

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Mentions - Network')

node_color = [G_screenname_mentions.degree(v) for v in G_screenname_mentions] 
# node colour is a list of degrees of nodes 
 
# node_size = [0.0005 * nx.get_node_attributes(G_screenname_mentions, tweets_smi_1_n['network_weight'])[v] for v in G_screenname_mentions] 
# size of node is a list of population of cities 
# edge_width = [0.0015 * G_screenname_mentions[u][v]['weight'] for u, v in G_screenname_mentions.edges()] 
# width of edge is a list of weight of edges 
# nx.draw_networkx(G_screenname_mentions, node_color = node_color, alpha = 0.7, with_labels = True, width = edge_width, edge_color ='.4', cmap = plt.cm.Blues) # node_size = node_size,


nx.draw(G_screenname_mentions, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(G_screenname_mentions, edge_labels=edge_labels_screenname_mentions)
# edge_labels_screenname_mentions = nx.get_edge_attributes(G_screenname_mentions, smi1_matrix_mentions['value'])
# draw_network_edge_labels(G_screenname_mentions, edge_labels=edge_labels_screenname_mentions)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_RD0_ScreenName_Mentions_Random_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT NETWORK


# random_layout_screenname_mentions = nx.random_layout(G_screenname_mentions, iterations=50)
# mentions_size = [G_screenname_mentions.degree(mentions) * 80 for mentions in mentions]
# nx.random_layout

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Mentions - Network')
nx.draw(G_screenname_mentions, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
# edge_labels_screenname_mentions = nx.get_edge_attributes(G_screenname_mentions, smi1_matrix_mentions['value'])
# draw_network_edge_labels(G_screenname_mentions, edge_labels=edge_labels_screenname_mentions)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_RD0_ScreenName_Mentions_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT CIRCULAR NETWORK

nx.circular_layout(G_screenname_mentions)

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Mentions - Network')
nx.draw(G_screenname_mentions, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
# edge_labels_screenname_mentions = nx.get_edge_attributes(G_screenname_mentions, smi1_matrix_mentions['value'])
# draw_network_edge_labels(G_screenname_mentions, edge_labels=edge_labels_screenname_mentions)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_RD0_ScreenName_Mentions_Circular_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('---')
print('Done Graph Network 1')
print('---')

## DELETE VARIABLE

del G_screenname_mentions

#################################################################################################################

# python-graph-gallery.com/320-basic-network-from-pandas-data-frame/
# datacamp.com/community/tutorials/social-networ-analysis-python

# CREATE NETWORK SCREENNAME_hashtags

# tweets_smi_1_n = tweets_smi_1_n.set_index('screenName', 'hashtags', 'hashtags_total', inplace=True)

G_screenname_hashtags = nx.MultiDiGraph()

# Create Connections between nodes

# G_screenname_hashtags = nx.from_pandas_edgelist(smi1_matrix_hashtags, 'value', 'hashtags', ['network_weight'])

G_screenname_hashtags = nx.from_pandas_edgelist(tweets_smi_1_n, 'hashtags_tuple', 'screenName', ['network_weight'], create_using=nx.DiGraph())

# GET NETWORK STATISTICS

G_screenname_hashtags_nodes_number = len(G_screenname_hashtags.nodes())

print('---')
print('G_screenname_hashtags_nodes_number:')
print(G_screenname_hashtags_nodes_number)
print('---')

G_screenname_hashtags_edges_number = len(G_screenname_hashtags.edges())

print('---')
print('G_screenname_hashtags_edges_number:')
print(G_screenname_hashtags_edges_number)
print('---')

# G_screenname_hashtags_average_clustering = nx.average_clustering(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_average_clustering:')
# print(G_screenname_hashtags_average_clustering)
print('---')


# G_screenname_hashtags_eccentricity = nx.eccentricity(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_eccentricity:')
# print(G_screenname_hashtags_eccentricity)
print('---')

# initialize list of Lists 
screenname_hashtags_network_numbers = [['G_screenname_hashtags_nodes_number', G_screenname_hashtags_nodes_number], ['G_screenname_hashtags_edges_number', G_screenname_hashtags_edges_number], ['G_screenname_hashtags_average_clustering', 'G_screenname_hashtags_average_clustering'], ['G_screenname_hashtags_eccentricity', 'G_screenname_hashtags_eccentricity']]
 
# Create the pandas DataFrame 
screenname_hashtags_network_numbers_df = pd.DataFrame(screenname_hashtags_network_numbers, columns = ['screenname_hashtags_network_numbers_item', 'screenname_hashtags_network_numbers_value']) 

screenname_hashtags_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Hashtags_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_hashtags_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Hashtags_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_hashtags_betweenness_centrality = nx.betweenness_centrality(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_betweenness_centrality:')
# print(G_screenname_hashtags_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_hashtags_closeness_centrality = nx.closeness_centrality(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_closeness_centrality:')
# print(G_screenname_hashtags_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_hashtags_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_eigenvector_centrality:')
# print(G_screenname_hashtags_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_hashtags_network_measures = [['G_screenname_hashtags_betweenness_centrality', 'G_screenname_hashtags_betweenness_centrality'], ['G_screenname_hashtags_closeness_centrality', 'G_screenname_hashtags_closeness_centrality'], ['G_screenname_hashtags_eigenvector_centrality', 'G_screenname_hashtags_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_hashtags_network_measures_df = pd.DataFrame(screenname_hashtags_network_measures, columns = ['screenname_hashtags_network_measures_item', 'screenname_hashtags_network_measures_value']) 

# screenname_hashtags_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Hashtags_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_hashtags_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Hashtags_network_measures_DF.xlsx', header=True)

# NETWORK SCREENNAME_hashtags

G_screenname_hashtags_network_info = nx.info(G_screenname_hashtags)

# Create the pandas DataFrame 
# screenname_hashtags_network_info_df = pd.DataFrame(G_screenname_hashtags_network_info, columns = ['G_screenname_hashtags_network_info']) 

# screenname_hashtags_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Hashtags_Network_Info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_hashtags_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Hashtags_Network_Info_DF.xlsx', header=True)

print('--- nEED TO SAVE')
print(main_smi)
print('screenname_hashtags_network INFO')
print(G_screenname_hashtags_network_info)
print('---')

# PLOT NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Hashtags - Network Graph')
nx.draw(G_screenname_hashtags, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_ScreenName_Hashtags_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network 1')
print('---')


#############

# hashtagS NETWORK kamada_kawai_layout

# kamada_kawai_layout

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Network - Kamada Kawai Layout')

# radious='network_radious',
nx.draw_kamada_kawai(G_screenname_hashtags, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=18)

# draw_networkx_labels(graph_hashtags)
# draw_networkx_edge_labels(graph_hashtags, pos=nx.fruchterman_reingold_layout(g_hashtags))
# plt.xlabel('Hashtags')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Hashtags_Network_Kamada_Kawai_Layout_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLE

del G_screenname_hashtags

##############################################

# changed graph type on top 

##############################################


# hashtagS NETWORK GRAPH ring_of_cliques

g_hashtags_rg = nx.ring_of_cliques(6, 100)

g_hashtags_rg = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'hashtags')
g_hashtags_rg.add_nodes_from('screenName')


# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Network - Ring of Cliques') 
nx.draw(g_hashtags_rg, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
# strategy_saturation_largest_first(g_hashtags_rg)
# draw_networkx_labels(graph_hashtags)
# draw_networkx_edge_labels(graph_hashtags, pos=nx.fruchterman_reingold_layout(g_hashtags))
# plt.xlabel('Hashtags')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Hashtags_Network_Ring_of_Cliques_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del g_hashtags_rg

##############################################

# hashtagS NETWORK GRAPH margulis_gabber_galil_graph

g_hashtags_gm = nx.margulis_gabber_galil_graph(6)

g_hashtags_gm = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'hashtags')
g_hashtags_gm.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Network - Margulis Gabber Galil Graph')


# pos_gm = graphviz_layout(g_hashtags_gm, prog='twopi')

pos_gm = nx.fruchterman_reingold_layout(g_hashtags_gm)

# pos_gm = nx.circular_layout(g_hashtags_gm)

nx.draw(g_hashtags_gm, pos_gm, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_hashtags_gm, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_hashtags_gm)
# draw_networkx_edge_labels(g_hashtags_gm, pos=nx.fruchterman_reingold_layout(g_hashtags))
# plt.xlabel('Hashtags')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Hashtags_Network_Margulis_Gabber_Galil_Graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del g_hashtags_gm
del pos_gm

##############################################

# hashtagS NETWORK GRAPH balanced tree

g_hashtags_bt = nx.balanced_tree(6, 6)

g_hashtags_bt = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'hashtags')
g_hashtags_bt.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Network - Balanced Tree')


# pos_bt = graphviz_layout(g_hashtags_bt, prog='twopi')

# pos_bt = nx.fruchterman_reingold_layout(g_hashtags_bt)

pos_bt = nx.circular_layout(g_hashtags_bt)

nx.draw(g_hashtags_bt, pos_bt, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_hashtags_bt, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_hashtags_bt)
# draw_networkx_edge_labels(g_hashtags_bt, pos=nx.fruchterman_reingold_layout(g_hashtags))
# plt.xlabel('Hashtags')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_hashtags_Network_Balanced_Tree_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del g_hashtags_bt

##############################################

# hashtagS NETWORK GRAPH cubical_graph

g_hashtags_cg = nx.cubical_graph()

g_hashtags_cg = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'hashtags')
g_hashtags_cg.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Network - Cubical Graph')


# pos_cg = graphviz_layout(g_hashtags_cg, prog='twopi')

pos_cg = nx.fruchterman_reingold_layout(g_hashtags_cg)

# pos_cg = nx.circular_layout(g_hashtags_cg)

nx.draw(g_hashtags_cg, pos_cg, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_hashtags_cg, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_hashtags_cg)
# draw_networkx_edge_labels(g_hashtags_cg, pos=nx.fruchterman_reingold_layout(g_hashtags))
# plt.xlabel('Hashtags')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_hashtags_Network_Cubical_Graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del g_hashtags_cg

##############################################

# dorogovtsev_goltsev_mendes_graph graph

g_hashtags_gm = nx.dorogovtsev_goltsev_mendes_graph(6)

g_hashtags_gm = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'hashtags')
g_hashtags_gm.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Network - Dorogovtsev Goltsev Mendes Graph')

# pos_gm = graphviz_layout(g_hashtags_gm, prog='twopi')

pos_gm = nx.fruchterman_reingold_layout(g_hashtags_gm)
# pos_gm = nx.circular_layout(g_hashtags_gm)

nx.draw(g_hashtags_gm, pos_gm, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_hashtags_gm, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_hashtags_gm)
# draw_networkx_edge_labels(g_hashtags_gm, pos=nx.fruchterman_reingold_layout(g_hashtags))
# plt.xlabel('Hashtags')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Hashtags_Network_Dorogovtsev_Goltsev_Mendes_Graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del g_hashtags_gm

##############################################

# hashtagS NETWORK GRAPH krackhardt_kite_graph

g_hashtags_kk = nx.krackhardt_kite_graph()

g_hashtags_kk = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'hashtags')
g_hashtags_kk.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Network - Krackhardt Kite Graph')

# pos_kk = graphviz_layout(g_hashtags_kk, prog='twopi')

pos_kk = nx.fruchterman_reingold_layout(g_hashtags_kk)
# pos_kk = nx.circular_layout(g_hashtags_kk)

nx.draw(g_hashtags_kk, pos_kk, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_hashtags_kk, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_hashtags_kk)
# draw_networkx_edge_labels(g_hashtags_kk, pos=nx.fruchterman_reingold_layout(g_hashtags))
# plt.xlabel('Hashtags')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Hashtags_Network_Krackhardt_Kite_Graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del g_hashtags_kk

###################################################

# hashtagS NETWORK GRAPH PATH

g_hashtags_pg = nx.path_graph(6)

g_hashtags_pg = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'hashtags_tuple')
g_hashtags_pg.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Network - Path')

# balanced_tree(

# pos_pg = graphviz_layout(g_hashtags_pg, prog='twopi')

pos_pg = nx.fruchterman_reingold_layout(g_hashtags_pg)

# pos_pg = nx.circular_layout(g_hashtags_pg)

nx.draw(g_hashtags_pg, pos_pg, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_hashtags_pg, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_hashtags_pg)
# draw_networkx_edge_labels(g_hashtags_pg, pos=nx.fruchterman_reingold_layout(g_hashtags))
# plt.xlabel('Hashtags')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Hashtags_Network_Path_Graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del g_hashtags_pg

####################################################################################################
# python-graph-gallery.com/320-basic-network-from-pandas-data-frame/
# datacamp.com/community/tutorials/social-networ-analysis-python

tweets_smi_1_n.set_index('created')

network_radious = 50

number_total_tweets = len(tweets_smi_1_n['created'])

### 

# DETECTING COMMUNITY LOUVAIN

# tweets_smi_1_n.set_index('screenName', 'hashtags', inplace=True)

G_community_louvain_screenname_hashtags = nx.MultiDiGraph()

# Create Connections between nodes

# smi1_matrix_hashtags

G_community_louvain_screenname_hashtags = nx.from_pandas_edgelist(tweets_smi_1_n, 'hashtags_tuple', 'screenName', ['network_weight'])
G_community_louvain_screenname_hashtags.add_nodes_from('screenName')

# G_community_louvain_screenname_hashtags = nx.from_pandas_edgelist(smi1_matrix_hashtags, 'screenName', 'hashtags', ['network_weight'], edge_attr=True)


# CREATE NETWORK community_louvain_screenname_hashtags

G_community_louvain_screenname_hashtags = nx.erdos_renyi_graph(100,0.01)


# CREATE BEST PARTITION 

G_community_louvain_screenname_hashtags_partition = community_louvain.best_partition(G_community_louvain_screenname_hashtags)


# GET NETWORK STATISTICS

G_community_louvain_screenname_hashtags_nodes_number = len(G_community_louvain_screenname_hashtags.nodes())

print('---')
print('G_community_louvain_screenname_hashtags_nodes_number:')
print(G_community_louvain_screenname_hashtags_nodes_number)
print('---')

G_community_louvain_screenname_hashtags_edges_number = len(G_community_louvain_screenname_hashtags.edges())

print('---')
print('G_community_louvain_screenname_hashtags_edges_number:')
print(G_community_louvain_screenname_hashtags_edges_number)
print('---')

G_community_louvain_screenname_hashtags_average_clustering = nx.average_clustering(G_community_louvain_screenname_hashtags)

print('---')
print('G_community_louvain_screenname_hashtags_average_clustering:')
print(G_community_louvain_screenname_hashtags_average_clustering)
print('---')


# G_community_louvain_screenname_hashtags_eccentricity = nx.eccentricity(G_community_louvain_screenname_hashtags)

print('---')
print('G_community_louvain_screenname_hashtags_eccentricity:')
# print(G_community_louvain_screenname_hashtags_eccentricity)
print('---')

G_community_louvain_screenname_hashtags_density = nx.density(G_community_louvain_screenname_hashtags)

print('---')
print('G_community_louvain_screenname_hashtags_density:')
# print(G_community_louvain_screenname_hashtags_density)
print('---')

# initialize list of Lists 
community_louvain_screenname_hashtags_network_numbers = [['G_community_louvain_screenname_hashtags_nodes_number', G_community_louvain_screenname_hashtags_nodes_number], ['G_community_louvain_screenname_hashtags_edges_number', G_community_louvain_screenname_hashtags_edges_number], ['G_community_louvain_screenname_hashtags_average_clustering', G_community_louvain_screenname_hashtags_average_clustering], ['G_community_louvain_screenname_hashtags_eccentricity', 'G_community_louvain_screenname_hashtags_eccentricity'], ['G_community_louvain_screenname_hashtags_density', 'G_community_louvain_screenname_hashtags_density']]
 
# Create the pandas DataFrame 
community_louvain_screenname_hashtags_network_numbers_df = pd.DataFrame(community_louvain_screenname_hashtags_network_numbers, columns = ['community_louvain_screenname_hashtags_network_numbers_item', 'community_louvain_screenname_hashtags_network_numbers_value']) 

community_louvain_screenname_hashtags_network_numbers_df.to_csv('4_5A_180_SMI1_Community_Louvain_Screenname_Hashtags_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# community_louvain_screenname_hashtags_network_numbers_df.to_excel('4_5A_180_SMI1_community_louvain_screenname_hashtags_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_community_louvain_screenname_hashtags_betweenness_centrality = nx.betweenness_centrality(G_community_louvain_screenname_hashtags)

print('---')
print('G_community_louvain_screenname_hashtags_betweenness_centrality:')
# print(G_community_louvain_screenname_hashtags_betweenness_centrality)
print('---')

# Closeness Centrality

# G_community_louvain_screenname_hashtags_closeness_centrality = nx.closeness_centrality(G_community_louvain_screenname_hashtags)

print('---')
print('G_community_louvain_screenname_hashtags_closeness_centrality:')
# print(G_community_louvain_screenname_hashtags_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_community_louvain_screenname_hashtags_eigenvector_centrality = nx.eigenvector_centrality(G_community_louvain_screenname_hashtags)

print('---')
print('G_community_louvain_screenname_hashtags_eigenvector_centrality:')
# print(G_community_louvain_screenname_hashtags_eigenvector_centrality)
print('---')

# initialize list of Lists 
community_louvain_screenname_hashtags_network_measures = [['G_community_louvain_screenname_hashtags_betweenness_centrality', 'G_community_louvain_screenname_hashtags_betweenness_centrality'], ['G_community_louvain_screenname_hashtags_closeness_centrality', 'G_community_louvain_screenname_hashtags_closeness_centrality'], ['G_community_louvain_screenname_hashtags_eigenvector_centrality', 'G_community_louvain_screenname_hashtags_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# community_louvain_screenname_hashtags_network_measures_df = pd.DataFrame(community_louvain_screenname_hashtags_network_measures, columns = ['community_louvain_screenname_hashtags_network_measures_item', 'community_louvain_screenname_hashtags_network_measures_value']) 

# community_louvain_screenname_hashtags_network_measures_df.to_csv('4_5A_180_SMI1_community_louvain_screenname_hashtags_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# community_louvain_screenname_hashtags_network_measures_df.to_excel('4_5A_180_SMI1_community_louvain_screenname_hashtags_network_measures_DF.xlsx', header=True)

# NETWORK community_louvain_screenname_hashtags

G_community_louvain_screenname_hashtags_network_info = nx.info(G_community_louvain_screenname_hashtags)

# Create the pandas DataFrame 
# community_louvain_screenname_hashtags_network_info_df = pd.DataFrame(G_community_louvain_screenname_hashtags_network_info, columns = ['G_community_louvain_screenname_hashtags_network_info']) 

# community_louvain_screenname_hashtags_network_info_df.to_csv('4_5A_180_SMI1_Community_Louvain_screenname_hashtags_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# community_louvain_screenname_hashtags_network_info_df.to_excel('4_5A_180_SMI1_Community_Louvain_screenname_hashtags_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('community_louvain_screenname_hashtags_network INFO')
print(G_community_louvain_screenname_hashtags_network_info)
print('---')

# PLOT NETWORK GRAPH

# layout_community_louvain_screenname_hashtags = nx.random_layout(G_community_louvain_screenname_hashtags, iterations=50)
G_community_louvain_screenname_hashtags_network_size = float(len(set(G_community_louvain_screenname_hashtags_partition.values())))
# nx.random_layout

G_community_louvain_screenname_hashtags_network_pos = nx.spring_layout(G_community_louvain_screenname_hashtags)
count = 0.

for com in set(G_community_louvain_screenname_hashtags_partition.values()):
	G_community_louvain_screenname_hashtags_network_count = count + 1.
	list_nodes = [nodes for nodes in G_community_louvain_screenname_hashtags_partition.keys() if G_community_louvain_screenname_hashtags_partition[nodes] == com]
	nx.draw_networkx_nodes(G_community_louvain_screenname_hashtags, G_community_louvain_screenname_hashtags_network_pos, list_nodes, node_size=20, node_color = str(G_community_louvain_screenname_hashtags_network_count / G_community_louvain_screenname_hashtags_network_size))

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Hashtags - Louvain Network')
# nx.draw(G_community_louvain_screenname_hashtags, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
# nx.draw(G_community_louvain_screenname_hashtags, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
# edge_labels_community_louvain_screenname_hashtags = nx.get_edge_attributes(G_community_louvain_screenname_hashtags, tweets_smi_1_n['screenName']) # , tweets_smi_1_n['hashtags']
nx.draw(G_community_louvain_screenname_hashtags, G_community_louvain_screenname_hashtags_network_pos, with_labels=True, node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9)
# draw_networkx_edge_labels(G_screenname_hashtags, G_community_louvain_screenname_hashtags_network_pos)
plt.xlabel('')
plt.ylabel('')
# plt.legend(G_community_louvain_screenname_hashtags) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_Louvain_Community_Community_Louvain_Screenname_Hashtags_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('---')
print('Done Graph Network 1')
print('---')


## DELETE VARIABLE

del G_community_louvain_screenname_hashtags_network_info
del G_community_louvain_screenname_hashtags
del community_louvain_screenname_hashtags_network_measures
del community_louvain_screenname_hashtags_network_measures_df
del community_louvain_screenname_hashtags_network_numbers
del community_louvain_screenname_hashtags_network_numbers_df

######################################################################################################


# CREATE NETWORK SCREENNAME_hashtagS


# G_screenname_hashtags = nx.MultiDiGraph()

G_screenname_hashtags_1 = nx.MultiDiGraph()
# G_screenname_hashtags = nx.contracted_nodes(G_screenname_hashtags_1)


# Create Connections between nodes

G_screenname_hashtags = nx.from_pandas_edgelist(tweets_smi_1_n, 'hashtags_tuple', 'screenName', ['network_weight'])

# G_screenname_hashtags = G_screenname_hashtags.add_edges_from(G_screenname_hashtags.edges())
# G_screenname_hashtags = G_screenname_hashtags.add_nodes_from(G_screenname_hashtags.nodes())
# G_screenname_hashtags = nx.from_pandas_edgelist(smi1_matrix_hashtags, 'screenName', 'hashtags', ['network_weight'], edge_attr=True)


# GET NETWORK STATISTICS

G_screenname_hashtags_nodes_number = len(G_screenname_hashtags.nodes())

print('---')
print('G_screenname_hashtags_nodes_number:')
# print(G_screenname_hashtags_nodes_number)
print('---')

G_screenname_hashtags_edges_number = len(G_screenname_hashtags.edges())

print('---')
print('G_screenname_hashtags_edges_number:')
print(G_screenname_hashtags_edges_number)
print('---')

# G_screenname_hashtags_average_clustering = nx.average_clustering(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_average_clustering:')
# print(G_screenname_hashtags_average_clustering)
print('---')


# G_screenname_hashtags_eccentricity = nx.eccentricity(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_eccentricity:')
# print(G_screenname_hashtags_eccentricity)
print('---')

G_screenname_hashtags_density = nx.density(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_density:')
# print(G_screenname_hashtags_density)
print('---')

# initialize list of Lists 
screenname_hashtags_network_numbers = [['G_screenname_hashtags_nodes_number', G_screenname_hashtags_nodes_number], ['G_screenname_hashtags_edges_number', G_screenname_hashtags_edges_number], ['G_screenname_hashtags_average_clustering', G_screenname_hashtags_average_clustering], ['G_screenname_hashtags_eccentricity', 'G_screenname_hashtags_eccentricity'], ['G_screenname_hashtags_density', 'G_screenname_hashtags_density']]
 
# Create the pandas DataFrame 
screenname_hashtags_network_numbers_df = pd.DataFrame(screenname_hashtags_network_numbers, columns = ['screenname_hashtags_network_numbers_item', 'screenname_hashtags_network_numbers_value']) 

screenname_hashtags_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Hashtags_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_hashtags_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Hashtags_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_hashtags_betweenness_centrality = nx.betweenness_centrality(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_betweenness_centrality:')
# print(G_screenname_hashtags_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_hashtags_closeness_centrality = nx.closeness_centrality(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_closeness_centrality:')
# print(G_screenname_hashtags_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_hashtags_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_eigenvector_centrality:')
# print(G_screenname_hashtags_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_hashtags_network_measures = [['G_screenname_hashtags_betweenness_centrality', 'G_screenname_hashtags_betweenness_centrality'], ['G_screenname_hashtags_closeness_centrality', 'G_screenname_hashtags_closeness_centrality'], ['G_screenname_hashtags_eigenvector_centrality', 'G_screenname_hashtags_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_hashtags_network_measures_df = pd.DataFrame(screenname_hashtags_network_measures, columns = ['screenname_hashtags_network_measures_item', 'screenname_hashtags_network_measures_value']) 

# screenname_hashtags_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Hashtags_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_hashtags_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Hashtags_network_measures_DF.xlsx', header=True)

# NETWORK SCREENNAME_hashtagS

G_screenname_hashtags_network_info = nx.info(G_screenname_hashtags)

# Create the pandas DataFrame 
# screenname_hashtags_network_info_df = pd.DataFrame(G_screenname_hashtags_network_info, columns = ['G_screenname_hashtags_network_info']) 

# screenname_hashtags_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Hashtags_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_hashtags_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Hashtags_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_hashtags_network INFO')
print(G_screenname_hashtags_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# RANDOM LAYOUT 

# random_layout_screenname_hashtags = nx.random_layout(G_screenname_hashtags, iterations=50)
# hashtags_size = [G_screenname_hashtags.degree(hashtags) * 80 for hashtags in hashtags]

nx.random_layout

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Hashtags - Network')

node_color = [G_screenname_hashtags.degree(v) for v in G_screenname_hashtags] 
# node colour is a list of degrees of nodes 
 
# node_size = [0.0005 * nx.get_node_attributes(G_screenname_hashtags, tweets_smi_1_n['network_weight'])[v] for v in G_screenname_hashtags] 
# size of node is a list of population of cities 
# edge_width = [0.0015 * G_screenname_hashtags[u][v]['weight'] for u, v in G_screenname_hashtags.edges()] 
# width of edge is a list of weight of edges 
# nx.draw_networkx(G_screenname_hashtags, node_color = node_color, alpha = 0.7, with_labels = True, width = edge_width, edge_color ='.4', cmap = plt.cm.Blues) # node_size = node_size,


nx.draw(G_screenname_hashtags, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(G_screenname_hashtags, edge_labels=edge_labels_screenname_hashtags)
# edge_labels_screenname_hashtags = nx.get_edge_attributes(G_screenname_hashtags, smi1_matrix_hashtags['value'])
# draw_network_edge_labels(G_screenname_hashtags, edge_labels=edge_labels_screenname_hashtags)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_RD0_ScreenName_hashtags_Random_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT NETWORK


# random_layout_screenname_hashtags = nx.random_layout(G_screenname_hashtags, iterations=50)
# hashtags_size = [G_screenname_hashtags.degree(hashtags) * 80 for hashtags in hashtags]
# nx.random_layout

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Hashtags - Network')
nx.draw(G_screenname_hashtags, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
# edge_labels_screenname_hashtags = nx.get_edge_attributes(G_screenname_hashtags, smi1_matrix_hashtags['value'])
# draw_network_edge_labels(G_screenname_hashtags, edge_labels=edge_labels_screenname_hashtags)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_RD0_ScreenName_Hashtags_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT CIRCULAR NETWORK

nx.circular_layout(G_screenname_hashtags)

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Hashtags - Network')
nx.draw(G_screenname_hashtags, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
# edge_labels_screenname_hashtags = nx.get_edge_attributes(G_screenname_hashtags, smi1_matrix_hashtags['value'])
# draw_network_edge_labels(G_screenname_hashtags, edge_labels=edge_labels_screenname_hashtags)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_RD0_ScreenName_Hashtags_Circular_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('---')
print('Done Graph Network 1')
print('---')

#################################################################################################################
#################################################################################################################

# python-graph-gallery.com/320-basic-network-from-pandas-data-frame/
# datacamp.com/community/tutorials/social-networ-analysis-python

# CREATE NETWORK SCREENNAME_emojis_unicode

# tweets_smi_1_n = tweets_smi_1_n.set_index('screenName', 'emojis_unicode', inplace=True)

G_screenname_emojis_unicode = nx.MultiDiGraph()

# Create Connections between nodes

# G_screenname_emojis_unicode = nx.from_pandas_edgelist(smi1_matrix_emojis_unicode, 'value', 'emojis_unicode', ['network_weight'])

G_screenname_emojis_unicode = nx.from_pandas_edgelist(tweets_smi_1_n, 'emoji_unicodes_tuple', 'screenName', ['network_weight'], create_using=nx.DiGraph())

# GET NETWORK STATISTICS

G_screenname_emojis_unicode_nodes_number = len(G_screenname_emojis_unicode.nodes())

print('---')
print('G_screenname_emojis_unicode_nodes_number:')
print(G_screenname_emojis_unicode_nodes_number)
print('---')

G_screenname_emojis_unicode_edges_number = len(G_screenname_emojis_unicode.edges())

print('---')
print('G_screenname_emojis_unicode_edges_number:')
print(G_screenname_emojis_unicode_edges_number)
print('---')

G_screenname_emojis_unicode_average_clustering = nx.average_clustering(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_average_clustering:')
print(G_screenname_emojis_unicode_average_clustering)
print('---')


# G_screenname_emojis_unicode_eccentricity = nx.eccentricity(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_eccentricity:')
# print(G_screenname_emojis_unicode_eccentricity)
print('---')

# initialize list of Lists 
screenname_emojis_unicode_network_numbers = [['G_screenname_emojis_unicode_nodes_number', G_screenname_emojis_unicode_nodes_number], ['G_screenname_emojis_unicode_edges_number', G_screenname_emojis_unicode_edges_number], ['G_screenname_emojis_unicode_average_clustering', G_screenname_emojis_unicode_average_clustering], ['G_screenname_emojis_unicode_eccentricity', 'G_screenname_emojis_unicode_eccentricity']]
 
# Create the pandas DataFrame 
screenname_emojis_unicode_network_numbers_df = pd.DataFrame(screenname_emojis_unicode_network_numbers, columns = ['screenname_emojis_unicode_network_numbers_item', 'screenname_emojis_unicode_network_numbers_value']) 

screenname_emojis_unicode_network_numbers_df.to_csv('4_5A_180_SMI1_screenname_emojis_unicode_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_unicode_network_numbers_df.to_excel('4_5A_180_SMI1_screenname_emojis_unicode_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_emojis_unicode_betweenness_centrality = nx.betweenness_centrality(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_betweenness_centrality:')
# print(G_screenname_emojis_unicode_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_emojis_unicode_closeness_centrality = nx.closeness_centrality(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_closeness_centrality:')
# print(G_screenname_emojis_unicode_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_emojis_unicode_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_eigenvector_centrality:')
# print(G_screenname_emojis_unicode_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_emojis_unicode_network_measures = [['G_screenname_emojis_unicode_betweenness_centrality', 'G_screenname_emojis_unicode_betweenness_centrality'], ['G_screenname_emojis_unicode_closeness_centrality', 'G_screenname_emojis_unicode_closeness_centrality'], ['G_screenname_emojis_unicode_eigenvector_centrality', 'G_screenname_emojis_unicode_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_emojis_unicode_network_measures_df = pd.DataFrame(screenname_emojis_unicode_network_measures, columns = ['screenname_emojis_unicode_network_measures_item', 'screenname_emojis_unicode_network_measures_value']) 

# screenname_emojis_unicode_network_measures_df.to_csv('4_5A_180_SMI1_screenname_emojis_unicode_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_unicode_network_measures_df.to_excel('4_5A_180_SMI1_screenname_emojis_unicode_network_measures_DF.xlsx', header=True)

# NETWORK SCREENNAME_emojis_unicode

G_screenname_emojis_unicode_network_info = nx.info(G_screenname_emojis_unicode)

# Create the pandas DataFrame 
# screenname_emojis_unicode_network_info_df = pd.DataFrame(G_screenname_emojis_unicode_network_info, columns = ['G_screenname_emojis_unicode_network_info']) 

# screenname_emojis_unicode_network_info_df.to_csv('4_5A_180_SMI1_screenname_emojis_unicode_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_unicode_network_info_df.to_excel('4_5A_180_SMI1_screenname_emojis_unicode_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_emojis_unicode_network INFO')
print(G_screenname_emojis_unicode_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(40,30))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Emojis - Network Graph')
nx.draw(G_screenname_emojis_unicode, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_ScreenName_Emojis_Unicode_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################

# emojis_unicode NETWORK kamada_kawai_layout

# kamada_kawai_layout

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Kamada Kawai Layout')
nx.draw_kamada_kawai(G_screenname_emojis_unicode, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=18)

# draw_networkx_labels(graph_emojis_unicode)
# draw_networkx_edge_labels(graph_emojis_unicode, pos=nx.fruchterman_reingold_layout(g_emojis_unicode))
# plt.xlabel('')
# plt.ylabel('')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_emojis_unicode_Network_Kamada_Kawai_Layout_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################

# changed graph type on top 

##############################################


# emojis_unicode NETWORK GRAPH ring_of_cliques

g_emojis_unicode_rg = nx.ring_of_cliques(6, 100)

g_emojis_unicode_rg = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'emojis_unicode')
g_emojis_unicode_rg.add_nodes_from('screenName')


# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Ring of Cliques') 
nx.draw(g_emojis_unicode_rg, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
# strategy_saturation_largest_first(g_emojis_unicode_rg)
# draw_networkx_labels(graph_emojis_unicode)
# draw_networkx_edge_labels(graph_emojis_unicode, pos=nx.fruchterman_reingold_layout(g_emojis_unicode))
# plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_emojis_unicode_Network_ring_of_cliques_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################

# emojis_unicode NETWORK GRAPH margulis_gabber_galil_graph

g_emojis_unicode_gg = nx.margulis_gabber_galil_graph(6)

g_emojis_unicode_gg = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'emojis_unicode')
g_emojis_unicode_gg.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Margulis Gabber Galil Graph')


# pos_gg = graphviz_layout(g_emojis_unicode_gg, prog='twopi')

pos_gg = nx.fruchterman_reingold_layout(g_emojis_unicode_gg)

# pos_gg = nx.circular_layout(g_emojis_unicode_gg)

nx.draw(g_emojis_unicode_gg, pos_gg, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_emojis_unicode_gg, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_emojis_unicode_gg)
# draw_networkx_edge_labels(g_emojis_unicode_gg, pos=nx.fruchterman_reingold_layout(g_emojis_unicode))
# plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_emojis_unicode_Network_margulis_gabber_galil_graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################

# emojis_unicode NETWORK GRAPH balanced tree

g_emojis_unicode_bt = nx.balanced_tree(6, 6)

g_emojis_unicode_bt = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'emojis_unicode')
g_emojis_unicode_bt.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Balanced Tree')


# pos_bt = graphviz_layout(g_emojis_unicode_bt, prog='twopi')

pos_bt = nx.fruchterman_reingold_layout(g_emojis_unicode_bt)

# pos_bt = nx.circular_layout(g_emojis_unicode_bt)

nx.draw(g_emojis_unicode_bt, pos_bt, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_emojis_unicode_bt, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_emojis_unicode_bt)
# draw_networkx_edge_labels(g_emojis_unicode_bt, pos=nx.fruchterman_reingold_layout(g_emojis_unicode))
# plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_emojis_unicode_Network_Balanced_Tree_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################

# emojis_unicode NETWORK GRAPH cubical_graph

g_emojis_unicode_cg = nx.cubical_graph()

g_emojis_unicode_cg = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'emojis_unicode')
g_emojis_unicode_cg.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Cubical Graph')


# pos_cg = graphviz_layout(g_emojis_unicode_cg, prog='twopi')

pos_cg = nx.fruchterman_reingold_layout(g_emojis_unicode_cg)

# pos_cg = nx.circular_layout(g_emojis_unicode_cg)

nx.draw(g_emojis_unicode_cg, pos_cg, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_emojis_unicode_cg, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_emojis_unicode_cg)
# draw_networkx_edge_labels(g_emojis_unicode_ct, pos=nx.fruchterman_reingold_layout(g_emojis_unicode))
# plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_emojis_unicode_Network_Cubical_Graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################

# dorogovtsev_goltsev_mendes_graph graph

g_emojis_unicode_gm = nx.dorogovtsev_goltsev_mendes_graph(6)

g_emojis_unicode_gm = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'emojis_unicode')
g_emojis_unicode_gm.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Dorogovtsev Goltsev Mendes Graph')


# pos_gm = graphviz_layout(g_emojis_unicode_gm, prog='twopi')

pos_gm = nx.fruchterman_reingold_layout(g_emojis_unicode_gm)

# pos_gm = nx.circular_layout(g_emojis_unicode_gm)

nx.draw(g_emojis_unicode_gm, pos_gm, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_emojis_unicode_gm, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_emojis_unicode_gm)
# draw_networkx_edge_labels(g_emojis_unicode_gm, pos=nx.fruchterman_reingold_layout(g_emojis_unicode))
# plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Emojis_Unicode_Network_Dorogovtsev_Goltsev_Mendes_Graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################

# emojis_unicode NETWORK GRAPH krackhardt_kite_graph

g_emojis_unicode_kk = nx.krackhardt_kite_graph()

g_emojis_unicode_kk = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'emojis_unicode')
g_emojis_unicode_kk.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Krackhardt Kite Graph')

# pos_kk = graphviz_layout(g_emojis_unicode_kk, prog='twopi')

pos_kk = nx.fruchterman_reingold_layout(g_emojis_unicode_kk)
# pos_kk = nx.circular_layout(g_emojis_unicode_kk)

nx.draw(g_emojis_unicode_kk, pos_kk, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_emojis_unicode_kk, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_emojis_unicode_kk)
# draw_networkx_edge_labels(g_emojis_unicode_kk, pos=nx.fruchterman_reingold_layout(g_emojis_unicode))
# plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Emojis_Unicode_Network_Krackhardt_Kite_Graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################


# emojis_unicode NETWORK GRAPH PATH

g_emojis_unicode_pg = nx.path_graph(6)

g_emojis_unicode_pg = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'emojis_unicode_tuple')
g_emojis_unicode_pg.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Path')

# balanced_tree(

# pos_pg = graphviz_layout(g_emojis_unicode_pg, prog='twopi')

pos_pg = nx.fruchterman_reingold_layout(g_emojis_unicode_pg)

nx.draw(g_emojis_unicode_pg, pos_pg, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_emojis_unicode_pg, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_emojis_unicode_pg)
# draw_networkx_edge_labels(g_emojis_unicode_pg, pos=nx.fruchterman_reingold_layout(g_emojis_unicode))
# plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Emojis_Unicode_Network_Path_Graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################
# python-graph-gallery.com/320-basic-network-from-pandas-data-frame/
# datacamp.com/community/tutorials/social-networ-analysis-python

tweets_smi_1_n.set_index('created')

network_radious = 50

number_total_tweets = len(tweets_smi_1_n['created'])

### 

# DETECTING COMMUNITY LOUVAIN

# tweets_smi_1_n.set_index('screenName', 'emojis_unicode', inplace=True)

G_community_louvain_screenname_emojis_unicode = nx.MultiDiGraph()

# Create Connections between nodes

# smi1_matrix_emojis_unicode

G_community_louvain_screenname_emojis_unicode = nx.from_pandas_edgelist(tweets_smi_1_n, 'emojis_unicode_tuple', 'screenName', ['network_weight'])
G_community_louvain_screenname_emojis_unicode.add_nodes_from('screenName')

# G_community_louvain_screenname_emojis_unicode = nx.from_pandas_edgelist(smi1_matrix_emojis_unicode, 'screenName', 'emojis_unicode', ['network_weight'], edge_attr=True)


# CREATE NETWORK community_louvain_screenname_emojis_unicode

G_community_louvain_screenname_emojis_unicode = nx.erdos_renyi_graph(100,0.01)


# CREATE BEST PARTITION 

G_community_louvain_screenname_emojis_unicode_partition = community_louvain.best_partition(G_community_louvain_screenname_emojis_unicode)


# GET NETWORK STATISTICS

G_community_louvain_screenname_emojis_unicode_nodes_number = len(G_community_louvain_screenname_emojis_unicode.nodes())

print('---')
print('G_community_louvain_screenname_emojis_unicode_nodes_number:')
print(G_community_louvain_screenname_emojis_unicode_nodes_number)
print('---')

G_community_louvain_screenname_emojis_unicode_edges_number = len(G_community_louvain_screenname_emojis_unicode.edges())

print('---')
print('G_community_louvain_screenname_emojis_unicode_edges_number:')
print(G_community_louvain_screenname_emojis_unicode_edges_number)
print('---')

G_community_louvain_screenname_emojis_unicode_average_clustering = nx.average_clustering(G_community_louvain_screenname_emojis_unicode)

print('---')
print('G_community_louvain_screenname_emojis_unicode_average_clustering:')
print(G_community_louvain_screenname_emojis_unicode_average_clustering)
print('---')


# G_community_louvain_screenname_emojis_unicode_eccentricity = nx.eccentricity(G_community_louvain_screenname_emojis_unicode)

print('---')
print('G_community_louvain_screenname_emojis_unicode_eccentricity:')
# print(G_community_louvain_screenname_emojis_unicode_eccentricity)
print('---')

G_community_louvain_screenname_emojis_unicode_density = nx.density(G_community_louvain_screenname_emojis_unicode)

print('---')
print('G_community_louvain_screenname_emojis_unicode_density:')
# print(G_community_louvain_screenname_emojis_unicode_density)
print('---')

# initialize list of Lists 
community_louvain_screenname_emojis_unicode_network_numbers = [['G_community_louvain_screenname_emojis_unicode_nodes_number', G_community_louvain_screenname_emojis_unicode_nodes_number], ['G_community_louvain_screenname_emojis_unicode_edges_number', G_community_louvain_screenname_emojis_unicode_edges_number], ['G_community_louvain_screenname_emojis_unicode_average_clustering', G_community_louvain_screenname_emojis_unicode_average_clustering], ['G_community_louvain_screenname_emojis_unicode_eccentricity', 'G_community_louvain_screenname_emojis_unicode_eccentricity'], ['G_community_louvain_screenname_emojis_unicode_density', 'G_community_louvain_screenname_emojis_unicode_density']]
 
# Create the pandas DataFrame 
community_louvain_screenname_emojis_unicode_network_numbers_df = pd.DataFrame(community_louvain_screenname_emojis_unicode_network_numbers, columns = ['community_louvain_screenname_emojis_unicode_network_numbers_item', 'community_louvain_screenname_emojis_unicode_network_numbers_value']) 

community_louvain_screenname_emojis_unicode_network_numbers_df.to_csv('4_5A_180_SMI1_Community_Louvain_Screenname_Emojis_unicode_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# community_louvain_screenname_emojis_unicode_network_numbers_df.to_excel('4_5A_180_SMI1_community_louvain_screenname_emojis_unicode_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_community_louvain_screenname_emojis_unicode_betweenness_centrality = nx.betweenness_centrality(G_community_louvain_screenname_emojis_unicode)

print('---')
print('G_community_louvain_screenname_emojis_unicode_betweenness_centrality:')
# print(G_community_louvain_screenname_emojis_unicode_betweenness_centrality)
print('---')

# Closeness Centrality

# G_community_louvain_screenname_emojis_unicode_closeness_centrality = nx.closeness_centrality(G_community_louvain_screenname_emojis_unicode)

print('---')
print('G_community_louvain_screenname_emojis_unicode_closeness_centrality:')
# print(G_community_louvain_screenname_emojis_unicode_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_community_louvain_screenname_emojis_unicode_eigenvector_centrality = nx.eigenvector_centrality(G_community_louvain_screenname_emojis_unicode)

print('---')
print('G_community_louvain_screenname_emojis_unicode_eigenvector_centrality:')
# print(G_community_louvain_screenname_emojis_unicode_eigenvector_centrality)
print('---')

# initialize list of Lists 
community_louvain_screenname_emojis_unicode_network_measures = [['G_community_louvain_screenname_emojis_unicode_betweenness_centrality', 'G_community_louvain_screenname_emojis_unicode_betweenness_centrality'], ['G_community_louvain_screenname_emojis_unicode_closeness_centrality', 'G_community_louvain_screenname_emojis_unicode_closeness_centrality'], ['G_community_louvain_screenname_emojis_unicode_eigenvector_centrality', 'G_community_louvain_screenname_emojis_unicode_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# community_louvain_screenname_emojis_unicode_network_measures_df = pd.DataFrame(community_louvain_screenname_emojis_unicode_network_measures, columns = ['community_louvain_screenname_emojis_unicode_network_measures_item', 'community_louvain_screenname_emojis_unicode_network_measures_value']) 

# community_louvain_screenname_emojis_unicode_network_measures_df.to_csv('4_5A_180_SMI1_community_louvain_screenname_emojis_unicode_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# community_louvain_screenname_emojis_unicode_network_measures_df.to_excel('4_5A_180_SMI1_community_louvain_screenname_emojis_unicode_network_measures_DF.xlsx', header=True)

# NETWORK community_louvain_screenname_emojis_unicode

G_community_louvain_screenname_emojis_unicode_network_info = nx.info(G_community_louvain_screenname_emojis_unicode)

# Create the pandas DataFrame 
# community_louvain_screenname_emojis_unicode_network_info_df = pd.DataFrame(G_community_louvain_screenname_emojis_unicode_network_info, columns = ['G_community_louvain_screenname_emojis_unicode_network_info']) 

# community_louvain_screenname_emojis_unicode_network_info_df.to_csv('4_5A_180_SMI1_Community_Louvain_Screenname_emojis_unicode_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# community_louvain_screenname_emojis_unicode_network_info_df.to_excel('4_5A_180_SMI1_Community_Louvain_Screenname_emojis_unicode_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('community_louvain_screenname_emojis_unicode_network INFO')
print(G_community_louvain_screenname_emojis_unicode_network_info)
print('---')

# PLOT NETWORK GRAPH

# layout_community_louvain_screenname_emojis_unicode = nx.random_layout(G_community_louvain_screenname_emojis_unicode, iterations=50)
G_community_louvain_screenname_emojis_unicode_network_size = float(len(set(G_community_louvain_screenname_emojis_unicode_partition.values())))
# nx.random_layout

G_community_louvain_screenname_emojis_unicode_network_pos = nx.spring_layout(G_community_louvain_screenname_emojis_unicode)
count = 0.

for com in set(G_community_louvain_screenname_emojis_unicode_partition.values()):
	G_community_louvain_screenname_emojis_unicode_network_count = count + 1.
	list_nodes = [nodes for nodes in G_community_louvain_screenname_emojis_unicode_partition.keys() if G_community_louvain_screenname_emojis_unicode_partition[nodes] == com]
	nx.draw_networkx_nodes(G_community_louvain_screenname_emojis_unicode, G_community_louvain_screenname_emojis_unicode_network_pos, list_nodes, node_size=20, node_color = str(G_community_louvain_screenname_emojis_unicode_network_count / G_community_louvain_screenname_emojis_unicode_network_size))

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Emojis - Louvain Network')
# nx.draw(G_community_louvain_screenname_emojis_unicode, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
# nx.draw(G_community_louvain_screenname_emojis_unicode, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
# edge_labels_community_louvain_screenname_emojis_unicode = nx.get_edge_attributes(G_community_louvain_screenname_emojis_unicode, tweets_smi_1_n['screenName']) # , tweets_smi_1_n['emojis_unicode']
nx.draw(G_community_louvain_screenname_emojis_unicode, G_community_louvain_screenname_emojis_unicode_network_pos, with_labels=True, node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9)
# draw_networkx_edge_labels(G_screenname_emojis_unicode, G_community_louvain_screenname_emojis_unicode_network_pos)
plt.xlabel('')
plt.ylabel('')
# plt.legend(G_community_louvain_screenname_emojis_unicode) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_Louvain_Community_Community_Louvain_Screenname_Emojis_Unicode_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('---')
print('Done Graph Network emojis_unicode Louvain')
print('---')

## DELETE VARIABLE

del G_community_louvain_screenname_emojis_unicode_network_info
del G_community_louvain_screenname_emojis_unicode
del community_louvain_screenname_emojis_unicode_network_measures
del community_louvain_screenname_emojis_unicode_network_measures_df
del community_louvain_screenname_emojis_unicode_network_numbers
del community_louvain_screenname_emojis_unicode_network_numbers_df

######################################################################################################

# CREATE NETWORK SCREENNAME_emojis_unicode

# G_screenname_emojis_unicode = nx.MultiDiGraph()

G_screenname_emojis_unicode_1 = nx.MultiDiGraph()
# G_screenname_emojis_unicode = nx.contracted_nodes(G_screenname_emojis_unicode_1)


# Create Connections between nodes

G_screenname_emojis_unicode = nx.from_pandas_edgelist(tweets_smi_1_n, 'emojis_unicode_tuple', 'screenName', ['network_weight'])

# G_screenname_emojis_unicode = G_screenname_emojis_unicode.add_edges_from(G_screenname_emojis_unicode.edges())
# G_screenname_emojis_unicode = G_screenname_emojis_unicode.add_nodes_from(G_screenname_emojis_unicode.nodes())
# G_screenname_emojis_unicode = nx.from_pandas_edgelist(smi1_matrix_emojis_unicode, 'screenName', 'emojis_unicode', ['network_weight'], edge_attr=True)


# GET NETWORK STATISTICS

G_screenname_emojis_unicode_nodes_number = len(G_screenname_emojis_unicode.nodes())

print('---')
print('G_screenname_emojis_unicode_nodes_number:')
# print(G_screenname_emojis_unicode_nodes_number)
print('---')

G_screenname_emojis_unicode_edges_number = len(G_screenname_emojis_unicode.edges())

print('---')
print('G_screenname_emojis_unicode_edges_number:')
print(G_screenname_emojis_unicode_edges_number)
print('---')

G_screenname_emojis_unicode_average_clustering = nx.average_clustering(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_average_clustering:')
print(G_screenname_emojis_unicode_average_clustering)
print('---')


# G_screenname_emojis_unicode_eccentricity = nx.eccentricity(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_eccentricity:')
# print(G_screenname_emojis_unicode_eccentricity)
print('---')

G_screenname_emojis_unicode_density = nx.density(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_density:')
# print(G_screenname_emojis_unicode_density)
print('---')

# initialize list of Lists 
screenname_emojis_unicode_network_numbers = [['G_screenname_emojis_unicode_nodes_number', G_screenname_emojis_unicode_nodes_number], ['G_screenname_emojis_unicode_edges_number', G_screenname_emojis_unicode_edges_number], ['G_screenname_emojis_unicode_average_clustering', G_screenname_emojis_unicode_average_clustering], ['G_screenname_emojis_unicode_eccentricity', 'G_screenname_emojis_unicode_eccentricity'], ['G_screenname_emojis_unicode_density', 'G_screenname_emojis_unicode_density']]
 
# Create the pandas DataFrame 
screenname_emojis_unicode_network_numbers_df = pd.DataFrame(screenname_emojis_unicode_network_numbers, columns = ['screenname_emojis_unicode_network_numbers_item', 'screenname_emojis_unicode_network_numbers_value']) 

screenname_emojis_unicode_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Unicode_Network_Numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_unicode_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Unicode_Network_Numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_emojis_unicode_betweenness_centrality = nx.betweenness_centrality(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_betweenness_centrality:')
# print(G_screenname_emojis_unicode_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_emojis_unicode_closeness_centrality = nx.closeness_centrality(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_closeness_centrality:')
# print(G_screenname_emojis_unicode_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_emojis_unicode_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_eigenvector_centrality:')
# print(G_screenname_emojis_unicode_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_emojis_unicode_network_measures = [['G_screenname_emojis_unicode_betweenness_centrality', 'G_screenname_emojis_unicode_betweenness_centrality'], ['G_screenname_emojis_unicode_closeness_centrality', 'G_screenname_emojis_unicode_closeness_centrality'], ['G_screenname_emojis_unicode_eigenvector_centrality', 'G_screenname_emojis_unicode_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_emojis_unicode_network_measures_df = pd.DataFrame(screenname_emojis_unicode_network_measures, columns = ['screenname_emojis_unicode_network_measures_item', 'screenname_emojis_unicode_network_measures_value']) 

# screenname_emojis_unicode_network_measures_df.to_csv('4_5A_180_SMI1_screenname_emojis_unicode_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_unicode_network_measures_df.to_excel('4_5A_180_SMI1_screenname_emojis_unicode_network_measures_DF.xlsx', header=True)

# NETWORK SCREENNAME_emojis_unicode

G_screenname_emojis_unicode_network_info = nx.info(G_screenname_emojis_unicode)

# Create the pandas DataFrame 
# screenname_emojis_unicode_network_info_df = pd.DataFrame(G_screenname_emojis_unicode_network_info, columns = ['G_screenname_emojis_unicode_network_info']) 

# screenname_emojis_unicode_network_info_df.to_csv('4_5A_180_SMI1_screenname_emojis_unicode_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_unicode_network_info_df.to_excel('4_5A_180_SMI1_screenname_emojis_unicode_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_emojis_unicode_network INFO')
print(G_screenname_emojis_unicode_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# RANDOM LAYOUT 

# random_layout_screenname_emojis_unicode = nx.random_layout(G_screenname_emojis_unicode, iterations=50)
# emojis_unicode_size = [G_screenname_emojis_unicode.degree(emojis_unicode) * 80 for emojis_unicode in emojis_unicode]

nx.random_layout

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Emojis - Network')

node_color = [G_screenname_emojis_unicode.degree(v) for v in G_screenname_emojis_unicode] 
# node colour is a list of degrees of nodes 
 
# node_size = [0.0005 * nx.get_node_attributes(G_screenname_emojis_unicode, tweets_smi_1_n['network_weight'])[v] for v in G_screenname_emojis_unicode] 
# size of node is a list of population of cities 
# edge_width = [0.0015 * G_screenname_emojis_unicode[u][v]['weight'] for u, v in G_screenname_emojis_unicode.edges()] 
# width of edge is a list of weight of edges 
# nx.draw_networkx(G_screenname_emojis_unicode, node_color = node_color, alpha = 0.7, with_labels = True, width = edge_width, edge_color ='.4', cmap = plt.cm.Blues) # node_size = node_size,


nx.draw(G_screenname_emojis_unicode, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(G_screenname_emojis_unicode, edge_labels=edge_labels_screenname_emojis_unicode)
# edge_labels_screenname_emojis_unicode = nx.get_edge_attributes(G_screenname_emojis_unicode, smi1_matrix_emojis_unicode['value'])
# draw_network_edge_labels(G_screenname_emojis_unicode, edge_labels=edge_labels_screenname_emojis_unicode)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_RD0_ScreenName_emojis_unicode_Random_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT NETWORK


# random_layout_screenname_emojis_unicode = nx.random_layout(G_screenname_emojis_unicode, iterations=50)
# emojis_unicode_size = [G_screenname_emojis_unicode.degree(emojis_unicode) * 80 for emojis_unicode in emojis_unicode]
# nx.random_layout

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Emojis - Network')
nx.draw(G_screenname_emojis_unicode, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
# edge_labels_screenname_emojis_unicode = nx.get_edge_attributes(G_screenname_emojis_unicode, smi1_matrix_emojis_unicode['value'])
# draw_network_edge_labels(G_screenname_emojis_unicode, edge_labels=edge_labels_screenname_emojis_unicode)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_RD0_ScreenName_Emojis_Unicode_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT CIRCULAR NETWORK

nx.circular_layout(G_screenname_emojis_unicode)

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Emojis - Network')
nx.draw(G_screenname_emojis_unicode, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
# edge_labels_screenname_emojis_unicode = nx.get_edge_attributes(G_screenname_emojis_unicode, smi1_matrix_emojis_unicode['value'])
# draw_network_edge_labels(G_screenname_emojis_unicode, edge_labels=edge_labels_screenname_emojis_unicode)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_RD0_ScreenName_Emojis_Unicode_Circular_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network emojis unicode')
print('---')

#################################################################################################################
#################################################################################################################

# python-graph-gallery.com/320-basic-network-from-pandas-data-frame/
# datacamp.com/community/tutorials/social-networ-analysis-python

# CREATE NETWORK SCREENNAME_emojis_converted

# tweets_smi_1_n = tweets_smi_1_n.set_index('screenName', 'emojis_converted', inplace=True)

G_screenname_emojis_converted = nx.MultiDiGraph()

# Create Connections between nodes

# G_screenname_emojis_converted = nx.from_pandas_edgelist(smi1_matrix_emojis_converted, 'screenName', 'value', ['network_weight'])

G_screenname_emojis_converted = nx.from_pandas_edgelist(tweets_smi_1_n, 'emojis_converted_tuple', 'screenName', ['network_weight'], create_using=nx.DiGraph())

# GET NETWORK STATISTICS

G_screenname_emojis_converted_nodes_number = len(G_screenname_emojis_converted.nodes())

print('---')
print('G_screenname_emojis_converted_nodes_number:')
print(G_screenname_emojis_converted_nodes_number)
print('---')

G_screenname_emojis_converted_edges_number = len(G_screenname_emojis_converted.edges())

print('---')
print('G_screenname_emojis_converted_edges_number:')
print(G_screenname_emojis_converted_edges_number)
print('---')

G_screenname_emojis_converted_average_clustering = nx.average_clustering(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_average_clustering:')
print(G_screenname_emojis_converted_average_clustering)
print('---')


# G_screenname_emojis_converted_eccentricity = nx.eccentricity(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_eccentricity:')
# print(G_screenname_emojis_converted_eccentricity)
print('---')

# initialize list of Lists 
screenname_emojis_converted_network_numbers = [['G_screenname_emojis_converted_nodes_number', G_screenname_emojis_converted_nodes_number], ['G_screenname_emojis_converted_edges_number', G_screenname_emojis_converted_edges_number], ['G_screenname_emojis_converted_average_clustering', G_screenname_emojis_converted_average_clustering], ['G_screenname_emojis_converted_eccentricity', 'G_screenname_emojis_converted_eccentricity']]
 
# Create the pandas DataFrame 
screenname_emojis_converted_network_numbers_df = pd.DataFrame(screenname_emojis_converted_network_numbers, columns = ['screenname_emojis_converted_network_numbers_item', 'screenname_emojis_converted_network_numbers_value']) 

screenname_emojis_converted_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Converted_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_converted_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Converted_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_emojis_converted_betweenness_centrality = nx.betweenness_centrality(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_betweenness_centrality:')
# print(G_screenname_emojis_converted_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_emojis_converted_closeness_centrality = nx.closeness_centrality(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_closeness_centrality:')
# print(G_screenname_emojis_converted_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_emojis_converted_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_eigenvector_centrality:')
# print(G_screenname_emojis_converted_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_emojis_converted_network_measures = [['G_screenname_emojis_converted_betweenness_centrality', 'G_screenname_emojis_converted_betweenness_centrality'], ['G_screenname_emojis_converted_closeness_centrality', 'G_screenname_emojis_converted_closeness_centrality'], ['G_screenname_emojis_converted_eigenvector_centrality', 'G_screenname_emojis_converted_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_emojis_converted_network_measures_df = pd.DataFrame(screenname_emojis_converted_network_measures, columns = ['screenname_emojis_converted_network_measures_item', 'screenname_emojis_converted_network_measures_value']) 

# screenname_emojis_converted_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Converted_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_converted_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Converted_network_measures_DF.xlsx', header=True)

# NETWORK SCREENNAME_emojis_converted

G_screenname_emojis_converted_network_info = nx.info(G_screenname_emojis_converted)

# Create the pandas DataFrame 
# screenname_emojis_converted_network_info_df = pd.DataFrame(G_screenname_emojis_converted_network_info, columns = ['G_screenname_emojis_converted_network_info']) 

# screenname_emojis_converted_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Converted_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_converted_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Converted_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_emojis_converted_network INFO')
print(G_screenname_emojis_converted_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(40,30))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Emojis - Network Graph')
nx.draw(G_screenname_emojis_converted, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_180_SMI1_Screenname_Emojis_Converted_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################

# CREATE NETWORK

G_screenname_emojis_converted = nx.MultiDiGraph()

# Create Connections between nodes

G_screenname_emojis_converted = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'emojis_converted', ['network_weight'], create_using=nx.DiGraph())


# PLOT NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.autoscale() 
# plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Emojis Converted - Network Graph')
nx.draw(G_screenname_emojis_converted, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
#plt.savefig('4_5A_180_SMI1_Screenname_Emojis_Converted_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################

# emojis_converted NETWORK kamada_kawai_layout

# kamada_kawai_layout

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Kamada Kawai Layout')
nx.draw_kamada_kawai(G_screenname_emojis_converted, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=18)

# draw_networkx_labels(graph_emojis_converted)
# draw_networkx_edge_labels(graph_emojis_converted, pos=nx.fruchterman_reingold_layout(g_emojis_converted))
# plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Emojis_Converted_Network_kamada_kawai_layout_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################

# changed graph type on top 

##############################################


# emojis_converted NETWORK GRAPH ring_of_cliques

g_emojis_converted_rg = nx.ring_of_cliques(6, 100)

g_emojis_converted_rg = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'emojis_converted')
g_emojis_converted_rg.add_nodes_from('screenName')


# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Ring of Cliques') 
nx.draw(g_emojis_converted_rg, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
# strategy_saturation_largest_first(g_emojis_converted_rg)
# draw_networkx_labels(graph_emojis_converted)
# draw_networkx_edge_labels(graph_emojis_converted, pos=nx.fruchterman_reingold_layout(g_emojis_converted))
# plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Emojis_Converted_Network_ring_of_cliques_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################

# emojis_converted NETWORK GRAPH margulis_gabber_galil_graph

g_emojis_converted_mg = nx.margulis_gabber_galil_graph(6)

g_emojis_converted_mg = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'emojis_converted')
g_emojis_converted_mg.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Margulis Gabber Galil Graph')


# pos_mg = graphviz_layout(g_emojis_converted_mg, prog='twopi')

pos_mg = nx.fruchterman_reingold_layout(g_emojis_converted_mg)

# pos_mg = nx.circular_layout(g_emojis_converted_mg)

nx.draw(g_emojis_converted_mg, pos_mg, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_emojis_converted_mg, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_emojis_converted_mg)
# draw_networkx_edge_labels(g_emojis_converted_mg, pos=nx.fruchterman_reingold_layout(g_emojis_converted))
# plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Emojis_Converted_Network_margulis_gabber_galil_graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################

# emojis_converted NETWORK GRAPH balanced tree

g_emojis_converted_bt = nx.balanced_tree(6, 6)

g_emojis_converted_bt = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'emojis_converted')
g_emojis_converted_bt.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Balanced Tree')


# pos_bt = graphviz_layout(g_emojis_converted_bt, prog='twopi')

pos_bt = nx.fruchterman_reingold_layout(g_emojis_converted_bt)

# pos_bt = nx.circular_layout(g_emojis_converted_bt)

nx.draw(g_emojis_converted_bt, pos_bt, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_emojis_converted_bt, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_emojis_converted_bt)
# draw_networkx_edge_labels(g_emojis_converted_bt, pos=nx.fruchterman_reingold_layout(g_emojis_converted))
# plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Emojis_Converted_Network_Balanced_Tree_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################

# emojis_converted NETWORK GRAPH cubical_graph

g_emojis_converted_cg = nx.cubical_graph()

g_emojis_converted_cg = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'emojis_converted')
g_emojis_converted_cg.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Cubical Graph')


# pos_cg = graphviz_layout(g_emojis_converted_cg, prog='twopi')

pos_cg = nx.fruchterman_reingold_layout(g_emojis_converted_cg)

# pos_cg = nx.circular_layout(g_emojis_converted_cg)

nx.draw(g_emojis_converted_cg, pos_cg, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_emojis_converted_cg, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_emojis_converted_cg)
# draw_networkx_edge_labels(g_emojis_converted_cg, pos=nx.fruchterman_reingold_layout(g_emojis_converted))
# plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Emojis_Converted_Network_Cubical_Graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################

# dorogovtsev_goltsev_mendes_graph graph

g_emojis_converted_gm = nx.dorogovtsev_goltsev_mendes_graph(6)

g_emojis_converted_gm = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'emojis_converted')
g_emojis_converted_gm.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Dorogovtsev Goltsev Mendes Graph')


# pos_gm = graphviz_layout(g_emojis_converted_gm, prog='twopi')

pos_gm = nx.fruchterman_reingold_layout(g_emojis_converted_gm)

# pos_gm = nx.circular_layout(g_emojis_converted_gm)

nx.draw(g_emojis_converted_gm, pos_gm, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_emojis_converted_gm, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_emojis_converted_gm)
# draw_networkx_edge_labels(g_emojis_converted_gm, pos=nx.fruchterman_reingold_layout(g_emojis_converted))
# plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Emojis_Converted_Network_Dorogovtsev_goltsev_mendes_graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################

# emojis_converted NETWORK GRAPH krackhardt_kite_graph

g_emojis_converted_kk = nx.krackhardt_kite_graph()

g_emojis_converted_kk = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'emojis_converted')
g_emojis_converted_kk.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Krackhardt Kite Graph')

# pos_kk = graphviz_layout(g_emojis_converted_kk, prog='twopi')

pos_kk = nx.fruchterman_reingold_layout(g_emojis_converted_kk)
# pos_kk = nx.circular_layout(g_emojis_converted_kk)

nx.draw(g_emojis_converted_kk, pos_kk, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_emojis_converted_kk, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_emojis_converted_kk)
# draw_networkx_edge_labels(g_emojis_converted_kk, pos=nx.fruchterman_reingold_layout(g_emojis_converted))
# plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Emojis_Converted_Network_krackhardt_kite_graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################


# emojis_converted NETWORK GRAPH PATH

g_emojis_converted_pg = nx.path_graph(6)

g_emojis_converted_pg = nx.from_pandas_edgelist(tweets_smi_1_n, 'screenName', 'emojis_converted_tuple')
g_emojis_converted_pg.add_nodes_from('screenName')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Network - Path')

# balanced_tree(

# pos_pg = graphviz_layout(g_emojis_converted_pg, prog='twopi')
pos_pg = nx.fruchterman_reingold_layout(g_emojis_converted_pg)

nx.draw(g_emojis_converted_pg, pos_pg, node_size=20, alpha=0.5, node_color="blue", with_labels=True)
plt.axis('equal')
# nx.draw_spectral(g_emojis_converted_pg, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(g_emojis_converted_pg)
# draw_networkx_edge_labels(g_emojis_converted_pg, pos_pg=nx.fruchterman_reingold_layout(g_emojis_converted))
# plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Emojis_Converted_Network_Path_Graph_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################
# python-graph-gallery.com/320-basic-network-from-pandas-data-frame/
# datacamp.com/community/tutorials/social-networ-analysis-python

tweets_smi_1_n.set_index('created')

network_radious = 50

number_total_tweets = len(tweets_smi_1_n['created'])

### 

# DETECTING COMMUNITY LOUVAIN

# tweets_smi_1_n.set_index('screenName', 'emojis_converted', inplace=True)

G_community_louvain_screenname_emojis_converted = nx.MultiDiGraph()

# Create Connections between nodes

# smi1_matrix_emojis_converted

G_community_louvain_screenname_emojis_converted = nx.from_pandas_edgelist(tweets_smi_1_n, 'emojis_converted_tuple', 'screenName', ['network_weight'])
G_community_louvain_screenname_emojis_converted.add_nodes_from('screenName')

# G_community_louvain_screenname_emojis_converted = nx.from_pandas_edgelist(smi1_matrix_emojis_converted, 'screenName', 'emojis_converted', ['network_weight'], edge_attr=True)


# CREATE NETWORK community_louvain_screenname_emojis_converted

G_community_louvain_screenname_emojis_converted = nx.erdos_renyi_graph(100,0.01)


# CREATE BEST PARTITION 

G_community_louvain_screenname_emojis_converted_partition = community_louvain.best_partition(G_community_louvain_screenname_emojis_converted)


# GET NETWORK STATISTICS

G_community_louvain_screenname_emojis_converted_nodes_number = len(G_community_louvain_screenname_emojis_converted.nodes())

print('---')
print('G_community_louvain_screenname_emojis_converted_nodes_number:')
print(G_community_louvain_screenname_emojis_converted_nodes_number)
print('---')

G_community_louvain_screenname_emojis_converted_edges_number = len(G_community_louvain_screenname_emojis_converted.edges())

print('---')
print('G_community_louvain_screenname_emojis_converted_edges_number:')
print(G_community_louvain_screenname_emojis_converted_edges_number)
print('---')

G_community_louvain_screenname_emojis_converted_average_clustering = nx.average_clustering(G_community_louvain_screenname_emojis_converted)

print('---')
print('G_community_louvain_screenname_emojis_converted_average_clustering:')
print(G_community_louvain_screenname_emojis_converted_average_clustering)
print('---')


# G_community_louvain_screenname_emojis_converted_eccentricity = nx.eccentricity(G_community_louvain_screenname_emojis_converted)

print('---')
print('G_community_louvain_screenname_emojis_converted_eccentricity:')
# print(G_community_louvain_screenname_emojis_converted_eccentricity)
print('---')

G_community_louvain_screenname_emojis_converted_density = nx.density(G_community_louvain_screenname_emojis_converted)

print('---')
print('G_community_louvain_screenname_emojis_converted_density:')
# print(G_community_louvain_screenname_emojis_converted_density)
print('---')

# initialize list of Lists 
community_louvain_screenname_emojis_converted_network_numbers = [['G_community_louvain_screenname_emojis_converted_nodes_number', G_community_louvain_screenname_emojis_converted_nodes_number], ['G_community_louvain_screenname_emojis_converted_edges_number', G_community_louvain_screenname_emojis_converted_edges_number], ['G_community_louvain_screenname_emojis_converted_average_clustering', G_community_louvain_screenname_emojis_converted_average_clustering], ['G_community_louvain_screenname_emojis_converted_eccentricity', 'G_community_louvain_screenname_emojis_converted_eccentricity'], ['G_community_louvain_screenname_emojis_converted_density', 'G_community_louvain_screenname_emojis_converted_density']]
 
# Create the pandas DataFrame 
community_louvain_screenname_emojis_converted_network_numbers_df = pd.DataFrame(community_louvain_screenname_emojis_converted_network_numbers, columns = ['community_louvain_screenname_emojis_converted_network_numbers_item', 'community_louvain_screenname_emojis_converted_network_numbers_value']) 

community_louvain_screenname_emojis_converted_network_numbers_df.to_csv('4_5A_180_SMI1_Community_Louvain_Screenname_Emojis_Converted_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# community_louvain_screenname_emojis_converted_network_numbers_df.to_excel('4_5A_180_SMI1_community_louvain_screenname_emojis_converted_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_community_louvain_screenname_emojis_converted_betweenness_centrality = nx.betweenness_centrality(G_community_louvain_screenname_emojis_converted)

print('---')
print('G_community_louvain_screenname_emojis_converted_betweenness_centrality:')
# print(G_community_louvain_screenname_emojis_converted_betweenness_centrality)
print('---')

# Closeness Centrality

# G_community_louvain_screenname_emojis_converted_closeness_centrality = nx.closeness_centrality(G_community_louvain_screenname_emojis_converted)

print('---')
print('G_community_louvain_screenname_emojis_converted_closeness_centrality:')
# print(G_community_louvain_screenname_emojis_converted_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_community_louvain_screenname_emojis_converted_eigenvector_centrality = nx.eigenvector_centrality(G_community_louvain_screenname_emojis_converted)

print('---')
print('G_community_louvain_screenname_emojis_converted_eigenvector_centrality:')
# print(G_community_louvain_screenname_emojis_converted_eigenvector_centrality)
print('---')

# initialize list of Lists 
community_louvain_screenname_emojis_converted_network_measures = [['G_community_louvain_screenname_emojis_converted_betweenness_centrality', 'G_community_louvain_screenname_emojis_converted_betweenness_centrality'], ['G_community_louvain_screenname_emojis_converted_closeness_centrality', 'G_community_louvain_screenname_emojis_converted_closeness_centrality'], ['G_community_louvain_screenname_emojis_converted_eigenvector_centrality', 'G_community_louvain_screenname_emojis_converted_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# community_louvain_screenname_emojis_converted_network_measures_df = pd.DataFrame(community_louvain_screenname_emojis_converted_network_measures, columns = ['community_louvain_screenname_emojis_converted_network_measures_item', 'community_louvain_screenname_emojis_converted_network_measures_value']) 

# community_louvain_screenname_emojis_converted_network_measures_df.to_csv('4_5A_180_SMI1_community_louvain_screenname_emojis_converted_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# community_louvain_screenname_emojis_converted_network_measures_df.to_excel('4_5A_180_SMI1_community_louvain_screenname_emojis_converted_network_measures_DF.xlsx', header=True)

# NETWORK community_louvain_screenname_emojis_converted

G_community_louvain_screenname_emojis_converted_network_info = nx.info(G_community_louvain_screenname_emojis_converted)

# Create the pandas DataFrame 
# community_louvain_screenname_emojis_converted_network_info_df = pd.DataFrame(G_community_louvain_screenname_emojis_converted_network_info, columns = ['G_community_louvain_screenname_emojis_converted_network_info']) 

# community_louvain_screenname_emojis_converted_network_info_df.to_csv('4_5A_180_SMI1_community_louvain_screenname_emojis_converted_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# community_louvain_screenname_emojis_converted_network_info_df.to_excel('4_5A_180_SMI1_community_louvain_screenname_emojis_converted_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('community_louvain_screenname_emojis_converted_network INFO')
print(G_community_louvain_screenname_emojis_converted_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# layout_community_louvain_screenname_emojis_converted = nx.random_layout(G_community_louvain_screenname_emojis_converted, iterations=50)
G_community_louvain_screenname_emojis_converted_network_size = float(len(set(G_community_louvain_screenname_emojis_converted_partition.values())))
# nx.random_layout

G_community_louvain_screenname_emojis_converted_network_pos = nx.spring_layout(G_community_louvain_screenname_emojis_converted)
count = 0.

for com in set(G_community_louvain_screenname_emojis_converted_partition.values()):
	G_community_louvain_screenname_emojis_converted_network_count = count + 1.
	list_nodes = [nodes for nodes in G_community_louvain_screenname_emojis_converted_partition.keys() if G_community_louvain_screenname_emojis_converted_partition[nodes] == com]
	nx.draw_networkx_nodes(G_community_louvain_screenname_emojis_converted, G_community_louvain_screenname_emojis_converted_network_pos, list_nodes, node_size=20, node_color = str(G_community_louvain_screenname_emojis_converted_network_count / G_community_louvain_screenname_emojis_converted_network_size))

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Emojis - Louvain Network')
# nx.draw(G_community_louvain_screenname_emojis_converted, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
# nx.draw(G_community_louvain_screenname_emojis_converted, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
# edge_labels_community_louvain_screenname_emojis_converted = nx.get_edge_attributes(G_community_louvain_screenname_emojis_converted, tweets_smi_1_n['screenName']) # , tweets_smi_1_n['emojis_converted']
nx.draw(G_community_louvain_screenname_emojis_converted, G_community_louvain_screenname_emojis_converted_network_pos, with_labels=True, node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9)
# draw_networkx_edge_labels(G_screenname_emojis_converted, G_community_louvain_screenname_emojis_converted_network_pos)
plt.xlabel('')
plt.ylabel('')
# plt.legend(G_community_louvain_screenname_emojis_converted) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_Louvain_Community_Louvain_Screenname_Emojis_Converted_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('---')
print('Done Graph Network emojis_converted')
print('---')

## DELETE VARIABLE

del G_community_louvain_screenname_emojis_converted_network_info
del G_community_louvain_screenname_emojis_converted
del community_louvain_screenname_emojis_converted_network_measures
del community_louvain_screenname_emojis_converted_network_measures_df
del community_louvain_screenname_emojis_converted_network_numbers
del community_louvain_screenname_emojis_converted_network_numbers_df

######################################################################################################


# CREATE NETWORK SCREENNAME_emojis_converted


# G_screenname_emojis_converted = nx.MultiDiGraph()

G_screenname_emojis_converted_1 = nx.MultiDiGraph()
# G_screenname_emojis_converted = nx.contracted_nodes(G_screenname_emojis_converted_1)


# Create Connections between nodes

G_screenname_emojis_converted = nx.from_pandas_edgelist(tweets_smi_1_n, 'emojis_converted_tuple', 'screenName', ['network_weight'])

# G_screenname_emojis_converted = G_screenname_emojis_converted.add_edges_from(G_screenname_emojis_converted.edges())
# G_screenname_emojis_converted = G_screenname_emojis_converted.add_nodes_from(G_screenname_emojis_converted.nodes())
# G_screenname_emojis_converted = nx.from_pandas_edgelist(smi1_matrix_emojis_converted, 'screenName', 'emojis_converted', ['network_weight'], edge_attr=True)


# GET NETWORK STATISTICS

G_screenname_emojis_converted_nodes_number = len(G_screenname_emojis_converted.nodes())

print('---')
print('G_screenname_emojis_converted_nodes_number:')
# print(G_screenname_emojis_converted_nodes_number)
print('---')

G_screenname_emojis_converted_edges_number = len(G_screenname_emojis_converted.edges())

print('---')
print('G_screenname_emojis_converted_edges_number:')
print(G_screenname_emojis_converted_edges_number)
print('---')

G_screenname_emojis_converted_average_clustering = nx.average_clustering(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_average_clustering:')
print(G_screenname_emojis_converted_average_clustering)
print('---')


# G_screenname_emojis_converted_eccentricity = nx.eccentricity(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_eccentricity:')
# print(G_screenname_emojis_converted_eccentricity)
print('---')

G_screenname_emojis_converted_density = nx.density(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_density:')
# print(G_screenname_emojis_converted_density)
print('---')

# initialize list of Lists 
screenname_emojis_converted_network_numbers = [['G_screenname_emojis_converted_nodes_number', G_screenname_emojis_converted_nodes_number], ['G_screenname_emojis_converted_edges_number', G_screenname_emojis_converted_edges_number], ['G_screenname_emojis_converted_average_clustering', G_screenname_emojis_converted_average_clustering], ['G_screenname_emojis_converted_eccentricity', 'G_screenname_emojis_converted_eccentricity'], ['G_screenname_emojis_converted_density', 'G_screenname_emojis_converted_density']]
 
# Create the pandas DataFrame 
screenname_emojis_converted_network_numbers_df = pd.DataFrame(screenname_emojis_converted_network_numbers, columns = ['screenname_emojis_converted_network_numbers_item', 'screenname_emojis_converted_network_numbers_value']) 

screenname_emojis_converted_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Converted_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_converted_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Converted_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_emojis_converted_betweenness_centrality = nx.betweenness_centrality(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_betweenness_centrality:')
# print(G_screenname_emojis_converted_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_emojis_converted_closeness_centrality = nx.closeness_centrality(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_closeness_centrality:')
# print(G_screenname_emojis_converted_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_emojis_converted_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_eigenvector_centrality:')
# print(G_screenname_emojis_converted_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_emojis_converted_network_measures = [['G_screenname_emojis_converted_betweenness_centrality', 'G_screenname_emojis_converted_betweenness_centrality'], ['G_screenname_emojis_converted_closeness_centrality', 'G_screenname_emojis_converted_closeness_centrality'], ['G_screenname_emojis_converted_eigenvector_centrality', 'G_screenname_emojis_converted_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_emojis_converted_network_measures_df = pd.DataFrame(screenname_emojis_converted_network_measures, columns = ['screenname_emojis_converted_network_measures_item', 'screenname_emojis_converted_network_measures_value']) 

# screenname_emojis_converted_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Converted_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_converted_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Converted_network_measures_DF.xlsx', header=True)

# NETWORK SCREENNAME_emojis_converted

G_screenname_emojis_converted_network_info = nx.info(G_screenname_emojis_converted)

# Create the pandas DataFrame 
# screenname_emojis_converted_network_info_df = pd.DataFrame(G_screenname_emojis_converted_network_info, columns = ['G_screenname_emojis_converted_network_info']) 

# screenname_emojis_converted_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Converted_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_converted_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Converted_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_emojis_converted_network INFO')
print(G_screenname_emojis_converted_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# RANDOM LAYOUT 

# random_layout_screenname_emojis_converted = nx.random_layout(G_screenname_emojis_converted, iterations=50)
# emojis_converted_size = [G_screenname_emojis_converted.degree(emojis_converted) * 80 for emojis_converted in emojis_converted]

nx.random_layout

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Emojis - Network')

node_color = [G_screenname_emojis_converted.degree(v) for v in G_screenname_emojis_converted] 
# node colour is a list of degrees of nodes 
 
# node_size = [0.0005 * nx.get_node_attributes(G_screenname_emojis_converted, tweets_smi_1_n['network_weight'])[v] for v in G_screenname_emojis_converted] 
# size of node is a list of population of cities 
# edge_width = [0.0015 * G_screenname_emojis_converted[u][v]['weight'] for u, v in G_screenname_emojis_converted.edges()] 
# width of edge is a list of weight of edges 
# nx.draw_networkx(G_screenname_emojis_converted, node_color = node_color, alpha = 0.7, with_labels = True, width = edge_width, edge_color ='.4', cmap = plt.cm.Blues) # node_size = node_size,


nx.draw(G_screenname_emojis_converted, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)

# draw_networkx_labels(G_screenname_emojis_converted, edge_labels=edge_labels_screenname_emojis_converted)
# edge_labels_screenname_emojis_converted = nx.get_edge_attributes(G_screenname_emojis_converted, smi1_matrix_emojis_converted['value'])
# draw_network_edge_labels(G_screenname_emojis_converted, edge_labels=edge_labels_screenname_emojis_converted)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_RD0_ScreenName_Emojis_Converted_Random_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT NETWORK


# random_layout_screenname_emojis_converted = nx.random_layout(G_screenname_emojis_converted, iterations=50)
# emojis_converted_size = [G_screenname_emojis_converted.degree(emojis_converted) * 80 for emojis_converted in emojis_converted]
# nx.random_layout

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Emojis - Network')
nx.draw(G_screenname_emojis_converted, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
# edge_labels_screenname_emojis_converted = nx.get_edge_attributes(G_screenname_emojis_converted, smi1_matrix_emojis_converted['value'])
# draw_network_edge_labels(G_screenname_emojis_converted, edge_labels=edge_labels_screenname_emojis_converted)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_RD0_ScreenName_emojis_converted_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT CIRCULAR NETWORK

nx.circular_layout(G_screenname_emojis_converted)

# plt.figure(figsize=(30,20))
# plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Emojis - Network')
nx.draw(G_screenname_emojis_converted, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.6, font_size=12)
# edge_labels_screenname_emojis_converted = nx.get_edge_attributes(G_screenname_emojis_converted, smi1_matrix_emojis_converted['value'])
# draw_network_edge_labels(G_screenname_emojis_converted, edge_labels=edge_labels_screenname_emojis_converted)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_RD0_ScreenName_emojis_converted_Circular_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('---')
print('Done Graph Network emojis_converted')
print('---')



###################################################################################################################
###################################################################################################################
###################################################################################################################
###################################################################################################################
#
# 	 			 TEXT CLASSIFICATION
#                                              
###################################################################################################################	
	
# WITH TEXTBLOB - BASIC CLASSIFICATION

textblob_train_data = [
	('fucking love it', 'positive'),	
	('fucking great', 'positive'),
	('fucking amazing', 'positive'),
	('fucking kidding', 'negative'),
	('fucking bad', 'negative'),
	('fucking waste', 'negative')
]

textblob_test_data = [
	('fucking love it', 'positive'),	
	('fucking great', 'positive'),
	('fucking amazing', 'positive'),
	('fucking kidding', 'negative'),
	('fucking bad', 'negative'),
	('fucking bad', 'negative')
]

###########################################################

print('---')
print('Loading Libs 48')
print('---')

# NAIVE BAYES CLASSIFIER

# from textblob.classifiers import NaiveBayesClassifier

textblob_classifier = NaiveBayesClassifier(textblob_train_data)

textblob_test_phrase_1 = 'This lipstick is fucking amazing'
textblob_test_phrase_2 = 'This lipstick is fucking waste of money'

print('-------------------------')
print('TextBlob NaiveBayes Classifier  ------------ NEED TO DOOOOOO')
print(textblob_test_phrase_1)
print('is:')
print(textblob_classifier.classify(textblob_test_phrase_1))
print('-------------------------')

print('-------------------------')
print('TextBlob NaiveBayes Classifier')
print(textblob_test_phrase_2)
print('is:')
print(textblob_classifier.classify(textblob_test_phrase_2))
print('-------------------------')

# NOT WORKING 

######################################################################################################################

print('MAIN SMI: Done Initial TextBlob')
print(main_smi)
print('-------------------------')

###################################################################################################

# textblob_results = [TextBlob(i).sentiment.polarity for i in x_validation]

# textblob_pred = [0 if n < 0 else 1 doe n in textblob_results]


##############################################################################################

word_1_count_textblob = textblob_obj_text_c.word_counts[word_1]
word_2_count_textblob = textblob_obj_text_c.word_counts[word_2]
word_3_count_textblob = textblob_obj_text_c.word_counts[word_3]
word_4_count_textblob = textblob_obj_text_c.word_counts[word_4]
word_5_count_textblob = textblob_obj_text_c.word_counts[word_5]
word_6_count_textblob = textblob_obj_text_c.word_counts[word_6]
word_7_count_textblob = textblob_obj_text_c.word_counts[word_7]
word_8_count_textblob = textblob_obj_text_c.word_counts[word_8]
word_9_count_textblob = textblob_obj_text_c.word_counts[word_9]
word_10_count_textblob = textblob_obj_text_c.word_counts[word_10]
word_11_count_textblob = textblob_obj_text_c.word_counts[word_11]
word_12_count_textblob = textblob_obj_text_c.word_counts[word_12]
word_13_count_textblob = textblob_obj_text_c.word_counts[word_13]
word_14_count_textblob = textblob_obj_text_c.word_counts[word_14]
word_15_count_textblob = textblob_obj_text_c.word_counts[word_15]
word_16_count_textblob = textblob_obj_text_c.word_counts[word_16]
word_17_count_textblob = textblob_obj_text_c.word_counts[word_17]
word_18_count_textblob = textblob_obj_text_c.word_counts[word_18]
word_19_count_textblob = textblob_obj_text_c.word_counts[word_19]
word_20_count_textblob = textblob_obj_text_c.word_counts[word_20]
word_21_count_textblob = textblob_obj_text_c.word_counts[word_21]
word_22_count_textblob = textblob_obj_text_c.word_counts[word_22]
word_23_count_textblob = textblob_obj_text_c.word_counts[word_23]
word_24_count_textblob = textblob_obj_text_c.word_counts[word_24]
word_25_count_textblob = textblob_obj_text_c.word_counts[word_25]
word_26_count_textblob = textblob_obj_text_c.word_counts[word_26]
word_27_count_textblob = textblob_obj_text_c.word_counts[word_27]

# initialize list of Lists 
selected_tweets_words_counts_textblob = [[word_1, number_word_1], [word_2, number_word_2], [word_3, number_word_3], [word_4, number_word_4], [word_5, number_word_5], [word_6, number_word_6], [word_7, number_word_7], [word_8, number_word_8], [word_9, number_word_9], [word_10, number_word_10], [word_11, number_word_11], [word_12, number_word_12], [word_13, number_word_13], [word_14, number_word_14], [word_15, number_word_15], [word_16, number_word_16], [word_17, number_word_17], [word_18, number_word_18], [word_19, number_word_19], [word_20, number_word_20], [word_21, number_word_21], [word_22, number_word_22], [word_23, number_word_23], [word_24, number_word_24], [word_25, number_word_25], [word_26, number_word_26], [word_27, number_word_27]] 
 
# Create the pandas DataFrame 
selected_tweets_words_counts_textblob_df = pd.DataFrame(selected_tweets_words_counts_textblob, columns = ['tweets_words', 'Counts']) 

selected_tweets_words_counts_textblob_df.to_csv('4_5_211_SMI1_Selected_Tweets_Words_Counts_Textblob_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# selected_tweets_words_counts_textblob_df.to_excel('4_5_211_SMI1_Selected_Tweets_Words_Counts_Textblob_DF.xlsx', header=True)

# NOT WORKING

# Selected tweets_words Plot


# TABLE PLOT NEED TO DO 

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies - Textblob')
# selected_tweets_words_counts_textblob_df.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_211_SMI1_Selected_Tweets_Words_Textblob_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()
 
# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies Textblob - Pie')
# plt.pie(selected_tweets_words_counts_textblob_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.legend(selected_tweets_words_counts_textblob_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_211_SMI1_Selected_Tweets_Words_Textblob_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies TextBlob - Bars')
# selected_tweets_words_counts_textblob_df.plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_211_SMI1_Selected_Tweets_Words_Textblob_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

################################################################

# METHOD 2: 

word_1_query = tweets_smi_1.query('text == "love"')

print('---')
print('Word 1 Query:')
print(word_1_query.head)
print('---')

number_word_1 = len(word_1_query)

word_2_query = tweets_smi_1.query('text == "word_2"')
number_word_2 = len(word_2_query)

word_3_query = tweets_smi_1.query('text == "word_3"')
number_word_3 = len(word_3_query)
  
word_4_query = tweets_smi_1.query('text == "word_4"')
number_word_4 = len(word_4_query)
 
word_5_query = tweets_smi_1.query('text == "word_5"')
number_word_5 = len(word_5_query)
 
word_6_query = tweets_smi_1.query('text == "word_6"')
number_word_6 = len(word_6_query)
 
word_7_query = tweets_smi_1.query('text == "word_7"')
number_word_7 = len(word_7_query)
 
word_8_query = tweets_smi_1.query('text == "word_8"')
number_word_8 = len(word_8_query)
 
word_9_query = tweets_smi_1.query('text == "word_9"')
number_word_9 = len(word_9_query)
 
word_10_query = tweets_smi_1.query('text == "word_10"')
number_word_10 = len(word_10_query)

word_11_query = tweets_smi_1.query('text == "word_11"')
number_word_11 = len(word_11_query)

word_12_query = tweets_smi_1.query('text == "word_12"')
number_word_12 = len(word_12_query)

word_13_query = tweets_smi_1.query('text == "word_13"')
number_word_13 = len(word_13_query)

word_14_query = tweets_smi_1.query('text == "word_14"')
number_word_14 = len(word_14_query)

word_15_query = tweets_smi_1.query('text == "word_15"')
number_word_15 = len(word_15_query)

word_16_query = tweets_smi_1.query('text == "word_16"')
number_word_16 = len(word_16_query)

word_17_query = tweets_smi_1.query('text == "word_17"')
number_word_17 = len(word_17_query)

word_18_query = tweets_smi_1.query('text == "word_18"')
number_word_18 = len(word_18_query)

word_19_query = tweets_smi_1.query('text == "word_19"')
number_word_19 = len(word_19_query)

word_20_query = tweets_smi_1.query('text == "word_20"')
number_word_20 = len(word_20_query)

word_21_query = tweets_smi_1.query('text == "word_21"')
number_word_21 = len(word_21_query)

word_22_query = tweets_smi_1.query('text == "word_22"')
number_word_22 = len(word_22_query)

word_23_query = tweets_smi_1.query('text == "word_23"')
number_word_23 = len(word_23_query)

word_24_query = tweets_smi_1.query('text == "word_24"')
number_word_24 = len(word_24_query)

word_25_query = tweets_smi_1.query('text == "word_25"')
number_word_25 = len(word_25_query)

word_26_query = tweets_smi_1.query('text == "word_26"')
number_word_26 = len(word_26_query)

word_27_query = tweets_smi_1.query('text == "word_27"')
number_word_27 = len(word_27_query)

 
# initialize list of Lists 
selected_tweets_words_counts = [[word_1, number_word_1], [word_2, number_word_2], [word_3, number_word_3], [word_4, number_word_4], [word_5, number_word_5], [word_6, number_word_6], [word_7, number_word_7], [word_8, number_word_8], [word_9, number_word_9], [word_10, number_word_10], [word_11, number_word_11], [word_12, number_word_12], [word_13, number_word_13], [word_14, number_word_14], [word_15, number_word_15], [word_16, number_word_16], [word_17, number_word_17], [word_18, number_word_18], [word_19, number_word_19], [word_20, number_word_20], [word_21, number_word_21], [word_22, number_word_22], [word_23, number_word_23], [word_24, number_word_24], [word_25, number_word_25], [word_26, number_word_26], [word_27, number_word_27]] 
 
# Create the pandas DataFrame 
selected_tweets_words_counts_df = pd.DataFrame(selected_tweets_words_counts, columns = ['tweets_words', 'Counts']) 

selected_tweets_words_counts_df.to_csv('4_5_211_SMI1_Selected_Tweets_Words_Counts_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# selected_tweets_words_counts_df.to_excel('4_5_211_SMI1_Selected_Tweets_Words_Counts_DF.xlsx', header=True)

# NOT WORKING 

# Selected tweets_words Plot

# TABLE PLOT NEED TO DO 

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies')
# selected_tweets_words_counts_df.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_211_SMI1_Selected_Tweets_Words_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies - Pie')
# plt.pie(selected_tweets_words_counts_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.legend(selected_tweets_words_counts_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_211_SMI1_Selected_Tweets_Words_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies - Bars')
selected_tweets_words_counts_df.plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_211_SMI1_Selected_Tweets_Words_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



###############################################################################################################
#
#                      DATE   TIME SERIES ###################### NEED TO DO!!!!!!!!!!!
#
###############################################################################################################

# DATE TIME INFO - TIME SERIES

min_total_created = tweets_smi_1['created'].min()
max_total_created = tweets_smi_1['created'].max()

tweets_smi_1['created'] = pd.to_datetime(tweets_smi_1['created'], format='%Y%m%d', errors='ignore')

mean_total_created = statistics.mean(tweets_smi_1['created'])

print('---')
print('Min Time')
print(min_created)
print('---')

print('---')
print('Max created')
print(max_created)
print('---')

print('---')
print('Mean created')
# print(mean_created)
print('---')

# Initialize the list

created_stats = [['Min Time', min_created], ['Max Time', max_created]]

created_stats_df = pd.DataFrame(created_stats, columns=['created_measure', 'created_value'])

created_stats_df.to_csv('4_4_1_SMI1_Created_Stats_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# created_stats_df.to_excel('4_1_1_SMI1_Created_Stats_DF.xlsx', header=True)

# NEED TO DO TABLE PLOT


# PLOT 1 ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean Created Time')
plt.ioff()
created_stats_df.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_1_SMI1_Created_Stats_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOT 1 ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean Created Time - Bars')
plt.ioff()
created_stats_df.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_1_SMI1_Created_Stats_Bar.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

######################################################################################

# SNS PAIR PLOTS

# MULTIVARIABLE PLOT Favorites Followers

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.figure(figsize=(11,7))
# plt.figure(figsize=(14,10))
# plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Correlations Between Variables Favorites Followers / Years')
plt.ioff()
# sns.pairplot(tweets_smi_1, x_vars = ['total_favorites', 'followers', 'is_quote', 'is_retweet', 'quote_count', 'reply_count', 'followers_count', 'following', 'lists', 'number_total_hashtags', 'number_total_mentions', 'number_total_emojis_unicode'], y_vars = ['total_favorites', 'followers', 'is_quote', 'is_retweet', 'quote_count', 'reply_count', 'followers_count', 'following', 'lists', 'number_total_hashtags', 'number_total_mentions', 'number_total_emojis_unicode'], hue='year', kind='scatter')
sns.pairplot(tweets_smi_1, x_vars = ['total_favorites', 'followers', 'followers_count', 'following'], y_vars = ['total_favorites', 'followers', 'quote_count', 'reply_count', 'followers_count', 'following'], hue='year', kind='scatter')
# ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Time_Series_All_Total_Favorites_Followers_Tweets_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# MULTIVARIABLE PLOT Retweets Followers

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.figure(figsize=(11,7))
# plt.figure(figsize=(14,10))
# plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Correlations Between Variables Retweets Followers / Years')
plt.ioff()
# sns.pairplot(tweets_smi_1, x_vars = ['retweets', 'followers', 'is_quote', 'is_retweet', 'quote_count', 'reply_count', 'followers_count', 'following', 'lists', 'number_total_hashtags', 'number_total_mentions', 'number_total_emojis_unicode'], y_vars = ['retweets', 'followers', 'is_quote', 'is_retweet', 'quote_count', 'reply_count', 'followers_count', 'following', 'lists', 'number_total_hashtags', 'number_total_mentions', 'number_total_emojis_unicode'], hue='year', kind='scatter')
sns.pairplot(tweets_smi_1, x_vars = ['retweets', 'followers', 'followers_count', 'following'], y_vars = ['retweets', 'followers', 'quote_count', 'reply_count', 'followers_count', 'following'], hue='year', kind='scatter')
# ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_1_SMI1_Time_Series_All_Total_Retweets_Followers_Tweets_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('----------')
print('TEXT HEAD D')
# print(tweets_smi_1['text'].head)
print('-----------------------------------')


###################################################################################################################
#
# 		        TOPIC MODELLING : LSA Latent Semantic Analysis
#                                                 
###################################################################################################################

# analyticsvidhya.com/blob/2018/10/stewise-guide-topic-modeling-latent-semantic-analysis/


##############################################################################################################

# _df _df = pd.DataFrame()
# .to_csv('4_5_.csv', sep='\t', encoding='utf-8', index=True)
# excel

#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk


# NOT WORKING XXX NEED TO FIX


# Hashtags FREQ DISTRIBUTION

# Calculate frequency distribution

smi1_hashtags_fdist = nltk.FreqDist(tweets_smi_1['hashtags'])

# Output top 50 tweets_words

# for smi1_hashtags, frequency in smi1_hashtags_fdist.most_common(10):
#    print(u'{};{}'.format(smi1_hashtags, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


smi1_hashtags_fdist_df = pd.DataFrame([smi1_hashtags_fdist])

print('---')
print('Frequency Distribution of Hashtags')
print(smi1_hashtags_fdist_df.head)
print('---')

smi1_hashtags_fdist_df.to_csv('4_4_43A_110_SMI1_Hashtags_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_hashtags_fdist_df.to_excel('4_4_43A_110_SMI1_Hashtags_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution')
plt.ioff()
smi1_hashtags_fdist.plot(10, cumulative=False, alpha=0.9)  
# plt.plot(fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43A_110_SMI1_Hashtags_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_hashtags_fdist, patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_43A_110_SMI1_Hashtags_Freq_Dist_Box.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution - Pie')
plt.ioff()
# smi1_hashtags_fdist[:6], labels=top_smi1_hashtags_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_hashtags_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(smi1_hashtags_fdist, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_4_43A_110_SMI1_Hashtags_Freq_Dist_Pie_Chart.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_hashtags_fdist = smi1_hashtags_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution - Bars')
plt.ioff()
# smi1_hashtags_fdist[:10].plot.bar(alpha=0.9)
plt.xlabel('Hashtags')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_110_SMI1_Hashtags_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# screennames FREQ DISTRIBUTION

# Calculate frequency distribution

smi1_screennames_fdist = nltk.FreqDist(tweets_smi_1['screenName'])

# Output top 50 tweets_words

# for smi1_screennames, frequency in smi1_screennames_fdist.most_common(10):
#    print(u'{};{}'.format(smi1_screennames, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_screennames_fdist_df = pd.DataFrame(smi1_screennames_fdist)

smi1_screennames_fdist_df = pd.DataFrame([smi1_screennames_fdist])

print('---')
print('ScreenNames Frequency Distribution')
# print('smi1_screennames_fdist_df.head')
print('---')

smi1_screennames_fdist_df.to_csv('4_4_106_SMI1_Screennames_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_screennames_fdist_df.to_excel('4_4_106_SMI1_Screennames_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
# plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames Frequency Distribution')
plt.ioff()
smi1_screennames_fdist.plot(10,cumulative=False, alpha=0.9)  
# plt.plot(fdist)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.ioff()
plt.savefig('4_4_106_SMI1_Screennames_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
# plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_screennames_fdist, patch_artist=True, vert=False, notch=False, showfliers=True)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.ioff()
plt.savefig('4_4_106_SMI1_ScreenNames_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
# plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames Frequency Distribution - Pie')
plt.ioff()
# smi1_screennames_fdist[:6], labels=top_smi1_screennames_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_screennames_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_screennames_fdist, loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4) 
# plt.show()
plt.ioff()
plt.savefig('4_4_106_SMI1_ScreenNames_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_screennames_fdist = smi1_screennames_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
# plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Screennames Frequency Distribution - Bars')
plt.ioff()
# smi1_screennames_fdist[:10].plot.bar(alpha=0.9)
plt.xlabel('ScreenNames')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_106_SMI1_ScreenNames_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################################################################

#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Emojis Unicode FREQ DISTRIBUTION

# Calculate frequency distribution

smi1_emojis_unicode_fdist = nltk.FreqDist(tweets_smi_1['emojis_unicode'])

# Output top 50 tweets_words

# for smi1_emojis_unicode, frequency in smi1_emojis_unicode_fdist.most_common(10):
#    print(u'{};{}'.format(smi1_emojis_unicode, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


print('---')
print('Frequency Distribution of Emojis Unicode 1A')
# print(smi1_emojis_unicode_fdist.head)
print('---')

smi1_emojis_unicode_fdist_df = pd.DataFrame([smi1_emojis_unicode_fdist])

smi1_emojis_unicode_fdist_df.to_csv('4_4_112_SMI1_Emojis_Unicode_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_emojis_unicode_fdist_df.to_excel('4_4_112_SMI1_Emojis_Unicode_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution')
plt.ioff()
# smi1_emojis_unicode_fdist[:6].plot(cumulative=False, alpha=0.9) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_112_SMI1_Emojis_Unicode_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_emojis_unicode_fdist[:10], patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_112_SMI1_Emojis_Unicode_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Pie')
plt.ioff()
# smi1_emojis_unicode_fdist[:6], labels=top_smi1_emojis_unicode_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_emojis_unicode_fdist[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_emojis_unicode_fdist, loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_112_SMI1_Emojis_Unicode_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_emojis_unicode_fdist = smi1_emojis_unicode_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Bars')
plt.ioff()
# smi1_emojis_unicode_fdist[:6].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_112_SMI1_Emojis_Unicode_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


########################################################################################################
########################################################################################################
#
#    	      		TIME SERIES // DATE TIME DATETIME OPERATIONS - NEED TO FIX !!!!
#
########################################################################################################
########################################################################################################

tweets_smi_1['created'] = str(tweets_smi_1['created'])
# tweets_smi_1['created'] = tweets_smi_1['created'].astype(str).apply(lambda x: pd.to_datetime(x, format='%Y-%m-%d'))

print('--- Before TIMEDATE')
print(tweets_smi_1.dtypes)
print('---')

# tweets_smi_1['created'] = pd.to_datetime(tweets_smi_1['created'], format='%Y-%m-%d')

# tweets_smi_1['created'] = tweets_smi_1['created'].to_datetime()   ### OJO TO FIX QUITE EL DATETIME !!!!

# tweets_smi_1 = pd.DataFrame(tweets_smi_1)

print('--- After TIMEDATE')
print(tweets_smi_1.dtypes)
print('---')

############################################

# Followers OVER TIME 1

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Followers Over Time')
plt.plot(tweets_smi_1['created'], tweets_smi_1['followers'], alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_1_185_SMI1_Followers_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Followers OVER TIME 2

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Followers Over Time')
# tweets_smi_1.set_index('created')['followers'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_185_SMI1_Followers_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Followers Over Time')
# tweets_smi_1.set_indexbar('created')['followers'].plot(kind='bar', edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Followers_Time_All_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# favorites / Followers OVER TIME #################################### NEED TO DO!!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# color='#6593F5', #73C2FB

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites / Followers')
# tweets_smi_1.set_index('created')['favorites'].plot(color='lightskyblue', alpha=0.9)
# tweets_smi_1.set_index('created')['followers'].plot(color='blue', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_186_SMI1_Favorites_Followers.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# plt.rcdefaults()                 
fig, ax = plt.subplots()
plt.ioff()

# #73C2FB', '#6593F5'

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites / Followers - Bars')
# tweets_smi_1.set_index('created')['favorites'].plot(kind='bar', color='#73C2FB', edgecolor='white', label=' ', alpha=0.9)
# tweets_smi_1.set_index('created')['followers'].plot(kind='bar', color='#6593F5', edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_186_SMI1_Favorites_Followers_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Tweets favorites / Followers OVER TIME #################################### NEED TO DO!!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets / Favorites / Followers Over Time')
# tweets_smi_1.set_index('created')['total_tweets'].plot(color='lightskyblue', alpha=0.9)
# tweets_smi_1.set_index('created')['favorites'].plot(color='blue', alpha=0.9)
# tweets_smi_1.set_index('created')['followers'].plot(color='purple', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_186_SMI1_Tweets_Favorites_Followers_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets / Favorites / Followers Over Time - Bars')
# tweets_smi_1.set_index('created')['total_tweets'].plot(kind='bar', color='#73C2FB', edgecolor='white', label=' ', alpha=0.9)
# tweets_smi_1.set_index('created')['favorites'].plot(kind='bar', color='#6593F5', edgecolor='white', label=' ', alpha=0.9)
# tweets_smi_1.set_index('created')['followers'].plot(kind='bar', color='blue', edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_186_SMI1_Tweets_Favorites_Followers_Time_All_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##########################################################################################

# PLOT Followers / lists / favorites OVER TIME #################################### NEED TO DO!!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# followers,lists,total_tweets,lists,total_favorites
# color='#6593F5', #73C2FB

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Followers / Lists / Favorites Over Time')
# tweets_smi_1.set_index('created')['followers'].plot(color='purple', alpha=0.9)
# tweets_smi_1.set_index('created')['lists'].plot(color='blue', alpha=0.9)
# tweets_smi_1.set_index('created')['favorites'].plot(color='lightskyblue', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_186_SMI1_Followers_Lists_Favorites_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### NEED TO DO FOR SMI VS AUDIENCE!!!!!!!!!!!!!

################################################################################################
#########################################################################

sns.set()

# TIME SERIES 

# total_favorites_created_df = tweets_smi_1['created']

# total_favorites_created_df.month = pd.to_datetime(total_favorites_created_df.month)

# total_favorites_created_df.set_index('month', inplace=True)

## 22/09/2014 08:36:00

# tweets_smi_1['created'] = pd.to_datetime(tweets_smi_1['created'])



# SMI TWEETS PLOT NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(8,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Time Series: Tweets / Year')
# tweets_smi_1.groupby(['created'])['total_tweets'].plot(alpha=0.9)
tweets_smi_1['total_tweets'].plot(alpha=0.9)
ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend(bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.) 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Time_Series_TOTAL_Tweets_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()
 
# favorites PLOT NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(8,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Time Series: All Favorites / Year')
# tweets_smi_1['favorites'].sum().plot_date(alpha=0.9)
# tweets_smi_1.groupby(['created'])['favorites'].plot(alpha=0.9)
tweets_smi_1['favorites'].plot(alpha=0.9)
ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend(bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.) 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Time_Series_All_Favorites_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# retweets PLOT NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(8,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Time Series: All Retweets / Year')
# tweets_smi_1['retweets'].sum().plot_date(alpha=0.9)
# tweets_smi_1.groupby(['created'])['retweets'].plot(alpha=0.9)
tweets_smi_1['retweets'].plot(alpha=0.9)
ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend(bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.) 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Time_Series_All_Retweets_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Followers PLOT NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(8,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Time Series Followers / Year')
# tweets_smi_1['followers'].sum().plot_date(alpha=0.9)
# tweets_smi_1.groupby(['created'])['followers'].plot(alpha=0.9)
tweets_smi_1['followers'].plot(alpha=0.9)
ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend(bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.) 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Time_Series_Followers_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

######################################################################################

# https://towardsdatascience.com/an-end-to-end-project-on-total_favorites-series-analysis-and-forecasting-with-python-4835e6bf050b
# https://pythonplot.com/

# TWEETS YEAR CUM SUM 

smi1_year_tweets_counts = tweets_smi_1.groupby('year')['total_tweets'].count()

smi1_year_tweets_counts_df = pd.DataFrame([smi1_year_tweets_counts])

smi1_year_tweets_counts_df.to_csv('4_5_185_SMI1_Year_Tweets_Counts_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_year_tweets_counts_df.to_excel('4_5_185_SMI1_Year_Tweets_Counts_DF.xlsx', header='frequency_distribution') # Only argument is a string of the output file path


# PLOT TABLE NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets Counts per Year')
# tweets_smi_1.set_index('created')['total_tweets']
# smi1_year_tweets_counts.set_indexbar('created').plot(color='#6593F5', edgecolor='white', label=' ', alpha=0.9) 
smi1_year_tweets_counts.plot(alpha=0.9)  ########### NEED TO FIX -SHOWING FEW
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_185_SMI1_Tweets_Counts_Cum_Sum_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets Counts / Year - Cum. Sum.')
# tweets_smi_1.set_index('created')['total_tweets']
# smi1_year_tweets_counts.set_indexbar('created').plot(kind='bar', color='#6593F5', edgecolor='white', label=' ', alpha=0.9)
smi1_year_tweets_counts.plot(alpha=0.9)  ########### NEED TO FIX -SHOWING FEW
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_185_SMI1_Tweets_Counts_Cum_Sum_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###########

# total_favorites CUM SUM YEAR 

smi1_year_total_favorites_counts = tweets_smi_1.groupby('year')['favorites'].count()

smi1_year_total_favorites_counts_df = pd.DataFrame([smi1_year_total_favorites_counts])

smi1_year_tweets_counts_df.to_csv('4_5_185_SMI1_Year_Tweets_Counts_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_year_tweets_counts_df.to_excel('4_5_185_SMI1_Year_Tweets_Counts_DF.xlsx', header='frequency_distribution') # Only argument is a string of the output file path


# BARS PLOT Tweets OVER TIME NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites Over Time Cum. Sum. - Bars')
# smi1_year_total_favorites_counts_df.plot(kind='bar', edgecolor='white', label=' ', colors=colors_blue, alpha=0.9)
# tweets_smi_1.groupby('year')['favorites'].count().plot(kind='bar', edgecolor='white', label=' ', colors=colors_blue, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Favorites_Time_Cum_Sum_Year_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###########

# Followers CUM SUM YEAR 

smi1_year_followers_counts = tweets_smi_1.groupby('year')['followers'].count()

smi1_year_followers_counts_df = pd.DataFrame([smi1_year_followers_counts])

smi1_year_tweets_counts_df.to_csv('4_5_185_SMI1_Year_Tweets_Counts_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_year_tweets_counts_df.to_excel('4_5_185_SMI1_Year_Tweets_Counts_DF.xlsx', header='frequency_distribution') # Only argument is a string of the output file path


# BARS PLOT Tweets OVER TIME NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Followers / Time Cum. Sum. - Bars')
# smi1_year_followers_counts_df.plot(kind='bar', colors=colors_blue, edgecolor='white', label=' ', alpha=0.9)
smi1_year_followers_counts_df.plot(kind='bar', edgecolor='white', label=' ', alpha=0.9)
# tweets_smi_1.groupby('year')['followers'].count().plot(kind='bar', color='blue', edgecolor='white', label=' ', colors=colors_blue, alpha=0.9) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Followers_Time_Cum_Sum_Year_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('----------')
print('TEXT HEAD B')
# print(tweets_smi_1['text'].head)
print('-----------------------------------')



#############################################################################################

# BARS PLOT Tweets OVER TIME NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets Over Time')
# smi1_year_tweets_counts.plot(kind='bar', colors=colors_blue, edgecolor='white', label=' ', alpha=0.9)
smi1_year_tweets_counts.plot(kind='bar', edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Tweets_Time_All_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT favorites OVER TIME NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites Over Time')
# tweets_smi_1.set_index('created')['favorites'].plot(colors=colors_blue, alpha=0.9)
tweets_smi_1.set_index('created')['favorites'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Favorites_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites Over Time - Bars')
# tweets_smi_1.set_index('created')['favorites'].plot(kind='bar', colors=colors_blue, edgecolor='white', label=' ', alpha=0.9) # color='#73C2FB',
tweets_smi_1.set_index('created')['favorites'].plot(kind='bar', edgecolor='white', label=' ', alpha=0.9) # color='#73C2FB',
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Favorites_Time_All_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################
############################################################################################################
############################################################################################################

# Stratification Plot

# Another way to get more information out of a dataset is to divide it into smaller, more uniform subsets, and analyze each of these �strata� on its own. We will create a new HouseAge column, then partition the data into HouseAge strata, and construct side-by-side boxplots of the sale price within each stratum.

# tweets_smi_1.set['YearP'] = 2020 - tweets_smi_1.set['created']

# tweets_smi_1.set["YearGrp"] = pd.cut(tweets_smi_1.set.YearP, [2005, 2010, 2015, 2020]) # Create age strata based on these cut points

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Stratification Plot for Changes in Favorites / Year')
# sns.boxplot(x="year", y='favorites', colors=colors_blue, data='tweets_smi_1')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_196_SMI1_Strats_Favorites_Year.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################################################################################################################

# Stratification Plot

# Another way to get more information out of a dataset is to divide it into smaller, more uniform subsets, and analyze each of these �strata� on its own. We will create a new HouseAge column, then partition the data into HouseAge strata, and construct side-by-side boxplots of the sale price within each stratum.

# tweets_smi_1.set['year'] = 2020 - tweets_smi_1.set['year']
# tweets_smi_1.set["YearGrp"] = pd.cut(tweets_smi_1.set.YearP, [2005, 2010, 2015, 2020]) # Create age strata based on these cut points

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Stratification Plot for Changes in Followers / Year - Box')
# ns.boxplot(x="year", y='followers', colors=colors_blue, data='tweets_smi_1')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_196_SMI1_Strats_Followers_Year_Box_Plot.png', bbox_inches='tight')
plt.close(fig='all')


###############################################################################################################


# SCATTER PLOT PLOT 1 ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.figure(figsize=(16,14))
# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships Created / Network Weight - Scatter')
plt.ioff()
sns.relplot(x='created', y='network_weight', data=tweets_smi_1) # followers_count
# sns.lmplot(x='created', y='network_weight', hue='is_follower', data=tweets_smi_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_0_SMI1_Rel_Graphs_Created_Network_Weight_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################################################################

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.figure(figsize=(16,14))
# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships Created / Followers - Scatter')
plt.ioff()
# sns.relplot(x='created', y='followers', data=tweets_smi_1) # followers_count
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_0_SMI1_Rel_Graphs_Created_Followers_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

######################################################################################

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Friends All Created - Scatter')
plt.ioff()
# sns.pairplot(data=tweets_smi_1, hue='created')
# rel_graphs_tweets_smi_1_is_friend.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_is_friend.add_legend()
# rel_graphs_tweets_smi_1_is_friend.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_01_SMI1_Rel_Graphs_Is_Friend_Created_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


######################################################################################################################
######################################################################################################################
########################################################################################################

# Bars

# Number of Tweets / Date

# Prepare the data

# created = tweets_smi_1.iloc['created']
# tweets_numbers = tweets_smi_1.loc['total_tweets']

created = tweets_smi_1['created']
total_tweets_numbers = tweets_smi_1['total_tweets']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Total Tweets / Year - Bars')
plt.plot(created, total_tweets_numbers, label='linear')
# total_tweets_numbers.size().sort_values(ascending=False).plot.bar(colors=colors_blue, alpha=0.9)
plt.xlabel('Year / Month')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_215_SMI1_Total_Tweets_vs_Year_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


########################################################################################################

# Bars

# total_favorites

# Prepare the data

total_tweets_total_favorites = tweets_smi_1['favorites']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Favorites / Year - Bars')
plt.plot(created, total_tweets_total_favorites, label='linear')
# total_tweets_total_favorites.size().sort_values(ascending=False).plot.bar(colors=colors_blue, alpha=0.9)
plt.xlabel('Year / Month')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_216_SMI1_Total_Favorites_vs_Year_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


########################################################################################################

# Bars

# retweets

# Prepare the data

total_tweets_retweets = tweets_smi_1['retweets']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Retweets / Year - Bars')
plt.plot(created, total_tweets_retweets, label='linear')
# total_tweets_retweets.size().sort_values(ascending=False).plot.bar(colors=colors_blue, alpha=0.9)
plt.xlabel('Year / Month')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_216_SMI1_Total_Retweets_vs_Year_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


########################################################################################################


# Bars

# followers

# Prepare the data
tweets_followers = tweets_smi_1['followers']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Followers / Year - Bars')
plt.plot(created, tweets_followers, label='linear')
# tweets_followers.size().sort_values(ascending=False).plot.bar(colors=colors_blue, alpha=0.9)
plt.xlabel('Year / Month')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_217_SMI1_Followers_vs_Year_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

########################################################################################################

# Bars

# HASTAGS

tweets_smi_1['number_of_hashtags_in_tweets'] = pd.value_counts(tweets_smi_1['hashtags'], ascending=False, normalize=True)

# tweets_smi_1['number_of_hashtags_in_tweets'] = collections.Counter(tweets_smi_1['hashtags'])

number_of_hashtags_in_tweets = tweets_smi_1['number_of_hashtags_in_tweets']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Hashtags / Year - Bars')
# plt.plot(created, number_of_hashtags_in_tweets, label='linear')
# number_of_hashtags_in_tweets.size().sort_values(ascending=False).plot.bar(colors=colors_blue, alpha=0.9)
plt.xlabel('Year / Month')
# plt.ylabel('Count')
# ax.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_218_SMI1_Hashtags_vs_Year_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# number_of_hashtags_in_tweets_size = number_of_hashtags_in_tweets.size().sort_values(ascending=False)

number_of_hashtags_in_tweets_df = pd.DataFrame([number_of_hashtags_in_tweets])

number_of_hashtags_in_tweets_df.to_csv('4_4_218_SMI1_Number_of_Hashtags_in_Tweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

########################################################################################################

# MENTIONS PLOTS BAR

# MENTIONS


tweets_smi_1['number_of_mentions_in_tweets'] = pd.value_counts(tweets_smi_1['mentions'], ascending=False, normalize=True)

# tweets_smi_1['number_of_mentions_in_tweets'] = collections.Counter(tweets_smi_1['mentions'])

number_of_mentions_in_tweets = tweets_smi_1['number_of_mentions_in_tweets'] # tweets_smi_1.loc['mentions']


# Plot the data ## NEED TO FIX 

# TABLE PLOT NEED TO DO 

# Bars NEED TO DO

# Bars

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Mentions / Year - Bars')
# plt.plot(created, number_of_mentions_in_tweets, label='linear')
# number_of_mentions_in_tweets.size().sort_values(ascending=False).plot.bar(colors=colors_blue, alpha=0.9)
plt.xlabel('Year / Month')
# plt.ylabel('Mentions')
plt.plot(created[:10], number_of_mentions_in_tweets[:10], label='linear')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_219_SMI1_Mentions_vs_Year_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


number_of_mentions_in_tweets = pd.DataFrame([number_of_mentions_in_tweets], columns=['number_of_mentions_in_tweets'])

number_of_mentions_in_tweets.to_csv('4_4_219_SMI1_Number_of_Mentions_in_Tweets_CSV.csv')
# .to_excel()


########################################################################################################

# Bars

# Number of Following / Year

# Prepare the data
created = tweets_smi_1['created']

tweets_smi_1['following_numbers'] = pd.value_counts(tweets_smi_1['following'], ascending=False, normalize=True)

# tweets_smi_1['following_numbers'] = collections.Counter(tweets_smi_1['following'])

following_numbers = tweets_smi_1['following_numbers']


# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Following / Year - Bars')
# plt.plot(created, following_numbers, label='linear')
# following_numbers.sort_values(ascending=False).plot.bar(colors=colors_blue, alpha=0.9)
plt.xlabel('Year / Month')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_215_SMI1_Following_vs_Year_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################################################################

# Bars

# Total_total_favorites / Date

# Prepare the data
created = tweets_smi_1['created']
total_favorites_numbers = tweets_smi_1['favorites']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI All Favorites / Year - Bars')
plt.plot(created, total_favorites_numbers, label='linear')
# total_favorites_numbers.size().sort_values(ascending=False).plot.bar(colors=colors_blue, alpha=0.9)
plt.xlabel('Year / Month')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_215_SMI1_Total_Total_Favorites_vs_Year_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################################################################

# LINE PLOTS

# Numer of Followers / total_favorites

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))

plt.title('SMI Total Followers / Favorites - Bars')
# Plot with differently-colored markers.
plt.plot(created, tweets_followers, 'b-', label='followers', alpha=0.9)
plt.plot(created, tweets_smi_1['favorites'], 'r-', label='total_favorites', alpha=0.9)

# Create legend
plt.legend(loc='upper left')
plt.xlabel('Year')
# plt.ylabel('Followers / Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_220_SMI1_Followers_VS_Favorites_Time_Line_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################################################################

# Bars

# Total_retweets / Date Year 

# Prepare the data
created = tweets_smi_1['created']
retweets_numbers = tweets_smi_1['retweets']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI All Retweets / Year - Bars')
plt.plot(created, retweets_numbers, label='linear')
# retweets_numbers.size().sort_values(ascending=False).plot.bar(colors=colors_blue, alpha=0.9)
plt.xlabel('Year / Month')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_215_SMI1_Total_Total_Retweets_vs_Year_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################################################################

# LINE PLOTS

# Numer of Followers / retweets

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))

plt.title('SMI Followers / All Retweets / Year - Bars')
# Plot with differently-colored markers.
plt.plot(created, tweets_smi_1['followers'], 'b-', label='followers', alpha=0.9)
plt.plot(created, tweets_smi_1['retweets'], 'r-', label='retweets', alpha=0.9)

# Create legend
plt.legend(loc='upper left')
plt.xlabel('Year')
# plt.ylabel('Followers / Retweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_220_SMI1_Followers_VS_Total_Retweets_Year_Line_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()
###############################################################################################

# YEAR PLOT SNS

# METHOD 1 WORDS

# tweets_text_per_year = tweets_smi_1.set_index('year')['text']

smi1_value_counts_words_freq_dist_year = pd.value_counts(tweets_smi_1.set_index('year')['text'], ascending=False, normalize=True) #### NEED TO DO BUT FOR SENTENCES


smi1_value_counts_words_year = smi1_value_counts_words_freq_dist_year.sort_values(ascending=False)

# smi1_value_counts_words_freq_dist_year = tweets_text_words_year.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Words - Frequency _year')
# print(smi1_value_counts_words_year.head)

smi1_value_counts_words_year.to_csv('4_5A_185_SMI1_Value_Counts_Words_Year_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# smi1_value_counts_words_year.to_excel('4_5A_185_SMI1_Value_Counts_Words_YearF.xlsx', header=True)

# SCATTER PLOT YEAR 1 ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.figure(figsize=(16,14))
# plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships Created / Word Freq Year - Scatter')
plt.ioff()
# plt.bar(smi1_value_counts_words_year, alpha=0.7) # followers_count
# sns.lmplot(smi1_value_counts_words_freq_dist_year[:6], data=tweets_smi_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_0_0_SMI1_Rel_Graphs_Created_nWord_Freq_Year_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################

# ADD IMAGE LINK FIELD 

# METHOD 1 ######## Need to fix

###################################################################################################################
#
#		          SENTIMENT ANALYSIS: USING TEXTBLOB AND VADER SENTIMENT
#          
###################################################################################################################

# The SENTIMENT property returns a nameduple of the form sentiment(polarity, subjectivity). The polarity score is a 
# float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective
# and 1.0 is very subjective.

print('---')
print('Loading Libs 22')
print('---')

#load the descriptions into textblob

# XXX 

desc_blob = [TextBlob(desc) for desc in tweets_smi_1['text']]

#add the sentiment metrics to the dataframe

tweets_smi_1['textblob_polarity'] = [b.sentiment.polarity for b in desc_blob]
tweets_smi_1['textblob_subjectivity'] = [b.sentiment.subjectivity for b in desc_blob]

#show dataframe

print('---')
print('Vader Sentiment Polarity:')
print('---')

# returns the sentiment of text
# by returning a value between -1.0 and 1.0

tweets_smi_1['text'] = tweets_smi_1['text'].to_string()

# textblob_polarity = tweets_smi_1['text'].TextBlob(tweet).sentiment.polarity
# textblob_subjectivity = tweets_smi_1['text'].TextBlob(tweet).sentiment.subjectivity

textblob_polarity = tweets_smi_1['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)
textblob_subjectivity = tweets_smi_1['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)


# NOT WORKING - NEED TO FIX !!

# tweets_smi_1['textblob_sentiment'] = TextBlob(tweets_smi_1['text']).sentiment
# tweets_smi_1['textblob_polarity'] = TextBlob(tweets_smi_1['text']).sentiment.polarity
# tweets_smi_1['textblob_subjectivity'] = TextBlob(tweets_smi_1['text']).sentiment.subjectivity

tweets_smi_1['textblob_sentiment'] = tweets_smi_1['text'].apply(lambda tweet: TextBlob(tweet).sentiment)
tweets_smi_1['textblob_polarity'] = tweets_smi_1['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)
tweets_smi_1['textblob_subjectivity'] = tweets_smi_1['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)


print('---')
print('TextBlob Polarity:')
# print(textblob_polarity)

tweets_smi_1.to_csv('4_5_200_SMI1_Tweets_SMI_1_Textblob_Sentiment_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_excel('4_5_200_SMI1_Tweets_SMI_1_Textblob_Sentiment_DF.xlsx', header=True)

##### OJO !!! LO COMENTE!!! 

# if textblob_polarity == 0:
#  print('The Text is neutral')
# elif textblob_polarity > 0.75:
#  print('The Text is very positive') 
# elif textblob_polarity > 0.50:
#  print('The Text is positive')
# elif textblob_polarity > 0:
#  print('The Text is somewhat positive')
# elif textblob_polarity > -0.25:
#  print('The Text is somewhat negative') 
# elif textblob_polarity > -0.50:
#  print('The Text is negative')
# else:
#  print('The Text is very negative')
  
print('---')

print('TextBlob Subjectivity:')
# print(textblob_subjectivity)

# if textblob_subjectivity == 0:
#   print('The Text is extremely subjective')
# elif textblob_subjectivity > 0.75:
#   print('The Text is very objective')
# elif textblob_subjectivity > 0.50:
#   print('The Text is objective')
# elif textblob_subjectivity > 0.25:
#   print('The Text is subjective')
# else:
#   print('The Text is very subjective')

print('--- TENGO QUE ARREGLARRRRR ')

# Create the pandas DataFrame 
# textblob_sentiment_df = pd.DataFrame(textblob_obj_text_c.sentiment) 
# textblob_sentiment_df = textblob_sentiment_df.style.applymap(color_negative_red)

# textblob_sentiment_df.to_csv('4_5_200_SMI1_Textblob_Sentiment_df_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# textblob_sentiment_df.to_excel('4_5_200_SMI1_Textblob_Sentiment_df.xlsx', header=True)

# textblob_positiveness = 1 - textblob_polarity
# textblob_obj_text_cectivity = 1 - textblob_subjectivity

# initialize list of Lists 
# textblob_sentiments = [['Sentiment Polarity', textblob_polarity, textblob_positiveness]] 
 
# Create the pandas DataFrame 
# textblob_sentiments_df = pd.DataFrame(textblob_sentiments, columns = ['sentiment_item', 'sentiment_polarity', 'sentiment_positiveness']) 

# textblob_sentiments_df = textblob_sentiments_df.style.applymap(color_negative_red)

# textblob_sentiments_df.to_csv('4_5_200_SMI1_Textblob_Sentiments_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# textblob_sentiments_df.to_excel('4_5_200_SMI1_Textblob_Sentiments.xlsx', header=True)


# PLOT TABLE # NEED TO DO 

# Sentiment Plot

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity - TextBlob')
plt.ioff()
# textblob_polarity.plot(alpha=0.9, colors=colors_blue)
tweets_smi_1['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity).plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_200_SMI1_TextBlob_Sentiment_Polarity_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity TextBlob - Pie')
plt.ioff()
# plt.pie(tweets_smi_1['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.legend(textblob_polarity, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_200_SMI1_TextBLob_Sentiment_Polarity_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO   

## XXX NEED TO FIX NOT WORKING NEED TO GROUP BY YEARS!!! 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity TextBlob - Bars')
plt.ioff()
tweets_smi_1['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity).plot.bar(alpha=0.9)
plt.xlabel('Sentiment Polarity / Subjectivity')
plt.ylabel('Value')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_200_SMI1_TextBLob_Sentiment_Polarity_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Subjectivity - TextBlob')
plt.ioff()
# textblob_polarity.plot(alpha=0.9, colors=colors_blue)
tweets_smi_1['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity).plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_200_SMI1_TextBlob_Sentiment_Subjectivity_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity TextBlob - Pie')
plt.ioff()
# plt.pie(tweets_smi_1['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.legend(textblob_polarity, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_200_SMI1_TextBLob_Sentiment_Subjectivity_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Subjectivity TextBlob - Bars')
plt.ioff()
tweets_smi_1['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity).plot.bar(alpha=0.9)
plt.xlabel('Sentiment Polarity / Subjectivity')
plt.ylabel('Value')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_200_SMI1_TextBLob_Sentiment_Subjectivity_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()




###################################################################################################
##############################################################################################################################################

# Lexicon Normalization

# Lexicon normalization considers another type of noise in the text. For example, connection, connected, connecting word reduce to a 
# common word "connect". It reduces derivationally related forms of a word to a common root word.

# Stemming

# Stemming is a process of linguistic normalization, which reduces tweets_words to their word root word or chops off the derivational affixes. 
# For example, connection, connected, connecting word reduce to a common word "connect".

# The most common algorithm for stemming English, and one that has repeatedly been shown to be empirically very effective, is Porter’s algorithm
# (Porter 1980). The entire algorithm is too long and intricate to present here, but we will indicate its general nature. Porter’s algorithm consists of 5 phases
# of word reductions, applied sequentially. Within each phase there are various conventions to select rules, such as selecting the rule from each rule
# group that applies to the longest suffix. In the first phase, this convention is used with the Following rule group:

# (2.1) Rule Example
# SSES → SS caresses → caress
# IES → I ponies → poni
# SS → SS caress → caress
# S → cats → cat


print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

# STEMMING ## NEED TO DO 

tweets_text_words_porter = PorterStemmer().stem(tweets_text_words)  #### NOT WORKING NEED TO DO 

tweets_text_words_lancaster = LancasterStemmer().stem(tweets_text_words) #### NOT WORKING NEED TO DO

tweets_text_words_snowball = SnowballStemmer('english').stem(tweets_text_words)

# Initialize the List

tweets_text_words_stemmer = (['Porter', tweets_text_words_porter], ['Lancaster', tweets_text_words_lancaster], ['Snowball', tweets_text_words_snowball])

print('---')
print('Stemming Method Head')
print(tweets_text_words_stemmer_df.head)
print('---')


# Create the pandas DataFrame 
tweets_text_words_stemmer_df = pd.DataFrame(selected_tweets_words_counts, columns = ['stemming_method', 'stems']) 

tweets_text_words_stemmer_df.to_csv('4_5_210_SMI1_Tweets_Text_Words_Stemmer_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_text_words_stemmer_df.to_excel('4_5_210_SMI1_Tweets_Text_Words_Stemmer_DF.xlsx', header=True)


# TABLE PLOT NEED TO DO 

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Stemmer Methods')
plt.ioff()
# tweets_text_words_stemmer_df.plot(10,cumulative=False, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_210_SMI1_Tweets_Text_Words_Stemmer_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Stemmer Methods - Pie')
plt.ioff()
# plt.pie(tweets_text_words_stemmer_df[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.legend(tweets_text_words_stemmer_df[:6], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_210_SMI1_Tweets_Text_Words_Stemmer_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Stemmer Methods - Bars')
plt.ioff()
tweets_text_words_stemmers_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_210_SMI1_Tweets_Text_Words_Stemmer_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################################################################

# POLARITY DISTRIBUTION

# textblob_obj_text_c

def find_polarity_textblob(tweets):
	return TextBlob(tweets).sentiment.polarity
	
tweets_smi_1['textblob_sentiment_polarity'] = tweets_smi_1['text'].apply(find_polarity_textblob)

print('---')
print('TextBlob Sent Polarity Distributions')
print(tweets_smi_1['textblob_sentiment_polarity'].head)
print('---')

tweets_smi_1.to_csv('4_5_200_SMI1_Tweets_SMI_1_With_TBLOBPOLDIST_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_excel('4_5_200_SMI1_Tweets_SMI_1_With_TBLOBPOLDIST.xlsx', header=True)

# DIST PLOT # NEED TO DO

# HIST PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity TextBlob - Histogram')
plt.ioff()
sns.distplot(tweets_smi_1['textblob_sentiment_polarity'])
plt.xlabel('Sentiment Polarity')
plt.ylabel('Value')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_200_SMI1_TextBLob_Sentiment_Polarity_Distribution_Hist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###################################################################################################################

# DRAWING PARSE TREE ## NEED TO DO 

# USING NLTK 

fp_text_c_tagged = nltk.pos_tag(fp_text_c_sentence_tokens)

# text_nltk = tweets_smi_1['text']
text_nltk = fp_text_c

tokenized_text=sent_tokenize(text_nltk)

tokenized_text_df = pd.DataFrame(tokenized_text)

print('---')
print(tokenized_text_df.head())
print('---')

# NEED TO DO ARRIBA?????

tokenized_text_df.to_csv('4_5_211_SMI1_Tokenized_Sent_CSV.csv', sep='\t', encoding='utf-8', index=True)
# tokenized_text_df.to_excel('4_5_211_SMI1_Tokenized_Sent.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# tokenized_word=word_tokenize(fp_text_c)
tokenized_word= nltk.word_tokenize(fp_text_c)


fp_text_c_tagged = nltk.pos_tag(fp_text_c_sentence_tokens)


# PLOT  # NEED COUNT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentences')
# tokenized_text.plot(10,cumulative=False, alpha=0.9)
sns.distplot(tokenized_text)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_211_SMI1_Freq_Dist_Tokenized_Sentences.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentences - Pie')
plt.ioff()
# plt.pie(tokenized_text[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(tokenized_text, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_211_SMI1_Freq_Dist_Tokenized_Sentences_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentences - Bars')
plt.ioff()
# tokenized_text[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_211_SMI1_Freq_Dist_Tokenized_Sentences_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###################################################################################

# Word Tokenization

tokenized_tweets_words = nltk.tokenize.word_tokenize(text)
print(tokenized_word.head)

# tokenized_tweets_words = mosestokenizer.MosesTokenizer(text)

tokenized_tweets_words.to_csv('4_5_212_SMI1_Tokenized_Tweets_Words_CSV.csv', sep='\t', encoding='utf-8', index=True)
# tokenized_tweets_words.to_excel('4_5_212_SMI1_Tokenized_Tweets_Words.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution Tokenized Words')
plt.ioff()
# tokenized_tweets_words.plot(10,cumulative=False, alpha=0.9)
sns.distplot(tokenized_tweets_words, edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_212_SMI1_Freq_Dist_Tokenized_Tweets_Words.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution Tokenized Words - Pie')
plt.ioff()
# plt.pie(tokenized_tweets_words[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(tokenized_tweets_words, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_212_SMI1_Freq_Dist_Tokenized_Tweets_Words_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution Tokenized Words - Bars')
plt.ioff()
tokenized_tweets_words[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_212_SMI1_Freq_Dist_Tokenized_Tweets_Words_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#########################################################################################################################################################

# Stoptweets_words

# Stoptweets_words considered as noise in the text. Text may contain stop tweets_words such as is, am, are, this, a, an, the, etc.
# In NLTK for removing stoptweets_words, you need to create a list of stoptweets_words and filter out your list of tokens from these tweets_words.

# NEED TO DO - NOT WORKING!!!!!!!!!!!

# stop_tweets_words = nltk.corpus.stoptweets_words.tweets_words('english')

# stop_tweets_words = stoptweets_words.tweets_words('english')

print('---')
print('Stop tweets_words NOT WORKING NEED TO FIX')
# print(stop_tweets_words)
print('---')

filtered_sent=[]
for w in tokenized_tweets_words:
   if w not in stop_tweets_words:
        filtered_sent.append(w)
# print("Tokenized Sentence:",tokenized_sent)
# print("Filterd Sentence:",filtered_sent)

tokenized_sent.to_csv('4_5_213_SMI1_Tokenized_Sent_No_Stoptweets_words_CSV.csv', sep='\t', encoding='utf-8', index=True)
# tokenized_sent.to_excel('4_5_213_SMI1_Tokenized_Sent_No_Stoptweets_words.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# PLOT TOKENIZED SENT - 1 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentiment')
plt.ioff()
tokenized_sent.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)
tokenized_sent[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_213_SMI1_Freq_Dist_Tokenized_Sent.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentiment - Pie')
plt.ioff()
# plt.pie(tokenized_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(tokenized_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(tokenized_sent, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_213_SMI1_Freq_Dist_Tokenized_Sent_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

############################################################################

filtered_sent.to_csv('4_5_214_SMI1_Filtered_Tweets_Words_CSV.csv', sep='\t', encoding='utf-8', index=True)
# filtered_sent.to_excel('4_5_214_SMI1_Filtered_Tweets_Words.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# PLOT SENTIMENT OR SENTENCES????????? - 2

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Filtered Sentiment')
plt.ioff()
filtered_sent.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)
filtered_sent[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_214_SMI1_Freq_Dist_Filtered_Sent.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Filtered Sentiment - Pie')
plt.ioff()
plt.pie(filtered_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(filtered_sent, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_214_SMI1_Freq_Dist_Filtered_Sent_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO


###############################################################################################################
#
#         USE PACKAGE CORPUS - NEED TO DO 
#
###############################################################################################################

# https://towardsdatascience.com/practical-statistics-visualization-with-python-plotly-770e96e35067

print('---')
print('Loading Libs 49')
print('---')


print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

##########################################################################################################################

# NEED TO DO - FIX PLOTLY

##############################################################################################################
#
#                      SNA - CLUSTER ANALYSIS #############  NEED TO DO!!!!
#
##########################################################################################################################

print('done processing 4')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

###############################################################################################################

print('-- NEED TO DO Favorites AND RTS PER LANGUAGE!!!')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

###############################################################################################################

print('-- done quant processing 3 - analysis 1')
print(' -- NEED TO DO : SMIS Processing / DATA ANALYSIS QUANTITATIVE AND STATISTICS - SNA - CLUSTER ANALYSIS')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


#######################################################################################################################
#######################################################################################################################
#######################################################################################################################

# https://towardsdatascience.com/an-end-to-end-project-on-total_favorites-series-analysis-and-forecasting-with-python-4835e6bf050b

# Visualizing Furniture Sales Time Series Data

# Some distinguishable patterns appear when we plot the data. The total_favorites-series has seasonality pattern, such as sales are 
# always low at the beginning of the year and high at the end of the year. There is always an upward trend within any 
# single year with a couple of low months in the mid of the year. We can also visualize our data using a method called 
# total_favorites-series decomposition that allows us to decompose our total_favorites series into three distinct components: trend, 
# seasonality, and noise.


print('---')
print('Loading Libs 50')
print('---')

# from pylab import rcParams
# rcParams['figure.figsize'] = 18, 8

decomposition = sm.tsa.seasonal_decompose(y, model='additive')
fig = decomposition.plot(alpha=0.9)
# plt.show()

print('MAIN SMI: NEED TO DO')
print(main_smi)
print('----------------------------------------')

#######################################################################################################################
#######################################################################################################################
#######################################################################################################################
#######################################################################################################################


######################################################################################################

## SELECTED WORDS

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Calculate Frequency Distribution

smi1_tweets_text_words_fdist = nltk.FreqDist(tweets_text_words)

print('---')
print('Word Frequency Distribution - NEED TO DO - FIX KNOW TYPE')
print(smi1_tweets_text_words_fdist)
print('---')

print('---')
print('Word Frequency Distribution - Love')
print(smi1_tweets_text_words_fdist['love'])
print('---')

print('---')
print('Word Frequency Distribution - Hate')
print(smi1_tweets_text_words_fdist['hate'])
print('---')

print('---')
print('Word Frequency Distribution - Thanks')
print(smi1_tweets_text_words_fdist['thanks'])
print('---')

print('---')
print('Word Frequency Distribution - Fuck')
print(smi1_tweets_text_words_fdist['fuck'])
print('---')

print('---')
print('Word Frequency Distribution - Follow')
print(smi1_tweets_text_words_fdist['follow'])
print('---')

print('---')
print('Word Frequency Distribution - Friend')
print(smi1_tweets_text_words_fdist['friend'])
print('---')

print('---')
print('Word Frequency Distribution - Buy')
print(smi1_tweets_text_words_fdist['buy'])
print('---')

print('---')
print('Word Frequency Distribution - Brand')
print(smi1_tweets_text_words_fdist['brand'])
print('---')


word_love = smi1_tweets_text_words_fdist['love']
word_hate = smi1_tweets_text_words_fdist['hate']
word_thanks = smi1_tweets_text_words_fdist['thanks']
word_fuck = smi1_tweets_text_words_fdist['fuck']
word_follow = smi1_tweets_text_words_fdist['follow']
word_friend = smi1_tweets_text_words_fdist['friend']
word_buy = smi1_tweets_text_words_fdist['buy']
word_brand = smi1_tweets_text_words_fdist['brand']

## NEED TO DO PLOTS AND SAVE

# Output top 50 tweets_words

for word, frequency in smi1_tweets_text_words_fdist.most_common(10):
    print(u'{};{}'.format(word, frequency))
#     smi1_tweets_text_words_freq['tweets_text_words'] = pd.DataFrame(smi1_tweets_text_words_fdist.word)
#     smi1_tweets_text_words_freq['tweets_text_words_freq'] = pd.DataFrame(smi1_tweets_text_words_fdist.frequency)


# tweets_text_words_freq = tweets_text_words_fdist.keys()  ### NEED TO DO - FIX FROM ABOVE

print('---')
print('Word Frequency Distribution from List and Counts - Try 1')
# print(smi1_tweets_text_words_freq)  ######## NNED TO DO - NOT WORKING
print(type(smi1_tweets_text_words_fdist))
print('---')

print('---')
print('Number of Words In Text')
print(len(smi1_tweets_text_words_fdist))
print('---')

smi1_tweets_text_words_fdist_df = pd.DataFrame([smi1_tweets_text_words_fdist])

smi1_tweets_text_words_fdist_df.to_csv('4_5_101_SMI1_Word_Freq_Dist_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# tweets_text_words_fdist_df.to_excel('4_5_101_SMI1_Word_Freq_Dist_DF.xlsx', header='frequency_distribution') # Only argument is a string of the output file path


# PLOT TABLE NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Word: Love Frequency Distribution')
plt.ioff()
# word_love.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)   ########### NEED TO FIX -SHOWING FEW
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_101_SMI1_Word_LOVE_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Words Frequency Distribution - Box')
plt.ioff()
# plt.plot(smi1_tweets_text_words_fdist[:10])
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_101_SMI1_Words_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################

# HISTOGRAM PLOT NEED TO DO ## need to change

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Words Frequency Distribution - Histogram')
plt.ioff()
# plt.hist(smi1_tweets_text_words_fdist, labels=smi1_tweets_text_words_fdist, colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_tweets_text_words_fdist[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_101_SMI1_Words_Freq_Dist_PLOT_Hist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_tweets_text_words_fdist = tweets_text_words_fdist.sort(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets Words Frequency Distribution - Bars')
plt.ioff()
# smi1_tweets_text_words_fdist[:10].plot.bar(alpha=0.9)
# plt.bar(smi1_tweets_text_words_fdist[:10], tweets_text_words_fdist, color='#7f3d5f', edgecolor='white', label='words')
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_101_SMI1_Words_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################

## METHOD 2 - SEVERAL TRIES

# TO DF - NOT WORKING

# smi1_df_tweets_text_words_fdist = pd.DataFrame(smi1_tweets_text_words_fdist)

print('---')
print('Frequency Distribution of Words DF')
# print(smi1_df_tweets_text_words_fdist.head(10))
print('---')

#### TRY 2 NOT WORKING

# smi1_tweets_text_words_fdist_list = smi1_tweets_text_words_fdist.str.split()

# smi1_tweets_text_words_freq = ['smi1_tweets_text_words', 'smi1_tweets_text_words_freq']

# for w in smi1_tweets_text_words_fdist_list:
#	smi1_tweets_text_words_freq.append(smi1_tweets_text_words_fdist_list.count(w))
	

print('---')
print('Word Frequency Distribution from List and Counts - Try 2')
# print(smi1_tweets_text_words_freq)
print('---')
print('---')
# print('List\n' + str(smi1_tweets_text_words_freq) + '\n')
print('---')
print('---')
# print('Frequencies\n' + str(smi1_tweets_text_words_freq) + '\n')
print('---')
print('---')
# print('Pairs\n' + str(list(zip(smi1_tweets_text_words_fdist_list, smi1_tweets_text_words_freq)))
print('---')

# TABLE PLOT NEED TO DO 

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tweets Words - Pie')
# plt.pie(smi1_tweets_text_words_fdist[:6], labels=smi1_tweets_text_words_fdist, colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_tweets_text_words_fdist[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_words, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_102_SMI1_Tweets_Text_Words_fdist_df_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Words - Bars')
# smi1_tweets_text_words_fdist.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_102_SMI1_Tweets_Text_Words_fdist_df_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################### NEED TO FIX

# TUPLE TO DATAFRAME

# tweets_text_words_fdist_df = pd.DataFrame.from_records(tweets_text_words_fdist, columns=['tweets_text_words', 'tweets_text_words_freq'])
# tweets_text_words_fdist_df = pd.DataFrame.from_items(tweets_text_words_fdist)
# tweets_text_words_fdist_df = pd.DataFrame(tweets_text_words_fdist, index=[0])
# tweets_text_words_fdist_df = pd.DataFrame([tweets_text_words_fdist])
# tweets_text_words_fdist_df = pd.DataFrame(list(tweets_text_words_fdist), columns=['tweets_text_words', 'tweets_text_words_freq'], index['tweets_text_words', 'tweets_text_words_freq'])

# tweets_text_words_fdist_df = pd.DataFrame(tweets_text_words_fdist, columns=['tweets_text_words', 'tweets_text_words_freq'])
# a_tweets_text_words_fdist_df = tweets_text_words_fdist_df.pivot('tweets_text_words', 'tweets_text_words_freq')


# pd.DataFrame.from_dict(list(tweets_text_words_fdist.items()), columns=['tweets_words', 'tweets_words_frequency_counts'])
# pd.DataFrame.from_dict(tweets_text_words_fdist, orient='index')

# tweets_text_words_fdist_d_f = list(tweets_text_words_fdist, name='tweets_words_frequency_counts')

# tweets_text_words_fdist_d_f.index.name = 'tweets_words_frequency_counts' 

# tweets_text_words_fdist_df = pd.DataFrame(tweets_text_words_fdist, index=[0])

print('---')
print('Tweets_words Frequency Distribution DataFrame')
# print(tweets_text_words_fdist_df)
print('---')

print('FINISHED PRINTING WORD FREQUENCIES')

############ df_tweets_words_fdist is a tuple!!! NEED TO CHANGE TO DF and PLOT DUPLE!!!!

print('---')
print('DF tweets_words Frequency Distribution - fdist ')
# print(tweets_text_words_fdist_df)
print('---')

print('---')
print('Frequency Distribution of Words')
# print(tweets_text_words_fdist_df.head(10))
print('---')

# tweets_text_words_fdist_df.to_csv('4_5_103_SMI1_Tweets_Text_Words_fdist_df_CSV.csv', sep='\t', encoding='utf-8', index=True)
# tweets_text_words_fdist_df.to_excel('4_5_103_SMI1_Tweets_Text_Words_fdist_df.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# NEED TO DO TABLE PLOT

# PLOT NEED TO DO 

# Box 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Top Words - Box')
# tweets_text_words_fdist_df.plotbox() 
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_103_SMI1_Tweets_Text_Words_fdist_df_PLOT_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Top Words - Pie')
# plt.pie(tweets_text_words_fdist_df[:6], labels=tweets_text_words_fdist_df, colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# tweets_text_words_fdist_df[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_words, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_103_SMI1_Tweets_Text_Words_fdist_df_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## PLOT 2 TEST ## NEED TO DO FIX NOT WORKING

print('PLOT2 WORD DIST TEST - NEED TO FIX')

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Top Words')
# tweets_text_words_fdist_df.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
# tweets_text_words_fdist_df[:10].plot(alpha=0.9)
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_103_SMI1_Tweets_Text_Words_fdist_df_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

## Bars ## NEED TO DO FIX NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Top Words - Bars')
# tweets_text_words_fdist_df.plot.bars(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
# tweets_text_words_fdist_df[:10].plot.bars(alpha=0.9)
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_103_SMI1_Tweets_Text_Words_fdist_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

print('Box Test')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Word Frequency Distribution - Box')
# plt.boxplot(tweets_text_words_fdist_df) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_103_SMI1_Tweets_Text_Words_fdist_DF_Box_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#######################################################################

# Bars  ######### NEED TO DO!!!!!!!!!!!!!

print('Bars Test')

value_counts_text = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)

# Create DataFrame

value_counts_text_df = pd.DataFrame(value_counts_text, columns =['item', 'word_number_value', 'tweets_words_by_percentage'])
value_counts_text_df

print('---')
print('Tweets_words in Tweets and Values')
# print(value_counts_text_df.head)
print('---')

value_counts_text_df.to_csv('4_5_104_SMI1_Value_Counts_Text_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_text_df.to_excel('4_5_104_SMI1_Value_Counts_Text_DF.xlxs', header=True)

# top_tweets_words_fdist = tweets_words_fdist.sort_values(ascending=False)

# value_counts_df_tweets_words_fdist = pd.value_counts([value_counts_text], ascending=False, normalize=True)
# top_tweets_words_fdist = value_counts_df_tweets_words_fdist.sort_values(ascending=False)  ######## NEED TO PUT FIX SORTING DUPLE

# TABLE PLOT NEED TO DO 

# Bars

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Word Frequency Distribution - Bars')
pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
plt.tight_layout(pad=2)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_104_SMI1_Top_Tweets_Words_Freqdists_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')



print('------------------')
print('TEXT HEAD 2D')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')



##################################################

# PLOTS  ######### NEED TO DO!!!!!!!!!!!!! NOT WORKING

# value_counts_text = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)
# top_tweets_words_fdist = df_tweets_words_fdist.sort_values(ascending=False)

# value_counts_df_tweets_words_fdist = pd.value_counts(pd.DataFrame(df_tweets_words_fdist), ascending=False, normalize=True)
# top_tweets_words_fdist = pd.DataFrame(value_counts_df_tweets_words_fdist.sort_values(ascending=False))

# top_tweets_words_fdist_f = value_counts_df_tweets_words_fdist.sort_values(ascending=False)

## NEED TO DO SAVE INFO TO CSV!!!!

# top_tweets_words_fdist.to_csv('4_5_104_SMI1_Top_Tweets_Value_Counts_Words_fdist_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# top_tweets_words_fdist.to_excel('4_5_104_SMI1_Top_Tweets_Value_Counts_Words_fdist.xlsx', header=True)

# TABLE PLOT NEED TO DO 

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Word Frequency Distribution - Bars')
# top_tweets_words_fdist[:10].plot.bar(alpha=0.9)
# value_counts_df_tweets_words_fdist[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_104_SMI1_Top_Tweets_Words_Value_Counts_fdists_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

## NEED TO DO SCREENNAME STAS!!!!!!!!!!!!!!

############################################################################################################

# Value Counts screenNames   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_screenname = pd.value_counts(tweets_smi_1['screenName'], ascending=False, normalize=True)

smi1_value_counts_screenname = value_counts_screenname.sort_values(ascending=False)

print(value_counts_screenname)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics of ScreenNames - Grouped')
print(smi1_value_counts_screenname.describe().head())
print('---')

smi1_value_counts_screenname_df = pd.DataFrame(value_counts_screenname, columns =['screenname'])

smi1_value_counts_screenname_df.to_csv('4_5_105_SMI1_ScreenNames_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_screenname_df.to_excel('4_5_105_SMI1_Screennames_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Value Counts')
# smi1_value_counts_screenname.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_screenname[:10].plot(alpha=0.9)
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_105_SMI1_Top_ScreenNames_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Value Counts - Pie')
# plt.pie(smi1_value_counts_screenname[:6], labels=smi1_tweets_text_words_fdist['screenname'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_screenname[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True)
# plt.legend(smi1_value_counts_screenname, bbox_to_anchor=(1.05, 1.15), loc='upper right', borderaxespad=0.2)
# plt.legend() 
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_105_SMI1_Top_ScreenNames_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Value Counts - Bars')
plt.ioff()
# smi1_value_counts_screenname[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_105_SMI1_Top_ScreenNames_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# screennames FREQ DISTRIBUTION

smi1_screennames = tweets_smi_1['screenName']

# Calculate frequency distribution
smi1_screennames_fdist = nltk.FreqDist(smi1_screennames)

# Output top 50 tweets_words

for smi1_screennames, frequency in smi1_screennames_fdist.most_common(10):
   print(u'{};{}'.format(smi1_screennames, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_screennames_fdist_df = pd.DataFrame(smi1_screennames_fdist)

smi1_screennames_fdist_df = pd.DataFrame([smi1_screennames_fdist])

print('---')
print('ScreenNames Frequency Distribution C')
print('smi1_screennames_fdist_df.head(10)')
print('---')

smi1_screennames_fdist_df.to_csv('4_5_106_SMI1_Screennames_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_screennames_fdist_df.to_excel('4_5_106_SMI1_Screennames_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames Frequency Distribution 3')
plt.ioff()
# smi1_screennames_fdist.plot(10,cumulative=False, alpha=0.9)  
# smi1_screennames_fdist[:10].plot(alpha=0.9)
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_106_3_SMI1_Screennames_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames Frequency Distribution - Box')
plt.ioff()
# plt.plot(smi1_screennames_fdist)
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_106_SMI1_ScreenNames_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames Frequency Distribution - Pie')
plt.ioff()
# smi1_screennames_fdist[:6], labels=top_smi1_screennames_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_screennames_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_screennames_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_106_SMI1_ScreenNames_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_screennames_fdist = smi1_screennames_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Screennames Frequency Distribution - Bars')
plt.ioff()
# smi1_screennames_fdist.plot.bar(alpha=0.9)
plt.xlabel('ScreenNames')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_106_SMI1_ScreenNames_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('---')
print('tweets_smi_1 Text HEAD 2E')
print(tweets_smi_1['text'].head)
# print(tweets_smi_1['text'].dtypes)
print('-----------------------------------------------------------------------')


############################################################################################################

## NEED TO DO MENTIONS STAS!!!!!!!!!!!!!!

############################################################################################################


# Value Counts All Mentions   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_mentions = pd.value_counts(tweets_smi_1['mentions'], ascending=False, normalize=True)

smi1_value_counts_mentions = value_counts_mentions.sort_values(ascending=False)

print(value_counts_mentions)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Mentions')
print(smi1_value_counts_mentions.describe().head())
print('---')

smi1_value_counts_mentions_df = pd.DataFrame(value_counts_mentions, columns =['mentions'])

smi1_value_counts_mentions_df.to_csv('4_5_107A_SMI1_Mentions_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_mentions_df.to_excel('4_5_107A_SMI1_Mentions_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts')
# smi1_value_counts_mentions.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_mentions[:10].plot(alpha=0.9)
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_107A_SMI1_Top_Mentions_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Pie')
smi1_value_counts_mentions[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True, subplots=True)
# plt.legend(smi1_value_counts_mentions, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_107A_SMI1_Top_Mentions_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Bars')
smi1_value_counts_mentions[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_107A_SMI1_Top_Mentions_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# MENTIONS FREQ DISTRIBUTION

smi1_mentions = tweets_smi_1['mentions']

# Calculate frequency distribution
smi1_mentions_fdist = nltk.FreqDist(smi1_mentions)

# Output top 50 tweets_words

for smi1_mentions, frequency in smi1_mentions_fdist.most_common(10):
    print(u'{};{}'.format(smi1_mentions, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_mentions_fdist_df = pd.DataFrame(smi1_mentions_fdist)

smi1_mentions_fdist_df = pd.DataFrame([smi1_mentions_fdist])

print('---')
print('Frequency Distribution of Mentions 4')
print('smi1_mentions_fdist_df.head(10)')
print('---')

smi1_mentions_fdist_df.to_csv('4_5_108_SMI1_Mentions_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_mentions_fdist_df.to_excel('4_5_108_SMI1_Mentions_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution')
# smi1_mentions_fdist.plot(10,cumulative=False, alpha=0.9)  
smi1_mentions_fdist[:10].plot(alpha=0.9) 
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_108_SMI1_Mentions_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution - Box')
# plt.plot(smi1_mentions_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_108_SMI1_Mentions_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution - Pie')
# smi1_mentions_fdist[:6], labels=top_smi1_mentions_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_mentions_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_mentions_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_5_108_SMI1_Mentions_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_mentions_fdist = smi1_mentions_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution - Bars')
# smi1_mentions_fdist.plot.bar(alpha=0.9)
plt.xlabel('Mentions')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_108_SMI1_Mentions_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

## NEED TO DO Hashtag STAS!!!!!!!!!!!!!!

############################################################################################################


# Value Counts All Hashtags   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_hashtags = pd.value_counts(tweets_smi_1['hashtags'], ascending=False, normalize=True)

smi1_value_counts_hashtags = value_counts_hashtags.sort_values(ascending=False)

print(value_counts_hashtags)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Hashtags')
print(smi1_value_counts_hashtags.describe().head())
print('---')

smi1_value_counts_hashtags_df = pd.DataFrame(value_counts_hashtags, columns =['hashtags'])

smi1_value_counts_hashtags_df.to_csv('4_5_109_SMI1_Hashtags_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_hashtags_df.to_excel('4_5_109_SMI1_Hashtags_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts')
# smi1_value_counts_hashtags.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_hashtags[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_109_SMI1_Top_Hashtags_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Pie')
smi1_value_counts_hashtags[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True)
# plt.legend(smi1_value_counts_hashtags, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_5_109_SMI1_Top_Hashtags_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Bars')
smi1_value_counts_hashtags[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_109_SMI1_Top_Hashtags_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Hashtags FREQ DISTRIBUTION

smi1_hashtags = tweets_smi_1['hashtags']

# Calculate frequency distribution
smi1_hashtags_fdist = nltk.FreqDist(smi1_hashtags)

# Output top 50 tweets_words

for smi1_hashtags, frequency in smi1_hashtags_fdist.most_common(10):
    print(u'{};{}'.format(smi1_hashtags, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_hashtags_fdist_df = pd.DataFrame(smi1_hashtags_fdist)

smi1_hashtags_fdist_df = pd.DataFrame([smi1_hashtags_fdist])

print('---')
print('Frequency Distribution of Hashtags')
print('smi1_hashtags_fdist_df.head(10)')
print('---')

smi1_hashtags_fdist_df.to_csv('4_5_110_SMI1_Hashtags_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_hashtags_fdist_df.to_excel('4_5_110_SMI1_Hashtags_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution 3')
plt.ioff()
# smi1_hashtags_fdist.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)  
# smi1_hashtags_fdist[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_110_3_SMI1_Hashtags_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_hashtags_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_110_SMI1_Hashtags_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution - Pie')
plt.ioff()
# smi1_hashtags_fdist[:6], labels=top_smi1_hashtags_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_hashtags_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_hashtags_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_5_110_SMI1_Hashtags_Freq_Dist_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_hashtags_fdist = smi1_hashtags_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution - Bars')
plt.ioff()
# smi1_hashtags_fdist.plot.bar(alpha=0.9)
plt.xlabel('Hashtags')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_110_SMI1_Hashtags_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLE

del smi1_hashtags_fdist

############################################################################################################

## NEED TO DO Emojis_Unicode STAS!!!!!!!!!!!!!!

############################################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Value Counts All Emojis Unicode   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].encode('unicode-escape')

value_counts_emojis_unicode = pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True)

smi1_value_counts_emojis_unicode = value_counts_emojis_unicode.sort_values(ascending=False)

print(value_counts_emojis_unicode.head)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Emojis Unicode')
print(smi1_value_counts_emojis_unicode.describe().head())
print('---')

smi1_value_counts_emojis_unicode_df = pd.DataFrame(value_counts_emojis_unicode, columns =['emojis_unicode'])

smi1_value_counts_emojis_unicode_df.to_csv('4_5_111_SMI1_Emojis_Unicode_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_emojis_unicode_df.to_excel('4_5_111_SMI1_Emojis_Unicode_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
# smi1_value_counts_emojis_unicode.plot(10,cumulative=False,alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_emojis_unicode[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_111_SMI1_Top_Emojis_Unicode_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
smi1_value_counts_emojis_unicode[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_emojis_unicode, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_111_SMI1_Top_Emojis_Unicode_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True)[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_111_SMI1_Top_Emojis_Unicode_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLE

del smi1_value_counts_emojis_unicode

#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Emojis Unicode FREQ DISTRIBUTION

smi1_emojis_unicode = tweets_smi_1['emojis_unicode']

# Calculate frequency distribution
smi1_emojis_unicode_fdist = nltk.FreqDist(smi1_emojis_unicode)

# Output top 50 tweets_words

for smi1_emojis_unicode, frequency in smi1_emojis_unicode_fdist.most_common(10):
    print(u'{};{}'.format(smi1_emojis_unicode, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_emojis_unicode_fdist_df = pd.DataFrame(smi1_emojis_unicode_fdist)

smi1_emojis_unicode_fdist_df = pd.DataFrame([smi1_emojis_unicode_fdist])

print('---')
print('Frequency Distribution of Emojis')
print(smi1_emojis_unicode_fdist_df.head(10))
print('---')

smi1_emojis_unicode_fdist_df.to_csv('4_5_111_SMI1_Emojis_Unicode_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_emojis_unicode_fdist_df.to_excel('4_5_111_SMI1_Emojis_Unicode_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution 9')
# smi1_emojis_unicode_fdist.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)  
# smi1_emojis_unicode_fdist[:10].plot(alpha=0.9) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_111_9_SMI1_Emojis_Unicode_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Box')
# plt.boxplot(smi1_emojis_unicode_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_111_SMI1_Emojis_Unicode_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Pie')
# smi1_emojis_unicode_fdist[:6], labels=top_smi1_emojis_unicode_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_emojis_unicode_fdist.plot.pie(colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_emojis_unicode_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_111_SMI1_Emojis_Unicode_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_emojis_unicode_fdist = smi1_emojis_unicode_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Bars')
# smi1_emojis_unicode_fdist.plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_111_SMI1_Emojis_Unicode_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLE

del smi1_emojis_unicode
del smi1_emojis_unicode_fdist

############################################################################################################

## NEED TO DO Emojis Converted STAS!!!!!!!!!!!!!!

############################################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Value Counts All Emojis Converted   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_emojis_converted = pd.value_counts(tweets_smi_1['emojis_converted'], ascending=False, normalize=True)

smi1_value_counts_emojis_converted = value_counts_emojis_converted.sort_values(ascending=False)

print(value_counts_emojis_converted)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Emojis')
print(smi1_value_counts_emojis_converted.describe().head())
print('---')

smi1_value_counts_emojis_converted_df = pd.DataFrame(value_counts_emojis_converted, columns =['emojis_converted'])

smi1_value_counts_emojis_converted_df.to_csv('4_5_112_SMI1_Emojis_Converted_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_emojis_converted_df.to_excel('4_5_112_SMI1_Emojis_Converted_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
# smi1_value_counts_emojis_converted.plot(10,cumulative=False,alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_emojis_converted[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_112_SMI1_Top_Emojis_Converted_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
smi1_value_counts_emojis_converted[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_emojis_converted, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_112_SMI1_Top_Emojis_Converted_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
# smi1_value_counts_emojis_converted[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_112_SMI1_Top_Emojis_Converted_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del smi1_value_counts_emojis_converted

#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Emojis Converted FREQ DISTRIBUTION

smi1_emojis_converted = tweets_smi_1['emojis_converted']

# Calculate frequency distribution
smi1_emojis_converted_fdist = nltk.FreqDist(smi1_emojis_converted)

# Output top 50 tweets_words

for smi1_emojis_converted, frequency in smi1_emojis_converted_fdist.most_common(10):
    print(u'{};{}'.format(smi1_emojis_converted, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_emojis_converted_fdist_df = pd.DataFrame(smi1_emojis_converted_fdist)

smi1_emojis_converted_fdist_df = pd.DataFrame([smi1_emojis_converted_fdist])

print('---')
print('Frequency Distribution of Emojis')
print(smi1_emojis_converted_fdist_df.head(10))
print('---')

smi1_emojis_converted_fdist_df.to_csv('4_5_112_SMI1_Emojis_Converted_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_emojis_converted_fdist_df.to_excel('4_5_112_SMI1_Emojis_Converted_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution 10')
# smi1_emojis_converted_fdist.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)  
# smi1_emojis_converted_fdist[:10].plot(alpha=0.9) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_112_10_SMI1_Emojis_Converted_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Box')
# plt.boxplot(smi1_emojis_converted_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_112_SMI1_Emojis_Converted_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Pie')
# smi1_emojis_converted_fdist[:6], labels=top_smi1_emojis_converted_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_emojis_converted_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_emojis_converted_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.) 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_112_SMI1_Emojis_Converted_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_emojis_converted_fdist = smi1_emojis_converted_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Bars')
# smi1_emojis_converted_fdist.plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_112_SMI1_Emojis_Converted_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del smi1_emojis_converted
del smi1_emojis_converted_fdist

###########################################################################################################

### EMOJIS GRAPHICAL STATS 2

###########################################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Value Counts All Emojis Graphical   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# tweets_smi_1['emojis_graphical'] = tweets_smi_1['emojis_unicode'].encode('unicode-escape')

value_counts_emojis_graphical_2 = pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True)

smi1_value_counts_emojis_graphical_2 = value_counts_emojis_graphical_2.sort_values(ascending=False)

print(value_counts_emojis_graphical_2)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Emojis Graphical_2')
print(smi1_value_counts_emojis_graphical_2.describe().head())
print('---')

smi1_value_counts_emojis_graphical_2_df = pd.DataFrame(value_counts_emojis_graphical_2, columns =['emojis_graphical_2'])

smi1_value_counts_emojis_graphical_2_df.to_csv('4_5_113_SMI1_Emojis_Graphical_2_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_emojis_graphical_2_df.to_excel('4_5_113_SMI1_Emojis_Graphical_2_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
# smi1_value_counts_emojis_graphical_2_df.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_emojis_graphical_2_df[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_SMI1_Top_Emojis_Graphical_2_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
# plt.pie(smi1_value_counts_emojis_graphical_2_df[:6], labels=smi1_tweets_text_words_fdist['emojis_graphical_2'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_emojis_graphical_2_df[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_emojis_graphical_2_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.tight_layout(pad=1)
# plt.show()
plt.savefig('4_5_113_SMI1_Top_Emojis_Graphical_2_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
smi1_value_counts_emojis_graphical_2_df[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_SMI1_Top_Emojis_Graphical_2_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del smi1_value_counts_emojis_graphical_2
del smi1_value_counts_emojis_graphical_2_df

#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Emojis Graphical_2 FREQ DISTRIBUTION

smi1_emojis_graphical_2 = tweets_smi_1['emojis_converted']

# Calculate frequency distribution
smi1_emojis_graphical_2_fdist = nltk.FreqDist(smi1_emojis_graphical_2)

# Output top 50 tweets_words

for smi1_emojis_graphical_2, frequency in smi1_emojis_graphical_2_fdist.most_common(10):
    print(u'{};{}'.format(smi1_emojis_graphical_2, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_emojis_graphical_2_fdist_df = pd.DataFrame(smi1_emojis_graphical_2_fdist)

smi1_emojis_graphical_2_fdist_df = pd.DataFrame([smi1_emojis_graphical_2_fdist])

print('---')
print('Frequency Distribution of Emojis Graphical_2')
print(smi1_emojis_graphical_2_fdist_df.head(10))
print('---')

smi1_emojis_graphical_2_fdist_df.to_csv('4_5_113_SMI1_Emojis_Graphical_2_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_emojis_graphical_2_fdist_df.to_excel('4_5_113_SMI1_Emojis_Graphical_2_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution 11')
# smi1_emojis_graphical_2_fdist.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)  
# plt.plot(fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_11_SMI1_Emojis_Graphical_2_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Box')
# plt.boxplot(smi1_emojis_graphical_2_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_113_SMI1_Emojis_Graphical_2_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Pie')
# smi1_emojis_graphical_2_fdist[:6], labels=top_smi1_emojis_graphical_2_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_emojis_graphical_2_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_emojis_graphical_2_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_113_SMI1_Emojis_Graphical_2_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_emojis_graphical_2_fdist = smi1_emojis_graphical_2_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Bars')
# smi1_emojis_graphical_2_fdist.plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
 
# plt.show()
plt.savefig('4_5_113_SMI1_Emojis_Graphical_2_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del smi1_emojis_graphical_2
del smi1_emojis_graphical_2_fdist

############################################################################################################

## NEED TO DO LANGUAGE STAS!!!!!!!!!!!!!!

############################################################################################################


# Value Counts All Languages   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_languages = pd.value_counts(tweets_smi_1['language'], ascending=False, normalize=True)

smi1_value_counts_languages = value_counts_languages.sort_values(ascending=False)


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Languages')
print(smi1_value_counts_languages.describe().head())
print('---')


smi1_value_counts_languages_percentages = (smi1_value_counts_languages * 100)/number_total_tweets

smi1_value_counts_list = [[smi1_value_counts_languages, smi1_value_counts_languages, smi1_value_counts_languages_percentages]]


smi1_value_counts_languages_df = pd.DataFrame(value_counts_languages, columns =['languages', 'languages_count', 'languages_percentage'])

smi1_value_counts_languages_df.to_csv('4_5_160_SMI1_Languages_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_languages_df.to_excel('4_5_160_SMI1_Languages_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Languages Value Counts')
# smi1_value_counts_languages_df.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_languages_df[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_160_SMI1_Top_Languages_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Languages Value Counts - Pie')
smi1_value_counts_languages_df[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_languages_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_160_SMI1_Top_Languages_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Languages Value Counts - Bars')
smi1_value_counts_languages_df[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_160_SMI1_Top_Languages_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del smi1_value_counts_languages
del smi1_value_counts_languages_df

#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Languages FREQ DISTRIBUTION

smi1_languages = tweets_smi_1['language']

# Calculate frequency distribution
smi1_languages_fdist = nltk.FreqDist(smi1_languages)

# Output top 50 tweets_words

for smi1_languages, frequency in smi1_languages_fdist.most_common(10):
    print(u'{};{}'.format(smi1_languages, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_languages_fdist_df = pd.DataFrame(smi1_languages_fdist)

smi1_languages_fdist_df = pd.DataFrame([smi1_languages_fdist])

print('---')
print('Frequency Distribution of Languages')
print('smi1_languages_fdist_df.head(10)')
print('---')

smi1_languages_fdist_df.to_csv('4_5_161_SMI1_Languages_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_languages_fdist_df.to_excel('4_5_161_SMI1_Languages_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Languages Frequency Distribution')
# smi1_languages_fdist.plot(10,cumulative=False)  
# plt.plot(fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_161_SMI1_Languages_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Languages Frequency Distribution - Box')
# plt.boxplot(smi1_languages_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_161_SMI1_Languages_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Languages Frequency Distribution - Pie')
# smi1_languages_fdist[:6], labels=top_smi1_languages_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_languages_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_languages_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_161_SMI1_Languages_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_languages_fdist = smi1_languages_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Languages Frequency Distribution - Bars')
# smi1_languages_fdist.plot.bar(alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_161_SMI1_Languages_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLE

del smi1_languages
del smi1_languages_fdist
del smi1_languages_fdist_df


print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

############################################################################################################

# NEED FREQ DIST EMOJIS, IMAGE LINK< NEED TO DO MISSING HASHTAFS MENTIONS !!!! < ETC

############################################################################################################
#######################################################################################################

print('---')
print('Loading Libs 51')
print('---')

## NEED TO DO MISSING MENTIONS AND HASTAGS!!!!

# missing_mentions = pd.DataFrame(missing_mentions)

# quant_stats_smi_tweets_1 = go.Figure(data=[go.Table(header=dict(values=['Tweets by JAMESCHARLES', 'Tweets by JEFFREESTAR', 'Tweets by MANNYMUA733', 'Tweets by MICHELLEPHAN', 'Tweets by NIKKIETUTORIALS', 'Tweets by ZOELLA', 'Tweets by AUDIENCE']),
#                 cells=dict(values=[[number_tweets_by_jamescharles, number_tweets_by_jeffreestar, number_tweets_by_mannymua733, number_tweets_by_michellephan, number_tweets_by_nikkietutorials, number_tweets_by_zoella, 'number_tweets_by_audience']]))])

# quant_stats_smi_tweets_1.show()

# quant_stats_smi_tweets_1.to_csv('4_5_165_SMI1_Quant_Stats_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# quant_stats_smi_tweets_1.to_excel('4_5_165_SMI1_Quant_Stats.xlsx', header=True)

# Plot ## NEED TO DO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets SMIs - Audience')
# plt.plot(quant_stats_smi_tweets_1, edgecolor='white', label=' ', alpha=0.9)
# plt.imshow(quant_stats_smi_tweets_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
 
# plt.show()
plt.savefig('4_5_165_SMI1_Quant_Stats_SMI_Tweets_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))  ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets SMIs - Audience - Pie')
# plt.pie(top_retweets_tweets[:6], labels=top_retweets_tweets, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# quant_stats_smi_tweets_1.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(top_retweets_tweets, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_165_SMI1_Quant_Stats_SMI_Tweets_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets SMIs vs Audience - Bars')
# plt.plot.bar(quant_stats_smi_tweets_1)
# quant_stats_smi_tweets_1_df['tweets_about_smi_number'].plot.bar(alpha=0.9)
# ax.bar(tweets_about_percentages_df['tweets_about_smi_item'], tweets_about_percentages_df['tweets_about_smi_number'])
plt.xlabel('SMI / Audience')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_165_SMI1_Quant_Stats_SMI_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

## DELETE VARIABLE

# del missing_mentions
# del quant_stats_smi_tweets_1
# del tweets_about_percentages
# del tweets_about_percentages_df

####################################################################################################################################################

# This selects the top 5 highest average points among all Tweets: # NEED TO DO


# Mean ScreenName

# smi1_screenname_mean = statistics.mean(tweets_smi_1['screenName'])

# smi1_screenname_mean.sort_values(by='screenName', ascending=False).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest ScreenName Average Points - Tweets:')
# print(smi1_screenname_mean.sort_values(by="screenName').head)
print('--')

# smi1_screenname_mean_sort_values_df = pd.DataFrame(smi1_screenname_mean().sort_values(by="screenName'))

# smi1_screenname_mean_sort_values_df.to_csv('4_5_166_SM1_Screenname_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Average Points - Tweets')
# plt.plot(smi1_screenname_mean_sort_values_df[:10], color='#6593F5', edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_166_SMI1_Screenname_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenName Average Points - Pie')
# plt.pie(smi1_screenname_mean_sort_values_df.most_common(10), labels=screenname_mean_sort_values_df.most_common(10), colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_screenname_mean_sort_values_df[:10], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_166_SMI1_Screenname_Mean_Sort_Values_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenName Average Points - Bars')
# smi1_screenname_mean_sort_values_df[:10].plot.bar(alpha=0.9)
plt.xlabel('ScreenName')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_166_SMI1_Screenname_Mean_Sort_Values_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

# del smi1_screenname_mean
# del smi1_screenname_mean_sort_values
# del smi1_screenname_mean_sort_values_df

############################################################################################################

# This selects the top 5 highest average points among all Tweets:

# smi1_favorites_mean().sort_values(by='favorites',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest Favorites Average Points Among All Tweets:')
# print(smi1_favorites_mean().sort_values(by='favorites', ascending=True).head())
print('---')


# smi1_favorites_mean_sort_values_favorites_df = pd.DataFrame(smi1_favorites_mean().sort_values(by='favorites',ascending=True))

# smi1_favorites_mean_sort_values_favorites_df.to_csv('4_5_167_SMI1_Favorites_Mean_Sort_Values_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_favorites_mean_sort_values_favorites_df.to_excel('4_5_167_SMI1_Favorites_Mean_Sort_Values_Favorites_DF.xlsx', header=True)

# PLOT TABLE plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Average Points - Tweets')
plt.plot(smi1_favorites_mean_sort_values_favorites_df[:10], edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_167_SMI1_Favorites_Mean_Sort_Values_Favorites_df_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Average Points - Pie')
plt.pie(smi1_favorites_mean_sort_values_favorites_df[:10], labels=smi1_favorites_mean_sort_values_favorites_df.most_common(10), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_favorites_mean_sort_values_favorites_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_167_SMI1_Favorites_Mean_Sort_Values_Favorites_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Average Points - Bars')
# smi1_screenname_mean_sort_values_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_167_SMI1_Favorites_Mean_Sort_Values_Favorites_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

# del smi1_favorites_mean_sort_values_favorites
# del smi1_favorites_mean_sort_values_favorites_df

############################################################################################################

# This selects the top 5 highest average points among all Tweets:

# smi1_retweets_mean().sort_values(by='retweets',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest Retweets Average Points Amongst All Tweets:')
# print(smi1_retweets_mean().sort_values(by='retweets',ascending=True).head())
print('---')

# smi1_retweets_mean_sort_values_retweets_df = pd.DataFrame(smi1_retweets_mean().sort_values(by='retweets',ascending=True))

# smi1_retweets_mean_sort_values_retweets_df.to_csv('4_5_168_SMI1_Retweets_Mean_Sort_Values_Retweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Retweets - Grouped')
# plt.plot(smi1_languages.describe(), edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_168_SMI1_Retweets_Mean_Sort_Values_Retweets_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO Box


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Retweets Grouped - Pie')
# plt.pie(smi1_languages.describe(), labels=smi1_languages.describe(), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_languages.describe(), bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_168_SMI1_Retweets_Mean_Sort_Values_Retweets_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Average Points Bars')
# smi1_languages.describe().plot.bar(alpha=0.9)
plt.xlabel('Retweets')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_168_SMI1_Retweets_Mean_Sort_Values_Retweets_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#########################################################################################################################################################

# Number of tweets_words in text

number_of_tweets_words = len(smi1_tweets_text_words_fdist)
number_of_tweets_words

print('---')
print('Number of tweets_words Analyzed : No Stop Words')
print(number_of_tweets_words)
print('---')

number_of_tweets_words_df = pd.DataFrame([number_of_tweets_words])

number_of_tweets_words_df.to_csv('4_5_169_SMI1_Number_of_Tweets_Words_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# number_of_tweets_words_df.to_excel('4_5_169_SMI1_Number_of_Tweets_Words_DF.xlsx, header=True)

# PLOT TABLE plt.plot

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Text')
# plt.plot(number_of_tweets_words_df.describe())
# plt.plot(number_of_tweets_words_df, edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_169_SMI1_Number_of_Tweets_Words_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO DO Box


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Text - Pie')
# plt.pie(number_of_tweets_words_df, labels=number_of_tweets_words_df, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(number_of_tweets_words_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_5_169_SMI1_Number_of_Tweets_Words_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

## DELETE VARIABLES

del number_of_tweets_words
del number_of_tweets_words_df

###################################################################################################################

# STATISTICS DF # NEED TO DO 


# initialize list of Lists 

# quant_stats_1_pairs = [['Mean Favorites', median_favorites, 'Median Retweets', median_retweets, 'Mode Favorites', mode_favorites, 'Mode Retweets', mode_retweets], ['Variance Favorites', variance_favorites, 'Variance Retweets', variance_retweets, 'Population Variance Favorites', pvariance_favorites, 'Population Variance Retweets', pvariance_retweets, 'Standard Deviation Retweets', stdev_retweets, 'Population Standard Deviation Favorites', pstdev_favorites, 'Population Standard Deviation Retweets', pstdev_retweets, 'Skewness Favorites', skewness_favorites, 'Skewness Retweets', skewness_retweets, 'Percentiles Favorites (25, 50, 75)', quantiles_favorites, 'Percentiles Retweets (25, 50, 75)', quantiles_retweets, 'Ranges Favorites', ptp_favorites, 'Ranges Retweets', ptp_retweets, 'Correlation Coefficient - Pearson Regression', corr_coef_favs_rts_pearson, 'Linear Regession', r_linar_reg],['Number of Tweets Analyzed', number_tweets, 'Number of Unique Tweets Analyzed', number_unique_tweets, 'Number of tweets_words in Text', number_of_tweets_words, 'List Unique Followers ReTweeting, Commenting, Engaged', number_unique_engaged_users, 'Number of Users Who Favorite', number_unique_tweets_with_favorites, 'Number of Unique Tweets with Retweets', 'number_unique_retweets_users', 'List Unique Hashtags', 'number_unique_hashtags', 'List Unique Mentions', 'number_unique_mentions', 'List Unique Emojis', 'number_unique_emojis_unicode', 'List Unique Emojis', 'number_unique_emojis_converted', 'List Unique Language', 'number_unique_languages', 'Summary Statistics All Favorites / Desc', 'summ_stats_all_favs_desc', 'Summary Statistics All Retweets / Desc', 'summ_stats_all_rts_desc']]

# Create the pandas DataFrame 
# quant_stats_measures_1 = pd.DataFrame(quant_stats_1_pairs, columns = ['Measures of Centrality', 'Measures of Variability', 'General User Stats', 'Other Stats']) 

# quant_stats_measures_1.to_csv('4_5_170_SMI1_Quant_Stats_Measures_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# quant_stats_measures_1.to_excel('4_5_170_SMI1_Quant_Stats_Measures.xlsx', header=True)

### NEED TO DO PLOT NEED TO FIX ?????????????????

############################################################################################################

print('---')
print('Loading Libs 52')
print('---')

### FROM tweets_words ABOVE

fdist_2 = FreqDist(word)
print(fdist_2)

fdist_2.most_common(10)

print('---')
print('Frequency Distribution of Tweets_words - Most Common 10')
print(fdist_2.most_common(10))
print('---')

df_fdist_2_df = pd.DataFrame([fdist_2])

df_fdist_2_df.to_csv('4_5_171_SMI1_Word_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# df_fdist_2_df.to_excel('4_5_171_SMI1_Word_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# NEED TO DO - TABLE PLOT 

# PLOT

# Frequency Distribution Plot

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Frequency Distribution of Words')
# df_fdist_2_df.plot(10,cumulative=False, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_171_SMI1_Word_Freq_Dist_10.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Box ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Word Frequency Distribution - Box')
# plt.boxplot(FreqDist(word), edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_171_SMI1_Word_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))    ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Word Frequency Distribution - Pie')
# plt.pie(FreqDist(word)[:6], labels=FreqDist(word), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(FreqDist(word), bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_5_171_SMI1_Word_Freq_Dist_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

## DELETE VARIABLE

del fdist_2
del df_fdist_2_df

###############################################################################################################


# Summary Statistics of all screenNames     # XXX     ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_screenname.describe().head()

print('---')
print('Summary Statistics of All ScreenNames')
print(smi1_screenname.describe().head())
print('---')

smi1_screenname_describe = smi1_screenname_describe_df.describe()

smi1_screenname_describe_df = pd.DataFrame([smi1_screenname_describe])

smi1_screenname_describe_df.to_csv('4_5_172_SMI1_Screenname_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot NEED TO DO

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All ScreenNames')
# plt.plot(smi1_screenname_describe_df.describe())
# plt.plot(ssmi1_screenname_describe_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_172_SMI1_ScreenName_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All ScreenNames - Pie')
# plt.pie(smi1_screenname_describe_df.describe(), colors=colors_blue, labels=smi1_screenname_describe_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=smi1_screenname_describe_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend(smi1_screenname_describe_df.describe(), loc=3)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_172_SMI1_ScreenName_Describe_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

## DELETE VARIABLE

del smi1_screenname_describe
del smi1_screenname_describe_df

##########################################################################################################


# Summary Statistics of all Text          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_text.describe().head()

print('---')
print('Summary Statistics of All Text')
print(smi1_text.describe().head())
print('---')

smi1_text_describe_df = pd.DataFrame(smi1_text.describe())

smi1_text_describe_df.to_csv('4_5_173_SM1_Text_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot NEED TO DO

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Text')
# plt.plot(smi1_hashtags.describe())
# plt.plot(smi1_text_describe_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_173_SMI1_Text_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################


# hashtags_total_1

# Summary Statistics of all Hashtags          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_hashtags.describe().head()

print('---')
print('Summary Statistics of All Hashtags')
# print(smi1_hashtags.describe().head())
print('---')

# smi1_hashtags_describe_df = pd.DataFrame([smi1_hashtags.describe()])

# smi1_hashtags_describe_df.to_csv('4_5_174_SMI1_Hashtags_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_hashtags_describe_df.to_excel()

# PLOT TABLE ## NEED TO DO 

# plt.plot

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Mentions - Grouped')
# plt.plot(smi1_hashtags.describe(), color='#73C2FB', edgecolor='white', label=' ', alpha=0.9)
# plt.plot(smi1_hashtags_describe_df, edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_174_SMI1_Hashtags_Describe_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################


# Summary Statistics of all Mentions          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_mentions.describe().head()


# smi1_mentions_describe_df = pd.DataFrame(smi1_mentions.describe())

# smi1_mentions_describe_df.to_csv('4_5_175_SM1_mentions_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of all Mentions - Grouped')
# plt.plot(smi1_mentions.describe(), edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_175_SMI1_Mentions_Describe_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie - NEED TO DO

# Bars - NEED TO DO


############################################################################################################

# Summary Statistics of all Emojis       ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Summary Statistics of All Emojis')
# print(smi1_emojis_unicode.describe())
print('---')


# smi1_emojis_unicode_describe_df = pd.DataFrame(smi1_emojis_unicode.describe())

# smi1_emojis_unicode_describe_df.to_csv('4_5_176_SM1_Emojis_Unicode_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Emojis - Grouped')
# plt.plot(smi1_emojis_unicode_df.describe(), edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_176_SMI1_Emojis_Unicode_Describe_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT

# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################

# Summary Statistics of all Emojis Converted          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_emojis_converted.describe().head()

# smi1_emojis_converted_describe_df = pd.DataFrame(smi1_emojis_converted.describe())

# smi1_emojis_converted_describe_df.to_csv('4_5_177_SMI1_Emojis_Converted_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO TABLE 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Emojis - Grouped')
# plt.plot(smi1_emojis_converted_describe_df, edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_177_SMI1_Emojis_Converted_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################

# This selects the top 5 highest average points among all Tweets:

# smi1_screenname.mean().sort_values(by="screenname",ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

smi1_screenname_describe_df = pd.DataFrame(smi1_screenname.mean().sort_values(by="screenname",ascending=True).describe())

smi1_screenname_describe.to_csv('4_5_178_SMI1_Screenname_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Average Points ScreenNames')
# plt.plot(smi1_screenname_mean_sort_values_df[:10], edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_178_SMI1_Screenname_Mean_Sort_Values_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Average Points ScreenNames - Pie')
plt.pie(smi1_screenname_mean_sort_values_df, colors=colors_blue, labels=smi1_screenname_mean_sort_values_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=smi1_screenname_mean_sort_values_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
plt.legend(smi1_screenname_mean_sort_values_df, loc=3)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_178_SMI1_Screenname_Mean_Sort_Values_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

#########################################################################

tweets_smi_1['unique_hashtags'] = tweets_smi_1['hashtags'].unique()    
# tweets_smi_1['unique_hashtags']


## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['number_unique_hashtags'] = len(tweets_smi_1['unique_hashtags'])
# tweets_smi_1['number_unique_hashtags']

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Hashtags Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['number_unique_hashtags'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_188_SMI1_Unique_Hashtags_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


tweets_smi_1['unique_mentions'] = tweets_smi_1([tweets_smi_1['mentions'].unique()]) 
# tweets_smi_1['unique_mentions'] 

## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['number_unique_mentions'] = len(tweets_smi_1['number_unique_mentions'])
# tweets_smi_1['number_unique_mentions'] 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Mentions Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['number_unique_mentions'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_187_SMI1_Unique_Mentions_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Unique Mentions / Hashtags OVER TIME #################################### NEED TO DO!!!!!!!!!!

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Mentions / Hashtags Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['number_unique_mentions'].plot(alpha=0.9)
tweets_smi_1.set_index('created')['number_unique_hashtags'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_189_SMI1_Unique_Mentions_Hashtags_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

tweets_smi_1['unique_emojis_converted'] = tweets_smi_1['emojis_converted'].unique()    
# tweets_smi_1['unique_emojis_converted'] 

## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['number_unique_emojis_converted'] = len(tweets_smi_1['number_unique_emojis_converted'])
# tweets_smi_1['number_unique_emojis_converted'] 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Emojis Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['number_unique_emojis_converted'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_190_SMI1_Unique_Emojis_Converted_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


tweets_smi_1['unique_screeName'] = tweets_smi_1['screeName'].unique()    
# tweets_smi_1['unique_screeName']


## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['number_unique_screeName'] = len(tweets_smi_1['unique_screeName'])
# tweets_smi_1['number_unique_screeName']

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique ScreeNames Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['number_unique_screeName'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_191_SMI1_Unique_ScreeNames_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


tweets_smi_1['unique_language'] = tweets_smi_1['language'].unique()    
# tweets_smi_1['unique_language']


## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['number_unique_language'] = len(tweets_smi_1['unique_language'])
# tweets_smi_1['number_unique_language']

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Languages Over Time')
plt.ioff()
tweets_smi_1.set_index('created')['number_unique_language'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_191_SMI1_Unique_Languages_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Unique Emojis / Languages OVER TIME #################################### NEED TO DO!!!!!!!!!!

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Emojis / Languages Over Time')
plt.ioff()
# tweets_smi_1.set_index('created')['number_unique_emojis'].plot(alpha=0.9)
# tweets_smi_1.set_index('created')['number_unique_hashtags'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_192_SMI1_Unique_EMOJIS_Languages_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################


# This selects the top 5 highest average points among all Tweets:

smi1_hashtags.mean().sort_values(by='hashtags',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

smi1_hashtags_mean_sort_values_df = pd.DataFrame(smi1_hashtags.mean().sort_values(by='hashtags',ascending=True))

smi1_hashtags_mean_sort_values_df.to_csv('4_5_179_SMI1_Hashtags_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Average Points Hashtags')
# plt.plot(smi1_hashtags_mean_sort_values_df[:10], edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_179_SMI1_Hashtags_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Average Points Hashtags - Pie')
plt.pie(smi1_hashtags_mean_sort_values_df, colors=colors_blue, labels=smi1_hashtags_mean_sort_values_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_hashtags_mean_sort_values_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
plt.legend(smi1_hashtags_mean_sort_values_df, loc=3)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_179_SMI1_Hashtags_Mean_Sort_Values_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

############################################################################################################

# This selects the top 5 highest average points among all Tweets:

smi1_mentions.mean().sort_values(by='mentions',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

smi1_mentions_mean_sort_values_df = pd.DataFrame(smi1_mentions.mean().sort_values(by='mentions',ascending=True))

smi1_mentions_mean_sort_values_df.to_csv('4_5_140_SMI1_Mentions_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Average Points Mentions')
# plt.plot(smi1_mentions_mean_sort_values_df[:10], edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_140_SMI1_Mentions_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################

# This selects the top 5 highest average points among all Tweets:

# smi1_emojis_unicode.mean().sort_values(by='emojis_unicode',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

smi1_emojis_unicode_mean_sort_values_df = pd.DataFrame(smi1_emojis_unicode.mean().sort_values(by='emojis_unicode',ascending=True))

smi1_emojis_unicode_mean_sort_values_df.to_csv('4_5_144_SMI1_Emojis_Unicode_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Highest Average Points Emojis')
plt.plot(smi1_emojis_unicode_mean_sort_values_df[:10], edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_144_SMI1_Emojis_Unicode_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################


# This selects the top 5 highest average points among all Tweets:

# smi1_emojis_converted.mean().sort_values(by='emojis_converted',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

smi1_emojis_converted_sort_values_df = pd.DataFrame(smi1_emojis_converted.mean().sort_values(by='emojis_converted',ascending=True))

smi1_emojis_converted_mean_sort_values_df.to_csv('4_5_145_SMI1_Emojis_converted_mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Highest Average Emojis')
plt.plot(smi1_emojis_converted_mean_sort_values_df[:10], edgecolor='white', label=' ', alpha=0.9)
pplt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_145_SMI1_Emojis_Converted_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')




print('---')
print('tweets_smi_1 Text HEAD 2F')
print(tweets_smi_1['text'].head)
# print(tweets_smi_1['text'].dtypes)
print('-----------------------------------------------------------------------')


############################################################################################################


# This selects the top 5 highest average points among all Tweets:

smi1_languages.mean().sort_values(by='language',ascending=True).head() ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


smi1_languages_mean_sort_values_df = pd.DataFrame(smi1_languages.mean().sort_values(by='mentions',ascending=True))

smi1_languages_mean_sort_values_df.to_csv('4_5_146_SMI1_Languages_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Highest Average Languages')
plt.plot(smi1_languages_mean_sort_values_df[:10], edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_146_SMI1_Languages_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO


#############################################################################################################

############ NEED TO DO = WHAT ABOUT THE OTHER VARIABLES?????????

# List Unique Hashtags ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!

total_hashtags = tweets_smi_1['hashtags']    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_total_hashtags = len(total_hashtags)
number_total_hashtags

print('---')
print('List Total Hashtags')
print(number_total_hashtags)
print('---')

unique_hashtags = tweets_smi_1['hashtags'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_hashtags = len(unique_hashtags)
number_unique_hashtags

print('---')
print('List Unique Hashtags')
print(number_unique_hashtags)
print('---')


number_unique_hashtags_df = pd.DataFrame(number_unique_hashtags, columns=['number_unique_hashtags'])

number_unique_hashtags_df.to_csv('4_5_147_SMI1_2_Number_Unique_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# number_unique_hashtags_df.to_excel('4_5_147_SMI1_2_Number_Unique_Hashtags_DF.xlsx', header=True)

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Hashtags')
# plt.plot(number_unique_hashtags_df[:10], edgecolor='white', label=' ', alpha=0.9)
plt.plot(number_unique_hashtags_df[:10], label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_147_SMI1_2_Number_Unique_Hashtags_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Hashtags - Pie')
# plt.pie(number_unique_hashtags_df, colors=colors_blue, labels=number_unique_hashtags_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(number_unique_hashtags_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_147_SMI1_Number_Unique_Hashtags_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO


# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Hashtags Bars')
number_unique_hashtags_df.plot.bar(alpha=0.9)
plt.xlabel('Hashtags')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_147_SMI1_Numbers_Unique_Hashtags_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###############################################################################################################

# List Unique TOTAL Hashtags ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!


hashtags_total_1 = pd.DataFrame([hashtags_total_1])
missing_unique_hashtags = hashtags_total_1.unique()

missing_number_unique_mentions = len(missing_unique_hashtags)
missing_number_unique_hashtags

print('---')
print('Missing Unique Hashtags')
# print(missing_number_unique_hashtags)
print('---')

missing_number_unique_hashtags_df = pd.DataFrame(missing_number_unique_hashtags, columns=['missing_number_unique_hashtags'])

missing_number_unique_hashtags_df.to_csv('4_5_148_SMI1_Missing_Number_Unique_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Hashtags')
plt.plot(missing_number_unique_hashtags_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_148_SMI1_Missing_Number_Unique_Hashtags_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Hashtags - Pie')
# plt.pie(missing_number_unique_hashtags_df, colors=colors_blue, labels=missing_number_unique_hashtags_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(missing_number_unique_hashtags_df, loc=3)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_148_SMI1_Missing_Number_Unique_Hashtags_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO


##############################################################################################################
#############################################################################################################

############ NEED TO DO = WHAT ABOUT THE OTHER VARIABLES?????????

# List Number of Total Hashtags ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!

total_hashtags = tweets_smi_1['hashtags']    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['number_total_hashtags'] = len(tweets_smi_1['hashtags'])
tweets_smi_1['number_total_hashtags']

print('---')
print('List Total Number of Hashtags Head')
print(tweets_smi_1['number_total_hashtags'].head)
print('---')



tweets_smi_1.to_csv('4_5_147_SMI1_Tweets_1_With_Number_Total_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# tweets_smi_1.to_excel('4_5_147_SMI1_Tweets_1_Number_Total_Hashtags_DF.xlsx', header=True)

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Hashtags')
# plt.plot(tweets_smi_1['number_total_hashtags'][:10], edgecolor='white', label=' ', alpha=0.9)
plt.plot(tweets_smi_1['number_total_hashtags'][:10], label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_147_SMI1_Number_Total_Hashtags_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Hashtags - Pie')
plt.pie(tweets_smi_1['number_total_hashtags'][:10], colors=colors_blue, labels=number_unique_hashtags_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(number_unique_hashtags_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_147_SMI1_Number_Total_Hashtags_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO


# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Hashtags Bars')
tweets_smi_1['number_total_hashtags'].plot.bar(alpha=0.9)
plt.xlabel('Hashtags')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_147_SMI1_Numbers_Total_Hashtags_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###############################################################################################################
###############################################################################################################

# List Unique Mentions ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!

total_mentions = tweets_smi_1['mentions']   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_total_mentions = len(total_mentions)
number_total_mentions

print('---')
print('Number Total Mentions')
print(number_total_mentions)
print('---')

unique_mentions = tweets_smi_1['mentions'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_mentions = len(unique_mentions)
number_unique_mentions

print('---')
print('Number Unique Mentions')
print(number_unique_mentions)
print('---')

number_unique_mentions_df = pd.DataFrame(number_unique_mentions, columns=['number_unique_mentions'])

number_unique_mentions_df.to_csv('4_5_149_SMI1_Number_Unique_Mentions_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Mentions')
plt.plot(number_unique_mentions_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_149_SMI1_Number_Unique_Mentions_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Mentions - Pie')
plt.pie(number_unique_mentions_df, colors=colors_blue, labels=number_unique_mentions_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(number_unique_mentions_df, loc=3)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_149_SMI1_Number_Unique_Mentions_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Mentions Bars')
number_unique_mentions_df.plot.bar(alpha=0.9)
plt.xlabel('Mentions')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_149_SMI1_Number_Unique_Mentions_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###############################################################################################################

# List MISSING Unique Mentions ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!


mentions_1 = pd.DataFrame(['mentions_1'])
missing_unique_mentions = mentions_1.unique()

missing_number_unique_mentions = len(missing_unique_mentions)
missing_number_unique_mentions

print('---')
print('Missing Unique Number of Mentions')
print(missing_number_unique_mentions)
print('---')

missing_number_unique_mentions_df = pd.DataFrame([missing_number_unique_mentions])

missing_number_unique_mentions_df.to_csv('4_5_150A_SMI1_Missing_Number_Unique_Mentions_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Mentions')
plt.plot(missing_number_unique_mentions_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_150A_SMI1_Missing_Number_Unique_Mentions_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Mentions - Pie')
# plt.pie(missing_number_unique_mentions_df, colors=colors_blue, labels=missing_number_unique_mentions_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(missing_number_unique_mentions_df, loc=3)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_150A_SMI1_Missing_Number_Unique_Mentions_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

###############################################################################################################

# List Unique Emojis Unicode


unique_emojis_unicode = tweets_smi_1['emojis_unicode'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_emojis_unicode = len(unique_emojis_unicode)
number_unique_emojis_unicode

print('---')
print('Number Unique Emojis Unicode')
print(number_unique_emojis_unicode)
print('---')

number_unique_emojis_unicode_df = pd.DataFrame([number_unique_emojis_unicode])

number_unique_emojis_unicode_df.to_csv('4_5_151V_SMI1_Number_Unique_Emojis_Unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Emojis')
plt.plot(number_unique_emojis_unicode_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_151V_SMI1_Number_Unique_Emojis_Unicode_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

###############################################################################################################

# List Unique MISSING Emojis Unicode ###################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!

missing_unique_emojis_unicode = tweets_smi_1['emojis_unicode'].unique()

missing_number_unique_emojis_unicode = len(missing_unique_emojis_unicode)
missing_number_unique_emojis_unicode

print('---')
print('Missing Number Emojis Unicode')
# print(missing_number_unique_emojis_unicode)
print('---')

missing_number_unique_emojis_unicode_df = pd.DataFrame([missing_number_unique_emojis_unicode])

missing_number_unique_emojis_unicode_df.to_csv('4_5_152A_SMI1_Missing_Number_Unique_Emojis_Unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to.excel()

## NEED TO PLOT - FIX!!! ADD TO ALL EMOJIS

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Emojis')
plt.ioff()
plt.plot(missing_number_unique_emojis_unicode_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_152A_SMI1_Missing_Number_Unique_Emojis_Unicode_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

###############################################################################################################

# List Unique MISSING Emojis Unicode ###################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!

missing_unique_emojis_unicode = tweets_smi_1['emojis_unicode'].unique()

missing_number_unique_emojis_unicode = len(missing_unique_emojis_unicode)
missing_number_unique_emojis_unicode

print('---')
print('Missing Number Emojis Unicode')
# print(missing_number_unique_emojis_unicode)
print('---')

missing_number_unique_emojis_unicode_df = pd.DataFrame([missing_number_unique_emojis_unicode])

missing_number_unique_emojis_unicode_df.to_csv('4_5_152_SMI1_Missing_Number_Unique_Emojis_Unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to.excel()

## NEED TO PLOT - FIX!!! ADD TO ALL EMOJIS

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Emojis')
plt.plot(missing_number_unique_emojis_unicode_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_152_SMI1_Missing_Number_Unique_Emojis_Unicode_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

###############################################################################################################

# List Unique Emojis Converted

unique_emojis_converted = tweets_smi_1['emojis_converted'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_emojis_converted = len(unique_emojis_converted)
number_unique_emojis_converted

print('---')
print('Number Unique Emojis Converted')
print(number_unique_emojis_converted)
print('---')

number_unique_emojis_converted_df = pd.DataFrame([number_unique_emojis_converted])

number_unique_emojis_converted_df.to_csv('4_5_153_SMI1_Number_Unique_Emojis_Converted_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Emojis')
plt.plot(number_unique_emojis_converted_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_153_SMI1_Number_Unique_Emojis_Converted_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO


#####################################

# initialize list of Lists 
numbers_more_values = [['Values for Hashtags', number_total_hashtags, number_unique_hashtags], ['Values for Mentions', number_total_mentions, number_unique_mentions], ['Values for Emojis', number_total_emojis_unicode, number_unique_emojis_unicode]] 
 
# Create the pandas DataFrame 
numbers_hashtags_df = pd.DataFrame(numbers_more_values, columns = ['total_values', 'unique_values']) 

numbers_hashtags_df.to_csv('4_5_154_SMI1_More_Values_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# numbers_hashtags_df.to_excel('4_5_154_SMI1_More_Values.xlsx', header=True)

###############################################################################################################

# List Unique Language

unique_languages = tweets_smi_1['language'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_languages = len(unique_languages)
number_unique_languages

print('---')
print('Number Unique Languages')
print(number_unique_languages)
print('---')

number_unique_languages_df = pd.DataFrame([number_unique_languages])

number_unique_languages_df.to_csv('4_5_154_SMI1_Number_Unique_Languages_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Languages')
plt.plot(number_unique_languages_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
 
# plt.show()
plt.savefig('4_5_154_SMI1_Number_Unique_Languages_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

# Pie - NEED TO DO

# Bars - NEED TO DO



#######################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# DATES WITH MOST Tweets

# This is necessary to show lots of columns in pandas 0.12. 
# Not necessary in pandas 0.13.
# pd.set_option('display.width', 5000) 
# pd.set_option('display.max_columns', 60)

# plt.rcParams['figure.figsize'] = (15, 5)

#####################################################################################################

# Most Common Tweet Date

# METHOD 1

value_counts_date = pd.value_counts(tweets_smi_1['created'], ascending=False, normalize=True)

def get_counts(sequence):  
	counts = defaultdict(int) # values will initialize to 0  
	for x in sequence:    
		counts[x] += 1  
	return counts


def top_counts(count_dict, n=10):  
	value_key_pairs = [(count, tz) for tz, count in count_dict.items()]  
	value_key_pairs.sort()  
	return value_key_pairs[-n:] 

# counts_created_1 = get_counts(tweets_smi_1['created'])

# top_counts_created_1 = top_counts(counts_created)

print('---')
print('Most Common Tweet Date - 1B')
# print('counts_created_1')
print('---')

##############################################

# METHOD 2

counts_created_2 = Counter(tweets_smi_1['created'])

print('---')
print('Most Common Tweet Date - 2B')
# print('counts_created_2')
print('---')

###########################################################

### NEED TO PLOT

# SAVE TO CSV   ######################################  NEED TO SAVE DATE ON FIRST COLUMN / SECOND COUNT

value_counts_date.to_csv('4_5_160_SMI1_B_df_Top_Dates_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_date = value_counts_date.to_excel('4_5_160_SMI1_B_df_Top_Dates_and_No_Tweets.xlsx', header=True) # Only argument is a string of the output file path


# value_counts_date

print('---')
print('Value Counts Date')
print(value_counts_date.head)
print('---')

# TABLE PLOT NEED TO DO 

# Pie NEED TO DO

# Bars

# TOP DATES WITH TWEET COUNT

top_dates_tweets = value_counts_date.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Dates Where Users Activity for an SMI - Bars')
top_dates_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Dates')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_160_B_SMI1_Top_Tweet_Dates_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################################


## NEED TO DO Favorites AND Retweets FOR THOSE DATES!!

# _df _df = pd.DataFrame()

# .to_csv('4_5_.csv', sep='\t', encoding='utf-8', index=True)
# excel

#####################################################################################################

print('---')
print('Loading Libs 53')
print('---')

# TREEMAPS

# Treemap Plotting

# Use ggplot style

style.use('ggplot') 

# BY Favorites

treemap_favs = tweets_smi_1.sort_values(by='favorites', ascending=False)

# Find Percentage

treemap_favs['fav_percentage'] = round(100 * treemap_favs['favorites'] / sum(treemap_favs['favorites']), 2)

# Create Treemaps Labels

treemap_favs['text'] = treemap_favs['text'] + '(' + treemap_favs['fav_percentage'].astype('str') + '%)'

print('---')
print('Tree Maps Favs 2')
print(treemap_favs['fav_percentage'].head(10)) ## NEED TO DO - FIX
print('---')

# Get Axis and Figure

fig, ax = plt.subplots()

# Colormap

# cmap = matplotlib.cm.coolwarm

# Min and Max Values

mini_favs = min(treemap_favs['favorites'])
maxi_favs = max(treemap_favs['favorites'])

# Finding Colors for each tile

# norm_favs = plt.colors.Normalize(vmini=mini_favs, vmax=maxi_favs)
# colors = [plt.cmap(norm(value)) for value in treemap_favs['favorites']]

# Plotting

# squarify.plot(sizes=treemap_favs['favorites'], label=treemap_favs['text'], alpha=0.8, color=colors)

# Removing Axis

plt.axis('off')

# Invert Y-Axis

plt.gca().invert_yaxis()     ############## NEED TO FIX

# NEED TABLE AND SAVE TO EXCEL AND CSV - NEED TO DO

# Pie ## NEED TO DO - NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Texts by Favorites - Pie') # fontsize=32
plt.pie(treemap_favs)
plt.legend(treemap_favs, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_121_SMI1_10_2_Most_Repeteaded_Tweet_Favorites_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BARS PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Texts by Favorites - Bars') # fontsize=32
treemap_favs.plot.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_121_SMI1_10_2_Most_Repeteaded_Tweet_Favorites_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



# Plot ## NEED TO DO - NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Texts by Favorites') # fontsize=32
plt.plot(treemap_favs)
plt.legend(treemap_favs, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_121_SMI1_10_2_Most_Repeteaded_Tweet_Favorites_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Common Tweet Text

value_counts_text = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)

df_value_counts_text = pd.DataFrame([value_counts_text])

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

df_value_counts_text.to_csv('4_5_122_3_SMI1_DF_Top_Text_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# df_value_counts_text.to_excel('4_5_122_3_SMI1_DF_Top_Text_and_No_Tweets.xlsx', header=True)

## NEED TO PLOT

# value_counts_text

print('---')
print('Most Common Tweet Text 3')
# print(value_counts_text)
print('---')

## NEED TO DO Favorites AND Retweets FOR THEM!!!

# NEED TO DO TABLE PLOT

# Pie ## NEED TO DO - NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Content of Text - Pie') # fontsize=32
# plt.pie(top_texts_tweets[:10])
plt.legend(top_texts_tweets[:6], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_122_3_SMI1_10_Most_Repeteaded_Tweet_Text_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars

# MOST FREQUENT TEXT IN Tweets

top_texts_tweets = value_counts_text.sort_values(ascending=False)

print('---')
print('Most Frequent Complete Text in Tweets - Bars')
print(value_counts_text.sort_values(ascending=False))
print('---')

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Content of Text - Bars')
top_texts_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Most Repeated / Shared / Text Content')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_122_SMI1_10_Most_Repeteaded_Tweet_Text_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Plot ## NEED TO DO - NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Content of Text') # fontsize=32
plot.plot(top_texts_tweets[:10])
plt.legend(top_texts_tweets[:6], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_122_3_SMI1_10_Most_Repeteaded_Tweet_Text_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Common Hashtags

value_counts_hashtags = pd.value_counts(tweets_smi_1['hashtags'], ascending=False, normalize=True)

## NEED TO PLOT

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_hashtags.to_csv('4_5_123_3_SMI1_df_Top_Hashtags_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_hashtags.to_excel('4_5_123_3_SMI1_df_Top_Hashtags_and_No_Tweets.xlsx', header=True)

value_counts_hashtags

print('---')
print('---Most Common Hashtags 3')
# print(pd.value_counts(tweets_smi_1['hashtags']), ascending=False, normalize=True)
print('---')

# TABLE AND FRAME DF NEED TO DO 

# Pie NEED TO DO 

# Bars 

# MOST FREQUENT HASHTAGS IN Tweets

top_hashtags_tweets = value_counts_hashtags.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Hashtags - Bars')
top_hashtags_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Most Repeated / Shared / Hashtags')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_123_3_SMI1_10_Most_Repeteaded_Hashtags_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### NEED TO PUT Favorites AND RTS!!!

# _df _df = pd.DataFrame()

# .to_csv('4_5_.csv', sep='\t', encoding='utf-8', index=True)
# excel



###############################################################################################################

# Bars

# TOP NUMBERS OF HASHTAGS IN Tweets 

top_hashtags_tweets = value_counts_hashtags.sort_values(ascending=False)

print('---')
print('Most Common Tweet Hashtags')
# print(pd.value_counts(tweets_smi_1['hashtags'], ascending=False, normalize=True))
print('---')

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Hashtags Used - Bars')
top_hashtags_tweets[:10].plot.bar(alpha=0.9)
plt.xticks(rotation=50)
plt.xlabel('Hashtags')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_124_SMI1_Top_Tweet_Hashtags_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

top_hashtags_tweets_df = pd.DataFrame(top_hashtags_tweets)

top_hashtags_tweets_df.to_csv('4_5_124_SMI1_Top_Hashtags_tweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Common Tweet Mentions

value_counts_mentions = pd.value_counts(tweets_smi_1['mentions'], ascending=False, normalize=True)
value_counts_mentions


# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_mentions.to_csv('4_5_147_SMI1_df_Top_Mentions_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_mentions.to_excel('4_5_147_SMI1_df_Top_Mentions_and_No_Tweets.xlsx', header=True)


print('---')
print('Most Common Tweet Mentions')
# print(pd.value_counts(tweets_smi_1['mentions'], ascending=False, normalize=True))
print('---')

top_mentions_tweets_df = pd.DataFrame(top_mentions_tweets)

top_mentions_tweets_df.to_csv('4_5_148_SMI1_Top_Mentions_Tweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
#.to_ excel()

# TABLE PLOT NEED TO DO 

# Pie ###### NEED TO DO

# Bars

# TOP NUMBERS OF MENTIONS IN Tweets 

top_mentions_tweets = value_counts_mentions.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Mentions Used - Bars')
top_mentions_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Mentions')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_148_SMI1_Top_Tweet_Mentions_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/


# Most Commons Emojis Unicode

value_counts_emojis_unicode = pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True)
value_counts_emojis_unicode

print('---')
print('Most Common Emojis Unicode')
# print(value_counts_emojis_unicode)
print('---')

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_emojis_unicode.to_csv('4_5_149_SMI1_df_Top_Emojis_Unicode_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_emojis_unicode.to_excel('4_5_149_SMI1_df_Top_Emojis_Unicode_and_No_Tweets.xlsx', header=True)

## NEED TO PLOT

##########################################################################################################

top_emojis_unicode_tweets_df = pd.DataFrame(top_emojis_unicode_tweets)

top_emojis_unicode_tweets_df.to_csv('4_5_150_SMI1_Top_emojis_unicode_tweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# NEED TO DO Pie

# PLOT BARS

# TOP NUMBERS OF EMOJIS UNICODE IN Tweets 

top_emojis_unicode_tweets = value_counts_emojis_unicode.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis - Bars')
top_emojis_unicode_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_150_SMI1_Top_Tweet_Emojis_Unicode_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################################

## nEED TO DO --------- Favorites AND RTS!!!

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Commons Emojis Converted

value_counts_emojis_converted = pd.value_counts(tweets_smi_1['emojis_converted'], ascending=False, normalize=True)
value_counts_emojis_converted

print('---')
print('Most Common Emojis - Converted')
# print(value_counts_emojis_converted)
print('---')

top_emojis_converted_tweets_df = pd.DataFrame(top_emojis_converted_tweets)

top_emojis_converted_tweets_df.to_csv('4_5_151_SMI1_Top_Emojis_Converted_Tweets_df_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_emojis_converted.to_csv('4_5_151_SMI1_df_Top_Emojis_Converted_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_emojis_converted.to_excel('4_5_151_SMI1_df_Top_Emojis_Converted_and_No_Tweets.xlsx', header=True)


## NEED TO PLOT

# Bars

# TOP NUMBERS OF EMOJIS CONVERTED IN Tweets 

top_emojis_converted_tweets = value_counts_emojis_converted.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis - Bars')
top_emojis_converted_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis / Graphical')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_151_SMI1_Top_Tweet_Emojis_Converted_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Common Tweet Languages

value_counts_language = pd.value_counts(tweets_smi_1['language'], ascending=False, normalize=True)

## NEED TO PLOT

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_language.to_csv('4_5_155_SMI1_df_Top_Language_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_language.to_excel('4_5_155_SMI1_df_Top_Language_and_No_Tweets.xlsx', header=True)

value_counts_language

print('---')
print('Most Common Tweet Languages')
# print(value_counts_language)
print('---')

percentage_tweets_language_df = pd.DataFrame(percentage_tweets_language)


## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets Languages - Pie')
# plt.pie(percentage_tweets_language[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentage_tweets_language[:6], autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentage_tweets_language, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_155_SMI1_Percentage_Tweets_Language_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars

# TOP NUMBERS OF LANGUAGE IN Tweets 

top_languages_tweets = value_counts_language.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Languages Used - Bars')
top_languages_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_155_SMI1_Top_Tweet_Languages_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################

# PERCENTAGE OF Tweets BY TOP USERS

percentage_tweets_screenname = (tweets_smi_1['screenName'].value_counts(normalize=True) * 100)
percentage_tweets_screenname

print('---')
print('Percentage of Tweets by Top Users - ScreenName')
# print(percentage_tweets_screenname)
print('---')

percentage_tweets_screenname_df = pd.DataFrame(percentage_tweets_screenname)

percentage_tweets_screenname_df.to_csv('4_5_157_SMI1_Percentage_Tweets_Screenname_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets by ScreenName - Pie')
# plt.pie(percentage_tweets_screenname[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentage_tweets_screenname[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentage_tweets_screenname, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_157_SMI1_Percentage_Tweets_ScreenName_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

# PERCENTAGE OF Tweets WITH Retweets

percentage_tweets_retweets = (tweets_smi_1['retweets'].value_counts(normalize=True) * 100)

print('---')
print('Percentage of Tweets with Retweets')
# print(percentage_tweets_retweets)
print('---')

percentage_tweets_retweets_df = pd.DataFrame(percentage_tweets_retweets)

percentage_tweets_retweets_df.to_csv('4_5_158_SMI1_Percentage_Tweets_Retweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Retweets - Pie')
# plt.pie(percentage_tweets_retweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentage_tweets_retweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentage_tweets_retweets, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_158_SMI1_Percentage_Tweets_Retweets_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

# PERCENTAGE OF Tweets WITH HASHTAGS

percentage_tweets_hashtags = (tweets_smi_1['hashtags'].value_counts(normalize=True) * 100)
percentage_tweets_hashtags

print('---')
print('Percentage of Tweets with Hashtags')
# print(percentage_tweets_hashtags)
print('---')

percentage_tweets_hashtags_df = pd.DataFrame(percentage_tweets_hashtags)

percentage_tweets_hashtags_df.to_csv('4_5_159_SMI1_Percentage_Tweets_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Hashtags - Pie')
# plt.pie(percentage_tweets_hashtags[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentage_tweets_hashtags[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentage_tweets_hashtags, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()
# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_159_SMI1_Percentage_Tweets_Hashtags_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

percentage_tweets_screenname = (tweets_smi_1['screenName'].value_counts(normalize=True) * 100)
percentage_tweets_screenname

# PERCENTAGE OF Tweets WITH EMOJIS_UNICODE


print('---')
print('Percentage of Tweets with Emojis - Unicode')
# print(percentage_tweets_emojis_unicode)
print('---')


## NEED TO PLOT 

percentage_tweets_emojis_unicode_df = pd.DataFrame(percentage_tweets_emojis_unicode)

percentage_tweets_emojis_unicode_df.to_csv('4_5_160_SMI1_Percentage_Tweets_Emojis_Unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Emojis - Pie')
# plt.pie(percentage_tweets_emojis_unicode[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentage_tweets_emojis_unicode[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentage_tweets_emojis_unicode, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_160_SMI1_Percentage_Tweets_Emojis_Unicode_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

# PERCENTAGE OF Tweets WITH EMOJIS_CONVERTED

percentage_tweets_emojis_converted = (tweets_smi_1['emojis_converted'].value_counts(normalize=True) * 100)
percentage_tweets_emojis_converted

print('---')
print('Percentage of Tweets with Emojis Converted')
# print(percentage_tweets_emojis_converted)
print('---')


percentage_tweets_emojis_converted_df = pd.DataFrame(percentage_tweets_emojis_converted)

percentage_tweets_emojis_converted_df.to_csv('4_5_161_SMI1_Percentage_Tweets_Emojis_Converted_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Emojis - Pie')
# plt.pie(percentage_tweets_emojis_converted[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentage_tweets_emojis_converted[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentage_tweets_emojis_converted, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_161_SMI1_Percentage_Tweets_Emojis_Converted_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO


########################################################################################################

# PERCENTAGE OF LANGUAGES

percentage_tweets_languages = (tweets_smi_1['language'].value_counts(normalize=True) * 100)
percentage_tweets_languages

print('---')
print('Percentage of Tweets Languages')
# print(percentage_tweets_languages)
print('---') 

percentage_tweets_languages_df = pd.DataFrame(percentage_tweets_languages)

percentage_tweets_languages_df.to_csv('4_5_163_SMI1_Percentage_Tweets_Languages_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# percentage_tweets_languages_df.to_excel()

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets Languages - Pie')
# plt.pie(percentages_tweets_languages[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentage_tweets_languages[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentage_tweets_languages, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_165_SMI1_Percentage_Tweets_Languages_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO


############################################################################################################

# https://matplotlib.org/3.1.1/gallery/pie_and_polar_charts/pie_and_donut_labels.html#sphx-glr-gallery-pie-and-polar-charts-pie-and-donut-labels-py
# https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplt.pie.html

##############################################################################################################

# Pie : PERCENTAGE OF Favorites / Top

percentages_favorites_tweets = smi1_favorites.size().sort_values(ascending=False)

print('--')
print('Percentage of Favorite Tweets')
# print(percentages_favorites_tweets)
print('--')

percentages_favorites_tweets_df = pd.DataFrame(percentages_favorites_tweets)

percentages_favorites_tweets_df.to_csv('4_5_165_SMI1_Percentages_Favorites_Tweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# to_excel()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Favorites - Pie')
# plt.pie(percentages_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentages_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentages_favorites_tweets, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_165_SMI1_Percentages_Favorites_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

####################################################################################################################

# https://plot.ly/python/pie-charts/

# Pie : PERCENTAGE OF Favorites / Top

percentages_favorites_tweets = smi1_favorites.size().sort_values(ascending=False)

print('--')
print('Percentage of Favorites - Top')
# print(smi1_favorites.size().sort_values(ascending=False))
print('--')

percentages_favorites_tweets_df = pd.DataFrame(percentages_favorites_tweets)

percentages_favorites_tweets_df.to_csv('4_5_167_SMI1_Percentages_favorites_tweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# to_excel()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Favorites - Pie')
# plt.pie(percentages_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentages_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentages_favorites_tweets, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_167_SMI1_Percentage_Favorites_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO


####################################################################################################################

# Pie: PERCENTAGE Retweets


smi1_retweets_size_sort_values_df = pd.DataFrame(tweets_smi_1['retweets'].size().sort_values(ascending=False))

smi1_retweets_size_sort_values_df.to_csv('4_5_168_SMI1_retweets_size_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Retweets - Pie')
plt.pie(smi1_retweets.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_retweets, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_168_SMI1_Percentage_Retweets_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR
# PLOT # NEED TO DO


########################################################################################################

# Pie: PERCENTAGE OF HASHTAGS

smi1_hashtags_size_sort_values_df = pd.DataFrame(smi1_hashtags.size().sort_values(ascending=False))

smi1_hashtags_size_sort_values_df.to_csv('4_5_169_SMI1_Hashtags_size_sort_values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Hashtags - Pie')
plt.pie(smi1_hashtags.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_hashtags, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_169_SMI1_Percentage_Hashtags_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO


########################################################################################################

# Pie: PERCENTAGE OF MENTIONS ## NEED TO FIX


smi1_mentions_size_sort_values_df = pd.DataFrame(smi1_mentions.size().sort_values(ascending=False))

smi1_mentions_size_sort_values_df.to_csv('4_5_170_SMI1_mentions_size_sort_values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Mentions - Pie')
plt.pie(smi1_mentions.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_mentions, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
# centre_circle = plt.Circle((0,0),0.70,fc='white')
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_170_SMI1_Percentage_Mentions_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

# Pie: PERCENTAGE OF EMOJIS_UNICODE ## NEED TO FIX

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Emojis_Unicode - Pie')
plt.pie(smi1_emojis_unicode.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_emojis_unicode, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
# centre_circle = plt.Circle((0,0),0.70,fc='white')
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_172_SMI1_Percentage_Emojis_Unicode_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

# Pie: PERCENTAGE OF EMOJIS_CONVERTED ## NEED TO FIX

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Emojis - Pie')
plt.pie(smi1_emojis_converted.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_emojis_converted, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
# centre_circle = plt.Circle((0,0),0.70,fc='white')
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_173_SMI1_Percentage_Emojis_Converted_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO 

########################################################################################################

# https://stackoverflow.com/questions/27898830/python-how-to-change-autopct-text-color-to-be-white-in-a-pie-chart
# https://medium.com/@kvnamipara/a-better-visualisation-of-pie-charts-by-matplotlib-935b7667d77f

# Pie : PERCENTAGE OF LANGUAGES ## NEED TO FIXs

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Languages - Pie')
plt.pie(smi1_languages.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_languages, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_174_SMI1_Percentage_Languages_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################################################################

# Bars

# Number of Tweets / Date


# Prepare the data
created = tweets_smi_1.loc['created']
tweets_numbers = tweets_smi_1.loc['id']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Favorites / Time - Bars')
smi1_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_175_SMI1_Favorites_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################################################################

# Bars

# Favorites


# Prepare the data

tweets_favs = tweets_smi_1.loc['favorites']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Favorites / Time - Bars')
plt.plot(created, tweets_favs, label='linear')
# smi1_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_176_SMI1_Favorites_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


########################################################################################################

# Bars

# Retweets

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Retweets / Time - Bars')
plt.plot(created, tweets_rts, label='linear')
tweets_smi_1['retweets'].size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_177_SMI1_Retweets_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

########################################################################################################

# Bars

# HASTAGS

number_of_hashtags_in_tweets = tweets_smi_1['hashtags'].count()

# NEED TO GROUP

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Hashtags / Time - Bars')
# plt.plot(created, number_of_hashtags_in_tweets, label='linear')
# number_of_hashtags_in_tweets.sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Count')
ax.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_178_SMI1_Hashtags_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


smi1_favorites_size_sort_values_df = pd.DataFrame(smi1_favorites.size().sort_values(ascending=False))

smi1_favorites_size_sort_values_df.to_csv('4_5_178_SMI1_Favorites_Size_sort_values_df_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

########################################################################################################

# MENTIONS PLOTS BAR

# MENTIONS

number_of_mentions_in_tweets = tweets_smi_1['mentions'].counts()

# NEED TO GROPU!!!!

# Plot the data ## NEED TO FIX 

# TABLE PLOT NEED TO DO 
# Bars NEED TO DO

# Bars

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Mentions / Time - Bars')
number_of_mentions_in_tweets.sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Number of Mentions')
plt.plot(created, number_of_mentions_in_tweets, label='linear')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_179_SMI1_Mentions_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()
plt.clf()


number_of_mentions_in_tweets = pd.DataFrame(number_of_mentions_in_tweets, columns=['number_of_mentions_in_tweets'])

number_of_mentions_in_tweets.to_csv('4_5_179_SMI1_number_of_mentions_in_tweets_CSV.csv')
# .to_excel()

########################################################################################################

# LINE PLOTS

# Numer of Retweets / Favorites


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Numer of Retweets / Favorites')

# Plot with differently-colored markers.
plt.plot(created, tweets_rts, 'b-', label='Retweets')
plt.plot(created, tweets_favs, 'r-', label='Favorites')

# Create legend.
plt.legend(loc='upper left')
plt.xlabel('Year')
plt.ylabel('Retweets / Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_180_SMI1_Number_Retweets_Favorites_Time_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################################################################################

# Pie NEED TO DO

# Bars

# Number of Favorites of Tweets

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Favorites - Bars')
smi1_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_180_SMI1_Number_Favorites_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars
 
# Number of Favorites / Retweets of Tweets


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Favorites / Retweets - Bars')
smi1_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Favorites / Retweets')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_181_SMI1_Number_Favorites_Retweets_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################

# Bars

# Number of Retweets of Tweets


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Retweets - Bars')
smi1_retweets.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Retweets')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
ax.grid(True)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_182_SMI1_Number_Retweets_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################


# Bars

# Most Commom Languages 


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Languages - Bars')
smi1_languages.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_183_SMI1_Language_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################

df_tweets_smi_processes_tokens_1_fdist = FreqDist(tweets_words)
print(df_tweets_smi_processes_tokens_1_fdist)

df_tweets_smi_processes_tokens_1_fdist_most_common_2 = df_tweets_smi_processes_tokens_1_fdist.most_common(2)

## NEED TO PLOT????????????

print('--')
print('Word Frequency Distribution')
print(df_tweets_smi_processes_tokens_1_fdist.most_common(2))
print('--')

df_tweets_smi_processes_tokens_1_fdist_most_common_2 = pd.DataFrame(df_tweets_smi_processes_tokens_1_fdist_most_common_2)

df_tweets_smi_processes_tokens_1_fdist_most_common_2.to_csv('4_5_184_SMI1_DF_Tweets_SMI_Processes_Tokens_1_fdist_most_common_CSV.csv')
# df_tweets_smi_processes_tokens_1_fdist_most_common_2.to_excel()

# TABLE PLOT NEED TO DO

# Pie NEED TO DO 

# PLOT

# Frequency Distribution Plot


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Word Frequencies')
SMI1_Word_Freq_Graph = df_tweets_smi_processes_tokens_1_fdist.plot(10,cumulative=False, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_184_SMI1_tweets_processes_tokens_1_fdist_most_common.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##########################################################################################

# ourcodingclub.github.io/tutorials/topic-modelling-python/

# Hashtag Correlations

# Take the rows from the hashtag colum 

# hashtags_list_df = tweets_smi_1[tweets_smi_1.hashtags.apply(lambda hashtags_list: hashtags_list !=[]), ['hashtag']]

# Create a DataFrame where each of the hashtags has its own row via list comprehension

flattened_hashtags_df = pd.DataFrame(
#	[hashtag in hashtags_list in hashtags_list_df.hashtags
	[hashtag in tweets_smi_1['hashtags']
#	for hashtag in hashtags_list], 
	for hashtag in tweets_smi_1['hashtags']],
	columns=['hashtag'])

# Number of Unique Hashtags

number_unique_hashtags = flattened_hashtags_df['hashtag'].unique().size

# Count the appereances of each hashtag

popular_hashtags = flattened_hashtags_df.groupby('hashtags').size()\
					 .reset_index('counts')\
					 .sort_values('counts', ascending=False)\
					 .reset_index(drop=True)


popular_hashtags.to_csv('4_5_183_SMI1_Popular_Hashtags_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# popular_hashtags.to_excel('4_4_183_SMI1_Popular_Hashtags.xlsx', header=True)

# Number of total_favoritess each hashtag appears

hashtag_counts = flattened_hashtags_df.groupby('hashtags').size()\
					 .reset_index('counts')\
					 .counts


# Define bins for histogram

hashtags_bins = np.arrange(0,counts.max()+2, 5)-0.5

# Plot Histogram of tweet counts


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Popular Hashtags - Histogram')
plt.hist(hashtag_counts, bins = hashtags_bins)
plt.xlabels = np.arrange(1,hashtag_counts.max()+1, 1)
plt.xlabel('Hashtag Number of Appearances')
plt.ylabel('Frequency')
plt.yscale('log', nonposy='clip')
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_183_SMI1_Popular_Hashtags_Hist_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# TABLE ## NEED TO DO

# plot.legend()

# Pie 

# plt.rcdefaults()
fig, ax = plt.subplots()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.subplot(223)
# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Popular Hashtags - Pie')
plt.pie(hashtag_counts, colors=colors_blue, labels=tweets_numbers_item_values_df['tweets_by_item_description'], startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.xlabel('Number of Repeated Retweets vs Unique Tweets')
# plt.ylabel('Count')
plt.legend(labels=tweets_numbers_item_values_df['tweets_by_item_description'], bbox_to_anchor=(0.7, 0.7), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_183_SMI1_Popular_Hashtags_PLT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars ## NEED TO DO # FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Popular Hashtags - Bars')
hashtag_counts.plot.bar
plt.xlabel('Hashtag Number of Appearances')
plt.ylabel('frequency')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
 
# plt.show()
plt.savefig('4_5_183_SMI1_Popular_Hashtags_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################

# Summary Statistics of all Dates       ## NEED TO FIX AND PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_created_describe = tweets_smi_1['created'].describe()
smi1_created_describe

print('---')
print('Summary Statistics of all Dates')
print(smi1_created.describe().head())
print('---')

smi1_created_describe_df = pd.DataFrame(smi1_created_describe)

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

smi1_created_describe.to_csv('4_5_193_SM1_Created_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_created_describe.to_excel('4_5_193_SM1_Created_Describe_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# plt.plot

# PLOT


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of all Dates - Grouped')
# plt.plot(smi1_created.describe())
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_193_SM1_Created_Describe_DF_g_1.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################
#####################################################################################
###############################################################################
#########################################################################

tweets_smi_1['unique_hashtags'] = tweets_smi_1['hashtags'].unique()    
# tweets_smi_1['unique_hashtags']


## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['number_unique_hashtags'] = len(tweets_smi_1['unique_hashtags'])
# tweets_smi_1['number_unique_hashtags']

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Hashtags Over Time')
tweets_smi_1.set_index('created')['number_unique_hashtags'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_188_SMI1_Unique_Hashtags_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


tweets_smi_1['unique_mentions'] = tweets_smi_1([tweets_smi_1['mentions'].unique()]) 
# tweets_smi_1['unique_mentions'] 

## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['number_unique_mentions'] = len(tweets_smi_1['number_unique_mentions'])
# tweets_smi_1['number_unique_mentions'] 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Mentions Over Time')
tweets_smi_1.set_index('created')['number_unique_mentions'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_187_SMI1_Unique_Mentions_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Unique Mentions / Hashtags OVER TIME #################################### NEED TO DO!!!!!!!!!!

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Mentions / Hashtags Over Time')
tweets_smi_1.set_index('created')['number_unique_mentions'].plot(alpha=0.9)
tweets_smi_1.set_index('created')['number_unique_hashtags'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_189_SMI1_Unique_Mentions_Hashtags_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

tweets_smi_1['unique_emojis_converted'] = tweets_smi_1['emojis_converted'].unique()    
# tweets_smi_1['unique_emojis_converted'] 

## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['number_unique_emojis_converted'] = len(tweets_smi_1['number_unique_emojis_converted'])
# tweets_smi_1['number_unique_emojis_converted'] 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Emojis_converted Over Time')
tweets_smi_1.set_index('created')['number_unique_emojis_converted'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_190_SMI1_Unique_Emojis_Converted_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


tweets_smi_1['unique_screeName'] = tweets_smi_1['screeName'].unique()    
# tweets_smi_1['unique_screeName']


## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['number_unique_screeName'] = len(tweets_smi_1['unique_screeName'])
# tweets_smi_1['number_unique_screeName']

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique screeNames Over Time')
tweets_smi_1.set_index('created')['number_unique_screeName'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_191_SMI1_Unique_ScreeNames_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


tweets_smi_1['unique_language'] = tweets_smi_1['language'].unique()    
# tweets_smi_1['unique_language']


## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['number_unique_language'] = len(tweets_smi_1['unique_language'])
# tweets_smi_1['number_unique_language']

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Languages Over Time')
tweets_smi_1.set_index('created')['number_unique_language'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_191_SMI1_Unique_Languages_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Unique Emojis / Languages OVER TIME #################################### NEED TO DO!!!!!!!!!!

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Emojis / Languages Over Time')
# tweets_smi_1.set_index('created')['number_unique_emojis'].plot(alpha=0.9)
# tweets_smi_1.set_index('created')['number_unique_hashtags'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_192_SMI1_Unique_Emojis_Languages_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################################################################
##############################################################################################
###################################################################################
#################################################################################################


# CREATE TUPLES

# + ',' + tweets_smi_1['network_weight'].astype(str)

for mention in tweets_smi_1['mentions_total']:
	mentions_tuple_temp = '(' + tweets_smi_1['screenName'] + ',' + mention + ')'


# UNIQUE ELEMENTS IN LIST / REMOVE DUPLICATES 

tweets_smi_1['mentions_tuple'] = '[' + mentions_tuple_temp + ']'


for hashtag in tweets_smi_1['hashtags_total']:
	hashtags_tuple_temp = '(' + tweets_smi_1['screenName'] + ',' + hashtag + ')'

# UNIQUE ELEMENTS IN LIST / REMOVE DUPLICATES 

tweets_smi_1['hashtags_tuple'] = '[' + hashtags_tuple_temp + ']'


for emoji_unicodes in tweets_smi_1['emojis_unicode']:
	emoji_unicodes_tuple_temp = '(' + tweets_smi_1['screenName'] + ',' + emoji_unicodes + ')'

# UNIQUE ELEMENTS IN LIST / REMOVE DUPLICATES 

tweets_smi_1['emoji_unicodes_tuple'] = '[' + emoji_unicodes_tuple_temp + ']'


for emoji_converted in tweets_smi_1['emojis_converted']:
	emojis_converted_tuple_temp = '(' + tweets_smi_1['screenName'] + ',' + emoji_converted + ')'

# UNIQUE ELEMENTS IN LIST / REMOVE DUPLICATES 

tweets_smi_1['emojis_converted_tuple'] = '[' + emojis_converted_tuple_temp + ']'



# for missing_emojis_unicodes in tweets_smi_1['missing_emojis_unicode']:
#	missing_emojis_unicode_tuple_temp = '(' + tweets_smi_1['screenName'] + ',' + 'missing_emojis_unicodes' + ')'

# UNIQUE ELEMENTS IN LIST / REMOVE DUPLICATES 

# tweets_smi_1['missing_emojis_unicode_tuple'] = '[' + missing_emojis_unicode_tuple_temp + ']'

# tweets_smi_1['missing_emojis_unicode_tuple'] = tuple(tweets_smi_1['missing_emojis_unicode'])


# tweets_smi_1['screenName'] = tweets_smi_1['screenName'].astype(str)
# tweets_smi_1['geo'] = tweets_smi_1['geo'].astype(str)
# tweets_smi_1['missing_geo'] = tweets_smi_1['geo'].astype(str)
# tweets_smi_1['missing_geo'] = tweets_smi_1['geo'].astype(str) # OJO QUE LO CAMBIE !!!! MISSING_GEO !!! 

for missing_geos in tweets_smi_1['missing_geo']:
	missing_geos_tuple_temp = '(' + tweets_smi_1['screenName'] + ',' + missing_geos + ')'


# UNIQUE ELEMENTS IN LIST / REMOVE DUPLICATES 

tweets_smi_1['missing_geos_tuple'] = '[' + missing_geos_tuple_temp + ']'


tweets_smi_1['missing_geo_tuple'] = tuple(tweets_smi_1['geo'])
# tweets_smi_1['missing_geo_tuple'] = tuple(tweets_smi_1['missing_geo'])

tweets_smi_1['missing_geo_tuple'] = tuple(tweets_smi_1['missing_geo'])
# tweets_smi_1['missing_geo_total_tuple'] = tuple(tweets_smi_1['missing_geo_total']) ###### LO CAMBIE
tweets_smi_1['missing_geo_total_tuple'] = tuple(tweets_smi_1['missing_geo']) ###### LO CAMBIE
# tweets_smi_1['missing_country_tuple'] = tuple(tweets_smi_1['missing_geo_total']) ### LO CAMBIE
tweets_smi_1['missing_country_tuple'] = tuple(tweets_smi_1['missing_geo'])
# tweets_smi_1['location_tuple'] = tuple(tweets_smi_1['location']) ## LO CAMBIE
tweets_smi_1['location_tuple'] = tuple(tweets_smi_1['geo'])
# tweets_smi_1['country_tuple'] = tuple(tweets_smi_1['country']) ## LO CAMBIE
tweets_smi_1['country_tuple'] = tuple(tweets_smi_1['geo'])

# tweets_smi_1['mentions_tuple'] = tweets_smi_1['mentions'].apply(lambda x: tuple(mentions_tuple_temp))
# tweets_smi_1['hashtags_tuple'] = tweets_smi_1['hashtags'].apply(lambda x: tuple(x))
# tweets_smi_1['emojis_unicode_tuple'] = tweets_smi_1['emojis_unicode'].apply(lambda x: tuple(x))
# tweets_smi_1['hashtags_total_tuple'] = tweets_smi_1['hashtags_total'].apply(lambda x: tuple(x))
# tweets_smi_1['mentions_total_tuple'] = tweets_smi_1['mentions_total'].apply(lambda x: tuple(x))
# tweets_smi_1['emojis_unicode_total_tuple'] = tweets_smi_1['emojis_unicode_total'].apply(lambda x: tuple(x))
# tweets_smi_1['missing_geo_tuple'] = tweets_smi_1['missing_geo'].apply(lambda x: tuple(x))
# tweets_smi_1['missing_geo_total_tuple'] = tweets_smi_1['missing_geo_total'].apply(lambda x: tuple(x))
# tweets_smi_1['missing_country_tuple'] = tweets_smi_1['missing_geo_total'].apply(lambda x: tuple(x))
# tweets_smi_1['location_tuple'] = tweets_smi_1['location'].apply(lambda x: tuple(x))
# tweets_smi_1['country_tuple'] = tweets_smi_1['country'].apply(lambda x: tuple(x))
# tweets_smi_1['missing_emojis_unicode_tuple'] = tweets_smi_1['missing_emojis_unicode'].apply(lambda x: tuple(x))

# # tweets_smi_1['geo'] = tweets_smi_1['geo'].apply(lambda x: tuple(x))

# for mention in tweets_smi_1['mentions']:
# 	mentions_temp = '(' + tweets_smi_1['screenName'] + mention + ')'


## TO INT AGAIN 

tweets_smi_1['network_weight'] = tweets_smi_1['network_weight'].transform(int)
tweets_smi_1['network_weight'] = tweets_smi_1['network_weight'] + 1

print('33333333333##################################')
print('MENTIONS TEMP')
print(mentions_tuple_temp)
print(tweets_smi_1['mentions_tuple'].head)
print('333333333333333333#######################################################')

# tweets_smi_1['mentions_tuple'] = tuple(list(zip(tweets_smi_1.screenName, tweets_smi_1.mentions)))
# tweets_smi_1['mentions_tuple_total'] = tuple(list(zip(tweets_smi_1.screenName, tweets_smi_1.mentions_total)))

# tweets_smi_1['mentions_total_tuple'] = tuple('\'' + tweets_smi_1['screenName'] + '\'' + ',' + tweets_smi_1['mentions_total'])

############
############

tweets_smi_1['hashtags_tuple'] = tuple(tweets_smi_1['hashtags_total'])
tweets_smi_1['emojis_unicode_tuple'] = tuple(tweets_smi_1['emojis_unicode'])
tweets_smi_1['hashtags_total_tuple'] = tuple(tweets_smi_1['hashtags_total'])


# UNIQUE ELEMENTS IN LIST / REMOVE DUPLICATES


###########################=======


print('##################################')
print('TWEETS_SMI_1 AFTER TUPLE')
print(tweets_smi_1.dtypes)
print('#######################################################')

print('##################################')
print('TWEETS_SMI_1 AFTER TUPLE - TUPLE')
# print(tweets_smi_1['mentions_total_tuple'].head)
print('#######################################################')

# TO INT 32

tweets_smi_1['quote_count'] = tweets_smi_1['quote_count'].astype(np.int32, errors='ignore')
tweets_smi_1['reply_count'] = tweets_smi_1['reply_count'].astype(np.int32, errors='ignore')
# tweets_smi_1['followers'] = tweets_smi_1['followers'].astype(np.int32, errors='ignore')
# tweets_smi_1['following'] = tweets_smi_1['following'].astype(np.int32, errors='ignore')


# tweets_smi_1['network_weight'] = tweets_smi_1['network_weight'].astype(np.int64, errors='ignore')

# TO STR


# tweets_smi_1['language'] = tweets_smi_1['language'].astype(str, errors='ignore')
# tweets_smi_1[''] = tweets_smi_1[''].astype(str, errors='ignore')

# TO BOOLEAN

# tweets_smi_1['is_follower'] = tweets_smi_1['is_follower'].astype(bool)
# tweets_smi_1['is_friend'] = tweets_smi_1['is_friend'].astype(bool)

# NECESITO CAMBIAR EMOJIS CONVERTED A CORRECT DATA TYPE

# emojis_converted            object
# tweets_smi_1['total_emojis_unicode'] = list(tweets_smi_1['total_emojis_unicode'])

# # tweets_smi_1['missing_country_total'] = list(tweets_smi_1['missing_country_total'])

# DROP MORE FIELDS AFTER TOTALS 

# tweets_smi_1 = tweets_smi_1.drop(columns='emojis_unicode_orig')
# tweets_smi_1 = tweets_smi_1.drop(columns='total_emojis_unicode')

# tweets_smi_1 = tweets_smi_1.drop(columns='total_missing_country')
# tweets_smi_1 = tweets_smi_1.drop(columns='missing_country_orig')
# tweets_smi_1 = tweets_smi_1.drop(columns='missing_country_orig')
# tweets_smi_1 = tweets_smi_1.drop(columns='total_missing_geo')
# tweets_smi_1 = tweets_smi_1.drop(columns='missing_geo_orig')
# tweets_smi_1 = tweets_smi_1.drop(columns='missing_country_total')

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str)
# tweets_smi_1['screenName'] = tweets_smi_1['screenName'].astype(str)
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str, errors='ignore')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str)
# tweets_smi_1['language'] = tweets_smi_1['language'].astype(str)
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore')


print('##################################')
print('TWEETS_SMI_1 AFTER ERRORS IGNORE IN DTYPES AND CHANGE UNIQUE')
print(tweets_smi_1['mentions_total'].head)
print(tweets_smi_1.dtypes)
print('#################')

##############################################################################################
##############################################################################################

###############################################################################################################
#
#                       CLUSTER ANALYSIS AND TIME SERIES ###################### NEED TO DO!!!!!!!!!!!
#
###############################################################################################################

## https://www.datacamp.com/community/tutorials/wordcloud-python

scatterplot_favs_total_favorites_language = scipy.stats.pearsonr(tweets_smi_1['favorites'], tweets_smi_1['retweets'])

# SCATTERPLOT FACETED ON ONE VARIABLE / LANGUAGE - NEED TO DO 

## SCATTERPLOT FAV TIME LANGUAGE METHOD 1 - 1

# SCATTER PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites / Time / Language - Scatter')
# plt.scatter(scipy.stats.pearsonr(tweets_smi_1['favorites'], tweets_smi_1['retweets']), colors=colors_blue, alpha=0.9)
plt.xlabel('Favorites / Time')
plt.ylabel('Language')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_195_SMI1_Scatterplot_Favorites_Time_Language_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


### SCATTERPLOT RETWEETS TIME LANGUAGE METHOD 1 -2 MEED TO DO
 
#### SCATTERPLOT - Method 2 FAVORITES

# PLOT SCATTER

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favs / Time / Language - Scatter Faceted')
scatterplot_favs_total_favorites_language.map(plt.scatter, 'year', 'followers_count', alpha=0.9)
plt.xlabel('Favorites / Time ')
plt.ylabel('Language')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_195_SMI1_Facetonevar_Favorites_Time_Language_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


### SCATTERPLOT METHOD 2 RETWEETS

# PLOT SCATTER

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Retweets / Time / Language - Scatter Faceted')
# scatterplot_facetonevar_rts_total_favorites = figure_factory.create_facet_grid(df=tweets_smi_1, x='created', y='retweets', facet_col='language')
plt.xlabel('Retweets / Time ')
plt.ylabel('Language')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_195_SMI1_Facetonevar_Retweets_Time_Language_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################################

print('GOING TO START MATRIXXXXXXXXXXXXXXXXXXXXXX CONVERSIONS')


#######################################################################################################
#######################################################################################################
#######################################################################################################
#####################################################################################################

print('--------------------------------------------------')
print(' ----- MATRIX Hashtags -- OJO TOTAL')
print('--------------------------------------------------')

tweets_smi_1['hashtags'] = pd.DataFrame(tweets_smi_1['hashtags_total'])

# CREATE MATRIX hashtags

matrix_hashtags_unique = []

# matrix_hashtags = tweets_smi_1[['screenName', 'network_weight', 'hashtags']].copy()

matrix_hashtags = pd.DataFrame(tweets_smi_1[['screenName', 'network_weight', 'hashtags']])

# ######################matrix_hashtags = matrix_hashtags.reset_index()
# matrix_hashtags = matrix_hashtags.drop(columns='author_id')
# matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].astype(str, errors='ignore')
############ matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].replace('\]', '')
# ## matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].str.replace('\[', '')


# matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].str.replace('\'', '')

# [' ']

# SAVE TO FILE

# matrix_hashtags.to_csv('1_6_1_SMI1_Matrix_Hashtags_BEFORE_SPLIT_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_hashtags.to_csv('1_6_1_SMI1_Matrix_Hashtags_BEFORE_SPLIT_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)


# matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].str.split(',', n=20, expand=True)

matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].apply(lambda x: x.str.split(','))

matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].astype(str, errors='ignore')

# matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].str.replace(',', ' ')
matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].fillna('[]')
# matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].str.replace(']', '')
# matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].str.replace('[', '')
# matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].str.replace('\"', '')

# hashtags_unique = tweets_smi_1['hashtags'].unique() # axis=1 -> TO MOVE HORIZONTALLY

print('---')
print('Hashtags DIVIDED Head New DataFrame')
print(matrix_hashtags.head(20))
print('---')

print('---')
print('Matrix hashtags dtypes')
print(matrix_hashtags.dtypes)
print('---')

print('---')
print('Matrix hashtags Shape AFTER SPLIT')
print(matrix_hashtags.shape)
print('---')

# SAVE TO FILE

matrix_hashtags.to_csv('1_6_1_SMI1_Matrix_Hashtags_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_hashtags.to_csv('1_6_1_SMI1_Matrix_Hashtags_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)

# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

# matrix_hashtags_unique = matrix_hashtags['hashtags'].apply(lambda x: x.unique())

# matrix_hashtags_unique = removeDupWithoutOrder(matrix_hashtags['hashtags'])
# matrix_hashtags_unique = matrix_hashtags['hashtags'].apply(lambda x: removeDupWithoutOrder(x))

# matrix_hashtags_unique = matrix_hashtags_unique.astype(str, errors='ignore')

matrix_hashtags_unique = pd.DataFrame(matrix_hashtags_unique)

print('---------')
print('matrix_hashtags_unique head')
print(matrix_hashtags_unique.head(20))
print('-------------------------------')

matrix_hashtags_unique = pd.DataFrame(matrix_hashtags_unique)


# SAVE TO CSV 

matrix_hashtags_unique.to_csv('1_6_1_SMI1_Matrix_hashtags_Unique_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_hashtags_unique.to_csv('1_6_1_SMI1_Matrix_hashtags_Unique_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

########################

# MATRIX TRANSPOSE hashtags 

matrix_hashtags_transposed = matrix_hashtags

matrix_hashtags_transposed = matrix_hashtags_transposed.melt(id_vars = ['screenName', 'network_weight'])

matrix_hashtags_transposed = matrix_hashtags_transposed.astype(str, errors='ignore')

matrix_hashtags_transposed = matrix_hashtags_transposed.drop(columns='variable')

matrix_hashtags_unique['hashtags'] = matrix_hashtags['hashtags'].unique()

# matrix_hashtags_transposed['hashtags'] = matrix_hashtags_transposed.groupby('screenName')

print('---')
print('Head Missing hashtags MA')
print(matrix_hashtags_transposed.head)
print('---')

# SAVE TO CSV 

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

matrix_hashtags_transposed.to_csv('1_6_1_SMI1_Matrix_Hashtags_transposed_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_hashtags_transposed.to_csv('1_6_1_SMI1_Matrix_Hashtags_transposed_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)


#####################################################################################################
#####################################################################################################

print('--------------------------------------------------')
print(' ----- MATRIX Mentions -- OJO TOTAL')
print('--------------------------------------------------')

tweets_smi_1['mentions'] = pd.DataFrame(tweets_smi_1['mentions_total'])

# CREATE MATRIX mentions

matrix_mentions_unique = []

# matrix_mentions = tweets_smi_1[['screenName', 'network_weight', 'mentions']].copy()

matrix_mentions = pd.DataFrame(tweets_smi_1[['screenName', 'network_weight', 'mentions']])

# ######################matrix_mentions = matrix_mentions.reset_index()
# matrix_mentions = matrix_mentions.drop(columns='author_id')
# matrix_mentions['mentions'] = matrix_mentions['mentions'].astype(str, errors='ignore')
############ matrix_mentions['mentions'] = matrix_mentions['mentions'].replace('\]', '')
# ## matrix_mentions['mentions'] = matrix_mentions['mentions'].str.replace('\[', '')


# matrix_mentions['mentions'] = matrix_mentions['mentions'].str.replace('\'', '')

# [' ']

# SAVE TO FILE

# matrix_mentions.to_csv('1_6_1_SMI1_matrix_mentions_BEFORE_SPLIT_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_mentions.to_csv('1_6_1_SMI1_matrix_mentions_BEFORE_SPLIT_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)


# matrix_mentions['mentions'] = matrix_mentions['mentions'].str.split(',', n=20, expand=True)

matrix_mentions['mentions'] = matrix_mentions['mentions'].apply(lambda x: x.str.split(','))

matrix_mentions['mentions'] = matrix_mentions['mentions'].astype(str, errors='ignore')

# matrix_mentions['mentions'] = matrix_mentions['mentions'].str.replace(',', ' ')
matrix_mentions['mentions'] = matrix_mentions['mentions'].fillna('[]')


# mentions_unique = tweets_smi_1['mentions'].unique() # axis=1 -> TO MOVE HORIZONTALLY

print('---')
print('mentions DIVIDED Head New DataFrame')
print(matrix_mentions.head(20))
print('---')

print('---')
print('Matrix mentions dtypes')
print(matrix_mentions.dtypes)
print('---')

print('---')
print('Matrix mentions Shape AFTER SPLIT')
print(matrix_mentions.shape)
print('---')

# SAVE TO FILE

matrix_mentions.to_csv('1_6_1_SMI1_matrix_mentions_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_mentions.to_csv('1_6_1_SMI1_matrix_mentions_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)

# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

# matrix_mentions_unique = matrix_mentions['mentions'].apply(lambda x: x.unique())

# matrix_mentions_unique = removeDupWithoutOrder(matrix_mentions['mentions'])
# matrix_mentions_unique = matrix_mentions['mentions'].apply(lambda x: removeDupWithoutOrder(x))

# matrix_mentions_unique = matrix_mentions_unique.astype(str, errors='ignore')

matrix_mentions_unique = pd.DataFrame(matrix_mentions_unique)

print('---------')
print('matrix_mentions_unique head')
print(matrix_mentions_unique.head(20))
print('-------------------------------')

matrix_mentions_unique = pd.DataFrame(matrix_mentions_unique)


# SAVE TO CSV 

matrix_mentions_unique.to_csv('1_6_1_SMI1_Matrix_mentions_Unique_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_mentions_unique.to_csv('1_6_1_SMI1_Matrix_mentions_Unique_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

########################

# MATRIX TRANSPOSE mentions 

matrix_mentions_transposed = matrix_mentions

matrix_mentions_transposed = matrix_mentions_transposed.melt(id_vars = ['screenName', 'network_weight'])

matrix_mentions_transposed = matrix_mentions_transposed.drop(columns='variable')

matrix_mentions_transposed = matrix_mentions_transposed.astype(str, errors='ignore')

matrix_mentions_unique['mentions'] = matrix_mentions['mentions'].unique()

# matrix_mentions_transposed['mentions'] = matrix_mentions_transposed.groupby('screenName')

print('---')
print('Head Missing mentions MA')
print(matrix_mentions_transposed.head)
print('---')

# SAVE TO CSV 

# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

matrix_mentions_transposed.to_csv('1_6_1_SMI1_matrix_mentions_transposed_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_mentions_transposed.to_csv('1_6_1_SMI1_matrix_mentions_transposed_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

#####################################################################################################

tweets_smi_1['emojis_unicode_total'] = list(tweets_smi_1['emojis_unicode_total'])
tweets_smi_1['emojis_unicode_total_tuple'] = tuple(tweets_smi_1['emojis_unicode_total'])
tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].astype(str, errors='ignore')

tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].fillna('0')
tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.lstrip()
tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.rstrip()
tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace('\'nan\'', '')
tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace('NaN', '')

#####################################################################################################

print('--------------------------------------------------')
print(' ----- MATRIX emojis_unicode -- OJO TOTAL')
print('--------------------------------------------------')

tweets_smi_1['emojis_unicode'] = pd.DataFrame(tweets_smi_1['emojis_unicode_total'])

# CREATE MATRIX emojis_unicode

matrix_emojis_unicode_unique = []

# matrix_emojis_unicode = tweets_smi_1[['screenName', 'network_weight', 'emojis_unicode']].copy()

matrix_emojis_unicode = pd.DataFrame(tweets_smi_1[['screenName', 'network_weight', 'emojis_unicode']])

# ######################matrix_emojis_unicode = matrix_emojis_unicode.reset_index()
# matrix_emojis_unicode = matrix_emojis_unicode.drop(columns='author_id')
# matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].astype(str, errors='ignore')
############ matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].replace('\]', '')
# ## matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].str.replace('\[', '')


# matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].str.replace('\'', '')

# [' ']

# SAVE TO FILE

# matrix_emojis_unicode.to_csv('1_6_1_SMI1_matrix_emojis_unicode_BEFORE_SPLIT_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_unicode.to_csv('1_6_1_SMI1_matrix_emojis_unicode_BEFORE_SPLIT_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)


# matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].str.split(',', n=20, expand=True)

matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].apply(lambda x: x.str.split(','))

matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].astype(str, errors='ignore')

# matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].str.replace(',', ' ')
matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].fillna('[]')


# emojis_unicode_unique = tweets_smi_1['emojis_unicode'].unique() # axis=1 -> TO MOVE HORIZONTALLY

print('---')
print('Emojis DIVIDED Head New DataFrame')
print(matrix_emojis_unicode.head(20))
print('---')

print('---')
print('Matrix emojis_unicode dtypes')
print(matrix_emojis_unicode.dtypes)
print('---')

print('---')
print('Matrix emojis_unicode Shape AFTER SPLIT')
print(matrix_emojis_unicode.shape)
print('---')

# SAVE TO FILE

matrix_emojis_unicode.to_csv('1_6_1_SMI1_matrix_emojis_unicode_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_unicode.to_csv('1_6_1_SMI1_matrix_emojis_unicode_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

# matrix_emojis_unicode_unique = matrix_emojis_unicode['emojis_unicode'].apply(lambda x: x.unique())

# matrix_emojis_unicode_unique = removeDupWithoutOrder(matrix_emojis_unicode['emojis_unicode'])
# matrix_emojis_unicode_unique = matrix_emojis_unicode['emojis_unicode'].apply(lambda x: removeDupWithoutOrder(x))

# matrix_emojis_unicode_unique = matrix_emojis_unicode_unique.astype(str, errors='ignore')

matrix_emojis_unicode_unique = pd.DataFrame(matrix_emojis_unicode_unique)

print('---------')
print('matrix_emojis_unicode_unique head')
print(matrix_emojis_unicode_unique.head(20))
print('-------------------------------')

matrix_emojis_unicode_unique = pd.DataFrame(matrix_emojis_unicode_unique)


# SAVE TO CSV 

matrix_emojis_unicode_unique.to_csv('1_6_1_SMI1_Matrix_emojis_unicode_Unique_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_unicode_unique.to_csv('1_6_1_SMI1_Matrix_emojis_unicode_Unique_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

########################

# MATRIX TRANSPOSE emojis_unicode 

matrix_emojis_unicode_transposed = matrix_emojis_unicode

matrix_emojis_unicode_transposed = matrix_emojis_unicode_transposed.melt(id_vars = ['screenName', 'network_weight'])

matrix_emojis_unicode_transposed = matrix_emojis_unicode_transposed.drop(columns='variable')

matrix_emojis_unicode_transposed = matrix_emojis_unicode_transposed.astype(str, errors='ignore')

matrix_emojis_unicode_unique['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].unique()

# matrix_emojis_unicode_transposed['emojis_unicode'] = matrix_emojis_unicode_transposed.groupby('screenName')

print('---')
print('Head Missing emojis_unicode MA')
print(matrix_emojis_unicode_transposed.head)
print('---')

# SAVE TO CSV 

# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

matrix_emojis_unicode_transposed.to_csv('1_6_1_SMI1_matrix_emojis_unicode_transposed_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_unicode_transposed.to_csv('1_6_1_SMI1_matrix_emojis_unicode_transposed_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

#############################################################################################################
#####################################################################################################

print('--------------------------------------------------')
print(' ----- MATRIX emojis_converted -- OJO TOTAL')
print('--------------------------------------------------')

# tweets_smi_1['emojis_converted'] = pd.DataFrame(tweets_smi_1['emojis_converted_total'])

tweets_smi_1['emojis_converted'] = pd.DataFrame(tweets_smi_1['emojis_converted']) # OJO LO PUSDE ASI PORQUE NO TENGO LOS EMOJIS CONVETED AUN!!!!

# CREATE MATRIX emojis_converted

matrix_emojis_converted_unique = []

# matrix_emojis_converted = tweets_smi_1[['screenName', 'network_weight', 'emojis_converted']].copy()

matrix_emojis_converted = pd.DataFrame(tweets_smi_1[['screenName', 'network_weight', 'emojis_converted']])

# ######################matrix_emojis_converted = matrix_emojis_converted.reset_index()
# matrix_emojis_converted = matrix_emojis_converted.drop(columns='author_id')
# matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].astype(str, errors='ignore')
############ matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].replace('\]', '')
# ## matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].str.replace('\[', '')


# matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].str.replace('\'', '')

# [' ']

# SAVE TO FILE

# matrix_emojis_converted.to_csv('1_6_1_SMI1_matrix_emojis_converted_BEFORE_SPLIT_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_converted.to_csv('1_6_1_SMI1_matrix_emojis_converted_BEFORE_SPLIT_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)


# matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].str.split(',', n=20, expand=True)

matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].apply(lambda x: x.str.split(','))

matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].astype(str, errors='ignore')

# matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].str.replace(',', ' ')
matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].fillna('[]')


# emojis_converted_unique = tweets_smi_1['emojis_converted'].unique() # axis=1 -> TO MOVE HORIZONTALLY

print('---')
print('Emojis DIVIDED Head New DataFrame')
print(matrix_emojis_converted.head(20))
print('---')

print('---')
print('Matrix emojis_converted dtypes')
print(matrix_emojis_converted.dtypes)
print('---')

print('---')
print('Matrix emojis_converted Shape AFTER SPLIT')
print(matrix_emojis_converted.shape)
print('---')

# SAVE TO FILE

matrix_emojis_converted.to_csv('1_6_1_SMI1_matrix_emojis_converted_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_converted.to_csv('1_6_1_SMI1_matrix_emojis_converted_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

# matrix_emojis_converted_unique = matrix_emojis_converted['emojis_converted'].apply(lambda x: x.unique())

# matrix_emojis_converted_unique = removeDupWithoutOrder(matrix_emojis_converted['emojis_converted'])
# matrix_emojis_converted_unique = matrix_emojis_converted['emojis_converted'].apply(lambda x: removeDupWithoutOrder(x))

# matrix_emojis_converted_unique = matrix_emojis_converted_unique.astype(str, errors='ignore')

matrix_emojis_converted_unique = pd.DataFrame(matrix_emojis_converted_unique)

print('---------')
print('matrix_emojis_converted_unique head')
print(matrix_emojis_converted_unique.head(20))
print('-------------------------------')

matrix_emojis_converted_unique = pd.DataFrame(matrix_emojis_converted_unique)


# SAVE TO CSV 

matrix_emojis_converted_unique.to_csv('1_6_1_SMI1_Matrix_emojis_converted_Unique_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_converted_unique.to_csv('1_6_1_SMI1_Matrix_emojis_converted_Unique_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

########################

# MATRIX TRANSPOSE emojis_converted 

matrix_emojis_converted_transposed = matrix_emojis_converted

matrix_emojis_converted_transposed = matrix_emojis_converted_transposed.melt(id_vars = ['screenName', 'network_weight'])

matrix_emojis_converted_transposed = matrix_emojis_converted_transposedastype(str)

matrix_emojis_converted_transposed = matrix_emojis_converted_transposed.drop(columns='variable')

matrix_emojis_converted_unique['emojis_converted'] = matrix_emojis_converted['emojis_converted'].unique()

# matrix_emojis_converted_transposed['emojis_converted'] = matrix_emojis_converted_transposed.groupby('screenName')

print('---')
print('Head Missing emojis_converted MA')
print(matrix_emojis_converted_transposed.head)
print('---')

# SAVE TO CSV 

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

matrix_emojis_converted_transposed.to_csv('1_6_1_SMI1_matrix_emojis_converted_transposed_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_converted_transposed.to_csv('1_6_1_SMI1_matrix_emojis_converted_transposed_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)


#####################################################################################################
#####################################################################################################

print('--------------------------------------------------')
print(' ----- MATRIX Missing_geo -- OJO TOTAL')
print('--------------------------------------------------')

tweets_smi_1['missing_geo'] = pd.DataFrame(tweets_smi_1['missing_geo_total'])


# CREATE MATRIX missing_geo

matrix_missing_geo_unique = []

# matrix_missing_geo = tweets_smi_1[['screenName', 'network_weight', 'missing_geo']].copy()

matrix_missing_geo = pd.DataFrame(tweets_smi_1[['screenName', 'network_weight', 'missing_geo']])

# ######################matrix_missing_geo = matrix_missing_geo.reset_index()
# matrix_missing_geo = matrix_missing_geo.drop(columns='author_id')
# matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].astype(str, errors='ignore')
############ matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].replace('\]', '')
# ## matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].str.replace('\[', '')


# matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].str.replace('\'', '')

# [' ']

# SAVE TO FILE

# matrix_missing_geo.to_csv('1_6_1_SMI1_matrix_missing_geo_BEFORE_SPLIT_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_geo.to_csv('1_6_1_SMI1_matrix_missing_geo_BEFORE_SPLIT_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)


# matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].str.split(',', n=20, expand=True)

matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].apply(lambda x: x.str.split(','))

matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].astype(str, errors='ignore')

# matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].str.replace(',', ' ')
matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].fillna('[]')


# missing_geo_unique = tweets_smi_1['missing_geo'].unique() # axis=1 -> TO MOVE HORIZONTALLY

print('---')
print('missing_geo DIVIDED Head New DataFrame')
print(matrix_missing_geo.head(20))
print('---')

print('---')
print('Matrix missing_geo dtypes')
print(matrix_missing_geo.dtypes)
print('---')

print('---')
print('Matrix missing_geo Shape AFTER SPLIT')
print(matrix_missing_geo.shape)
print('---')

# SAVE TO FILE

matrix_missing_geo.to_csv('1_6_1_SMI1_matrix_missing_geo_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_geo.to_csv('1_6_1_SMI1_matrix_missing_geo_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

# matrix_missing_geo_unique = matrix_missing_geo['missing_geo'].apply(lambda x: x.unique())

# matrix_missing_geo_unique = removeDupWithoutOrder(matrix_missing_geo['missing_geo'])
# matrix_missing_geo_unique = matrix_missing_geo['missing_geo'].apply(lambda x: removeDupWithoutOrder(x))

# matrix_missing_geo_unique = matrix_missing_geo_unique.astype(str, errors='ignore')

matrix_missing_geo_unique = pd.DataFrame(matrix_missing_geo_unique)

print('---------')
print('matrix_missing_geo_unique head')
print(matrix_missing_geo_unique.head(20))
print('-------------------------------')

matrix_missing_geo_unique = pd.DataFrame(matrix_missing_geo_unique)


# SAVE TO CSV 

matrix_missing_geo_unique.to_csv('1_6_1_SMI1_Matrix_missing_geo_Unique_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_geo_unique.to_csv('1_6_1_SMI1_Matrix_missing_geo_Unique_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

########################

# MATRIX TRANSPOSE missing_geo 

matrix_missing_geo_transposed = matrix_missing_geo

matrix_missing_geo_transposed = matrix_missing_geo_transposed.melt(id_vars = ['screenName', 'network_weight'])

matrix_missing_geo_transposed = matrix_missing_geo_transposed.drop(columns='variable')

matrix_missing_geo_transposed = matrix_missing_geo_transposed.astype(str, errors='ignore')

matrix_missing_geo_unique['missing_geo'] = matrix_missing_geo['missing_geo'].unique()

# matrix_missing_geo_transposed['missing_geo'] = matrix_missing_geo_transposed.groupby('screenName')

print('---')
print('Head Missing missing_geo MA')
print(matrix_missing_geo_transposed.head)
print('---')

# SAVE TO CSV 

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

matrix_missing_geo_transposed.to_csv('1_6_1_SMI1_matrix_missing_geo_transposed_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_geo_transposed.to_csv('1_6_1_SMI1_matrix_missing_geo_transposed_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

#######################################################################################################
#####################################################################################################

print('--------------------------------------------------')
print(' ----- MATRIX missing_country -- OJO TOTAL')
print('--------------------------------------------------')

tweets_smi_1['missing_country'] = pd.DataFrame(tweets_smi_1['missing_country_total'])

# CREATE MATRIX missing_country

matrix_missing_country_unique = []

# matrix_missing_country = tweets_smi_1[['screenName', 'network_weight', 'missing_country']].copy()

matrix_missing_country = pd.DataFrame(tweets_smi_1[['screenName', 'network_weight', 'missing_country']])

# ######################matrix_missing_country = matrix_missing_country.reset_index()
# matrix_missing_country = matrix_missing_country.drop(columns='author_id')
# matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].astype(str, errors='ignore')
############ matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].replace('\]', '')
# ## matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].str.replace('\[', '')


# matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].str.replace('\'', '')

# [' ']

# SAVE TO FILE

# matrix_missing_country.to_csv('1_6_1_SMI1_matrix_missing_country_BEFORE_SPLIT_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_country.to_csv('1_6_1_SMI1_matrix_missing_country_BEFORE_SPLIT_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)


# matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].str.split(',', n=20, expand=True)

matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].apply(lambda x: x.str.split(','))

# matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].astype(str, errors='ignore')

# matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].str.replace(',', ' ')
matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].fillna('[]')


# missing_country_unique = tweets_smi_1['missing_country'].unique() # axis=1 -> TO MOVE HORIZONTALLY

print('---')
print('missing_country DIVIDED Head New DataFrame')
print(matrix_missing_country.head(20))
print('---')

print('---')
print('Matrix missing_country dtypes')
print(matrix_missing_country.dtypes)
print('---')

print('---')
print('Matrix missing_country Shape AFTER SPLIT')
print(matrix_missing_country.shape)
print('---')

# SAVE TO FILE

matrix_missing_country.to_csv('1_6_1_SMI1_matrix_missing_country_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_country.to_csv('1_6_1_SMI1_matrix_missing_country_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

# matrix_missing_country_unique = matrix_missing_country['missing_country'].apply(lambda x: x.unique())

# matrix_missing_country_unique = removeDupWithoutOrder(matrix_missing_country['missing_country'])
# matrix_missing_country_unique = matrix_missing_country['missing_country'].apply(lambda x: removeDupWithoutOrder(x))

# matrix_missing_country_unique = matrix_missing_country_unique.astype(str, errors='ignore')

matrix_missing_country_unique = pd.DataFrame(matrix_missing_country_unique)

print('---------')
print('matrix_missing_country_unique head')
print(matrix_missing_country_unique.head(20))
print('-------------------------------')

matrix_missing_country_unique = pd.DataFrame(matrix_missing_country_unique)


# SAVE TO CSV 

matrix_missing_country_unique.to_csv('1_6_1_SMI1_Matrix_missing_country_Unique_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_country_unique.to_csv('1_6_1_SMI1_Matrix_missing_country_Unique_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

########################

# MATRIX TRANSPOSE missing_country 

matrix_missing_country_transposed = matrix_missing_country

matrix_missing_country_transposed = matrix_missing_country_transposed.melt(id_vars = ['screenName', 'network_weight'])

matrix_missing_country_transposed = matrix_missing_country_transposed.drop(columns='variable')

# matrix_missing_country_transposed = matrix_missing_country_transposed.astype(str, errors='ignore')

matrix_missing_country_unique['missing_country'] = matrix_missing_country['missing_country'].unique()

# matrix_missing_country_transposed['missing_country'] = matrix_missing_country_transposed.groupby('screenName')

print('---')
print('Head Missing missing_country MA')
print(matrix_missing_country_transposed.head)
print('---')

# SAVE TO CSV 

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

matrix_missing_country_transposed.to_csv('1_6_1_SMI1_matrix_missing_country_transposed_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_country_transposed.to_csv('1_6_1_SMI1_matrix_missing_country_transposed_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)


#####################################################################################################
#####################################################################################################

# REMOVE EXTRA ' 

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].astype(str, errors='ignore').str.replace('\'', '"')

# tweets_smi_1['hashtags_total'] = tweets_smi_1['hashtags_total'].astype(str, errors='ignore').str.replace('\'', '"')
# tweets_smi_1['mentions_total'] = tweets_smi_1['mentions_total'].astype(str, errors='ignore').str.replace('\'', '"')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].astype(str, errors='ignore').str.replace('\'', '"')
# tweets_smi_1['total_missing_country'] = tweets_smi_1['total_missing_country'].astype(str, errors='ignore').str.replace('\'', '"')

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore').str.replace('~', '')

tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace('\'', '"')
tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.replace('\'', '"')



#######################################################################################################


tweets_smi_1['network_weight'] = tweets_smi_1['network_weight'].fillna(0)
tweets_smi_1['retweets'] = tweets_smi_1['retweets'].fillna(0)
# tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].fillna(0)
# tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].fillna(0)

tweets_smi_1['network_weight'] = tweets_smi_1['network_weight'].replace('nan', '0')
tweets_smi_1['network_weight'] = tweets_smi_1['network_weight'].replace('Nan', '0')
tweets_smi_1['retweets'] = tweets_smi_1['retweets'].replace('nan', '0')
tweets_smi_1['retweets'] = tweets_smi_1['retweets'].replace('Nan', '0')
# tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].replace('nan', '0')
# tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].replace('Nan', '0')
# tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].replace('nan', '0')
# tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].replace('Nan', '0')

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].astype(str, errors='ignore')

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str, errors='ignore')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str, errors='ignore')
# tweets_smi_1['language'] = tweets_smi_1['language'].astype(str, errors='ignore')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore')

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace('\[,\]', '')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(',,', '')

tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].replace('\[,\]', '')

# tweets_smi_1['country'] = tweets_smi_1['country'].astype(str, errors='ignore')

tweets_smi_1['network_weight'] = tweets_smi_1['network_weight'].astype(np.int32, errors='ignore')
tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int32, errors='ignore')
# tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(np.int64, errors='ignore')
# # tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(np.int64, errors='ignore')

# tweets_smi_1['created'] = pd.to_datetime(tweets_smi_1['created'])
# tweets_smi_1['created'] = tweets_smi_1['created'].to_datetime()

# tweets_smi_1 = pd.DataFrame(tweets_smi_1)
tweets_smi_1['network_weight'] = tweets_smi_1['network_weight'].fillna(0)
tweets_smi_1['retweets'] = tweets_smi_1['retweets'].fillna(0)

print('---')
print(tweets_smi_1.head(10))
print(tweets_smi_1.dtypes)
print('---')

#############################################################################################
#########################################################################################

# ###############  NEED TO DO 

# tweets_smi_1 = pd.DataFrame(tweets_smi_1)

# tweets_smi_1 = pd.read_excel(wb)
# tweets_smi_1 = pd.read_excel(smi_file_4_4, parse_dates=['created'], sort=False)

# missing_hashtags_1 = codecs.open(smi_file_4_4_missing_hashtags, 'r', 'utf-8')
# missing_mentions_1 = codecs.open(smi_file_4_4_missing_mentions, 'r', 'utf-8')
# missing_mentions_with_smi_names_1 = codecs.open(smi_file_4_4_missing_mentions_with_smi_names, 'r', 'utf-8')

############## NEED TO DO MISSING EMOJIS

# missing_emojis_unicode_1 = codecs.open(smi_file_4_4_missing_emoji_unicode, 'r', 'utf-8')
# missing_image_link_1 = codecs.open(smi_file_4_4_missing_image_link, 'r', 'utf-8')

# missing_hashtags_1 = pd.DataFrame(missing_hashtags_1)
# missing_mentions_1 = pd.DataFrame(missing_mentions_1)
# missing_mentions_with_smi_names_1 = pd.DataFrame(missing_mentions_with_smi_names_1)
# missing_emojis_unicode_1 = pd.DataFrame(missing_emojis_unicode_1)
# missing_image_link_1 = pd.DataFrame(missing_image_link_1)

print('-- imported missing files')

######################################################################################################################################

# https://realpython.com/python-statistics/

# DESCRIPTIVE STATISTICS / # Measures of Central Tendency

###  PERCENTAGE ORIG FORMULAS FOR PIE PLOT: %1.1f%% 


# ANALYSING THE DATA

# Retweets

#### NEED TO COMPLETE DATA: TAKE OUT MENTIONS, HASTAGS, SUMMARY EMOJI CODES WITH EMOTICONS, 
#### NEED FOLLOWER GROWTH OVER TIME GRAPHICS

# ANALYSING THE DATA

#### NEED TO COMPLETE DATA: TAKE OUT MENTIONS, HASTAGS, SUMMARY EMOJI CODES WITH EMOTICONS, 
#### NEED FOLLOWER GROWTH OVER TIME GRAPHICS

# FIX FORMATING OF PIE CHARTS

# NEED TO LINK TO TWITTER R DATA AND GET LOCATION INFO

# NEED TO DO SAVE TABLES TO FILES

# CHECK ALL 'NEED TO DO'

#################################################################################################################

# Check Data Imported

tweets_shape = tweets_smi_1.shape # View number of rows and columms in a df

print('---')
print('Tweets Shape and Types')
print(tweets_smi_1.shape)
print(tweets_smi_1.dtypes)
print('---')

#################################################################################################################
#################################################################################################################
#################################################################################################################

# SETTING COLOR MAPS ## NEED TO DO NOT WORKING 

plt.rcParams['image.cmap']='Blues'
plt.set_cmap('Blues')
plt.rcParams['figure.facecolor']='#6593F5'
plt.rcParams['figure.edgecolor']='white'
plt.interactive(False)
cmap = plt.set_cmap('Blues')

def ioff():
	matplotlib.interactive(False)
	uninstall_repl_display_hook()


colors_blue = ['#73C2FB', '#6593F5', '#0F52BA', '#000080', 'blue', 'lightskyblue', 'blue']
explode_pie = (0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1)

# plt.rcParams['image.cmap']='#73C2FB'
# plt.set_cmap('colors_blue')

# figure.max_open_warning

font = FontProperties()
# font.set_family('serif')
font.set_name('Segoe UI Emoji')

# plt.rcParams.update({'font.size': 16})

# plt.rcParams['xtick']=labelsize=14)
# plt.rcParams['ytick']=labelsize=14)

axis_font = {'fontname':'Segoe UI Emoji', 'size': 10}

legend_font = {'fontname':'Segoe UI Emoji', 'size': 10}

sns.set(style='ticks')
sns.palplot(sns.color_palette('Blues'))
sns.set()

#################################################################################################################
#################################################################################################################
##############################################################################################################
#
#                              SNA - CLUSTER ANALYSIS #############  NEED TO DO!!!!
#
##########################################################################################################################

graph_mentions = nx.MultiDiGraph()

# graph_mentions = nx.from_pandas_edgelist(tweets_smi_1['mentions_total'], 'screenName', ['network_weight'])

graph_mentions = nx.from_pandas_edgelist(tweets_smi_1['mentions_total'], ['network_weight'])

# graph_mentions.add_edge(tweets_smi_1['mentions'])

graph_mentions_number_of_nodes = int(g_mentions.number_of_nodes())
graph_mentions_number_of_edges = int(g_mentions.number_of_edges())
graph_mentions_list_of_all_nodes = list(g_mentions.nodes())
graph_mentions_list_of_all_edges = list(g_mentions.edges())
graph_mentions_degree_of_all_nodes = dict(g_mentions.edges(data = True))
graph_mentions_total_number_of_self_loops = int(g_mentions.number_of_selfloops())
graph_mentions_all_neighbours_main_SMI1 = list(g_mentions.neighbours('michellephan'))

print('Total Number of Nodes : ', int(g_mentions.number_of_nodes()))
print('Total Number of Edges : ', int(g_mentions.number_of_edges()))
print('List of All Nodes : ', list(g_mentions.nodes()))
print('List of All Edges : ', list(g_mentions.edges()))
print('Degree for All Nodes : ', dict(g_mentions.edges(data = True)))
print('Total Number of Self-Loops : ', int(g_mentions.number_of_selfloops()))
print('List All Nodes with Self-Loops : ', list(g_mentions.nodes_with_selfloops()))
print('List All Nodes That Go in a Single Step from node main SMI : ', list(g_mentions.neighbours('michellephan')))

# MENTIONS NETWORK GRAPH

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Network Graph')
nx.draw_spectral(graph_mentions)
# plt.xlabel('Mentions')
# plt.ylabel('Count')
# plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
p# lt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_245_SMI1_Mentions_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del graph_mentions

####################################################################################################
# python-graph-gallery.com/320-basic-network-from-pandas-data-frame/
# datacamp.com/community/tutorials/social-networ-analysis-python

number_total_tweets = len(tweets_smi_1['id'])

### 

# DETECTING COMMUNITY LOUVAIN

G_community_louvain_screenname_mentions = nx.MultiDiGraph()

# Create Connections between nodes

# smi1_matrix_mentions
G_community_louvain_screenname_mentions = nx.from_pandas_edgelist(smi1_matrix_mentions, 'value', 'screenName', ['network_weight'])

# G_community_louvain_screenname_mentions = nx.from_pandas_edgelist(smi1_matrix_mentions, 'screenName', 'mentions', ['network_weight'], edge_attr=True)


# CREATE NETWORK community_louvain_screenname_mentions

G_community_louvain_screenname_mentions = nx.erdos_renyi_graph(100,0.01)


# CREATE BEST PARTITION 

G_community_louvain_screenname_mentions_partition = community_louvain.best_partition(G_community_louvain_screenname_mentions)


# GET NETWORK STATISTICS

G_community_louvain_screenname_mentions_nodes_number = len(G_community_louvain_screenname_mentions.nodes())

print('---')
print('G_community_louvain_screenname_mentions_nodes_number:')
print(G_community_louvain_screenname_mentions_nodes_number)
print('---')

G_community_louvain_screenname_mentions_edges_number = len(G_community_louvain_screenname_mentions.edges())

print('---')
print('G_community_louvain_screenname_mentions_edges_number:')
print(G_community_louvain_screenname_mentions_edges_number)
print('---')

G_community_louvain_screenname_mentions_average_clustering = nx.average_clustering(G_community_louvain_screenname_mentions)

print('---')
print('G_community_louvain_screenname_mentions_average_clustering:')
print(G_community_louvain_screenname_mentions_average_clustering)
print('---')


# G_community_louvain_screenname_mentions_eccentricity = nx.eccentricity(G_community_louvain_screenname_mentions)

print('---')
print('G_community_louvain_screenname_mentions_eccentricity:')
# print(G_community_louvain_screenname_mentions_eccentricity)
print('---')

G_community_louvain_screenname_mentions_density = nx.density(G_community_louvain_screenname_mentions)

print('---')
print('G_community_louvain_screenname_mentions_density:')
# print(G_community_louvain_screenname_mentions_density)
print('---')

# initialize list of Lists 
community_louvain_screenname_mentions_network_numbers = [['G_community_louvain_screenname_mentions_nodes_number', G_community_louvain_screenname_mentions_nodes_number], ['G_community_louvain_screenname_mentions_edges_number', G_community_louvain_screenname_mentions_edges_number], ['G_community_louvain_screenname_mentions_average_clustering', G_community_louvain_screenname_mentions_average_clustering], ['G_community_louvain_screenname_mentions_eccentricity', 'G_community_louvain_screenname_mentions_eccentricity'], ['G_community_louvain_screenname_mentions_density', 'G_community_louvain_screenname_mentions_density']]
 
# Create the pandas DataFrame 
community_louvain_screenname_mentions_network_numbers_df = pd.DataFrame(community_louvain_screenname_mentions_network_numbers, columns = ['community_louvain_screenname_mentions_network_numbers_item', 'community_louvain_screenname_mentions_network_numbers_value']) 

community_louvain_screenname_mentions_network_numbers_df.to_csv('4_5A_180_SMI1_Community_Louvain_Screenname_Mentions_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# community_louvain_screenname_mentions_network_numbers_df.to_excel('4_5A_180_SMI1_community_louvain_screenname_mentions_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_community_louvain_screenname_mentions_betweenness_centrality = nx.betweenness_centrality(G_community_louvain_screenname_mentions)

print('---')
print('G_community_louvain_screenname_mentions_betweenness_centrality:')
# print(G_community_louvain_screenname_mentions_betweenness_centrality)
print('---')

# Closeness Centrality

# G_community_louvain_screenname_mentions_closeness_centrality = nx.closeness_centrality(G_community_louvain_screenname_mentions)

print('---')
print('G_community_louvain_screenname_mentions_closeness_centrality:')
# print(G_community_louvain_screenname_mentions_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_community_louvain_screenname_mentions_eigenvector_centrality = nx.eigenvector_centrality(G_community_louvain_screenname_mentions)

print('---')
print('G_community_louvain_screenname_mentions_eigenvector_centrality:')
# print(G_community_louvain_screenname_mentions_eigenvector_centrality)
print('---')

# initialize list of Lists 
community_louvain_screenname_mentions_network_measures = [['G_community_louvain_screenname_mentions_betweenness_centrality', 'G_community_louvain_screenname_mentions_betweenness_centrality'], ['G_community_louvain_screenname_mentions_closeness_centrality', 'G_community_louvain_screenname_mentions_closeness_centrality'], ['G_community_louvain_screenname_mentions_eigenvector_centrality', 'G_community_louvain_screenname_mentions_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# community_louvain_screenname_mentions_network_measures_df = pd.DataFrame(community_louvain_screenname_mentions_network_measures, columns = ['community_louvain_screenname_mentions_network_measures_item', 'community_louvain_screenname_mentions_network_measures_value']) 

# community_louvain_screenname_mentions_network_measures_df.to_csv('4_5A_180_SMI1_community_louvain_screenname_mentions_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# community_louvain_screenname_mentions_network_measures_df.to_excel('4_5A_180_SMI1_community_louvain_screenname_mentions_network_measures_DF.xlsx', header=True)

# NETWORK community_louvain_screenname_mentions

G_community_louvain_screenname_mentions_network_info = nx.info(G_community_louvain_screenname_mentions)

# Create the pandas DataFrame 
# community_louvain_screenname_mentions_network_info_df = pd.DataFrame(G_community_louvain_screenname_mentions_network_info, columns = ['G_community_louvain_screenname_mentions_network_info']) 

# community_louvain_screenname_mentions_network_info_df.to_csv('4_5A_180_SMI1_community_louvain_screenname_mentions_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# community_louvain_screenname_mentions_network_info_df.to_excel('4_5A_180_SMI1_community_louvain_screenname_mentions_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('community_louvain_screenname_mentions_network INFO')
print(G_community_louvain_screenname_mentions_network_info)
print('---')

# PLOT NETWORK GRAPH

# layout_community_louvain_screenname_mentions = nx.random_layout(G_community_louvain_screenname_mentions, iterations=50)
G_community_louvain_screenname_mentions_network_size = float(len(set(G_community_louvain_screenname_mentions_partition.values())))
# nx.random_layout

G_community_louvain_screenname_mentions_network_pos = nx.spring_layout(G_community_louvain_screenname_mentions)
count = 0.

for com in set(G_community_louvain_screenname_mentions_partition.values()):
	G_community_louvain_screenname_mentions_network_count = count + 1.
	list_nodes = [nodes for nodes in G_community_louvain_screenname_mentions_partition.keys() if G_community_louvain_screenname_mentions_partition[nodes] == com]
	nx.draw_networkx_nodes(G_community_louvain_screenname_mentions, G_community_louvain_screenname_mentions_network_pos, list_nodes, node_size=20, node_color = str(G_community_louvain_screenname_mentions_network_count / G_community_louvain_screenname_mentions_network_size))

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Mentions - Louvain Network')
# nx.draw(G_community_louvain_screenname_mentions, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
# nx.draw(G_community_louvain_screenname_mentions, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
# edge_labels_community_louvain_screenname_mentions = nx.get_edge_attributes(G_community_louvain_screenname_mentions, tweets_smi_1['mentions'])
nx.draw(G_community_louvain_screenname_mentions, G_community_louvain_screenname_mentions_network_pos, with_labels=True, node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9)
plt.xlabel('')
plt.ylabel('')
# plt.legend(G_community_louvain_screenname_mentions) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_2_SMI1_Louvain_Community_Louvain_Screenname_Mentions_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('---')
print('Done Graph Network screenname_mentions Louvain')
print('---')


## DELETE VARIABLE

del G_community_louvain_screenname_mentions_network_info
del G_community_louvain_screenname_mentions
del community_louvain_screenname_mentions_network_measures
del community_louvain_screenname_mentions_network_measures_df
del community_louvain_screenname_mentions_network_numbers
del community_louvain_screenname_mentions_network_numbers_df

######################################################################################################


# CREATE NETWORK SCREENNAME_MENTIONS


G_screenname_mentions = nx.MultiDiGraph()


# Create Connections between nodes

G_screenname_mentions = nx.from_pandas_edgelist(smi1_matrix_mentions, 'value', 'screenName', ['network_weight'])

# G_screenname_mentions = G_screenname_mentions.add_edges_from(G_screenname_mentions.edges())
# G_screenname_mentions = G_screenname_mentions.add_nodes_from(G_screenname_mentions.nodes())
# G_screenname_mentions = nx.from_pandas_edgelist(smi1_matrix_mentions, 'screenName', 'mentions', ['network_weight'], edge_attr=True)


# GET NETWORK STATISTICS

G_screenname_mentions_nodes_number = len(G_screenname_mentions.nodes())

print('---')
print('G_screenname_mentions_nodes_number:')
# print(G_screenname_mentions_nodes_number)
print('---')

G_screenname_mentions_edges_number = len(G_screenname_mentions.edges())

print('---')
print('G_screenname_mentions_edges_number:')
print(G_screenname_mentions_edges_number)
print('---')

# G_screenname_mentions_average_clustering = nx.average_clustering(G_screenname_mentions)

print('---')
print('G_screenname_mentions_average_clustering:')
# print(G_screenname_mentions_average_clustering)
print('---')


# G_screenname_mentions_eccentricity = nx.eccentricity(G_screenname_mentions)

print('---')
print('G_screenname_mentions_eccentricity:')
# print(G_screenname_mentions_eccentricity)
print('---')

G_screenname_mentions_density = nx.density(G_screenname_mentions)

print('---')
print('G_screenname_mentions_density:')
# print(G_screenname_mentions_density)
print('---')

# initialize list of Lists 
screenname_mentions_network_numbers = [['G_screenname_mentions_nodes_number', G_screenname_mentions_nodes_number], ['G_screenname_mentions_edges_number', G_screenname_mentions_edges_number], ['G_screenname_mentions_average_clustering', 'G_screenname_mentions_average_clustering'], ['G_screenname_mentions_eccentricity', 'G_screenname_mentions_eccentricity'], ['G_screenname_mentions_density', 'G_screenname_mentions_density']]
 
# Create the pandas DataFrame 
screenname_mentions_network_numbers_df = pd.DataFrame(screenname_mentions_network_numbers, columns = ['screenname_mentions_network_numbers_item', 'screenname_mentions_network_numbers_value']) 

screenname_mentions_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Mentions_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_mentions_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Mentions_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_mentions_betweenness_centrality = nx.betweenness_centrality(G_screenname_mentions)

print('---')
print('G_screenname_mentions_betweenness_centrality:')
# print(G_screenname_mentions_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_mentions_closeness_centrality = nx.closeness_centrality(G_screenname_mentions)

print('---')
print('G_screenname_mentions_closeness_centrality:')
# print(G_screenname_mentions_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_mentions_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_mentions)

print('---')
print('G_screenname_mentions_eigenvector_centrality:')
# print(G_screenname_mentions_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_mentions_network_measures = [['G_screenname_mentions_betweenness_centrality', 'G_screenname_mentions_betweenness_centrality'], ['G_screenname_mentions_closeness_centrality', 'G_screenname_mentions_closeness_centrality'], ['G_screenname_mentions_eigenvector_centrality', 'G_screenname_mentions_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_mentions_network_measures_df = pd.DataFrame(screenname_mentions_network_measures, columns = ['screenname_mentions_network_measures_item', 'screenname_mentions_network_measures_value']) 

# screenname_mentions_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Mentions_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_mentions_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Mentions_network_measures_DF.xlsx', header=True)

# NETWORK SCREENNAME_MENTIONS

G_screenname_mentions_network_info = nx.info(G_screenname_mentions)

# Create the pandas DataFrame 
# screenname_mentions_network_info_df = pd.DataFrame(G_screenname_mentions_network_info, columns = ['G_screenname_mentions_network_info']) 

# screenname_mentions_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Mentions_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_mentions_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Mentions_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_mentions_network INFO')
print(G_screenname_mentions_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# RANDOM LAYOUT 

# random_layout_screenname_mentions = nx.random_layout(G_screenname_mentions, iterations=50)
# mentions_size = [G_screenname_mentions.degree(mentions) * 80 for mentions in mentions]
nx.random_layout

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Mentions - Network')
nx.draw(G_screenname_mentions, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
# edge_labels_screenname_mentions = nx.get_edge_attributes(G_screenname_mentions, smi1_matrix_mentions['value'])
# draw_network_edge_labels(G_screenname_mentions, edge_labels=edge_labels_screenname_mentions)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_RD0_ScreenName_Mentions_Random_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT EGO NETWORK


# random_layout_screenname_mentions = nx.random_layout(G_screenname_mentions, iterations=50)
# mentions_size = [G_screenname_mentions.degree(mentions) * 80 for mentions in mentions]
# nx.random_layout

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Mentions - Network')
nx.draw(G_screenname_mentions, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
# edge_labels_screenname_mentions = nx.get_edge_attributes(G_screenname_mentions, smi1_matrix_mentions['value'])
# draw_network_edge_labels(G_screenname_mentions, edge_labels=edge_labels_screenname_mentions)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_RD0_ScreenName_Mentions_Ego_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT CIRCULAR NETWORK

nx.circular_layout(G_screenname_mentions)

# plt.figure(figsize=(30,20))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Mentions - Network')
nx.draw(G_screenname_mentions, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
# edge_labels_screenname_mentions = nx.get_edge_attributes(G_screenname_mentions, smi1_matrix_mentions['value'])
# draw_network_edge_labels(G_screenname_mentions, edge_labels=edge_labels_screenname_mentions)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_RD0_ScreenName_Mentions_Circular_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('---')
print('Done Graph Network 3')
print('---')

######################################################################################################

# NETWORK INFLUENCER SMI ONLY

# CREATE NETWORK MAIN_SMI SCREENNAME_MENTIONS

# tweets_main_smi_1 = tweets_smi_1[tweets_smi_1.screenName == main_smi_1]


print('4444444444444444444---')
print('tweets_main_smi_1 HEAD')
print(tweets_main_smi_1.head)
print('44444444444444444---')

G_mentions_main_smi = nx.MultiDiGraph()

# Create Connections between nodes

# G_screenname_mentions_main_smi = nx.from_pandas_edgelist(tweets_main_smi_1, 'screenName', 'mentions_network')

# G_mentions_main_smi = nx.from_pandas_edgelist(tweets_main_smi_1, 'mentions', 'screenName', ['network_weight'])

G_mentions_main_smi = nx.from_pandas_edgelist(tweets_main_smi_1, 'mentions', 'screenName', ['network_weight'])
G_screenname_mentions_main_smi = nx.ego_graph(G_mentions_main_smi, 'main_smi_1', center=True)

# GET NETWORK STATISTICS

G_screenname_mentions_main_smi_nodes_number = len(G_screenname_mentions_main_smi.nodes())

print('---')
print('G_screenname_mentions_main_smi_nodes_number:')
print(G_screenname_mentions_main_smi_nodes_number)
print('---')

G_screenname_mentions_main_smi_edges_number = len(G_screenname_mentions_main_smi.edges())

print('---')
print('G_screenname_mentions_main_smi_edges_number:')
print(G_screenname_mentions_main_smi_edges_number)
print('---')

G_screenname_mentions_main_smi_average_clustering = nx.average_clustering(G_screenname_mentions_main_smi)

print('---')
print('G_screenname_mentions_main_smi_average_clustering:')
print(G_screenname_mentions_main_smi_average_clustering)
print('---')


# G_screenname_mentions_main_smi_eccentricity = nx.eccentricity(G_screenname_mentions_main_smi)

print('---')
print('G_screenname_mentions_main_smi_eccentricity:')
# print(G_screenname_mentions_main_smi_eccentricity)
print('---')

# initialize list of Lists 
screenname_mentions_main_smi_network_numbers = [['G_screenname_mentions_main_smi_nodes_number', G_screenname_mentions_main_smi_nodes_number], ['G_screenname_mentions_main_smi_edges_number', G_screenname_mentions_main_smi_edges_number], ['G_screenname_mentions_main_smi_average_clustering', G_screenname_mentions_main_smi_average_clustering], ['G_screenname_mentions_main_smi_eccentricity', 'G_screenname_mentions_main_smi_eccentricity']]
 
# Create the pandas DataFrame 
screenname_mentions_main_smi_network_numbers_df = pd.DataFrame(screenname_mentions_main_smi_network_numbers, columns = ['screenname_mentions_main_smi_network_numbers_item', 'screenname_mentions_main_smi_network_numbers_value']) 

screenname_mentions_main_smi_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Mentions_main_smi_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_mentions_main_smi_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Mentions_main_smi_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_mentions_main_smi_betweenness_centrality = nx.betweenness_centrality(G_screenname_mentions_main_smi)

print('---')
print('G_screenname_mentions_main_smi_betweenness_centrality:')
# print(G_screenname_mentions_main_smi_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_mentions_main_smi_closeness_centrality = nx.closeness_centrality(G_screenname_mentions_main_smi)

print('---')
print('G_screenname_mentions_main_smi_closeness_centrality:')
# print(G_screenname_mentions_main_smi_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_mentions_main_smi_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_mentions_main_smi)

print('---')
print('G_screenname_mentions_main_smi_eigenvector_centrality:')
# print(G_screenname_mentions_main_smi_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_mentions_main_smi_network_measures = [['G_screenname_mentions_main_smi_betweenness_centrality', 'G_screenname_mentions_main_smi_betweenness_centrality'], ['G_screenname_mentions_main_smi_closeness_centrality', 'G_screenname_mentions_main_smi_closeness_centrality'], ['G_screenname_mentions_main_smi_eigenvector_centrality', 'G_screenname_mentions_main_smi_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_mentions_main_smi_network_measures_df = pd.DataFrame(screenname_mentions_main_smi_network_measures, columns = ['screenname_mentions_main_smi_network_measures_item', 'screenname_mentions_main_smi_network_measures_value']) 

# screenname_mentions_main_smi_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Mentions_main_smi_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_mentions_main_smi_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Mentions_main_smi_network_measures_DF.xlsx', header=True)

# NETWORK MAIN_SMI

G_screenname_mentions_main_smi_network_info = nx.info(G_screenname_mentions_main_smi)

# Create the pandas DataFrame 
# screenname_mentions_main_smi_network_info_df = pd.DataFrame(G_screenname_mentions_main_smi_network_info, columns = ['G_screenname_mentions_main_smi_network_info']) 

# screenname_mentions_main_smi_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Mentions_Main_SMI_Network_Info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_mentions_main_smi_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Mentions_Main_SMI_Network_Info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_mentions_main_smi_network INFO')
print(G_screenname_mentions_main_smi_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
plt.autoscale() 
# plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Main SMI ScreenName Mentions - Network Graph')
nx.draw(G_screenname_mentions_main_smi, with_labels=False, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_180_SMI1_ScreenName_Mentions_Main_SMI_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network ..')
print('---')

G_screenname_mentions_main_smi_network_info_bridges = list(nx.bridges(G_screenname_mentions_main_smi))


# Create the pandas DataFrame 
G_screenname_mentions_main_smi_network_info_bridges_df = pd.DataFrame(G_screenname_mentions_main_smi_network_info_bridges) 

G_screenname_mentions_main_smi_network_info_bridges_df.to_csv('4_5A_181_SMI1_G_Screenname_Mentions_Main_SMI_Network_info_bridges_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_mentions_main_smi_network_info_df.to_excel('4_5A_181_SMI1_G_Screenname_Mentions_Main_SMI_Network_info_bridges_DF.xlsx', header=True)


# PLOT BRIDGES NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

plt.figure(figsize=(40,30))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Main SMI ScreenName Mentions Bridges - Network Graph')
nx.draw(G_screenname_mentions_main_smi, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
nx.bridges(G_screenname_mentions_main_smi, main_smi)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_181_SMI1_ScreenName_Mentions_Main_SMI_BRIDGES_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Bridges Graph Network ..')
print('---')

#################################################################################################################

# python-graph-gallery.com/320-basic-network-from-pandas-data-frame/
# datacamp.com/community/tutorials/social-networ-analysis-python

# CREATE NETWORK SCREENNAME_hashtags

G_screenname_hashtags = nx.MultiDiGraph()

# Create Connections between nodes

# G_screenname_hashtags = nx.from_pandas_edgelist(smi1_matrix_hashtags, 'value', 'hashtags', ['network_weight'])

G_screenname_hashtags = nx.from_pandas_edgelist(smi1_matrix_hashtags, 'value', 'screenName', ['network_weight'], create_using=nx.DiGraph())

# GET NETWORK STATISTICS

G_screenname_hashtags_nodes_number = len(G_screenname_hashtags.nodes())

print('---')
print('G_screenname_hashtags_nodes_number:')
print(G_screenname_hashtags_nodes_number)
print('---')

G_screenname_hashtags_edges_number = len(G_screenname_hashtags.edges())

print('---')
print('G_screenname_hashtags_edges_number:')
print(G_screenname_hashtags_edges_number)
print('---')

# G_screenname_hashtags_average_clustering = nx.average_clustering(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_average_clustering:')
# print(G_screenname_hashtags_average_clustering)
print('---')


# G_screenname_hashtags_eccentricity = nx.eccentricity(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_eccentricity:')
# print(G_screenname_hashtags_eccentricity)
print('---')

# initialize list of Lists 
screenname_hashtags_network_numbers = [['G_screenname_hashtags_nodes_number', G_screenname_hashtags_nodes_number], ['G_screenname_hashtags_edges_number', G_screenname_hashtags_edges_number], ['G_screenname_hashtags_average_clustering', 'G_screenname_hashtags_average_clustering'], ['G_screenname_hashtags_eccentricity', 'G_screenname_hashtags_eccentricity']]
 
# Create the pandas DataFrame 
screenname_hashtags_network_numbers_df = pd.DataFrame(screenname_hashtags_network_numbers, columns = ['screenname_hashtags_network_numbers_item', 'screenname_hashtags_network_numbers_value']) 

screenname_hashtags_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Hashtags_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_hashtags_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Hashtags_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_hashtags_betweenness_centrality = nx.betweenness_centrality(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_betweenness_centrality:')
# print(G_screenname_hashtags_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_hashtags_closeness_centrality = nx.closeness_centrality(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_closeness_centrality:')
# print(G_screenname_hashtags_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_hashtags_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_hashtags)

print('---')
print('G_screenname_hashtags_eigenvector_centrality:')
# print(G_screenname_hashtags_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_hashtags_network_measures = [['G_screenname_hashtags_betweenness_centrality', 'G_screenname_hashtags_betweenness_centrality'], ['G_screenname_hashtags_closeness_centrality', 'G_screenname_hashtags_closeness_centrality'], ['G_screenname_hashtags_eigenvector_centrality', 'G_screenname_hashtags_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_hashtags_network_measures_df = pd.DataFrame(screenname_hashtags_network_measures, columns = ['screenname_hashtags_network_measures_item', 'screenname_hashtags_network_measures_value']) 

# screenname_hashtags_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Hashtags_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_hashtags_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Hashtags_network_measures_DF.xlsx', header=True)

# NETWORK SCREENNAME_hashtags

G_screenname_hashtags_network_info = nx.info(G_screenname_hashtags)

# Create the pandas DataFrame 
# screenname_hashtags_network_info_df = pd.DataFrame(G_screenname_hashtags_network_info, columns = ['G_screenname_hashtags_network_info']) 

# screenname_hashtags_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Hashtags_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_hashtags_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Hashtags_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_hashtags_network INFO')
print(G_screenname_hashtags_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Hashtags - Network Graph')
nx.draw(G_screenname_hashtags, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_ScreenName_hashtags_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network 4')
print('---')

######################################################################################################

# NETWORK INFLUENCER SMI ONLY

# CREATE NETWORK MAIN_SMI SCREENNAME_hashtags

smi1_matrix_hashtags_main_smi_1 = tweets_smi_1[(smi1_matrix_hashtags['screenName'] == main_smi_1)]

G_screenname_hashtags_main_smi = nx.MultiDiGraph()

# Create Connections between nodes

# G_screenname_hashtags_main_smi = nx.from_pandas_edgelist(smi1_matrix_hashtags, 'screenName', 'value', ['network_weight'])

G_screenname_hashtags_main_smi = nx.from_pandas_edgelist(smi1_matrix_hashtags, 'value', 'screenName', ['network_weight'])
G_screenname_hashtags_main_smi = nx.ego_graph(G_screenname_hashtags_main_smi, main_smi_1, center=True)

# GET NETWORK STATISTICS

G_screenname_hashtags_main_smi_nodes_number = len(G_screenname_hashtags_main_smi.nodes())

print('---')
print('G_screenname_hashtags_main_smi_nodes_number:')
print(G_screenname_hashtags_main_smi_nodes_number)
print('---')

G_screenname_hashtags_main_smi_edges_number = len(G_screenname_hashtags_main_smi.edges())

print('---')
print('G_screenname_hashtags_main_smi_edges_number:')
print(G_screenname_hashtags_main_smi_edges_number)
print('---')

G_screenname_hashtags_main_smi_average_clustering = nx.average_clustering(G_screenname_hashtags_main_smi)

print('---')
print('G_screenname_hashtags_main_smi_average_clustering:')
print(G_screenname_hashtags_main_smi_average_clustering)
print('---')


# G_screenname_hashtags_main_smi_eccentricity = nx.eccentricity(G_screenname_hashtags_main_smi)

print('---')
print('G_screenname_hashtags_main_smi_eccentricity:')
# print(G_screenname_hashtags_main_smi_eccentricity)
print('---')

# initialize list of Lists 
screenname_hashtags_main_smi_network_numbers = [['G_screenname_hashtags_main_smi_nodes_number', G_screenname_hashtags_main_smi_nodes_number], ['G_screenname_hashtags_main_smi_edges_number', G_screenname_hashtags_main_smi_edges_number], ['G_screenname_hashtags_main_smi_average_clustering', G_screenname_hashtags_main_smi_average_clustering], ['G_screenname_hashtags_main_smi_eccentricity', 'G_screenname_hashtags_main_smi_eccentricity']]
 
# Create the pandas DataFrame 
screenname_hashtags_main_smi_network_numbers_df = pd.DataFrame(screenname_hashtags_main_smi_network_numbers, columns = ['screenname_hashtags_main_smi_network_numbers_item', 'screenname_hashtags_main_smi_network_numbers_value']) 

screenname_hashtags_main_smi_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Hashtags_main_smi_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_hashtags_main_smi_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Hashtags_main_smi_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_hashtags_main_smi_betweenness_centrality = nx.betweenness_centrality(G_screenname_hashtags_main_smi)

print('---')
print('G_screenname_hashtags_main_smi_betweenness_centrality:')
# print(G_screenname_hashtags_main_smi_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_hashtags_main_smi_closeness_centrality = nx.closeness_centrality(G_screenname_hashtags_main_smi)

print('---')
print('G_screenname_hashtags_main_smi_closeness_centrality:')
# print(G_screenname_hashtags_main_smi_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_hashtags_main_smi_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_hashtags_main_smi)

print('---')
print('G_screenname_hashtags_main_smi_eigenvector_centrality:')
# print(G_screenname_hashtags_main_smi_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_hashtags_main_smi_network_measures = [['G_screenname_hashtags_main_smi_betweenness_centrality', 'G_screenname_hashtags_main_smi_betweenness_centrality'], ['G_screenname_hashtags_main_smi_closeness_centrality', 'G_screenname_hashtags_main_smi_closeness_centrality'], ['G_screenname_hashtags_main_smi_eigenvector_centrality', 'G_screenname_hashtags_main_smi_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_hashtags_main_smi_network_measures_df = pd.DataFrame(screenname_hashtags_main_smi_network_measures, columns = ['screenname_hashtags_main_smi_network_measures_item', 'screenname_hashtags_main_smi_network_measures_value']) 

# screenname_hashtags_main_smi_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Hashtags_main_smi_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_hashtags_main_smi_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Hashtags_main_smi_network_measures_DF.xlsx', header=True)

# NETWORK MAIN_SMI

G_screenname_hashtags_main_smi_network_info = nx.info(G_screenname_hashtags_main_smi)

# Create the pandas DataFrame 
# screenname_hashtags_main_smi_network_info_df = pd.DataFrame(G_screenname_hashtags_main_smi_network_info, columns = ['G_screenname_hashtags_main_smi_network_info']) 

# screenname_hashtags_main_smi_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Hashtags_main_smi_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_hashtags_main_smi_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Hashtags_main_smi_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_hashtags_main_smi_network INFO')
print(G_screenname_hashtags_main_smi_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(40,30))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Main SMI ScreenName Hashtags - Network Graph')
nx.draw(G_screenname_hashtags_main_smi, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_180_SMI1_ScreenName_hashtags_main_smi_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network ..')
print('---')

#################################################################################################################

# python-graph-gallery.com/320-basic-network-from-pandas-data-frame/
# datacamp.com/community/tutorials/social-networ-analysis-python

# CREATE NETWORK SCREENNAME_emojis_unicode

G_screenname_emojis_unicode = nx.MultiDiGraph()

# Create Connections between nodes

# G_screenname_emojis_unicode = nx.from_pandas_edgelist(smi1_matrix_emojis_unicode, 'value', 'emojis_unicode', ['network_weight'])

G_screenname_emojis_unicode = nx.from_pandas_edgelist(smi1_matrix_emojis_unicode, 'value', 'screenName', ['network_weight'], create_using=nx.DiGraph())

# GET NETWORK STATISTICS

G_screenname_emojis_unicode_nodes_number = len(G_screenname_emojis_unicode.nodes())

print('---')
print('G_screenname_emojis_unicode_nodes_number:')
print(G_screenname_emojis_unicode_nodes_number)
print('---')

G_screenname_emojis_unicode_edges_number = len(G_screenname_emojis_unicode.edges())

print('---')
print('G_screenname_emojis_unicode_edges_number:')
print(G_screenname_emojis_unicode_edges_number)
print('---')

G_screenname_emojis_unicode_average_clustering = nx.average_clustering(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_average_clustering:')
print(G_screenname_emojis_unicode_average_clustering)
print('---')


# G_screenname_emojis_unicode_eccentricity = nx.eccentricity(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_eccentricity:')
# print(G_screenname_emojis_unicode_eccentricity)
print('---')

# initialize list of Lists 
screenname_emojis_unicode_network_numbers = [['G_screenname_emojis_unicode_nodes_number', G_screenname_emojis_unicode_nodes_number], ['G_screenname_emojis_unicode_edges_number', G_screenname_emojis_unicode_edges_number], ['G_screenname_emojis_unicode_average_clustering', G_screenname_emojis_unicode_average_clustering], ['G_screenname_emojis_unicode_eccentricity', 'G_screenname_emojis_unicode_eccentricity']]
 
# Create the pandas DataFrame 
screenname_emojis_unicode_network_numbers_df = pd.DataFrame(screenname_emojis_unicode_network_numbers, columns = ['screenname_emojis_unicode_network_numbers_item', 'screenname_emojis_unicode_network_numbers_value']) 

screenname_emojis_unicode_network_numbers_df.to_csv('4_5A_180_SMI1_screenname_emojis_unicode_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_unicode_network_numbers_df.to_excel('4_5A_180_SMI1_screenname_emojis_unicode_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_emojis_unicode_betweenness_centrality = nx.betweenness_centrality(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_betweenness_centrality:')
# print(G_screenname_emojis_unicode_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_emojis_unicode_closeness_centrality = nx.closeness_centrality(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_closeness_centrality:')
# print(G_screenname_emojis_unicode_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_emojis_unicode_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_emojis_unicode)

print('---')
print('G_screenname_emojis_unicode_eigenvector_centrality:')
# print(G_screenname_emojis_unicode_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_emojis_unicode_network_measures = [['G_screenname_emojis_unicode_betweenness_centrality', 'G_screenname_emojis_unicode_betweenness_centrality'], ['G_screenname_emojis_unicode_closeness_centrality', 'G_screenname_emojis_unicode_closeness_centrality'], ['G_screenname_emojis_unicode_eigenvector_centrality', 'G_screenname_emojis_unicode_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_emojis_unicode_network_measures_df = pd.DataFrame(screenname_emojis_unicode_network_measures, columns = ['screenname_emojis_unicode_network_measures_item', 'screenname_emojis_unicode_network_measures_value']) 

# screenname_emojis_unicode_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Unicode_Network_Measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_unicode_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Unicode_Network_Measures_DF.xlsx', header=True)

# NETWORK SCREENNAME_emojis_unicode

G_screenname_emojis_unicode_network_info = nx.info(G_screenname_emojis_unicode)

# Create the pandas DataFrame 
# screenname_emojis_unicode_network_info_df = pd.DataFrame(G_screenname_emojis_unicode_network_info, columns = ['G_screenname_emojis_unicode_network_info']) 

# screenname_emojis_unicode_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Unicode_Network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_unicode_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Unicode_Network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_emojis_unicode_network INFO')
print(G_screenname_emojis_unicode_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(40,30))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Emojis - Network Graph')
nx.draw(G_screenname_emojis_unicode, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5A_180_SMI1_ScreenName_emojis_unicode_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network 6')
print('---')

######################################################################################################

# NETWORK INFLUENCER SMI ONLY

# CREATE NETWORK MAIN_SMI SCREENNAME_emojis_unicode

smi1_matrix_emojis_unicode_main_smi_1 = tweets_smi_1[(smi1_matrix_emojis_unicode['screenName'] == main_smi_1)]

G_screenname_emojis_unicode_main_smi = nx.MultiDiGraph()

# Create Connections between nodes

# G_screenname_emojis_unicode_main_smi = nx.from_pandas_edgelist(smi1_matrix_emojis_unicode_main_smi_1, 'screenName', 'value', ['network_weight'])

G_screenname_emojis_unicode_main_smi = nx.from_pandas_edgelist(smi1_matrix_emojis_unicode, 'value', 'screenName', ['network_weight'], create_using=nx.DiGraph())
G_screenname_emojis_unicode_main_smi = nx.ego_graph(G_screenname_emojis_unicode_main_smi, main_smi_1, center=True)

# GET NETWORK STATISTICS

G_screenname_emojis_unicode_main_smi_nodes_number = len(G_screenname_emojis_unicode_main_smi.nodes())

print('---')
print('G_screenname_emojis_unicode_main_smi_nodes_number:')
print(G_screenname_emojis_unicode_main_smi_nodes_number)
print('---')

G_screenname_emojis_unicode_main_smi_edges_number = len(G_screenname_emojis_unicode_main_smi.edges())

print('---')
print('G_screenname_emojis_unicode_main_smi_edges_number:')
print(G_screenname_emojis_unicode_main_smi_edges_number)
print('---')

G_screenname_emojis_unicode_main_smi_average_clustering = nx.average_clustering(G_screenname_emojis_unicode_main_smi)

print('---')
print('G_screenname_emojis_unicode_main_smi_average_clustering:')
print(G_screenname_emojis_unicode_main_smi_average_clustering)
print('---')


# G_screenname_emojis_unicode_main_smi_eccentricity = nx.eccentricity(G_screenname_emojis_unicode_main_smi)

print('---')
print('G_screenname_emojis_unicode_main_smi_eccentricity:')
# print(G_screenname_emojis_unicode_main_smi_eccentricity)
print('---')

# initialize list of Lists 
screenname_emojis_unicode_main_smi_network_numbers = [['G_screenname_emojis_unicode_main_smi_nodes_number', G_screenname_emojis_unicode_main_smi_nodes_number], ['G_screenname_emojis_unicode_main_smi_edges_number', G_screenname_emojis_unicode_main_smi_edges_number], ['G_screenname_emojis_unicode_main_smi_average_clustering', G_screenname_emojis_unicode_main_smi_average_clustering], ['G_screenname_emojis_unicode_main_smi_eccentricity', 'G_screenname_emojis_unicode_main_smi_eccentricity']]
 
# Create the pandas DataFrame 
screenname_emojis_unicode_main_smi_network_numbers_df = pd.DataFrame(screenname_emojis_unicode_main_smi_network_numbers, columns = ['screenname_emojis_unicode_main_smi_network_numbers_item', 'screenname_emojis_unicode_main_smi_network_numbers_value']) 

screenname_emojis_unicode_main_smi_network_numbers_df.to_csv('4_5A_180_SMI1_screenname_emojis_unicode_main_smi_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_unicode_main_smi_network_numbers_df.to_excel('4_5A_180_SMI1_screenname_emojis_unicode_main_smi_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_emojis_unicode_main_smi_betweenness_centrality = nx.betweenness_centrality(G_screenname_emojis_unicode_main_smi)

print('---')
print('G_screenname_emojis_unicode_main_smi_betweenness_centrality:')
# print(G_screenname_emojis_unicode_main_smi_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_emojis_unicode_main_smi_closeness_centrality = nx.closeness_centrality(G_screenname_emojis_unicode_main_smi)

print('---')
print('G_screenname_emojis_unicode_main_smi_closeness_centrality:')
# print(G_screenname_emojis_unicode_main_smi_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_emojis_unicode_main_smi_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_emojis_unicode_main_smi)

print('---')
print('G_screenname_emojis_unicode_main_smi_eigenvector_centrality:')
# print(G_screenname_emojis_unicode_main_smi_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_emojis_unicode_main_smi_network_measures = [['G_screenname_emojis_unicode_main_smi_betweenness_centrality', 'G_screenname_emojis_unicode_main_smi_betweenness_centrality'], ['G_screenname_emojis_unicode_main_smi_closeness_centrality', 'G_screenname_emojis_unicode_main_smi_closeness_centrality'], ['G_screenname_emojis_unicode_main_smi_eigenvector_centrality', 'G_screenname_emojis_unicode_main_smi_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_emojis_unicode_main_smi_network_measures_df = pd.DataFrame(screenname_emojis_unicode_main_smi_network_measures, columns = ['screenname_emojis_unicode_main_smi_network_measures_item', 'screenname_emojis_unicode_main_smi_network_measures_value']) 

# screenname_emojis_unicode_main_smi_network_measures_df.to_csv('4_5A_180_SMI1_screenname_emojis_unicode_main_smi_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_unicode_main_smi_network_measures_df.to_excel('4_5A_180_SMI1_screenname_emojis_unicode_main_smi_network_measures_DF.xlsx', header=True)

# NETWORK MAIN_SMI

G_screenname_emojis_unicode_main_smi_network_info = nx.info(G_screenname_emojis_unicode_main_smi)

# Create the pandas DataFrame 
# screenname_emojis_unicode_main_smi_network_info_df = pd.DataFrame(G_screenname_emojis_unicode_main_smi_network_info, columns = ['G_screenname_emojis_unicode_main_smi_network_info']) 

# screenname_emojis_unicode_main_smi_network_info_df.to_csv('4_5A_180_SMI1_screenname_emojis_unicode_main_smi_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_unicode_main_smi_network_info_df.to_excel('4_5A_180_SMI1_screenname_emojis_unicode_main_smi_network_info_DF.xlsx', header=True)

print('--- nEED TO SAVE')
print(main_smi)
print('screenname_emojis_unicode_main_smi_network INFO')
print(G_screenname_emojis_unicode_main_smi_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(40,30))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Main SMI ScreenName Emojis - Network Graph')
nx.draw(G_screenname_emojis_unicode_main_smi, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_180_SMI1_ScreenName_emojis_unicode_main_smi_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network ..')
print('---')

#################################################################################################################

# python-graph-gallery.com/320-basic-network-from-pandas-data-frame/
# datacamp.com/community/tutorials/social-networ-analysis-python

# CREATE NETWORK SCREENNAME_emojis_converted

G_screenname_emojis_converted = nx.MultiDiGraph()

# Create Connections between nodes

# G_screenname_emojis_converted = nx.from_pandas_edgelist(smi1_matrix_emojis_converted, 'screenName', 'value', ['network_weight'])

G_screenname_emojis_converted = nx.from_pandas_edgelist(tweets_smi_1, 'value', 'screenName', ['network_weight'], create_using=nx.DiGraph())

# GET NETWORK STATISTICS

G_screenname_emojis_converted_nodes_number = len(G_screenname_emojis_converted.nodes())

print('---')
print('G_screenname_emojis_converted_nodes_number:')
print(G_screenname_emojis_converted_nodes_number)
print('---')

G_screenname_emojis_converted_edges_number = len(G_screenname_emojis_converted.edges())

print('---')
print('G_screenname_emojis_converted_edges_number:')
print(G_screenname_emojis_converted_edges_number)
print('---')

G_screenname_emojis_converted_average_clustering = nx.average_clustering(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_average_clustering:')
print(G_screenname_emojis_converted_average_clustering)
print('---')


# G_screenname_emojis_converted_eccentricity = nx.eccentricity(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_eccentricity:')
# print(G_screenname_emojis_converted_eccentricity)
print('---')

# initialize list of Lists 
screenname_emojis_converted_network_numbers = [['G_screenname_emojis_converted_nodes_number', G_screenname_emojis_converted_nodes_number], ['G_screenname_emojis_converted_edges_number', G_screenname_emojis_converted_edges_number], ['G_screenname_emojis_converted_average_clustering', G_screenname_emojis_converted_average_clustering], ['G_screenname_emojis_converted_eccentricity', 'G_screenname_emojis_converted_eccentricity']]
 
# Create the pandas DataFrame 
screenname_emojis_converted_network_numbers_df = pd.DataFrame(screenname_emojis_converted_network_numbers, columns = ['screenname_emojis_converted_network_numbers_item', 'screenname_emojis_converted_network_numbers_value']) 

screenname_emojis_converted_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Converted_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_converted_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Converted_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_emojis_converted_betweenness_centrality = nx.betweenness_centrality(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_betweenness_centrality:')
# print(G_screenname_emojis_converted_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_emojis_converted_closeness_centrality = nx.closeness_centrality(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_closeness_centrality:')
# print(G_screenname_emojis_converted_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_emojis_converted_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_emojis_converted)

print('---')
print('G_screenname_emojis_converted_eigenvector_centrality:')
# print(G_screenname_emojis_converted_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_emojis_converted_network_measures = [['G_screenname_emojis_converted_betweenness_centrality', 'G_screenname_emojis_converted_betweenness_centrality'], ['G_screenname_emojis_converted_closeness_centrality', 'G_screenname_emojis_converted_closeness_centrality'], ['G_screenname_emojis_converted_eigenvector_centrality', 'G_screenname_emojis_converted_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_emojis_converted_network_measures_df = pd.DataFrame(screenname_emojis_converted_network_measures, columns = ['screenname_emojis_converted_network_measures_item', 'screenname_emojis_converted_network_measures_value']) 

# screenname_emojis_converted_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Converted_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_converted_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Converted_network_measures_DF.xlsx', header=True)

# NETWORK SCREENNAME_emojis_converted

G_screenname_emojis_converted_network_info = nx.info(G_screenname_emojis_converted)

# Create the pandas DataFrame 
# screenname_emojis_converted_network_info_df = pd.DataFrame(G_screenname_emojis_converted_network_info, columns = ['G_screenname_emojis_converted_network_info']) 

# screenname_emojis_converted_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Converted_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_converted_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Converted_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_emojis_converted_network INFO')
print(G_screenname_emojis_converted_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(40,30))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Emojis - Network Graph')
nx.draw(G_screenname_emojis_converted, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_180_SMI1_Screenname_Emojis_Converted_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network 8')
print('---')

######################################################################################################

# NETWORK INFLUENCER SMI ONLY

# CREATE NETWORK MAIN_SMI SCREENNAME_emojis_converted

smi1_matrix_emojis_converted_main_smi_1 = tweets_smi_1[(smi1_matrix_emojis_converted['screenName'] == main_smi_1)]

G_screenname_emojis_converted_main_smi = nx.MultiDiGraph()

# Create Connections between nodes

# G_screenname_emojis_converted_main_smi = nx.from_pandas_edgelist(smi1_matrix_emojis_converted_main_smi_1, 'screenName', 'value', ['network_weight'])

G_screenname_emojis_converted_main_smi = nx.from_pandas_edgelist(smi1_matrix_emojis_converted, 'value', 'screenName', ['network_weight'], create_using=nx.DiGraph())
G_screenname_emojis_converted_main_smi = nx.ego_graph(G_screenname_emojis_converted_main_smi, main_smi_1, center=True)

# GET NETWORK STATISTICS

G_screenname_emojis_converted_main_smi_nodes_number = len(G_screenname_emojis_converted_main_smi.nodes())

print('---')
print('G_screenname_emojis_converted_main_smi_nodes_number:')
print(G_screenname_emojis_converted_main_smi_nodes_number)
print('---')

G_screenname_emojis_converted_main_smi_edges_number = len(G_screenname_emojis_converted_main_smi.edges())

print('---')
print('G_screenname_emojis_converted_main_smi_edges_number:')
print(G_screenname_emojis_converted_main_smi_edges_number)
print('---')

G_screenname_emojis_converted_main_smi_average_clustering = nx.average_clustering(G_screenname_emojis_converted_main_smi)

print('---')
print('G_screenname_emojis_converted_main_smi_average_clustering:')
print(G_screenname_emojis_converted_main_smi_average_clustering)
print('---')


# G_screenname_emojis_converted_main_smi_eccentricity = nx.eccentricity(G_screenname_emojis_converted_main_smi)

print('---')
print('G_screenname_emojis_converted_main_smi_eccentricity:')
# print(G_screenname_emojis_converted_main_smi_eccentricity)
print('---')

# initialize list of Lists 
screenname_emojis_converted_main_smi_network_numbers = [['G_screenname_emojis_converted_main_smi_nodes_number', G_screenname_emojis_converted_main_smi_nodes_number], ['G_screenname_emojis_converted_main_smi_edges_number', G_screenname_emojis_converted_main_smi_edges_number], ['G_screenname_emojis_converted_main_smi_average_clustering', G_screenname_emojis_converted_main_smi_average_clustering], ['G_screenname_emojis_converted_main_smi_eccentricity', 'G_screenname_emojis_converted_main_smi_eccentricity']]
 
# Create the pandas DataFrame 
screenname_emojis_converted_main_smi_network_numbers_df = pd.DataFrame(screenname_emojis_converted_main_smi_network_numbers, columns = ['screenname_emojis_converted_main_smi_network_numbers_item', 'screenname_emojis_converted_main_smi_network_numbers_value']) 

screenname_emojis_converted_main_smi_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Converted_main_smi_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_converted_main_smi_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Converted_main_smi_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_emojis_converted_main_smi_betweenness_centrality = nx.betweenness_centrality(G_screenname_emojis_converted_main_smi)

print('---')
print('G_screenname_emojis_converted_main_smi_betweenness_centrality:')
# print(G_screenname_emojis_converted_main_smi_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_emojis_converted_main_smi_closeness_centrality = nx.closeness_centrality(G_screenname_emojis_converted_main_smi)

print('---')
print('G_screenname_emojis_converted_main_smi_closeness_centrality:')
# print(G_screenname_emojis_converted_main_smi_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_emojis_converted_main_smi_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_emojis_converted_main_smi)

print('---')
print('G_screenname_emojis_converted_main_smi_eigenvector_centrality:')
# print(G_screenname_emojis_converted_main_smi_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_emojis_converted_main_smi_network_measures = [['G_screenname_emojis_converted_main_smi_betweenness_centrality', 'G_screenname_emojis_converted_main_smi_betweenness_centrality'], ['G_screenname_emojis_converted_main_smi_closeness_centrality', 'G_screenname_emojis_converted_main_smi_closeness_centrality'], ['G_screenname_emojis_converted_main_smi_eigenvector_centrality', 'G_screenname_emojis_converted_main_smi_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_emojis_converted_main_smi_network_measures_df = pd.DataFrame(screenname_emojis_converted_main_smi_network_measures, columns = ['screenname_emojis_converted_main_smi_network_measures_item', 'screenname_emojis_converted_main_smi_network_measures_value']) 

# screenname_emojis_converted_main_smi_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Converted_main_smi_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_converted_main_smi_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Converted_main_smi_network_measures_DF.xlsx', header=True)

# NETWORK MAIN_SMI

G_screenname_emojis_converted_main_smi_network_info = nx.info(G_screenname_emojis_converted_main_smi)

# Create the pandas DataFrame 
# screenname_emojis_converted_main_smi_network_info_df = pd.DataFrame(G_screenname_emojis_converted_main_smi_network_info, columns = ['G_screenname_emojis_converted_main_smi_network_info']) 

# screenname_emojis_converted_main_smi_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Converted_main_smi_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_converted_main_smi_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Converted_main_smi_network_info_DF.xlsx', header=True)

print('--- nEED TO SAVE')
print(main_smi)
print('screenname_emojis_converted_main_smi_network INFO')
print(G_screenname_emojis_converted_main_smi_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Main SMI ScreenName Emojis - Network Graph')
nx.draw(G_screenname_emojis_converted_main_smi, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_180_SMI1_Screenname_Emojis_Converted_main_smi_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network ..')
print('---')

#################################

# CREATE NETWORK

G_screenname_emojis_converted = nx.MultiDiGraph()

# Create Connections between nodes

G_screenname_emojis_converted = nx.from_pandas_edgelist(tweets_smi_1, 'screenName', 'emojis_converted', ['network_weight'], create_using=nx.DiGraph())


# PLOT NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Emojis - Network Graph')
nx.draw(G_screenname_emojis_converted, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
#plt.savefig('4_5A_180_SMI1_Screenname_Emojis_Converted_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network 2')
print('---')

#################################################################################################################

# python-graph-gallery.com/320-basic-network-from-pandas-data-frame/
# datacamp.com/community/tutorials/social-networ-analysis-python

# CREATE NETWORK SCREENNAME_missing_geo

G_screenname_missing_geo = nx.MultiDiGraph()

# Create Connections between nodes

# G_screenname_missing_geo = nx.from_pandas_edgelist(tweets_smi_1, 'screenName', 'missing_geo', ['network_weight'])

G_screenname_missing_geo = nx.from_pandas_edgelist(smi1_matrix_missing_geo, 'screenName', 'value', ['network_weight'], create_using=nx.DiGraph())

# GET NETWORK STATISTICS

G_screenname_missing_geo_nodes_number = len(G_screenname_missing_geo.nodes())

print('---')
print('G_screenname_missing_geo_nodes_number:')
print(G_screenname_missing_geo_nodes_number)
print('---')

G_screenname_missing_geo_edges_number = len(G_screenname_missing_geo.edges())

print('---')
print('G_screenname_missing_geo_edges_number:')
print(G_screenname_missing_geo_edges_number)
print('---')

G_screenname_missing_geo_average_clustering = nx.average_clustering(G_screenname_missing_geo)

print('---')
print('G_screenname_missing_geo_average_clustering:')
print(G_screenname_missing_geo_average_clustering)
print('---')


# G_screenname_missing_geo_eccentricity = nx.eccentricity(G_screenname_missing_geo)

print('---')
print('G_screenname_missing_geo_eccentricity:')
# print(G_screenname_missing_geo_eccentricity)
print('---')

# initialize list of Lists 
screenname_missing_geo_network_numbers = [['G_screenname_missing_geo_nodes_number', G_screenname_missing_geo_nodes_number], ['G_screenname_missing_geo_edges_number', G_screenname_missing_geo_edges_number], ['G_screenname_missing_geo_average_clustering', G_screenname_missing_geo_average_clustering], ['G_screenname_missing_geo_eccentricity', 'G_screenname_missing_geo_eccentricity']]
 
# Create the pandas DataFrame 
screenname_missing_geo_network_numbers_df = pd.DataFrame(screenname_missing_geo_network_numbers, columns = ['screenname_missing_geo_network_numbers_item', 'screenname_missing_geo_network_numbers_value']) 

screenname_missing_geo_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Missing_geo_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_missing_geo_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Missing_geo_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_missing_geo_betweenness_centrality = nx.betweenness_centrality(G_screenname_missing_geo)

print('---')
print('G_screenname_missing_geo_betweenness_centrality:')
# print(G_screenname_missing_geo_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_missing_geo_closeness_centrality = nx.closeness_centrality(G_screenname_missing_geo)

print('---')
print('G_screenname_missing_geo_closeness_centrality:')
# print(G_screenname_missing_geo_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_missing_geo_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_missing_geo)

print('---')
print('G_screenname_missing_geo_eigenvector_centrality:')
# print(G_screenname_missing_geo_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_missing_geo_network_measures = [['G_screenname_missing_geo_betweenness_centrality', 'G_screenname_missing_geo_betweenness_centrality'], ['G_screenname_missing_geo_closeness_centrality', 'G_screenname_missing_geo_closeness_centrality'], ['G_screenname_missing_geo_eigenvector_centrality', 'G_screenname_missing_geo_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_missing_geo_network_measures_df = pd.DataFrame(screenname_missing_geo_network_measures, columns = ['screenname_missing_geo_network_measures_item', 'screenname_missing_geo_network_measures_value']) 

# screenname_missing_geo_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Missing_Geo_Network_Measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_missing_geo_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Missing_Geo_Network_Measures_DF.xlsx', header=True)

# NETWORK SCREENNAME_missing_geo

G_screenname_missing_geo_network_info = nx.info(G_screenname_missing_geo)

# Create the pandas DataFrame 
# screenname_missing_geo_network_info_df = pd.DataFrame(G_screenname_missing_geo_network_info, columns = ['G_screenname_missing_geo_network_info']) 

# screenname_missing_geo_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Missing_Geo_Network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_missing_geo_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Missing_Geo_Network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_missing_geo_network INFO')
print(G_screenname_missing_geo_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

plt.figure(figsize=(40,30))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Location - Network Graph')
nx.draw(G_screenname_missing_geo, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
 
# plt.show()
plt.savefig('4_5A_180_SMI1_ScreenName_missing_geo_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network 10')
print('---')

######################################################################################################

# NETWORK MAIN_SMI INFLUENCER SMI ONLY

# CREATE NETWORK MAIN_SMI SCREENNAME_missing_geo

smi1_matrix_missing_geo_main_smi_1 = tweets_smi_1[(smi1_matrix_missing_geo['screenName'] == main_smi_1)]

G_screenname_missing_geo_main_smi = nx.MultiDiGraph()

# Create Connections between nodes

# G_screenname_missing_geo_main_smi = nx.from_pandas_edgelist(smi1_matrix_missing_geo_main_smi_1, 'screenName', 'missing_geo', ['network_weight'])

G_screenname_missing_geo_main_smi = nx.from_pandas_edgelist(smi1_matrix_missing_geo_main_smi_1, 'screenName', 'value', ['network_weight'], create_using=nx.DiGraph())

# GET NETWORK STATISTICS

G_screenname_missing_geo_main_smi_nodes_number = len(G_screenname_missing_geo_main_smi.nodes())

print('---')
print('G_screenname_missing_geo_main_smi_nodes_number:')
print(G_screenname_missing_geo_main_smi_nodes_number)
print('---')

G_screenname_missing_geo_main_smi_edges_number = len(G_screenname_missing_geo_main_smi.edges())

print('---')
print('G_screenname_missing_geo_main_smi_edges_number:')
print(G_screenname_missing_geo_main_smi_edges_number)
print('---')

G_screenname_missing_geo_main_smi_average_clustering = nx.average_clustering(G_screenname_missing_geo_main_smi)

print('---')
print('G_screenname_missing_geo_main_smi_average_clustering:')
print(G_screenname_missing_geo_main_smi_average_clustering)
print('---')


# G_screenname_missing_geo_main_smi_eccentricity = nx.eccentricity(G_screenname_missing_geo_main_smi)

print('---')
print('G_screenname_missing_geo_main_smi_eccentricity:')
# print(G_screenname_missing_geo_main_smi_eccentricity)
print('---')

# initialize list of Lists 
screenname_missing_geo_main_smi_network_numbers = [['G_screenname_missing_geo_main_smi_nodes_number', G_screenname_missing_geo_main_smi_nodes_number], ['G_screenname_missing_geo_main_smi_edges_number', G_screenname_missing_geo_main_smi_edges_number], ['G_screenname_missing_geo_main_smi_average_clustering', G_screenname_missing_geo_main_smi_average_clustering], ['G_screenname_missing_geo_main_smi_eccentricity', 'G_screenname_missing_geo_main_smi_eccentricity']]
 
# Create the pandas DataFrame 
screenname_missing_geo_main_smi_network_numbers_df = pd.DataFrame(screenname_missing_geo_main_smi_network_numbers, columns = ['screenname_missing_geo_main_smi_network_numbers_item', 'screenname_missing_geo_main_smi_network_numbers_value']) 

screenname_missing_geo_main_smi_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Missing_geo_main_smi_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_missing_geo_main_smi_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Missing_geo_main_smi_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_missing_geo_main_smi_betweenness_centrality = nx.betweenness_centrality(G_screenname_missing_geo_main_smi)

print('---')
print('G_screenname_missing_geo_main_smi_betweenness_centrality:')
# print(G_screenname_missing_geo_main_smi_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_missing_geo_main_smi_closeness_centrality = nx.closeness_centrality(G_screenname_missing_geo_main_smi)

print('---')
print('G_screenname_missing_geo_main_smi_closeness_centrality:')
# print(G_screenname_missing_geo_main_smi_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_missing_geo_main_smi_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_missing_geo_main_smi)

print('---')
print('G_screenname_missing_geo_main_smi_eigenvector_centrality:')
# print(G_screenname_missing_geo_main_smi_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_missing_geo_main_smi_network_measures = [['G_screenname_missing_geo_main_smi_betweenness_centrality', 'G_screenname_missing_geo_main_smi_betweenness_centrality'], ['G_screenname_missing_geo_main_smi_closeness_centrality', 'G_screenname_missing_geo_main_smi_closeness_centrality'], ['G_screenname_missing_geo_main_smi_eigenvector_centrality', 'G_screenname_missing_geo_main_smi_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_missing_geo_main_smi_network_measures_df = pd.DataFrame(screenname_missing_geo_main_smi_network_measures, columns = ['screenname_missing_geo_main_smi_network_measures_item', 'screenname_missing_geo_main_smi_network_measures_value']) 

# screenname_missing_geo_main_smi_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Missing_geo_main_smi_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_missing_geo_main_smi_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Missing_geo_main_smi_network_measures_DF.xlsx', header=True)

# NETWORK MAIN_SMI

G_screenname_missing_geo_main_smi_network_info = nx.info(G_screenname_missing_geo_main_smi)

# Create the pandas DataFrame 
# screenname_missing_geo_main_smi_network_info_df = pd.DataFrame(G_screenname_missing_geo_main_smi_network_info, columns = ['G_screenname_missing_geo_main_smi_network_info']) 

# screenname_missing_geo_main_smi_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Missing_geo_main_smi_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_missing_geo_main_smi_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Missing_geo_main_smi_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_missing_geo_main_smi_network INFO')
print(G_screenname_missing_geo_main_smi_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Main SMI ScreenName Location - Network Graph')
nx.draw(G_screenname_missing_geo_main_smi, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.9, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
 
# plt.show()
plt.savefig('4_5A_180_SMI1_ScreenName_Missing_Geo_Main_SMI_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network ..')
print('---')

################################################################################################################

# TURN COLLUMS TO STRING 

# TEXTUAL ANALYSICS

# https://www.strehle.de/tim/weblog/archives/2015/09/03/1569

# WORD FREQUENCY DISTRIBUTION IN TEXT OF Tweets



# TEXT BIGRAMS

print('---')
print('Loading Libs 56')
print('---')

# input_file = sys.argv[1]

# fp_text = tweets_smi_1['text'].astype(str, errors='ignore')
# fp_text['tweet_text_fp_text'] = pd.DataFrame(tweets_smi_1['text'].astype(str, errors='ignore'))
# fp_text = tweets_smi_1.text.astype(str, errors='ignore')

fp_text_temp = tweets_smi_1['text']
fp_text = fp_text_temp.to_string()
fp_text_c = fp_text ### OJO QIE ESTA SIN ARREGLAR EL C

print('---')
print('DataFrame Types fp_text')
# print(fp_text.dtypes)
print('---')

# fp_text = pd.DataFrame(tweets_smi_1['text'].astype('str'))
# fp_text = pd.DataFrame(StringIO(tweets_smi_1['text']))

# input_file = sys.argv[1]

# fp_text = pd.DataFrame(tweets_smi_1['text'].astype('str'))
# fp_text = StringIO(tweets_smi_1['text'])

# fp_text = pd.read_csv(StringIO(smi_file_4_4_text_only, 'r', 'utf-8'))
# fp_text = pd.read_csv(smi_file_4_4_text_only, sep=';', encoding='utf-8', parse_dates=True, header=0, low_memory=False)# 
# fp_text = codecs.open(smi_file_4_4_text_only, 'r', 'utf-8')
# fp_text = pd.DataFrame(tweets_smi_1['text'].astype('str'))
# fp_text = np.to_string(fp_text)

# fp_text = pd.DataFrame(fp_text)

# fp_text = open(smi_file_4_4_text_only, encoding='utf-8')
# f_text = fp_text.read() # As bytes

# data_f = fp_text.read() # As bytes

# f_text = fp_text

# f_text = data_f.decode('utf-8') # Unicode not bytes

print('---')
# print(f_text)
print('---')

# fp_text = f_text

print('---')
print('Tweets Text First 10')
print(tweets_smi_1['text'].head(10))
print('---')

#######################################################################################

# CORRECT SPELLING

# tweets_smi_1

# tweets_smi_1.parse() #Parse the article
# ('punkt')   #1 total_favorites download of the sentence tokenizer
# tweets_smi_1.nlp() # Keyword extraction wrapper

textblob_obj_text_c = TextBlob(fp_text) ## OJO QUE SI ES EL CORREGIDO O NO

#########   textblob_obj_text_c = textblob_obj_text.correct() ## NEED TO CHECK HOW IT WORKS!!!!
# textblob_obj_text_c = textblob_obj_text

textblob_obj_text_c_df = pd.DataFrame(textblob_obj_text_c)

print('--')
print('textblob_obj_text_C_DF TYPE:')
# print(textblob_obj_text_c)
print('--')

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

textblob_obj_text_c_df.to_csv('4_5A_184_SMI1_Text_Obj_C_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# textblob_obj_text_c_df.to_excel('4_5A_184_SMI1_Text_Obj_C_DF.xlsx', header=True)

# fp_text_c = textblob_obj_text_c.to_string()

# fp_text_c = textblob_obj_text_c

#######################################################################################

# tweets_text_words = nltk.word_tokenize(pd.to_string(fp_text_c))
# tweets_text_words = nltk.word_tokenize(fp_text_c['tweet_text_fp_text_c'])
tweets_text_words = nltk.word_tokenize(fp_text_c)
tweets_text_words_df = pd.DataFrame(tweets_text_words)

# tweets_text_words = nltk.word_tokenize((tweets_smi_1['text']).pd.to_string())
# tweets_text_words = tweets_smi_1['text']).nltk.word_tokenize()

print('--')
print('Tokenized text_words')
print(tweets_text_words_df.head(10))
print('--')

print('--')
print('Tokenized text_words Shape')
print(tweets_text_words_df.shape)
print('--')

print('--')
print('Tokenized text_words Info')
print(tweets_text_words_df.info)
print('--')

# Remove single-character tokens (mostly punctuation) ######## NEED TO DO FIX 
# tweets_text_words = [word for word in tweets_text_words if len(word) > 1]

# Remove numbers ######## NEED TO DO FIX
# tweets_text_words = [word for word in tweets_text_words if not word.isnumeric()]

# Lowercase all tweets_words (default_stoptweets_words are lowercase too) ######## NEED TO DO FIX
# tweets_text_words = [word.lower() for word in tweets_text_words]

# Stemming tweets_words seems to make matters worse, disabled
# stemmer = nltk.stem.snowball.SnowballStemmer('english')
# tweets_text_words = [stemmer.stem(word) for word in tweets_text_words]

# Remove stoptweets_words          ################################################################
# tweets_text_words = [word for word in tweets_text_words if word not in stoptweets_words]

# print('removed stoptweets_words')

##################################################################################################################

# FINDING N-GRAMS TEXT

# N-Grams refer to n combination of words in a sentence. For instance, for a sentence "I love watching football", some 2-grams would 
# be (I love), (love watching) and (watching football). N-Grams can play a cricual role in Text classification. 

for ngram_text in textblob_obj_text_c.ngrams(2):
	print('-------------------------')
	print('N-Grams text: 2')
#	print(ngram_text)
	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_text = pd.DataFrame([str(ngram_text)])

ngram_text.to_csv('4_5A_200_SMI1_ngram_text_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
ngram_text.to_csv('4_5A_200_SMI1_ngram_text_TEXT.txt', sep=';', encoding='utf-8', index=False, header=True)

####


for ngram_trigrams_text in textblob_obj_text_c.ngrams(3):
	print('-------------------------')
	print('N-Grams text: 3')
#	print(ngram_trigrams_text)
#	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_trigrams_text = pd.DataFrame(ngram_trigrams_text)

ngram_trigrams_text.to_csv('4_5A_200_SMI1_ngram_trigrams_text_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
ngram_trigrams_text.to_csv('4_5A_200_SMI1_ngram_trigrams_text_TEXT.txt', sep='\t', encoding='utf-8', index=False, header=True)


####

# VISUALIZATION OF triGRAMS

# Create a list of Lists containing trigrams in tweets

trigrams_text_terms = list(nltk.trigrams(fp_text))

trigrams_text = list(itertools.chain(*trigrams_text_terms))

# Create counter of words in trigrams

# trigrams_text_counts = collections.Counter(trigrams_text)

trigrams_text_counts = pd.value_counts(trigrams_text, ascending=False, normalize=True)

trigrams_text_counts = trigrams_text_counts.sort_values(ascending=False)

trigrams_text_counts = trigrams_text_counts.astype(str, errors='ignore').apply(lambda x: x.split(' '))

print('---')
print('trigrams_text_counts DF SEPERATED ')
print(trigrams_text_counts.head)
print('---')

# trigram_text_df = pd.DataFrame(trigrams_text_counts, columns=['trigrams_text', 'trigrams_counts'])

trigram_text_df = pd.DataFrame([str(trigrams_text_counts)])

trigram_text_df.to_csv('4_5A_200_SMI1_trigram_text_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# trigram_text_df.to_excel('4_5A_200_SMI1_trigram_text_df_DF.xlsx', header=True)

########################################################################################################
########################################################################################################
########################################################################################################

def ngrams_wrapper(sent):
	yield list(nltk.ngrams(sent, 2))

raw_text = fp_text_c

sentences_text = nltk.sent_tokenize(raw_text)

tokenized_text = map(nltk.tokenize, sentences_text)

print('---')
print('Tokenized text')
# print(tokenized_text)
print('---')

bigrams_text = []
for sentence_text in sentences_text:
	sequence_text = word_tokenize(sentence_text)
	bigrams_text.extend(list(ngrams(sequence_text, 2)))

freq_dist_text = nltk.FreqDist(bigrams_text)
prob_dist_text = nltk.MLEProbDist(freq_dist_text)
number_of_bigrams_text = freq_dist_text.N()

print('---')
print('freq_dist text')
# print(freq_dist_text)
print('---')

print('---')
print('prob_dist text')
# print(prob_dist_text)
print('---')

print('---')
print('number_of_bigrams text')
print(number_of_bigrams_text)
print('---')

freq_dist_text_df = pd.DataFrame([freq_dist_text], columns=['freq_dist_text'])

freq_dist_text_df.to_csv('4_5A_201_SMI1_Freq_Dist_Text_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# freq_dist_text_df.to_excel('4_5A_201_SMI1_Freq_Dist_Text_DF.xlsx', index=True, header=True)

prob_dist_text_df = pd.DataFrame([prob_dist_text])

prob_dist_text_df.to_csv('4_5A_201_SMI1_Prob_Dist_Text_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# prob_dist_text_DF.to_excel('4_5A_201_SMI1_Prob_Dist_Text_DF.xlsx', index=True, header=True)

number_of_bigrams_text_df = pd.DataFrame([number_of_bigrams_text], columns=['number_of_bigrams_text'])

number_of_bigrams_text_df.to_csv('4_5A_201_SMI1_Number_of_Bigrams_Text_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# number_of_bigrams_text_df.to_excel('4_5A_201_SMI1_Number_of_Bigrams_Text_DF.xlsx', index=True, header=True)

#############################################################################################################

value_counts_bigram_text = pd.value_counts(bigrams_text, ascending=False, normalize=True)

# .rename_axis('value_counts_bigrams_text_items').reset_index(name='value_counts_bigrams_text_counts')


value_counts_bigram_text = pd.DataFrame(value_counts_bigram_text)

# value_counts_bigram_text = value_counts_bigram_text.astype(str, errors='ignore')

value_counts_bigram_text = value_counts_bigram_text['value_counts_bigrams_text_counts'].sort_values(ascending=False)

value_counts_bigram_text = value_counts_bigram_text.apply(lambda x: x.str.split(';').astype(str, errors='ignore'))

value_counts_bigram_text = value_counts_bigram_text.rename(columns={0:'value_counts_bigrams_text_items', 1:'value_counts_bigrams_text_counts'})

value_counts_bigram_text.to_csv('4_5A_201_SMI1_Value_Counts_Bigram_Text_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# value_counts_bigram_text.to_excel('4_5A_201_SMI1_Value_Counts_Bigram_Text.xlsx', index=True, header=True)

print('---')
print('value_counts_bigram_text HEAD')
print(value_counts_bigram_text.head)
print('---')

print('---')
print('value_counts_bigram_text dtypes')
print(value_counts_bigram_text.dtypes)
print('---')

# value_counts_bigram_text['value_counts_bigrams_text_items'] = value_counts_bigram_text['value_counts_bigrams_text_items'].astype(str, errors='ignore')

#####

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Text Value Counts')
value_counts_bigram_text[:10].plot(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_bigram_value_counts_bigram_text_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Text Value Counts - Pie')
value_counts_bigram_text[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
# plt.legend(value_counts_bigram_text, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.) 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Value_Counts_Bigram_Text_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Text Value Counts - Bars')
value_counts_bigram_text[:10].plot.bar(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Value_Counts_Bigram_Text_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# value_counts_bigrams_text_items value_counts_bigrams_text_counts

# TREEMAPS 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Text Bigrams - Treemap')
squarify.plot(sizes=value_counts_bigram_text.value_counts_bigrams_text_items, label=value_counts_bigram_text.value_counts_bigrams_text_counts, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Text_Bigrams_Treemap.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#############################################################################################################

# tidytextmining.com/ngrams.html

# USING BIGRAMS TO GIVE CONTEXT TO SENTIMENT ANALYSIS / NEED TO CHANGE THIS ONE IF R NOT PYTHON!!!!

# bigrams_separated %>%
#	filter(word == 'not') %>%
#	count(word1, word2, sort=True)

# AFINN <- get_sentiments('afinn')

# not_words <- bigrams_seperated %>%
#	filter(word1 == 'not') %.%
# 	inner_join(AFINN, by = c(word2 = 'word')) %>%
#	count(word2, value, sort=True)

#############################################################################################################
####################################################################################
#############################################################################################
###############################################################################################
#################################################################################################
########################################################################################################

# developer.ibm.com/technologies/artificial-intelligence/articles/cc-patterns-artificial-intelligence-part2

######################################################################################################################
############################################################################################################

# WORD FREQUENCY HASHTAGS



# HASHTAGS BIGRAMS

fp_hashtags_temp = tweets_smi_1['hashtags']
fp_hashtags = fp_hashtags_temp.to_string()
fp_hashtags_c = fp_hashtags ### OJO QIE ESTA SIN ARREGLAR EL C

print('---')
print('DataFrame Types fp_hashtags')
# print(fp_hashtags.dtypes)
print('---')


# data_f = fp_hashtags.read() # As bytes

# f_hashtags = fp_hashtags

# f_hashtags = data_f.decode('utf-8') # Unicode not bytes

print('---')
# print(f_hashtags)
print('---')

# fp_hashtags = f_hashtags

print('---')
print('Tweets hashtags First 10')
print(tweets_smi_1['hashtags'].head(10))
print('---')

#######################################################################################

# CORRECT SPELLING

# tweets_smi_1

# tweets_smi_1.parse() #Parse the article
# ('punkt')   #1 total_favorites download of the sentence tokenizer
# tweets_smi_1.nlp() # Keyword extraction wrapper

textblob_obj_hashtags_c = TextBlob(fp_hashtags) ## OJO QUE SI ES EL CORREGIDO O NO

#########   textblob_obj_hashtags_c = textblob_obj_hashtags.correct() ## NEED TO CHECK HOW IT WORKS!!!!
# textblob_obj_hashtags_c = textblob_obj_hashtags

textblob_obj_hashtags_c_df = pd.DataFrame(textblob_obj_hashtags_c)

print('--')
print('textblob_obj_hashtags_C_DF TYPE:')
# print(textblob_obj_hashtags_c)
print('--')

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

textblob_obj_hashtags_c_df.to_csv('4_5A_184_SMI1_Hashtags_Obj_C_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# textblob_obj_hashtags_c_df.to_excel('4_5A_184_SMI1_Hashtags_Obj_C_DF.xlsx', header=True)

# fp_hashtags_c = textblob_obj_hashtags_c.to_string()

# fp_hashtags_c = textblob_obj_hashtags_c

#######################################################################################

# tweets_hashtags_words = nltk.word_tokenize(pd.to_string(fp_hashtags_c))
# tweets_hashtags_words = nltk.word_tokenize(fp_hashtags_c['tweet_hashtags_fp_hashtags_c'])
tweets_hashtags_words = nltk.word_tokenize(fp_hashtags_c)
tweets_hashtags_words_df = pd.DataFrame(tweets_hashtags_words)

# tweets_hashtags_words = nltk.word_tokenize((tweets_smi_1['hashtags']).pd.to_string())
# tweets_hashtags_words = tweets_smi_1['hashtags']).nltk.word_tokenize()

print('--')
print('Tokenized hashtags_words')
print(tweets_hashtags_words_df.head(10))
print('--')

print('--')
print('Tokenized hashtags_words Shape')
print(tweets_hashtags_words_df.shape)
print('--')

print('--')
print('Tokenized hashtags_words Info')
print(tweets_hashtags_words_df.info)
print('--')

# Remove single-character tokens (mostly punctuation) ######## NEED TO DO FIX 
# tweets_hashtags_words = [word for word in tweets_hashtags_words if len(word) > 1]

# Remove numbers ######## NEED TO DO FIX
# tweets_hashtags_words = [word for word in tweets_hashtags_words if not word.isnumeric()]

# Lowercase all tweets_words (default_stoptweets_words are lowercase too) ######## NEED TO DO FIX
# tweets_hashtags_words = [word.lower() for word in tweets_hashtags_words]

# Stemming tweets_words seems to make matters worse, disabled
# stemmer = nltk.stem.snowball.SnowballStemmer('english')
# tweets_hashtags_words = [stemmer.stem(word) for word in tweets_hashtags_words]

# Remove stoptweets_words          ################################################################
# tweets_hashtags_words = [word for word in tweets_hashtags_words if word not in stoptweets_words]

# print('removed stoptweets_words')

##################################################################################################################

# FINDING N-GRAMS

# N-Grams refer to n combination of words in a sentence. For instance, for a sentence "I love watching football", some 2-grams would 
# be (I love), (love watching) and (watching football). N-Grams can play a cricual role in Text classification. 

for ngram_hashtags in textblob_obj_hashtags_c.ngrams(2):
#	print('-------------------------')
	print('N-Grams hashtags: 2')
#	print(ngram_hashtags)
#	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_hashtags = pd.DataFrame(ngram_hashtags, columns=['ngran_hashtags'])

ngram_hashtags.to_csv('4_5A_200_SMI1_ngram_hashtags_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
ngram_hashtags.to_csv('4_5A_200_SMI1_ngram_hashtags_TEXT.txt', sep=';', encoding='utf-8', index=False, header=True)


########################################################################################################

def ngrams_wrapper(sent):
	yield list(nltk.ngrams(sent, 2))

raw_hashtags = fp_hashtags_c

sentences_hashtags = nltk.sent_tokenize(raw_hashtags)

tokenized_hashtags = map(nltk.tokenize, sentences_hashtags)

# print('---')
print('Tokenized hashtags')
# print(tokenized_hashtags)
print('---')

bigrams_hashtags = []
for sentence_hashtags in sentences_hashtags:
	sequence_hashtags = word_tokenize(sentence_hashtags)
	bigrams_hashtags.extend(list(ngrams(sequence_hashtags, 2)))

freq_dist_hashtags = nltk.FreqDist(bigrams_hashtags)
prob_dist_hashtags = nltk.MLEProbDist(freq_dist_hashtags)
number_of_bigrams_hashtags = freq_dist_hashtags.N()

# print('---')
print('freq_dist hashtags')
# print(freq_dist_hashtags)
print('---')

# print('---')
print('prob_dist hashtags')
# print(prob_dist_hashtags)
print('---')

# print('---')
print('number_of_bigrams hashtags')
print(number_of_bigrams_hashtags)
print('---')

# tokenized_hashtags_df = pd.DataFrame([tokenized_hashtags])

# tokenized_hashtags_df.to_csv('4_5A_201_SMI1_Tokenized_Hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# tokenized_hashtags_df.to_excel('4_5A_201_SMI1_Tokenized_Hashtags_DF.xlsx', index=True, header=True)

freq_dist_hashtags_df = pd.DataFrame([freq_dist_hashtags], columns=['freq_dist_hashtags'])

freq_dist_hashtags_df.to_csv('4_5A_201_SMI1_Freq_Dist_Hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# freq_dist_hashtags_df.to_excel('4_5A_201_SMI1_Freq_Dist_Hashtags_DF.xlsx', index=True, header=True)

prob_dist_hashtags_df = pd.DataFrame([prob_dist_hashtags])

prob_dist_hashtags_df.to_csv('4_5A_201_SMI1_Prob_Dist_Hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# prob_dist_hashtags_DF.to_excel('4_5A_201_SMI1_Prob_Dist_Hashtags_DF.xlsx', index=True, header=True)

number_of_bigrams_hashtags_df = pd.DataFrame([number_of_bigrams_hashtags], columns=['number_of_bigrams_hashtags'])

number_of_bigrams_hashtags_df.to_csv('4_5A_201_SMI1_Number_of_Bigrams_Hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# number_of_bigrams_hashtags_df.to_excel('4_5A_201_SMI1_Number_of_Bigrams_Hashtags_DF.xlsx', index=True, header=True)

#############################################################################################################

value_counts_bigram_hashtags = pd.value_counts(bigrams_hashtags, ascending=False, normalize=True) 

value_counts_bigram_hashtags = value_counts_bigram_hashtags.sort_values(ascending=False)

value_counts_bigram_hashtags_df = pd.DataFrame(value_counts_bigram_hashtags, columns=['value_counts_bigrams_hashtags'])

value_counts_bigram_hashtags_df.to_csv('4_5A_201_SMI1_Value_Counts_Bigram_Hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# value_counts_bigram_hashtags_df.to_excel('4_5A_201_SMI1_Value_Counts_Bigram_Hashtags_DF.xlsx', index=True, header=True)

# print('---')
print('value_counts_bigram_hashtags_df info')
print(value_counts_bigram_hashtags_df.info)
print('---')

# print('---')
print('value_counts_bigram_hashtags_df shape')
print(value_counts_bigram_hashtags_df.shape)
print('---')

# CREATE SEPERATE BIGRAMS DATAFRAMES 

# value_counts_bigram_hashtags_df = value_counts_bigram_hashtags_df.astype(str, errors='ignore')

# seperate_value_counts_bigram_hashtags = [value_counts_bigram_hashtags_df[:0], value_counts_bigram_hashtags_df[:1]]

# value_counts_bigram_hashtags_df = value_counts_bigram_hashtags_df['value_counts_bigrams'].apply(list)

# seperate_value_counts_bigram_hashtags_df = pd.DataFrame.from_items(value_counts_bigram_hashtags, columns=['items_counts_bigrams', 'number_counts_bigrams'])
# seperate_value_counts_bigram_hashtags_df[['value_bigrams_hashtags', 'value_counts_bigrams_hashtags']] = pd.DataFrame(value_counts_bigram_hashtags_df['value_counts_bigrams'].tolist(),index=value_counts_bigram_hashtags_df)
# seperate_value_counts_bigram_hashtags_df = seperate_value_counts_bigram_hashtags_df.join(value_counts_bigram_hashtags_df_temp)
# seperate_value_counts_bigram_hashtags_df.to_csv('4_5A_201_SMI1_seperate_value_counts_bigram_hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# seperate_value_counts_bigram_hashtags_df.to_excel('4_5A_201_SMI1_seperate_value_counts_bigram_hashtags_DF.xlsx', index=True, header=True)

# print('---')
print('seperate_value_counts_bigram_hashtags_df head')
# print(seperate_value_counts_bigram_hashtags_df.head)
print('---')

# print('---')
print('value_counts_bigram_hashtags_df info')
print(value_counts_bigram_hashtags_df.info)
print('---')

# print('---')
print('value_counts_bigram_hashtags_df shape')
print(value_counts_bigram_hashtags_df.shape)
print('---')

#####

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Hashtags Value Counts')
plt.ioff()
value_counts_bigram_hashtags_df[:10].plot(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Bigram_Value_Counts_Bigram_Hashtags_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Hashtags Value Counts - Pie')
plt.ioff()
value_counts_bigram_hashtags_df[:7].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.7, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['hashtags'], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Value_Counts_Bigram_Hashtags_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Hashtags Value Counts - Bars')
plt.ioff()
value_counts_bigram_hashtags_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Value_Counts_Bigram_Hashtags_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del value_counts_bigram_hashtags
del value_counts_bigram_hashtags_del

############################################################################################################

# WORD FREQUENCY DISTRIBUTION IN Mentions OF Tweets


print('---')
print('WORD FREQUENCY DISTRIBUTION IN mentions OF Tweets 2')
print('---')

# BIGRAMS MENTIONS

# fp_mentions_2 = tweets_smi_1['mentions'].astype(str, errors='ignore')
# fp_mentions_2['tweet_mentions_fp_mentions'] = pd.DataFrame(tweets_smi_1['mentions'].astype(str, errors='ignore'))
# fp_mentions_2 = tweets_smi_1.mentions.astype(str, errors='ignore')

fp_mentions_temp_2 = tweets_smi_1['mentions']
fp_mentions_2 = fp_mentions_temp_2.to_string()

# fp_mentions_c_2 = fp_mentions_2 ### OJO QIE ESTA SIN ARREGLAR EL C

# print('---')
print('DataFrame Types fp_mentions_2 NEED TO FIX NEED TO DO')
# print(fp_mentions_2.dtypes)
print('---')

# f_mentions_2 = fp_mentions_2

# f_mentions_2 = data_f.decode('utf-8') # Unicode not bytes

# print('---')
# print(f_mentions_2)
print('---')

# fp_mentions_2 = f_mentions_2

# print('---')
print('Tweets mentions First 10 fp_mentions_2')
# print(fp_mentions_2['tweet_mentions_fp_mentions'].head(10))
print('---')

#######################################################################################

# CORRECT SPELLING

# tweets_smi_1

# tweets_smi_1.parse() #Parse the article
# ('punkt')   #1 total_favorites download of the sentence tokenizer
# tweets_smi_1.nlp() # Keyword extraction wrapper

textblob_obj_mentions_c = TextBlob(fp_mentions) ## OJO QUE SI ES EL CORREGIDO O NO

#########   textblob_obj_mentions_c = textblob_obj_mentions.correct() ## NEED TO CHECK HOW IT WORKS!!!!
# textblob_obj_mentions_c = textblob_obj_mentions

textblob_obj_mentions_c_df = pd.DataFrame(textblob_obj_mentions_c)

# print('--')
print('textblob_obj_mentions_C_DF TYPE:')
# print(textblob_obj_mentions_c)
print('--')

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

textblob_obj_mentions_c_df.to_csv('4_5A_184_SMI1_mentions_Obj_C_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# textblob_obj_mentions_c_df.to_excel('4_5A_184_SMI1_mentions_Obj_C_DF.xlsx', header=True)

# fp_mentions_c = textblob_obj_mentions_c.to_string()

# fp_mentions_c = textblob_obj_mentions_c

#######################################################################################

# tweets_mentions_words = nltk.word_tokenize(pd.to_string(fp_mentions_c))
# tweets_mentions_words = nltk.word_tokenize(fp_mentions_c['tweet_mentions_fp_mentions_c'])
tweets_mentions_words = nltk.word_tokenize(fp_mentions_c)
tweets_mentions_words_df = pd.DataFrame(tweets_mentions_words)

# tweets_mentions_words = nltk.word_tokenize((tweets_smi_1['mentions']).pd.to_string())
# tweets_mentions_words = tweets_smi_1['mentions']).nltk.word_tokenize()

# print('--')
print('Tokenized mentions_words')
print(tweets_mentions_words_df.head(10))
print('--')

# print('--')
print('Tokenized mentions_words Shape')
print(tweets_mentions_words_df.shape)
print('--')

# print('--')
print('Tokenized mentions_words Info')
print(tweets_mentions_words_df.info)
print('--')

# Remove single-character tokens (mostly punctuation) ######## NEED TO DO FIX 
# tweets_mentions_words = [word for word in tweets_mentions_words if len(word) > 1]

# Remove numbers ######## NEED TO DO FIX
# tweets_mentions_words = [word for word in tweets_mentions_words if not word.isnumeric()]

# Lowercase all tweets_words (default_stoptweets_words are lowercase too) ######## NEED TO DO FIX
# tweets_mentions_words = [word.lower() for word in tweets_mentions_words]

# Stemming tweets_words seems to make matters worse, disabled
# stemmer = nltk.stem.snowball.SnowballStemmer('english')
# tweets_mentions_words = [stemmer.stem(word) for word in tweets_mentions_words]

# Remove stoptweets_words          ################################################################
# tweets_mentions_words = [word for word in tweets_mentions_words if word not in stoptweets_words]

# print('removed stoptweets_words')

##################################################################################################################

# FINDING N-GRAMS

# N-Grams refer to n combination of words in a sentence. For instance, for a sentence "I love watching football", some 2-grams would 
# be (I love), (love watching) and (watching football). N-Grams can play a cricual role in Text classification. 

for ngram_mentions in textblob_obj_mentions_c.ngrams(2):
#	print('-------------------------')
	print('N-Grams mentions: 2')
#	print(ngram_mentions)
#	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_mentions = pd.DataFrame(ngram_mentions, columns=['ngran_mentions'])

ngram_mentions.to_csv('4_5A_200_SMI1_ngram_mentions_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
ngram_mentions.to_csv('4_5A_200_SMI1_ngram_mentions_TEXT.txt', sep=';', encoding='utf-8', index=False, header=True)


########################################################################################################

def ngrams_wrapper(sent):
	yield list(nltk.ngrams(sent, 2))

raw_mentions = fp_mentions_c

sentences_mentions = nltk.sent_tokenize(raw_mentions)

tokenized_mentions = map(nltk.tokenize, sentences_mentions)

# print('---')
print('Tokenized mentions')
# print(tokenized_mentions)
print('---')

bigrams_mentions = []
for sentence_mentions in sentences_mentions:
	sequence_mentions = word_tokenize(sentence_mentions)
	bigrams_mentions.extend(list(ngrams(sequence_mentions, 2)))

freq_dist_mentions = nltk.FreqDist(bigrams_mentions)
prob_dist_mentions = nltk.MLEProbDist(freq_dist_mentions)
number_of_bigrams_mentions = freq_dist_mentions.N()

# print('---')
print('freq_dist mentions')
# print(freq_dist_mentions)
print('---')

# print('---')
print('prob_dist mentions')
# print(prob_dist_mentions)
print('---')

print('---')
print('number_of_bigrams mentions')
print(number_of_bigrams_mentions)
print('---')

# tokenized_mentions_df = pd.DataFrame([tokenized_mentions])

# tokenized_mentions_df.to_csv('4_5A_201_SMI1_tokenized_mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# tokenized_mentions_df.to_excel('4_5A_201_SMI1_tokenized_mentions_DF.xlsx', index=True, header=True)

freq_dist_mentions_df = pd.DataFrame([freq_dist_mentions], columns=['freq_dist_mentions'])

freq_dist_mentions_df.to_csv('4_5A_201_SMI1_freq_dist_mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# freq_dist_mentions_df.to_excel('4_5A_201_SMI1_freq_dist_mentions_DF.xlsx', index=True, header=True)

prob_dist_mentions_df = pd.DataFrame([prob_dist_mentions])

prob_dist_mentions_df.to_csv('4_5A_201_SMI1_prob_dist_mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# prob_dist_mentions_DF.to_excel('4_5A_201_SMI1_prob_dist_mentions_DF.xlsx', index=True, header=True)

number_of_bigrams_mentions_df = pd.DataFrame([number_of_bigrams_mentions], columns=['number_of_bigrams_mentions'])

number_of_bigrams_mentions_df.to_csv('4_5A_201_SMI1_number_of_bigrams_mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# number_of_bigrams_mentions_df.to_excel('4_5A_201_SMI1_number_of_bigrams_mentions_DF.xlsx', index=True, header=True)

#############################################################################################################

# value_counts_bigram_mentions = pd.value_counts(bigrams_mentions, bins=2, ascending=False, normalize=True).reset_index().rename(columns={0:'bigrams_mentions_text','bigrams_mentions':'bigrams_mentions_count'})

value_counts_bigram_mentions = pd.value_counts(bigrams_mentions, ascending=False, normalize=True)

value_counts_bigram_mentions = value_counts_bigram_mentions.sort_values(ascending=False)

value_counts_bigram_mentions_df[['bigrams_mentions_text','bigrams_mentions_count']] = pd.DataFrame(value_counts_bigram_mentions)

print('value_counts_bigram_mentions_df DTYPES')
print(value_counts_bigram_mentions_df.dtypes)
print('---')

print('value_counts_bigram_mentions_df info')
print(value_counts_bigram_mentions_df.info)
print('---')

print('value_counts_bigram_mentions_df shape')
print(value_counts_bigram_mentions_df.shape)
print('---')

# value_counts_bigram_mentions_df = value_counts_bigram_mentions_df.str.split(';')

# value_counts_bigram_mentions_df = value_counts_bigram_mentions_df.rename(columns={0:'bigrams_mentions_text','bigrams_mentions':'bigrams_mentions_count'})

value_counts_bigram_mentions_df['bigrams_mentions_count'] = value_counts_bigram_mentions_df['bigrams_mentions_count'].astype(np.int32, errors='ignore')
# value_counts_bigram_mentions_df['bigrams_mentions_text'] = value_counts_bigram_mentions_df['bigrams_mentions_text'].astype(str, errors='ignore')

value_counts_bigram_mentions_df['bigrams_mentions_text'] = value_counts_bigram_mentions_df['bigrams_mentions_text'].replace('\(', '')
value_counts_bigram_mentions_df['bigrams_mentions_text'] = value_counts_bigram_mentions_df['bigrams_mentions_text'].replace('\)', '')

# value_counts_bigram_mentions_df['bigrams_mentions_count'] = value_counts_bigram_mentions_df['bigrams_mentions_count'].astype(np.int32, errors='ignore')

value_counts_bigram_mentions_df.to_csv('4_5A_201_SMI1_value_counts_bigram_mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# value_counts_bigram_mentions_df.to_excel('4_5A_201_SMI1_value_counts_bigram_mentions_DF.xlsx', index=True, header=True)

print('value_counts_bigram_mentions_df DTYPES 2')
print(value_counts_bigram_mentions_df.dtypes)
print('---')

print('value_counts_bigram_mentions_df info')
print(value_counts_bigram_mentions_df.info)
print('---')

print('value_counts_bigram_mentions_df shape')
print(value_counts_bigram_mentions_df.shape)
print('---')

# CREATE SEPERATE BIGRAMS DATAFRAMES 

# value_counts_bigram_mentions_df = value_counts_bigram_mentions_df.astype(str, errors='ignore')

# seperate_value_counts_bigram_mentions = [value_counts_bigram_mentions_df[:0], value_counts_bigram_mentions_df[:1]]

# value_counts_bigram_mentions_df = value_counts_bigram_mentions_df['value_counts_bigrams'].apply(list)

# seperate_value_counts_bigram_mentions_df = pd.DataFrame.from_items(value_counts_bigram_mentions, columns=['items_counts_bigrams', 'number_counts_bigrams'])
# seperate_value_counts_bigram_mentions_df[['value_bigrams_mentions', 'value_counts_bigrams_mentions']] = pd.DataFrame(value_counts_bigram_mentions_df['value_counts_bigrams'].tolist(),index=value_counts_bigram_mentions_df)
# seperate_value_counts_bigram_mentions_df = seperate_value_counts_bigram_mentions_df.join(value_counts_bigram_mentions_df_temp)
# seperate_value_counts_bigram_mentions_df.to_csv('4_5A_201_SMI1_seperate_value_counts_bigram_mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# seperate_value_counts_bigram_mentions_df.to_excel('4_5A_201_SMI1_seperate_value_counts_bigram_mentions_DF.xlsx', index=True, header=True)

# print('---')
print('seperate_value_counts_bigram_mentions_df head')
# print(seperate_value_counts_bigram_mentions_df.head)
print('---')

# print('---')
print('value_counts_bigram_mentions_df info')
print(value_counts_bigram_mentions_df.info)
print('---')

# print('---')
print('value_counts_bigram_mentions_df shape')
print(value_counts_bigram_mentions_df.shape)
print('---')

#####

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Mentions Value Counts')
plt.ioff()
value_counts_bigram_mentions[:10].plot(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Bigram_Value_Counts_Bigram_Mentions_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Mentions Value Counts - Pie')
plt.ioff()
value_counts_bigram_mentions[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.7, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['mentions'], bbox_to_anchor=(1.9, 0.4), loc=1, borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Value_Counts_Bigram_Mentions_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Mentions Value Counts - Bars')
plt.ioff()
value_counts_bigram_mentions[:10].plot.bar(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Value_Counts_Bigram_Mentions_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# TREEMAPS 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Bigrams - Treemap')
plt.ioff()
squarify.plot(sizes=value_counts_bigram_mentions_df['bigrams_mentions_count'], label=value_counts_bigram_mentions_df['bigrams_mentions_text'], alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Bigrams_Treemap_Mentions.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLES

del value_counts_bigram_mentions
del value_counts_bigram_mentions_df

############################################################################################################

# WORD FREQUENCY DISTRIBUTION IN emojis_unicode OF Tweets



# BIGRAMS emojis_unicode

# fp_emojis_unicode = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore')
# fp_emojis_unicode['tweet_emojis_unicode_fp_emojis_unicode'] = pd.DataFrame(tweets_smi_1['emojis_unicode'].astype(str, errors='ignore'))
# fp_emojis_unicode = tweets_smi_1.emojis_unicode.astype(str, errors='ignore')

fp_emojis_unicode_temp = tweets_smi_1['emojis_unicode']
fp_emojis_unicode = fp_emojis_unicode_temp.to_string()
fp_emojis_unicode_c = fp_emojis_unicode ### OJO QIE ESTA SIN ARREGLAR EL C

# print('---')
print('DataFrame Types fp_emojis_unicode')
# print(fp_emojis_unicode.dtypes)
print('---')

# fp_emojis_unicode = pd.DataFrame(tweets_smi_1['emojis_unicode'].astype('str'))
# fp_emojis_unicode = pd.DataFrame(StringIO(tweets_smi_1['emojis_unicode']))

# input_file = sys.argv[1]

# fp_emojis_unicode = pd.DataFrame(tweets_smi_1['emojis_unicode'].astype('str'))
# fp_emojis_unicode = StringIO(tweets_smi_1['emojis_unicode'])

# fp_emojis_unicode = pd.read_csv(StringIO(smi_file_4_4_emojis_unicode_only, 'r', 'utf-8', memory_map=True))
# fp_emojis_unicode = pd.read_csv(smi_file_4_4_emojis_unicode_only, sep=';', encoding='utf-8', parse_dates=True, header=0, low_memory=False)# 
# fp_emojis_unicode = codecs.open(smi_file_4_4_emojis_unicode_only, 'r', 'utf-8')
# fp_emojis_unicode = pd.DataFrame(tweets_smi_1['emojis_unicode'].astype('str'))
# fp_emojis_unicode = np.to_string(fp_emojis_unicode)

# fp_emojis_unicode = pd.DataFrame(fp_emojis_unicode)

# fp_emojis_unicode = open(smi_file_4_4_emojis_unicode_only, encoding='utf-8')
# f_emojis_unicode = fp_emojis_unicode.read() # As bytes

# data_f = fp_emojis_unicode.read() # As bytes

# f_emojis_unicode = fp_emojis_unicode

# f_emojis_unicode = data_f.decode('utf-8') # Unicode not bytes

print('---')
# print(f_emojis_unicode)
print('---')

# fp_emojis_unicode = f_emojis_unicode

print('---')
print('Tweets emojis_unicode First 10')
print(tweets_smi_1['emojis_unicode'].head(10))
print('---')

#######################################################################################

# CORRECT SPELLING

# tweets_smi_1

# tweets_smi_1.parse() #Parse the article
# ('punkt')   #1 total_favorites download of the sentence tokenizer
# tweets_smi_1.nlp() # Keyword extraction wrapper

textblob_obj_emojis_unicode_c = TextBlob(fp_emojis_unicode) ## OJO QUE SI ES EL CORREGIDO O NO

#########   textblob_obj_emojis_unicode_c = textblob_obj_emojis_unicode.correct() ## NEED TO CHECK HOW IT WORKS!!!!
# textblob_obj_emojis_unicode_c = textblob_obj_emojis_unicode

textblob_obj_emojis_unicode_c_df = pd.DataFrame(textblob_obj_emojis_unicode_c)

print('--')
print('textblob_obj_emojis_unicode_C_DF TYPE:')
# print(textblob_obj_emojis_unicode_c)
print('--')

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

textblob_obj_emojis_unicode_c_df.to_csv('4_5A_184_SMI1_emojis_unicode_Obj_C_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# textblob_obj_emojis_unicode_c_df.to_excel('4_5A_184_SMI1_emojis_unicode_Obj_C_DF.xlsx', header=True)

# fp_emojis_unicode_c = textblob_obj_emojis_unicode_c.to_string()

# fp_emojis_unicode_c = textblob_obj_emojis_unicode_c

#######################################################################################

# tweets_emojis_unicode_words = nltk.word_tokenize(pd.to_string(fp_emojis_unicode_c))
# tweets_emojis_unicode_words = nltk.word_tokenize(fp_emojis_unicode_c['tweet_emojis_unicode_fp_emojis_unicode_c'])
tweets_emojis_unicode_words = nltk.word_tokenize(fp_emojis_unicode_c)
tweets_emojis_unicode_words_df = pd.DataFrame(tweets_emojis_unicode_words)

# tweets_emojis_unicode_words = nltk.word_tokenize((tweets_smi_1['emojis_unicode']).pd.to_string())
# tweets_emojis_unicode_words = tweets_smi_1['emojis_unicode']).nltk.word_tokenize()

print('--')
print('Tokenized emojis_unicode_words')
print(tweets_emojis_unicode_words_df.head(10))
print('--')

print('--')
print('Tokenized emojis_unicode_words Shape')
print(tweets_emojis_unicode_words_df.shape)
print('--')

print('--')
print('Tokenized emojis_unicode_words Info')
print(tweets_emojis_unicode_words_df.info)
print('--')

# Remove single-character tokens (mostly punctuation) ######## NEED TO DO FIX 
# tweets_emojis_unicode_words = [word for word in tweets_emojis_unicode_words if len(word) > 1]

# Remove numbers ######## NEED TO DO FIX
# tweets_emojis_unicode_words = [word for word in tweets_emojis_unicode_words if not word.isnumeric()]

# Lowercase all tweets_words (default_stoptweets_words are lowercase too) ######## NEED TO DO FIX
# tweets_emojis_unicode_words = [word.lower() for word in tweets_emojis_unicode_words]

# Stemming tweets_words seems to make matters worse, disabled
# stemmer = nltk.stem.snowball.SnowballStemmer('english')
# tweets_emojis_unicode_words = [stemmer.stem(word) for word in tweets_emojis_unicode_words]

# Remove stoptweets_words          ################################################################
# tweets_emojis_unicode_words = [word for word in tweets_emojis_unicode_words if word not in stoptweets_words]

# print('removed stoptweets_words')

## DELETE VARIABLE

del textblob_obj_emojis_unicode_c
del textblob_obj_emojis_unicode_c_df
del fp_emojis_unicode_c
del tweets_emojis_unicode_words
del tweets_emojis_unicode_words_df

##################################################################################################################

# FINDING N-GRAMS

# N-Grams refer to n combination of words in a sentence. For instance, for a sentence "I love watching football", some 2-grams would 
# be (I love), (love watching) and (watching football). N-Grams can play a cricual role in Text classification. 

for ngram_emojis_unicode in textblob_obj_emojis_unicode_c.ngrams(2):
#	print('-------------------------')
	print('N-Grams emojis_unicode: 2')
#	print(ngram_emojis_unicode)
#	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_emojis_unicode_df = pd.DataFrame(ngram_emojis_unicode, columns=['ngran_emojis_unicode'])

ngram_emojis_unicode_df.to_csv('4_5A_200_SMI1_Ngram_Emojis_Unicode_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# ngram_emojis_unicode_df.to_csv('4_5A_200_SMI1_Ngram_Emojis_Unicode_TEXT.txt', sep=';', encoding='utf-8', index=False, header=True)


## DELETE VARIABLE

del fp_emojis_unicode_c
del ngram_emojis_unicode
del ngram_emojis_unicode_df

## XXX NEED TO DO GRAPHS

########################################################################################################

def ngrams_wrapper(sent):
	yield list(nltk.ngrams(sent, 2))

raw_emojis_unicode = fp_emojis_unicode_c

sentences_emojis_unicode = nltk.sent_tokenize(raw_emojis_unicode)

tokenized_emojis_unicode = map(nltk.tokenize, sentences_emojis_unicode)

print('---')
print('Tokenized emojis_unicode')
# print(tokenized_emojis_unicode)
print('---')

bigrams_emojis_unicode = []
for sentence_emojis_unicode in sentences_emojis_unicode:
	sequence_emojis_unicode = word_tokenize(sentence_emojis_unicode)
	bigrams_emojis_unicode.extend(list(ngrams(sequence_emojis_unicode, 2)))

freq_dist_emojis_unicode = nltk.FreqDist(bigrams_emojis_unicode)
prob_dist_emojis_unicode = nltk.MLEProbDist(freq_dist_emojis_unicode)
number_of_bigrams_emojis_unicode = freq_dist_emojis_unicode.N()

print('---')
print('freq_dist emojis_unicode')
# print(freq_dist_emojis_unicode)
print('---')

print('---')
print('prob_dist emojis_unicode')
# print(prob_dist_emojis_unicode)
print('---')

print('---')
print('number_of_bigrams emojis_unicode')
print(number_of_bigrams_emojis_unicode)
print('---')

# tokenized_emojis_unicode_df = pd.DataFrame([tokenized_emojis_unicode])

# tokenized_emojis_unicode_df.to_csv('4_5A_201_SMI1_Tokenized_Emojis_Unicode_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# tokenized_emojis_unicode_df.to_excel('4_5A_201_SMI1_Tokenized_Emojis_Unicode_DF.xlsx', index=True, header=True)

freq_dist_emojis_unicode_df = pd.DataFrame([freq_dist_emojis_unicode], columns=['freq_dist_emojis_unicode'])

freq_dist_emojis_unicode_df.to_csv('4_5A_201_SMI1_Freq_Dist_Emojis_Unicode_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# freq_dist_emojis_unicode_df.to_excel('4_5A_201_SMI1_Freq_Dist_Emojis_Unicode_DF.xlsx', index=True, header=True)

prob_dist_emojis_unicode_df = pd.DataFrame([prob_dist_emojis_unicode])

prob_dist_emojis_unicode_df.to_csv('4_5A_201_SMI1_prob_dist_emojis_unicode_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# prob_dist_emojis_unicode_DF.to_excel('4_5A_201_SMI1_prob_dist_emojis_unicode_DF.xlsx', index=True, header=True)

number_of_bigrams_emojis_unicode_df = pd.DataFrame([number_of_bigrams_emojis_unicode], columns=['number_of_bigrams_emojis_unicode'])

number_of_bigrams_emojis_unicode_df.to_csv('4_5A_201_SMI1_Number_of_Bigrams_Emojis_Unicode_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# number_of_bigrams_emojis_unicode_df.to_excel('4_5A_201_SMI1_Number_of_Bigrams_Emojis_Unicode_DF.xlsx', index=True, header=True)

## DELETE VARIABLE

del raw_emojis_unicode
del tokenized_emojis_unicode
del sentences_emojis_unicode
del number_of_bigrams_emojis_unicode
del number_of_bigrams_emojis_unicode_df

#############################################################################################################

value_counts_bigram_emojis_unicode = pd.value_counts(bigrams_emojis_unicode, ascending=False, normalize=True) 

value_counts_bigram_emojis_unicode = value_counts_bigram_emojis_unicode.sort_values(ascending=False)

value_counts_bigram_emojis_unicode_df = pd.DataFrame(value_counts_bigram_emojis_unicode, columns=['bigrams_emojis_unicode', 'value_counts_bigrams_emojis_unicode'])

value_counts_bigram_emojis_unicode_df.to_csv('4_5A_201_SMI1_value_counts_bigram_emojis_unicode_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# value_counts_bigram_emojis_unicode_df.to_excel('4_5A_201_SMI1_value_counts_bigram_emojis_unicode_DF.xlsx', index=True, header=True)

print('---')
print('value_counts_bigram_emojis_unicode_df info')
print(value_counts_bigram_emojis_unicode_df.info)
print('---')

print('---')
print('value_counts_bigram_emojis_unicode_df shape')
print(value_counts_bigram_emojis_unicode_df.shape)
print('---')

# CREATE SEPERATE BIGRAMS DATAFRAMES 

# value_counts_bigram_emojis_unicode_df = value_counts_bigram_emojis_unicode_df.astype(str, errors='ignore')

# seperate_value_counts_bigram_emojis_unicode = [value_counts_bigram_emojis_unicode_df[:0], value_counts_bigram_emojis_unicode_df[:1]]

# value_counts_bigram_emojis_unicode_df = value_counts_bigram_emojis_unicode_df['value_counts_bigrams'].apply(list)

# seperate_value_counts_bigram_emojis_unicode_df = pd.DataFrame.from_items(value_counts_bigram_emojis_unicode, columns=['items_counts_bigrams', 'number_counts_bigrams'])
# seperate_value_counts_bigram_emojis_unicode_df[['value_bigrams_emojis_unicode', 'value_counts_bigrams_emojis_unicode']] = pd.DataFrame(value_counts_bigram_emojis_unicode_df['value_counts_bigrams'].tolist(),index=value_counts_bigram_emojis_unicode_df)
# seperate_value_counts_bigram_emojis_unicode_df = seperate_value_counts_bigram_emojis_unicode_df.join(value_counts_bigram_emojis_unicode_df_temp)
# seperate_value_counts_bigram_emojis_unicode_df.to_csv('4_5A_201_SMI1_seperate_value_counts_bigram_emojis_unicode_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# seperate_value_counts_bigram_emojis_unicode_df.to_excel('4_5A_201_SMI1_seperate_value_counts_bigram_emojis_unicode_DF.xlsx', index=True, header=True)

print('---')
print('seperate_value_counts_bigram_emojis_unicode_df head')
# print(seperate_value_counts_bigram_emojis_unicode_df.head)
print('---')

print('---')
print('value_counts_bigram_emojis_unicode_df info')
print(value_counts_bigram_emojis_unicode_df.info)
print('---')

print('---')
print('value_counts_bigram_emojis_unicode_df shape')
print(value_counts_bigram_emojis_unicode_df.shape)
print('---')

#####

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Emojis Value Counts')
plt.ioff()
value_counts_bigram_emojis_unicode[:10].plot(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Bigram_Value_Counts_Bigram_Emojis_Unicode_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Emojis Value Counts - Pie')
plt.ioff()
value_counts_bigram_emojis_unicode[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['emojis_unicode'], bbox_to_anchor=(1.0, 1), loc=1, borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Value_Counts_Bigram_Emojis_Unicode_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Emojis Value Counts - Bars')
value_counts_bigram_emojis_unicode[:10].plot.bar(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Value_Counts_Bigram_Emojis_Unicode_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del bigrams_emojis_unicode
del value_counts_bigram_emojis_unicode
del value_counts_bigram_emojis_unicode_df

############################################################################################################

# WORD FREQUENCY DISTRIBUTION IN emojis_converted OF Tweets


# BIGRAMS emojis_converted


# fp_emojis_converted = tweets_smi_1['emojis_converted'].astype(str, errors='ignore')
# fp_emojis_converted['tweet_emojis_converted_fp_emojis_converted'] = pd.DataFrame(tweets_smi_1['emojis_converted'].astype(str, errors='ignore'))
# fp_emojis_converted = tweets_smi_1.emojis_converted.astype(str, errors='ignore')

fp_emojis_converted_temp = tweets_smi_1['emojis_converted']
fp_emojis_converted = fp_emojis_converted_temp.to_string()
fp_emojis_converted_c = fp_emojis_converted ### OJO QIE ESTA SIN ARREGLAR EL C

print('---')
print('DataFrame Types fp_emojis_converted')
# print(fp_emojis_converted.dtypes)
print('---')

# fp_emojis_converted = pd.DataFrame(tweets_smi_1['emojis_converted'].astype('str'))
# fp_emojis_converted = pd.DataFrame(StringIO(tweets_smi_1['emojis_converted']))

# input_file = sys.argv[1]

# fp_emojis_converted = pd.DataFrame(tweets_smi_1['emojis_converted'].astype('str'))
# fp_emojis_converted = StringIO(tweets_smi_1['emojis_converted'])

# fp_emojis_converted = pd.read_csv(StringIO(smi_file_4_4_emojis_converted_only, 'r', 'utf-8'))
# fp_emojis_converted = pd.read_csv(smi_file_4_4_emojis_converted_only, sep=';', encoding='utf-8', parse_dates=True, header=0, low_memory=False)# 
# fp_emojis_converted = codecs.open(smi_file_4_4_emojis_converted_only, 'r', 'utf-8')
# fp_emojis_converted = pd.DataFrame(tweets_smi_1['emojis_converted'].astype('str'))
# fp_emojis_converted = np.to_string(fp_emojis_converted)

# fp_emojis_converted = pd.DataFrame(fp_emojis_converted)

# fp_emojis_converted = open(smi_file_4_4_emojis_converted_only, encoding='utf-8')
# f_emojis_converted = fp_emojis_converted.read() # As bytes

# data_f = fp_emojis_converted.read() # As bytes

# f_emojis_converted = fp_emojis_converted

# f_emojis_converted = data_f.decode('utf-8') # Unicode not bytes

print('---')
# print(f_emojis_converted)
print('---')

# fp_emojis_converted = f_emojis_converted

print('---')
print('Tweets emojis_converted First 10')
print(tweets_smi_1['emojis_converted'].head(10))
print('---')

#######################################################################################

# CORRECT SPELLING

# tweets_smi_1

# tweets_smi_1.parse() #Parse the article
# ('punkt')   #1 total_favorites download of the sentence tokenizer
# tweets_smi_1.nlp() # Keyword extraction wrapper

textblob_obj_emojis_converted_c = TextBlob(fp_emojis_converted) ## OJO QUE SI ES EL CORREGIDO O NO

#########   textblob_obj_emojis_converted_c = textblob_obj_emojis_converted.correct() ## NEED TO CHECK HOW IT WORKS!!!!
# textblob_obj_emojis_converted_c = textblob_obj_emojis_converted

textblob_obj_emojis_converted_c_df = pd.DataFrame(textblob_obj_emojis_converted_c)

print('--')
print('textblob_obj_emojis_converted_C_DF TYPE:')
# print(textblob_obj_emojis_converted_c)
print('--')

# SAVING DESCRIBE DIRECTLY NOT THE DF!!!! NEED TO DO

textblob_obj_emojis_converted_c_df.to_csv('4_5A_184_SMI1_Emojis_Converted_Obj_C_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# textblob_obj_emojis_converted_c_df.to_excel('4_5A_184_SMI1_Emojis_Converted_Obj_C_DF.xlsx', header=True)

# fp_emojis_converted_c = textblob_obj_emojis_converted_c.to_string()

# fp_emojis_converted_c = textblob_obj_emojis_converted_c

#######################################################################################

# tweets_emojis_converted_words = nltk.word_tokenize(pd.to_string(fp_emojis_converted_c))
# tweets_emojis_converted_words = nltk.word_tokenize(fp_emojis_converted_c['tweet_emojis_converted_fp_emojis_converted_c'])
tweets_emojis_converted_words = nltk.word_tokenize(fp_emojis_converted_c)
tweets_emojis_converted_words_df = pd.DataFrame(tweets_emojis_converted_words)

# tweets_emojis_converted_words = nltk.word_tokenize((tweets_smi_1['emojis_converted']).pd.to_string())
# tweets_emojis_converted_words = tweets_smi_1['emojis_converted']).nltk.word_tokenize()

print('--')
print('Tokenized emojis_converted_words')
print(tweets_emojis_converted_words_df.head(10))
print('--')

print('--')
print('Tokenized emojis_converted_words Shape')
print(tweets_emojis_converted_words_df.shape)
print('--')

print('--')
print('Tokenized emojis_converted_words Info')
print(tweets_emojis_converted_words_df.info)
print('--')

# Remove single-character tokens (mostly punctuation) ######## NEED TO DO FIX 
# tweets_emojis_converted_words = [word for word in tweets_emojis_converted_words if len(word) > 1]

# Remove numbers ######## NEED TO DO FIX
# tweets_emojis_converted_words = [word for word in tweets_emojis_converted_words if not word.isnumeric()]

# Lowercase all tweets_words (default_stoptweets_words are lowercase too) ######## NEED TO DO FIX
# tweets_emojis_converted_words = [word.lower() for word in tweets_emojis_converted_words]

# Stemming tweets_words seems to make matters worse, disabled
# stemmer = nltk.stem.snowball.SnowballStemmer('english')
# tweets_emojis_converted_words = [stemmer.stem(word) for word in tweets_emojis_converted_words]

# Remove stoptweets_words          ################################################################
# tweets_emojis_converted_words = [word for word in tweets_emojis_converted_words if word not in stoptweets_words]

# print('removed stoptweets_words')

##################################################################################################################

# FINDING N-GRAMS

# N-Grams refer to n combination of words in a sentence. For instance, for a sentence "I love watching football", some 2-grams would 
# be (I love), (love watching) and (watching football). N-Grams can play a cricual role in Text classification. 

for ngram_emojis_converted in textblob_obj_emojis_converted_c.ngrams(2):
	print('-------------------------')
	print('N-Grams emojis_converted: 2')
#	print(ngram_emojis_converted)
	print('-------------------------')
	
	# NEED TO DO SAVE TO FILE OR GRAPH!!!!

ngram_emojis_converted = pd.DataFrame(ngram_emojis_converted, columns=['ngran_emojis_converted'])

ngram_emojis_converted.to_csv('4_5A_200_SMI1_ngram_emojis_converted_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
ngram_emojis_converted.to_csv('4_5A_200_SMI1_ngram_emojis_converted_TEXT.txt', sep=';', encoding='utf-8', index=False, header=True)


########################################################################################################

def ngrams_wrapper(sent):
	yield list(nltk.ngrams(sent, 2))

raw_emojis_converted = fp_emojis_converted_c

sentences_emojis_converted = nltk.sent_tokenize(raw_emojis_converted)

tokenized_emojis_converted = map(nltk.tokenize, sentences_emojis_converted)

print('---')
print('Tokenized emojis_converted')
# print(tokenized_emojis_converted)
print('---')

bigrams_emojis_converted = []
for sentence_emojis_converted in sentences_emojis_converted:
	sequence_emojis_converted = word_tokenize(sentence_emojis_converted)
	bigrams_emojis_converted.extend(list(ngrams(sequence_emojis_converted, 2)))

freq_dist_emojis_converted = nltk.FreqDist(bigrams_emojis_converted)
prob_dist_emojis_converted = nltk.MLEProbDist(freq_dist_emojis_converted)
number_of_bigrams_emojis_converted = freq_dist_emojis_converted.N()

print('---')
print('freq_dist emojis_converted')
print(freq_dist_emojis_converted)
print('---')

print('---')
print('prob_dist emojis_converted')
print(prob_dist_emojis_converted)
print('---')

print('---')
print('number_of_bigrams emojis_converted')
print(number_of_bigrams_emojis_converted)
print('---')

# tokenized_emojis_converted_df = pd.DataFrame([tokenized_emojis_converted])

# tokenized_emojis_converted_df.to_csv('4_5A_201_SMI1_Tokenized_emojis_converted_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# tokenized_emojis_converted_df.to_excel('4_5A_201_SMI1_Tokenized_emojis_converted_DF.xlsx', index=True, header=True)

freq_dist_emojis_converted_df = pd.DataFrame([freq_dist_emojis_converted], columns=['freq_dist_emojis_converted'])

freq_dist_emojis_converted_df.to_csv('4_5A_201_SMI1_freq_dist_emojis_converted_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# freq_dist_emojis_converted_df.to_excel('4_5A_201_SMI1_freq_dist_emojis_converted_DF.xlsx', index=True, header=True)

prob_dist_emojis_converted_df = pd.DataFrame([prob_dist_emojis_converted])

prob_dist_emojis_converted_df.to_csv('4_5A_201_SMI1_prob_dist_emojis_converted_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# prob_dist_emojis_converted_DF.to_excel('4_5A_201_SMI1_prob_dist_emojis_converted_DF.xlsx', index=True, header=True)

number_of_bigrams_emojis_converted_df = pd.DataFrame([number_of_bigrams_emojis_converted], columns=['number_of_bigrams_emojis_converted'])

number_of_bigrams_emojis_converted_df.to_csv('4_5A_201_SMI1_number_of_bigrams_emojis_converted_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# number_of_bigrams_emojis_converted_df.to_excel('4_5A_201_SMI1_number_of_bigrams_emojis_converted_DF.xlsx', index=True, header=True)

#############################################################################################################

value_counts_bigram_emojis_converted = pd.value_counts(bigrams_emojis_converted, ascending=False, normalize=True) 

value_counts_bigram_emojis_converted = value_counts_bigram_emojis_converted.sort_values(ascending=False)

value_counts_bigram_emojis_converted_df = pd.DataFrame(value_counts_bigram_emojis_converted, columns=['value_counts_bigrams_emojis_converted'])

value_counts_bigram_emojis_converted_df.to_csv('4_5A_201_SMI1_value_counts_bigram_emojis_converted_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# value_counts_bigram_emojis_converted_df.to_excel('4_5A_201_SMI1_value_counts_bigram_emojis_converted_DF.xlsx', index=True, header=True)

print('---')
print('value_counts_bigram_emojis_converted_df info')
print(value_counts_bigram_emojis_converted_df.info)
print('---')

print('---')
print('value_counts_bigram_emojis_converted_df shape')
print(value_counts_bigram_emojis_converted_df.shape)
print('---')

# CREATE SEPERATE BIGRAMS DATAFRAMES 

# value_counts_bigram_emojis_converted_df = value_counts_bigram_emojis_converted_df.astype(str, errors='ignore')

# seperate_value_counts_bigram_emojis_converted = [value_counts_bigram_emojis_converted_df[:0], value_counts_bigram_emojis_converted_df[:1]]

# value_counts_bigram_emojis_converted_df = value_counts_bigram_emojis_converted_df['value_counts_bigrams'].apply(list)

# seperate_value_counts_bigram_emojis_converted_df = pd.DataFrame.from_items(value_counts_bigram_emojis_converted, columns=['items_counts_bigrams', 'number_counts_bigrams'])
# seperate_value_counts_bigram_emojis_converted_df[['value_bigrams_emojis_converted', 'value_counts_bigrams_emojis_converted']] = pd.DataFrame(value_counts_bigram_emojis_converted_df['value_counts_bigrams'].tolist(),index=value_counts_bigram_emojis_converted_df)
# seperate_value_counts_bigram_emojis_converted_df = seperate_value_counts_bigram_emojis_converted_df.join(value_counts_bigram_emojis_converted_df_temp)
# seperate_value_counts_bigram_emojis_converted_df.to_csv('4_5A_201_SMI1_seperate_value_counts_bigram_emojis_converted_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# seperate_value_counts_bigram_emojis_converted_df.to_excel('4_5A_201_SMI1_seperate_value_counts_bigram_emojis_converted_DF.xlsx', index=True, header=True)

print('---')
print('seperate_value_counts_bigram_emojis_converted_df head')
# print(seperate_value_counts_bigram_emojis_converted_df.head)
print('---')

print('---')
print('value_counts_bigram_emojis_converted_df info')
print(value_counts_bigram_emojis_converted_df.info)
print('---')

print('---')
print('value_counts_bigram_emojis_converted_df shape')
print(value_counts_bigram_emojis_converted_df.shape)
print('---')

#####

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Emojis Value Counts')
value_counts_bigram_emojis_converted[:10].plot(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Bigram_Value_Counts_Bigram_Emojis_Converted_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Emojis Value Counts - Pie')
value_counts_bigram_emojis_converted[:7].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['emojis_converted'], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_value_counts_bigram_emojis_converted_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Emojis Value Counts - Bars')
value_counts_bigram_emojis_converted[:10].plot.bar(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_value_counts_bigram_emojis_converted_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

######################################################################################################################

# GRAPH NETWORK OF PEOPLE AND MENTIONS # NEED TO DO!!!!

# Find the neighbours of a node
	
######################################################################################################################
##################################################################################################################

# Scatter Plot Faceted on Two Variables

#################################################################################################################

print('---')
print('Loading Libs 56')
print('---')

# Seaborn visualization library

# screenName author_id created Retweets Favorites Text latitude longitude mentions hashtags id url emojis_unicode emojis_converted image_link language

tweets_smi_1_numeric = pd.DataFrame(tweets_smi_1)
# del tweets_smi_1_numeric['screenName']
# df.drop(['column_nameA', 'column_nameB'], axis=1, inplace=True)
# del tweets_smi_1_numeric['screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', 'url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language']

# tweets_smi_1_numeric.drop('screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language', axis=1, inplace=True)

# tweets_smi_1_numeric.drop('screenName', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('text', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('latitude', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('longitude', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('mentions', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('hashtags', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('url', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('emojis_unicode', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('emojis_converted', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('image_link', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('language', axis=1, inplace=True)

# tweets_smi_1_numeric.drop(['screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', 'url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language'], axis=1, inplace=True)
# tweets_smi_1_numeric = tweets_smi_1[['author_id', 'created', 'retweets', 'favorites', 'id']]

# Create the default pairplot

# PLOT  # NEED TO DO NOT WORKING !!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Pair Plot of SMI Numeric Data')
# sns.pairplot(tweets_smi_1_numeric)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_197_SMI1_Pair_Plot_Numeric.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('creating plots')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


###################################################################################################################

# http://seaborn.pydata.org/tutorial/relational.html

# Visualizing Statistical Relationships # NEED TO DO 

# Statistical analysis is a process of understanding how variables in a dataset relate to each other and how those relationships depend on other variables. Visualization can be a core component of this process because, when data are visualized properly, the human visual system can see trends and patterns that indicate a relationship.
# We will discuss three seaborn functions in this tutorial. The one we will use most is relplot(). This is a figure-level function for visualizing statistical relationships using two common approaches: scatter plots and line plots. relplot() combines a FacetGrid with one of two axes-level functions:
# scatterplot() (with kind="scatter"; the default)
# lineplot() (with kind="line')
# As we will see, these functions can be quite illuminating because they use simple and easily-understood representations of data that can nevertheless represent complex dataset structures. They can do so because they plot two-dimensional graphics that can be enhanced by mapping up to three additional variables using the semantics of hue, size, and style.

# Relating variables with scatter plots

# The scatter plot is a mainstay of statistical visualization. It depicts the joint distribution of two variables using a cloud of points, where each point represents an observation in the dataset. This depiction allows the eye to infer a substantial amount of information about whether there is any meaningful relationship between them.
# There are several ways to draw a scatter plot in seaborn. The most basic, which should be used when both variables 
# are numeric, is the scatterplot() function. In the categorical visualization tutorial, we will see specialized tools 
# for using scatterplots to visualize categorical data. The scatterplot() is the default kind in relplot() (it can also 
# be forced by setting kind="scatter'):

# SCATTER PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Scatter Plot Relating Retweets / Favorites')
sns.relplot(x='retweets', y='favorites', data=tweets_smi_1)
plt.xlabel('Retweets')
plt.ylabel('Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_198_SMI1_SB_Scatter_Plot_Rel_Favorites_Retweets_Numeric_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#####################

# In the simplest invocation, both functions draw a scatterplot of two variables, x and y, and then fit the regression model 
# y ~ x and plot the resulting regression line and a 95% confidence interval for that regression:

# SCATTER PLOT REG

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Regression Retweets / Favorites 95% Conf. Int. Scatter')
sns.regplot(x='retweets', y='favorites', data=tweets_smi_1)
plt.xlabel('Retweets')
plt.ylabel('Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_198_SMI1_SB_Scatter_Plot_Reg_Favorites_Retweets_REG_PLOT_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT LM

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Regression Retweets - Favorites: 95% Conf. Int. Scatter')
sns.lmplot(x='retweets', y='favorites', data=tweets_smi_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_198_SMI1_SB_Scatter_Plot_Reg_Favorites_Retweets_LM_PLOT_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('done - using seaborn')

#################################################################################

# _df _df = pd.DataFrame()
# .to_csv('4_5A_.csv', sep=';', encoding='utf-8', index=True)
# excel

###########################################################################################################

# https://www.datacamp.com/community/tutorials/wordcloud-python

# WORDCLOUD 

# SMI_WordCloud_1 = WordCloud(background_color="white",stoptweets_words=stoptweets_words,width=800, height=400, colors=colors_blue).generate(' '.join(data))
SMI_WordCloud_1 = WordCloud(background_color='white').generate(' '.join(tweets_text_words))

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet WordCloud Visualization')
plt.imshow(SMI_WordCloud_1, interpolation='bilinear')
plt.axis('off')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# plt.show()
plt.savefig('4_5A_199_SMI1_WordCloud_SB_1.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################################################################################
#
#		SENTIMENT ANALYSIS: USING TEXTBLOB
#
###################################################################################################################

# The SENTIMENT property returns a nameduple of the form sentiment(polarity, subjectivity). The polarity score is a 
# float within the range [-1.0, 1.0]. The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective
# and 1.0 is very subjective.


# returns the sentiment of text
# by returning a value between -1.0 and 1.0

textblob_obj_text_polarity = textblob_obj_text_c.sentiment.polarity
textblob_obj_text_subjectivity = textblob_obj_text_c.sentiment.subjectivity

print('---')
print('TextBlob Polarity:')
print(textblob_obj_text_polarity)

if textblob_obj_text_polarity == 0:
  print('The Text is neutral')
elif textblob_obj_text_polarity > 0.75:
  print('The Text is very positive') 
elif textblob_obj_text_polarity > 0.50:
  print('The Text is positive')
elif textblob_obj_text_polarity > 0:
  print('The Text is somewhat positive')
elif textblob_obj_text_polarity > -0.25:
  print('The Text is somewhat negative') 
elif textblob_obj_text_polarity > -0.50:
  print('The Text is negative')
else:
  print('The Text is very negative')
  
print('---')

print('TextBlob Subjectivity:')
print(textblob_obj_text_subjectivity)

if textblob_obj_text_subjectivity == 0:
  print('The Text is extremely subjective')
elif textblob_obj_text_subjectivity > 0.75:
  print('The Text is very objective')
elif textblob_obj_text_subjectivity > 0.50:
  print('The Text is objective')
elif textblob_obj_text_subjectivity > 0.25:
  print('The Text is subjective')
else:
  print('The Text is very subjective')

print('---')


textblob_obj_text_positiveness = 1 - textblob_obj_text_polarity
# textblob_obj_text_subjectivity = 1 - textblob_obj_text_subjectivity

# initialize list of Lists 
textblob_obj_text_sentiments = [['textblob_obj_text_polarity', textblob_obj_text_polarity], ['textblob_obj_text_subjectivity', textblob_obj_text_subjectivity], ['textblob_obj_text_positiveness', textblob_obj_text_positiveness]] 
 
# Create the pandas DataFrame 
textblob_obj_text_sentiments_df = pd.DataFrame(textblob_obj_text_sentiments, columns = ['textblob_obj_text_sentiment_item', 'textblob_obj_text_sentiment_value']) 

textblob_obj_text_sentiments_df.to_csv('4_5A_200_SMI1_Textblob_Obj_Text_Sentiments_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# textblob_obj_text_sentiments_df.to_excel('4_5A_200_SMI1_Textblob_Obj_Text_Sentiments.xlsx', header=True)

# PLOT TABLE # NEED TO DO 

# Sentiment Plot

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity - TextBlob')
textblob_obj_text_sentiments_df.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_200_SMI1_Textblob_Obj_Text_Sentiments_df_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity TextBlob - Pie')
plt.ioff()
plt.pie(textblob_obj_text_sentiments_df['textblob_obj_text_sentiment_value'], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90, radius=1.0, rotatelabels=False)
# plt.legend(textblob_obj_text_sentiments_df, bbox_to_anchor=(1., 1), loc=1, borderaxespad=0.)
# plt.legend()
# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_200_SMI1_Textblob_Obj_Text_Sentiments_df_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOT # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity / Subjectivity TextBlob - Bars')
textblob_obj_text_sentiments_df.plot.bar(alpha=0.9)
plt.xlabel('Sentiment Polarity / Subjectivity / Positiveness')
plt.ylabel('Value')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_200_SMI1_Textblob_Obj_Text_Sentiments_df_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


######################################################################################################################

# SENTENCES ANALYSIS

textblob_sentences = textblob_obj_text_c.sentences

print('-------------------------')
print('TextBlob Sentences Head - NOT WORKINGGGGGG')
# print(textblob_sentences[:10])
print('-------------------------')

 
# Create the pandas DataFrame 
textblob_sentences_df = pd.DataFrame(textblob_sentences) 

textblob_sentences_df.to_csv('4_5A_201_SMI1_Textblob_Sentences_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# textblob_sentences_df.to_excel('4_5A_201_SMI1_Textblob_Sentences.xlsx', header=True)

textblob_sentences_number = len(textblob_sentences)

print('-------------------------')
print('TextBlob Sentenes Number')
# print(textblob_sentences_number)
print('-------------------------')

# Create the pandas DataFrame 
# textblob_sentences_number_df = pd.DataFrame(textblob_sentences_number) 

# textblob_sentences_number_df.to_csv('4_5A_201_SMI1_Textblob_Sentences_Number_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# textblob_sentences_number_df.to_excel('4_5A_201_SMI1_Textblob_Sentences_Number.xlsx', header=True)

###################################################################################################################
#
# 	 			 TEXT CLASSIFICATION
#                                                 
###################################################################################################################
	
	
# WITH TEXTBLOB - BASIC CLASSIFICATION

textblob_train_data = [
	('fucking love it', 'positive'),	
	('fucking great', 'positive'),
	('fucking amazing', 'positive'),
	('fucking kidding', 'negative'),
	('fucking bad', 'negative')
]

textblob_test_data = [
	('fucking love it', 'positive'),	
	('fucking great', 'positive'),
	('fucking amazing', 'positive'),
	('fucking kidding', 'negative'),
	('fucking bad', 'negative')
]

###########################################################

print('---')
print('Loading Libs 58')
print('---')

# NAIVE BAYES CLASSIFIER

from textblob.classifiers import NaiveBayesClassifier

textblob_classifier = NaiveBayesClassifier(textblob_train_data)

textblob_test_phrase_1 = 'This lipstick is fucking amazing'
textblob_test_phrase_2 = 'This lipstick is fucking waste of money'

print('-------------------------')
print('TextBlob NaiveBayes Classifier')
print(textblob_test_phrase_1)
print('is:')
print(textblob_classifier.classify(textblob_test_phrase_1))
print('-------------------------')

print('-------------------------')
print('TextBlob NaiveBayes Classifier')
print(textblob_test_phrase_2)
print('is:')
print(textblob_classifier.classify(textblob_test_phrase_2))
print('-------------------------')


# NEED TO FINISHHHHHHHHHHHHHHHHHHHHHHHHHHH


######################################################################################################################
######################################################################################################################

# SENTIMENT PER TWEET

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore')
tweets_smi_1['text'] = tweets_smi_1['text'].to_string()

tweets_smi_1['textblob_obj_text_polarity'] = TextBlob(tweets_smi_1['text'].to_string()).sentiment.polarity
tweets_smi_1['textblob_obj_text_subjectivity'] = TextBlob(tweets_smi_1['text'].to_string()).sentiment.subjectivity


# MOST POSITIVE TWEETS

# most_positive_tweets_text_textblob = tweets_smi_1['textblob_obj_text_polarity'].where('textblob_obj_text_polarity' == 1)
# most_positive_tweets_text_textblob = pd.DataFrame(tweets_smi_1['textblob_obj_text_polarity' == 1])

# tweets_main_smi_1 = tweets_smi_1[(tweets_smi_1['screenName'] == main_smi_1)]

most_positive_tweets_text_textblob = tweets_smi_1[(tweets_smi_1['textblob_obj_text_polarity'] == 1)]

print('-------------------------')
print('Most Positive Tweets Text Head')
print(most_positive_tweets_text_textblob[:10])
print('-------------------------')

# MOST NEGATIVE TWEETS

# most_negative_tweets_text_textblob = tweets_smi_1['textblob_obj_text_polarity' == '-1']

# tweets_smi_1 = tweets_smi_1[(tweets_smi_1['screenName'] == main_smi_1)]

most_negative_tweets_text_textblob = tweets_smi_1[(tweets_smi_1['textblob_obj_text_polarity'] == '-1')]

print('-------------------------')
print('Most Negative Tweets Text Head')
print(most_negative_tweets_text_textblob[:10])
print('-------------------------')

# most_positive_tweets_text_textblob
# most_negative_tweets_text_textblob

# SAVE DATAFRAME TO CSV 


tweets_smi_1.to_csv('1_6_5A_SENT_SMI1_DF_Tweets_Processes_1_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
tweets_smi_1.to_csv('1_6_5A_SENT_SMI1_DF_Tweets_Processes_1.txt', sep=';', encoding='utf-8', index=False, header=True)

print('MAIN SMI: Done Initial TextBlob')
print(main_smi)
print('-------------------------')




###############################################################

# METHOD 1 : TEXTBLOB

word_1_count_textblob = textblob_obj_text_c.word_counts[word_1]

print('---')
print('Text Blob Counts Word:')
print(word_1)
print(word_1_count_textblob)
print('---')

word_1_count_textblob = textblob_obj_text_c.word_counts[word_1]
word_2_count_textblob = textblob_obj_text_c.word_counts[word_2]
word_3_count_textblob = textblob_obj_text_c.word_counts[word_3]
word_4_count_textblob = textblob_obj_text_c.word_counts[word_4]
word_5_count_textblob = textblob_obj_text_c.word_counts[word_5]
word_6_count_textblob = textblob_obj_text_c.word_counts[word_6]
word_7_count_textblob = textblob_obj_text_c.word_counts[word_7]
word_8_count_textblob = textblob_obj_text_c.word_counts[word_8]
word_9_count_textblob = textblob_obj_text_c.word_counts[word_9]
word_10_count_textblob = textblob_obj_text_c.word_counts[word_10]
word_11_count_textblob = textblob_obj_text_c.word_counts[word_11]
word_12_count_textblob = textblob_obj_text_c.word_counts[word_12]
word_13_count_textblob = textblob_obj_text_c.word_counts[word_13]
word_14_count_textblob = textblob_obj_text_c.word_counts[word_14]
word_15_count_textblob = textblob_obj_text_c.word_counts[word_15]
word_16_count_textblob = textblob_obj_text_c.word_counts[word_16]
word_17_count_textblob = textblob_obj_text_c.word_counts[word_17]
word_18_count_textblob = textblob_obj_text_c.word_counts[word_18]
word_19_count_textblob = textblob_obj_text_c.word_counts[word_19]
word_20_count_textblob = textblob_obj_text_c.word_counts[word_20]
word_21_count_textblob = textblob_obj_text_c.word_counts[word_21]
word_22_count_textblob = textblob_obj_text_c.word_counts[word_22]
word_23_count_textblob = textblob_obj_text_c.word_counts[word_23]
word_24_count_textblob = textblob_obj_text_c.word_counts[word_24]
word_25_count_textblob = textblob_obj_text_c.word_counts[word_25]
word_26_count_textblob = textblob_obj_text_c.word_counts[word_26]
word_27_count_textblob = textblob_obj_text_c.word_counts[word_27]

# initialize list of Lists 
selected_tweets_words_counts_textblob = [[word_1, word_1_count_textblob], [word_2, word_2_count_textblob], [word_3, word_3_count_textblob], [word_4, word_4_count_textblob], [word_5, word_5_count_textblob], [word_6, word_6_count_textblob], [word_7, word_7_count_textblob], [word_8, word_8_count_textblob], [word_9, word_9_count_textblob], [word_10, word_10_count_textblob], [word_11, word_11_count_textblob], [word_12, word_12_count_textblob], [word_13, word_13_count_textblob], [word_14, word_14_count_textblob], [word_15, word_15_count_textblob], [word_16, word_16_count_textblob], [word_17, word_17_count_textblob], [word_18, word_18_count_textblob], [word_19, word_19_count_textblob], [word_20, word_20_count_textblob], [word_21, word_21_count_textblob], [word_22, word_22_count_textblob], [word_23, word_23_count_textblob], [word_24, word_24_count_textblob], [word_25, word_25_count_textblob], [word_26, word_26_count_textblob], [word_27, word_27_count_textblob]] 
 
# Create the pandas DataFrame 
selected_tweets_words_counts_textblob_df = pd.DataFrame(selected_tweets_words_counts_textblob, columns = ['tweets_words', 'Counts']) 

selected_tweets_words_counts_textblob_df.to_csv('4_5A_211_SMI1_Selected_Tweets_Words_Counts_Textblob_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# selected_tweets_words_counts_textblob_df.to_excel('4_5A_211_SMI1_Selected_Tweets_Words_Counts_Textblob_DF.xlsx', header=True)

print('---')
print('Doing Selecting Words')
print('---')


# Selected tweets_words Plot


# TABLE PLOT NEED TO DO 

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies - Textblob')
# selected_tweets_words_counts_textblob_df.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_211_SMI1_Selected_Tweets_Words_Textblob_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies Textblob - Pie')
# plt.pie(selected_tweets_words_counts_textblob_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(selected_tweets_words_counts_textblob_df, bbox_to_anchor=(1.9, 0.4), loc=1, borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_211_SMI1_Selected_Tweets_Words_Textblob_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOT # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies Textblob - Bars')
selected_tweets_words_counts_textblob_df.plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_211_SMI1_Selected_Tweets_Words_Textblob_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

################################################################

# METHOD 2: 

tweets_smi_1['word_1_query'] = tweets_smi_1.query('text == "love"')

tweets_smi_1['number_word_1'] = pd.value_counts(tweets_smi_1['word_1_query'], ascending=False, normalize=True)

print('------------------------------------------------------------')
print('------------------------------------------------------------')
print('Word 1 Query: METHOD 2')
print(tweets_smi_1['word_1_query'])
print('------------------------------------------------------------')
print('Word 1 Query NUMEBR:')
print(tweets_smi_1['number_word_1'])
print('-------------------------------------------------------------')
print('-------------------------------------------------------------')


word_2_query = tweets_smi_1.query('text == "word_2"')
number_word_2 = len(word_2_query)

word_3_query = tweets_smi_1.query('text == "word_3"')
number_word_3 = len(word_3_query)
  
word_4_query = tweets_smi_1.query('text == "word_4"')
number_word_4 = len(word_4_query)
 
word_5_query = tweets_smi_1.query('text == "word_5"')
number_word_5 = len(word_5_query)
 
word_6_query = tweets_smi_1.query('text == "word_6"')
number_word_6 = len(word_6_query)
 
word_7_query = tweets_smi_1.query('text == "word_7"')
number_word_7 = len(word_7_query)
 
word_8_query = tweets_smi_1.query('text == "word_8"')
number_word_8 = len(word_8_query)
 
word_9_query = tweets_smi_1.query('text == "word_9"')
number_word_9 = len(word_9_query)
 
word_10_query = tweets_smi_1.query('text == "word_10"')
number_word_10 = len(word_10_query)

word_11_query = tweets_smi_1.query('text == "word_11"')
number_word_11 = len(word_11_query)

word_12_query = tweets_smi_1.query('text == "word_12"')
number_word_12 = len(word_12_query)

word_13_query = tweets_smi_1.query('text == "word_13"')
number_word_13 = len(word_13_query)

word_14_query = tweets_smi_1.query('text == "word_14"')
number_word_14 = len(word_14_query)

word_15_query = tweets_smi_1.query('text == "word_15"')
number_word_15 = len(word_15_query)

word_16_query = tweets_smi_1.query('text == "word_16"')
number_word_16 = len(word_16_query)

word_17_query = tweets_smi_1.query('text == "word_17"')
number_word_17 = len(word_17_query)

word_18_query = tweets_smi_1.query('text == "word_18"')
number_word_18 = len(word_18_query)

word_19_query = tweets_smi_1.query('text == "word_19"')
number_word_19 = len(word_19_query)

word_20_query = tweets_smi_1.query('text == "word_20"')
number_word_20 = len(word_20_query)

word_21_query = tweets_smi_1.query('text == "word_21"')
number_word_21 = len(word_21_query)

word_22_query = tweets_smi_1.query('text == "word_22"')
number_word_22 = len(word_22_query)

word_23_query = tweets_smi_1.query('text == "word_23"')
number_word_23 = len(word_23_query)

word_24_query = tweets_smi_1.query('text == "word_24"')
number_word_24 = len(word_24_query)

word_25_query = tweets_smi_1.query('text == "word_25"')
number_word_25 = len(word_25_query)

word_26_query = tweets_smi_1.query('text == "word_26"')
number_word_26 = len(word_26_query)

word_27_query = tweets_smi_1.query('text == "word_27"')
number_word_27 = len(word_27_query)

 
# initialize list of Lists 
selected_tweets_words_counts = [[word_1, number_word_1], [word_2, number_word_2], [word_3, number_word_3], [word_4, number_word_4], [word_5, number_word_5], [word_6, number_word_6], [word_7, number_word_7], [word_8, number_word_8], [word_9, number_word_9], [word_10, number_word_10], [word_11, number_word_11], [word_12, number_word_12], [word_13, number_word_13], [word_14, number_word_14], [word_15, number_word_15], [word_16, number_word_16], [word_17, number_word_17], [word_18, number_word_18], [word_19, number_word_19], [word_20, number_word_20], [word_21, number_word_21], [word_22, number_word_22], [word_23, number_word_23], [word_24, number_word_24], [word_25, number_word_25], [word_26, number_word_26], [word_27, number_word_27]] 
 
# Create the pandas DataFrame 
selected_tweets_words_counts_df = pd.DataFrame(selected_tweets_words_counts, columns = ['tweets_words', 'Counts']) 

selected_tweets_words_counts_df.to_csv('4_5A_211_SMI1_Selected_Tweets_Words_Counts_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# selected_tweets_words_counts_df.to_excel('4_5A_211_SMI1_Selected_Tweets_Words_Counts_DF.xlsx', header=True)

# Selected tweets_words Plot


# TABLE PLOT NEED TO DO 

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies')
# selected_tweets_words_counts_df.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_211_SMI1_Selected_Tweets_Words_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies - Pie')
# plt.pie(selected_tweets_words_counts_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(selected_tweets_words_counts_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_211_SMI1_Selected_Tweets_Words_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOT # NEED TO DO

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies - Bars')
selected_tweets_words_counts_df.plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_211_SMI1_Selected_Tweets_Words_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###################################################################################################################
#
# 	       TOPIC MODELLING : LDA Latent Dirichhlet Allocation
#                                                 
###################################################################################################################

# towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24

# Word Statistics


word_1 = 'love'
word_2 = 'hate'
word_3 = 'like' # NEED TO ADD LIKED
word_4 = 'brand'
word_5 = 'buy'
word_6 = 'fuck'
word_7 = 'thanks' # NEED TO ADD THANK YOU
word_8 = 'friend'
word_9 = 'follow'
word_10 = 'bitch'
word_11 = 'sister'
word_12 = 'video' # NEED TO ADD VIDEOS
word_13 = 'omg'
word_14 = 'good'
word_15 = 'bad'
word_16 = 'makeup'
word_17 = 'queen'
word_18 = 'give'
word_19 = 'review'
word_20 = 'share'
word_21 = 'recommend'
word_22 = 'feel'
word_23 = 'racist'
word_24 = 'ily'
word_25 = 'nigger'
word_26 = 'christmas'
word_27 = 'homophobic'

# apologize
# feud


###############################################################

# METHOD 1 : TEXTBLOB

word_1_count_textblob = textblob_obj_text_c.word_counts[word_1]

print('---')
print('Text Blob Counts Word: METHOD 1')
print(word_1)
print(word_1_count_textblob)
print('---')

# word_1_count_textblob = textblob_obj_text_c.word_counts[word_1]
# word_2_count_textblob = textblob_obj_text_c.word_counts[word_2]
# word_3_count_textblob = textblob_obj_text_c.word_counts[word_3]
# word_4_count_textblob = textblob_obj_text_c.word_counts[word_4]
# word_5_count_textblob = textblob_obj_text_c.word_counts[word_5]
# word_6_count_textblob = textblob_obj_text_c.word_counts[word_6]
# word_7_count_textblob = textblob_obj_text_c.word_counts[word_7]
# word_8_count_textblob = textblob_obj_text_c.word_counts[word_8]
# word_9_count_textblob = textblob_obj_text_c.word_counts[word_9]
# word_10_count_textblob = textblob_obj_text_c.word_counts[word_10]
# word_11_count_textblob = textblob_obj_text_c.word_counts[word_11]
# word_12_count_textblob = textblob_obj_text_c.word_counts[word_12]
# word_13_count_textblob = textblob_obj_text_c.word_counts[word_13]
# word_14_count_textblob = textblob_obj_text_c.word_counts[word_14]
# word_15_count_textblob = textblob_obj_text_c.word_counts[word_15]
# word_16_count_textblob = textblob_obj_text_c.word_counts[word_16]
# word_17_count_textblob = textblob_obj_text_c.word_counts[word_17]
# word_18_count_textblob = textblob_obj_text_c.word_counts[word_18]
# word_19_count_textblob = textblob_obj_text_c.word_counts[word_19]
# word_20_count_textblob = textblob_obj_text_c.word_counts[word_20]
# word_21_count_textblob = textblob_obj_text_c.word_counts[word_21]
# word_22_count_textblob = textblob_obj_text_c.word_counts[word_22]
# word_23_count_textblob = textblob_obj_text_c.word_counts[word_23]
# word_24_count_textblob = textblob_obj_text_c.word_counts[word_24]
# word_25_count_textblob = textblob_obj_text_c.word_counts[word_25]
# word_26_count_textblob = textblob_obj_text_c.word_counts[word_26]
# word_27_count_textblob = textblob_obj_text_c.word_counts[word_27]


# word_1_count_textblob = textblob_obj_text_c.count(word_1)
# word_2_count_textblob = textblob_obj_text_c.count(word_2)
# word_3_count_textblob = textblob_obj_text_c.count(word_3)
# word_4_count_textblob = textblob_obj_text_c.count(word_4)
# word_5_count_textblob = textblob_obj_text_c.count(word_5)
# word_6_count_textblob = textblob_obj_text_c.count(word_6)
# word_7_count_textblob = textblob_obj_text_c.count(word_7)
# word_8_count_textblob = textblob_obj_text_c.count(word_8)
# word_9_count_textblob = textblob_obj_text_c.count(word_9)
# word_10_count_textblob = textblob_obj_text_c.count(word_10)
# word_11_count_textblob = textblob_obj_text_c.count(word_11)
# word_12_count_textblob = textblob_obj_text_c.count(word_12)
# word_13_count_textblob = textblob_obj_text_c.count(word_13)
# word_14_count_textblob = textblob_obj_text_c.count(word_14)
# word_15_count_textblob = textblob_obj_text_c.count(word_15)
# word_16_count_textblob = textblob_obj_text_c.count(word_16)
# word_17_count_textblob = textblob_obj_text_c.count(word_17)
# word_18_count_textblob = textblob_obj_text_c.count(word_18)
# word_19_count_textblob = textblob_obj_text_c.count(word_19)
# word_20_count_textblob = textblob_obj_text_c.count(word_20)
# word_21_count_textblob = textblob_obj_text_c.count(word_21)
# word_22_count_textblob = textblob_obj_text_c.count(word_22)
# word_23_count_textblob = textblob_obj_text_c.count(word_23)
# word_24_count_textblob = textblob_obj_text_c.count(word_24)
# word_25_count_textblob = textblob_obj_text_c.count(word_25)
# word_26_count_textblob = textblob_obj_text_c.count(word_26)
# word_27_count_textblob = textblob_obj_text_c.count(word_27)

tweets_smi_1['word_1_count'] = tweets_smi_1['text'].str.count(word_1)


print('---')
print('Text Blob Counts Word:')
print(word_1)
print(tweets_smi_1['word_1_count'].head(20))
print(tweets_smi_1['word_1_count'].dtypes)
print('---')

# tweets_smi_1['word_1_count'] = tweets_smi_1['text'].str.count(word_1)
tweets_smi_1['word_2_count'] = tweets_smi_1['text'].str.count(word_2)
tweets_smi_1['word_3_count'] = tweets_smi_1['text'].str.count(word_3)
tweets_smi_1['word_4_count'] = tweets_smi_1['text'].str.count(word_4)
tweets_smi_1['word_5_count'] = tweets_smi_1['text'].str.count(word_5)
tweets_smi_1['word_6_count'] = tweets_smi_1['text'].str.count(word_6)
tweets_smi_1['word_7_count'] = tweets_smi_1['text'].str.count(word_7)
tweets_smi_1['word_8_count'] = tweets_smi_1['text'].str.count(word_8)
tweets_smi_1['word_9_count'] = tweets_smi_1['text'].str.count(word_9)
tweets_smi_1['word_10_count'] = tweets_smi_1['text'].str.count(word_10)
tweets_smi_1['word_11_count'] = tweets_smi_1['text'].str.count(word_11)
tweets_smi_1['word_12_count'] = tweets_smi_1['text'].str.count(word_12)
tweets_smi_1['word_13_count'] = tweets_smi_1['text'].str.count(word_13)
tweets_smi_1['word_14_count'] = tweets_smi_1['text'].str.count(word_14)
tweets_smi_1['word_15_count'] = tweets_smi_1['text'].str.count(word_15)
tweets_smi_1['word_16_count'] = tweets_smi_1['text'].str.count(word_16)
tweets_smi_1['word_17_count'] = tweets_smi_1['text'].str.count(word_17)
tweets_smi_1['word_18_count'] = tweets_smi_1['text'].str.count(word_18)
tweets_smi_1['word_19_count'] = tweets_smi_1['text'].str.count(word_19)
tweets_smi_1['word_20_count'] = tweets_smi_1['text'].str.count(word_20)
tweets_smi_1['word_21_count'] = tweets_smi_1['text'].str.count(word_21)
tweets_smi_1['word_22_count'] = tweets_smi_1['text'].str.count(word_22)
tweets_smi_1['word_23_count'] = tweets_smi_1['text'].str.count(word_23)
tweets_smi_1['word_24_count'] = tweets_smi_1['text'].str.count(word_24)
tweets_smi_1['word_25_count'] = tweets_smi_1['text'].str.count(word_25)
tweets_smi_1['word_26_count'] = tweets_smi_1['text'].str.count(word_26)
tweets_smi_1['word_27_count'] = tweets_smi_1['text'].str.count(word_27)


word_1_count_textblob = tweets_smi_1['word_1_count'].sum()

print('---')
print('Text Blob Counts Word NUMBER:')
print(word_1)
print(word_1_count_textblob)
# print(tweets_smi_1['word_1_count'].dtypes)
print('---')

word_2_count_textblob = tweets_smi_1['word_2_count'].sum()

print('---')
print('Text Blob Counts Word NUMBER:')
print(word_2)
print(word_2_count_textblob)
# print(tweets_smi_1['word_2_count'].dtypes)
print('---')

word_2_count_textblob = tweets_smi_1['word_2_count'].sum()
word_3_count_textblob = tweets_smi_1['word_3_count'].sum()
word_4_count_textblob = tweets_smi_1['word_4_count'].sum()
word_5_count_textblob = tweets_smi_1['word_5_count'].sum()
word_6_count_textblob = tweets_smi_1['word_6_count'].sum()
word_7_count_textblob = tweets_smi_1['word_7_count'].sum()
word_8_count_textblob = tweets_smi_1['word_8_count'].sum()
word_9_count_textblob = tweets_smi_1['word_9_count'].sum()
word_10_count_textblob = tweets_smi_1['word_10_count'].sum()
word_11_count_textblob = tweets_smi_1['word_11_count'].sum()
word_12_count_textblob = tweets_smi_1['word_12_count'].sum()
word_13_count_textblob = tweets_smi_1['word_13_count'].sum()
word_14_count_textblob = tweets_smi_1['word_14_count'].sum()
word_15_count_textblob = tweets_smi_1['word_15_count'].sum()
word_16_count_textblob = tweets_smi_1['word_16_count'].sum()
word_17_count_textblob = tweets_smi_1['word_17_count'].sum()
word_18_count_textblob = tweets_smi_1['word_18_count'].sum()
word_19_count_textblob = tweets_smi_1['word_19_count'].sum()
word_20_count_textblob = tweets_smi_1['word_20_count'].sum()
word_21_count_textblob = tweets_smi_1['word_21_count'].sum()
word_22_count_textblob = tweets_smi_1['word_22_count'].sum()
word_23_count_textblob = tweets_smi_1['word_23_count'].sum()
word_24_count_textblob = tweets_smi_1['word_24_count'].sum()
word_25_count_textblob = tweets_smi_1['word_25_count'].sum()
word_26_count_textblob = tweets_smi_1['word_26_count'].sum()
word_27_count_textblob = tweets_smi_1['word_27_count'].sum()

# initialize list of Lists 
selected_tweets_words_counts_textblob = [[word_1, word_1_count_textblob], [word_2, word_2_count_textblob], [word_3, word_3_count_textblob], [word_4, word_4_count_textblob], [word_5, word_5_count_textblob], [word_6, word_6_count_textblob], [word_7, word_7_count_textblob], [word_8, word_8_count_textblob], [word_9, word_9_count_textblob], [word_10, word_10_count_textblob], [word_11, word_11_count_textblob], [word_12, word_12_count_textblob], [word_13, word_13_count_textblob], [word_14, word_14_count_textblob], [word_15, word_15_count_textblob], [word_16, word_16_count_textblob], [word_17, word_17_count_textblob], [word_18, word_18_count_textblob], [word_19, word_19_count_textblob], [word_20, word_20_count_textblob], [word_21, word_21_count_textblob], [word_22, word_22_count_textblob], [word_23, word_23_count_textblob], [word_24, word_24_count_textblob], [word_25, word_25_count_textblob], [word_26, word_26_count_textblob], [word_27, word_27_count_textblob]] 
 
# Create the pandas DataFrame 
selected_tweets_words_counts_textblob_df = pd.DataFrame(selected_tweets_words_counts_textblob, columns = ['tweets_words', 'Counts']) 

selected_tweets_words_counts_textblob_df.to_csv('4_5A_211_SMI1_Selected_Tweets_Words_Counts_Textblob_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# selected_tweets_words_counts_textblob_df.to_excel('4_5A_211_SMI1_Selected_Tweets_Words_Counts_Textblob_DF.xlsx', header=True)

print('---')
print('Doing Selecting Words')
print('---')


# Selected tweets_words Plot


# TABLE PLOT NEED TO DO 

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies - Textblob')
plt.ioff()
# selected_tweets_words_counts_textblob_df.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_211_SMI1_Selected_Tweets_Words_Textblob_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
# plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies Textblob - Pie')
# plt.pie(selected_tweets_words_counts_textblob_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(selected_tweets_words_counts_textblob_df, bbox_to_anchor=(1.9, 0.4), loc=1, borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_211_SMI1_Selected_Tweets_Words_Textblob_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOT # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies Textblob - Bars')
selected_tweets_words_counts_textblob_df.plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_211_SMI1_Selected_Tweets_Words_Textblob_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################################################################################
#
# 		        TOPIC MODELLING : LSA Latent Semantic Analysis
#                                                 
###################################################################################################################

# analyticsvidhya.com/blob/2018/10/stewise-guide-topic-modeling-latent-semantic-analysis/


##############################################################################################################

# _df _df = pd.DataFrame()
# .to_csv('4_5A_.csv', sep=';', encoding='utf-8', index=True)
# excel


##################################################################################################################
#
#                                       USING NLTK ##### NEED TO DO !!!!!
#
###################################################################################################################

print('---')
print('Loading Libs 57')
print('---')


#############################################################################################################

# POLARITY DISTRIBUTION

# textblob_obj_text_c


def find_polarity_textblob(tweets):
	yield TextBlob(tweets).sentiment.polarity
	
tweets_smi_1['textblob_sentiment_polarity'] = tweets_smi_1['text'].apply(find_polarity_textblob)

print('---')
print('TextBlob Sent Polarity Distributions')
print(tweets_smi_1['textblob_sentiment_polarity'].head)
print('---')

textblob_sentiment_polarity_df = tweets_smi_1['textblob_sentiment_polarity']

textblob_sentiment_polarity_df.to_csv('4_5A_200_SMI1_Textblob_Sentiment_Polarity_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# textblob_sentiment_polarity_df.to_excel('4_5A_200_SMI1_Textblob_Sentiment_Polarity_DF.xlsx', header=True)

# DIST PLOT # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity Distribution TextBlob - Histogram')
# tweets_smi_1['textblob_sentiment_polarity'].plot.bar(alpha=0.9)
plt.xlabel('Sentiment Polarity')
plt.ylabel('Value')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_200_SMI1_TextBLob_Sentiment_Polarity_Distribution_Hist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##########################################################################################################################

# Word Tokenization

# Word tokenizer breaks Text paragraph into tweets_words.

tokenized_tweets_words = nltk.tokenize.word_tokenize(tweets_smi_1['text'].to_string())
# print(tokenized_tweets_words.head)

# tokenized_tweets_words = mosestokenizer.MosesTokenizer(tweets_smi_1['text'])

# tokenized_tweets_words.to_csv('4_5A_212_SMI1_Tokenized_Tweets_Words_CSV.csv', sep=';', encoding='utf-8', index=True)
# tokenized_tweets_words.to_excel('4_5A_212_SMI1_Tokenized_Tweets_Words.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Words')
# tokenized_tweets_words.plot(10,cumulative=False, alpha=0.9)
# sns.distplot(tokenized_tweets_words)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_212_SMI1_Freq_Dist_Tokenized_Tweets_Words.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Words - Pie')
plt.ioff()
# plt.pie(tokenized_tweets_words[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(tokenized_tweets_words, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_212_SMI1_Freq_Dist_Tokenized_Tweets_Words_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Words - Bars')
# tokenized_tweets_words[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_212_SMI1_Freq_Dist_Tokenized_Tweets_Words_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#########################################################################################################################################################

# Stoptweets_words

# Stoptweets_words considered as noise in the text. Text may contain stop tweets_words such as is, am, are, this, a, an, the, etc.
# In NLTK for removing stoptweets_words, you need to create a list of stoptweets_words and filter out your list of tokens from these tweets_words.

# NEED TO DO - NOT WORKING!!!!!!!!!!!

# stop_tweets_words = nltk.corpus.stoptweets_words.tweets_words('english')

# stop_tweets_words = stoptweets_words.tweets_words('english')

print('---')
print('Stop tweets_words NOT WORKING NEED TO FIX')
# print(stop_tweets_words)
print('---')

# filtered_sent=[]
# for w in tokenized_tweets_words:
#    if w not in stop_tweets_words:
#        filtered_sent.append(w)
# print("Tokenized Sentence:",tokenized_sent)
# print("Filterd Sentence:",filtered_sent)

# tokenized_sent.to_csv('4_5A_213_SMI1_Tokenized_Sent_No_Stoptweets_words_CSV.csv', sep=';', encoding='utf-8', index=True)
# tokenized_sent.to_excel('4_5A_213_SMI1_Tokenized_Sent_No_Stoptweets_words.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# PLOT TOKENIZED SENT - 1 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentiment')
plt.ioff()
# tokenized_sent.plot(10,cumulative=False, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_213_SMI1_Freq_Dist_Tokenized_Sent.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentiment - Pie')
plt.ioff()
# plt.pie(tokenized_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.pie(tokenized_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(tokenized_sent, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_213_SMI1_Freq_Dist_Tokenized_Sent_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO

############################################################################

# tokenized_sent.to_csv('4_5A_214_SMI1_tokenized_sent_CSV.csv', sep=';', encoding='utf-8', index=True)
# tokenized_sent.to_excel('4_5A_214_SMI1_tokenized_sent.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# PLOT SENTIMENT OR SENTENCES????????? - 2

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Filtered Sent')
plt.ioff()
# filtered_sent.plot(10,cumulative=False, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_214_SMI1_tokenized_sent.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Filtered Sent - Pie')
plt.ioff()
# plt.pie(filtered_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.pie(filtered_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(filtered_sent, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()
# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_214_SMI1_Freq_Dist_Filtered_Sent_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO

#############################################################################################################
###############################################################################################################
#
#         USE PACKAGE CORPUS - NEED TO DO 
#
###############################################################################################################

print('---')
print('Loading Libs 60')
print('---')

# https://towardsdatascience.com/practical-statistics-visualization-with-python-plotly-770e96e35067

# USING CUFFLNKS

# from plotly.offline import init_notebook_mode, iplot
# import plotly.figure_factory as ff
# import cufflinks
# cufflinks.go_offline()
# cufflinks.set_config_file(world_readable=True, theme='pearl')
# import plotly.graph_objs as go
# import plotly.plotly as py
# import plotly
# from plotly import tools

#############        plotly.tools.set_credentials_file(username='XXX', api_key='XXX')


print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

##########################################################################################################################

# NEED TO DO - FIX PLOTLY

##############################################################################################################
#
#                                SNA - CLUSTER ANALYSIS #############  NEED TO DO!!!!
#
##########################################################################################################################

print('done processing 4')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

###############################################################################################################

print('-- NEED TO DO FAVS AND RTS PER LANGUAGE!!!')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

###############################################################################################################

print('-- done quant processing 3 - analysis 1')
print(' -- NEED TO DO : SMIS Processing / DATA ANALYSIS QUANTITATIVE AND STATISTICS - SNA - CLUSTER ANALYSIS')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


#######################################################################################################################
#######################################################################################################################
#######################################################################################################################

print('---')
print('Loading Libs 61')
print('---')

# https://towardsdatascience.com/an-end-to-end-project-on-total_favorites-series-analysis-and-forecasting-with-python-4835e6bf050b

# Visualizing Furniture Sales Time Series Data

# Some distinguishable patterns appear when we plot the data. The total_favorites-series has seasonality pattern, such as sales are 
# always low at the beginning of the year and high at the end of the year. There is always an upward trend within any 
# single year with a couple of low months in the mid of the year. We can also visualize our data using a method called 
# total_favorites-series decomposition that allows us to decompose our total_favorites series into three distinct components: trend, 
# seasonality, and noise.

# from pylab import rcParams
# rcParams['figure.figsize'] = 18, 8

# decomposition = sm.tsa.seasonal_decompose(y, model='additive')
# fig = decomposition.plot(alpha=0.9)
# plt.show()

print('MAIN SMI: NEED TO DO')
print(main_smi)
print('----------------------------------------')

#######################################################################################################################
#######################################################################################################################
########################################################################################################################
#
#				TEXTUAL ANALYTICS
#
#######################################################################################################################
#######################################################################################################################

### NOT WORKING NEED TO DO


######################################################################################################

## SELECTED WORDS

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Calculate Frequency Distribution

smi1_tweets_text_words_fdist = nltk.FreqDist(tweets_text_words)

print('---')
print('Word Frequency Distribution - NEED TO DO - FIX KNOW TYPE')
print(smi1_tweets_text_words_fdist)
print('---')

print('---')
print('Word Frequency Distribution - Love')
print(smi1_tweets_text_words_fdist['love'])
print('---')

print('---')
print('Word Frequency Distribution - Hate')
print(smi1_tweets_text_words_fdist['hate'])
print('---')

print('---')
print('Word Frequency Distribution - Thanks')
print(smi1_tweets_text_words_fdist['thanks'])
print('---')

print('---')
print('Word Frequency Distribution - Fuck')
print(smi1_tweets_text_words_fdist['fuck'])
print('---')

print('---')
print('Word Frequency Distribution - Follow')
print(smi1_tweets_text_words_fdist['follow'])
print('---')

print('---')
print('Word Frequency Distribution - Friend')
print(smi1_tweets_text_words_fdist['friend'])
print('---')

print('---')
print('Word Frequency Distribution - Buy')
print(smi1_tweets_text_words_fdist['buy'])
print('---')

print('---')
print('Word Frequency Distribution - Brand')
print(smi1_tweets_text_words_fdist['brand'])
print('---')


word_love = smi1_tweets_text_words_fdist['love']
word_hate = smi1_tweets_text_words_fdist['hate']
word_thanks = smi1_tweets_text_words_fdist['thanks']
word_fuck = smi1_tweets_text_words_fdist['fuck']
word_follow = smi1_tweets_text_words_fdist['follow']
word_friend = smi1_tweets_text_words_fdist['friend']
word_buy = smi1_tweets_text_words_fdist['buy']
word_brand = smi1_tweets_text_words_fdist['brand']

## NEED TO DO PLOTS AND SAVE

# Output top 50 tweets_words

for word, frequency in smi1_tweets_text_words_fdist.most_common(10):
    print(u'{};{}'.format(word, frequency))
#     smi1_tweets_text_words_freq['tweets_text_words'] = pd.DataFrame(smi1_tweets_text_words_fdist.word)
#     smi1_tweets_text_words_freq['tweets_text_words_freq'] = pd.DataFrame(smi1_tweets_text_words_fdist.frequency)


# tweets_text_words_freq = tweets_text_words_fdist.keys()  ### NEED TO DO - FIX FROM ABOVE

print('---')
print('Word Frequency Distribution from List and Counts - Try 1')
# print(smi1_tweets_text_words_freq)  ######## NNED TO DO - NOT WORKING
print(type(smi1_tweets_text_words_fdist))
print('---')

print('---')
print('Number of Words In Text')
print(len(smi1_tweets_text_words_fdist))
print('---')

smi1_tweets_text_words_fdist_df = pd.DataFrame([smi1_tweets_text_words_fdist])

smi1_tweets_text_words_fdist_df.to_csv('4_5A_101_SMI1_Word_Freq_Dist_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# tweets_text_words_fdist_df.to_excel('4_5A_101_SMI1_Word_Freq_Dist_DF.xlsx', header='frequency_distribution') # Only argument is a string of the output file path


# PLOT TABLE NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Words Frequency Distribution')
plt.ioff()
smi1_tweets_text_words_fdist.plot(10,cumulative=False, alpha=0.9)   ########### NEED TO FIX -SHOWING FEW
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_101_SMI1_Words_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Words Frequency Distribution - Box')
plt.ioff()
# plt.plot(smi1_tweets_text_words_fdist[:10])
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_101_SMI1_Words_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################

# HISTOGRAM PLOT NEED TO DO ## need to change

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))     ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Words Frequency Distribution - Histogram')
plt.ioff()
# plt.hist(smi1_tweets_text_words_fdist, labels=smi1_tweets_text_words_fdist, colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_tweets_text_words_fdist[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_101_SMI1_Words_Freq_Dist_PLOT_Hist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOTS ######### NEED TO DO!!!!!!!!!!!!!

# top_tweets_text_words_fdist = tweets_text_words_fdist.sort(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Words Frequency Distribution - Bars')
plt.ioff()
# smi1_tweets_text_words_fdist[:6].plot.bar(alpha=0.9)
# plt.bar(smi1_tweets_text_words_fdist[:6], tweets_text_words_fdist, color='#7f3d5f', edgecolor='white', label='words')
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_101_SMI1_Words_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################

## METHOD 2 - SEVERAL TRIES

# TO DF - NOT WORKING

# smi1_df_tweets_text_words_fdist = pd.DataFrame(smi1_tweets_text_words_fdist)

print('---')
print('Frequency Distribution of Words DF')
# print(smi1_df_tweets_text_words_fdist.head(10))
print('---')

#### TRY 2 NOT WORKING

# smi1_tweets_text_words_fdist_list = smi1_tweets_text_words_fdist.str.split()

# smi1_tweets_text_words_freq = ['smi1_tweets_text_words', 'smi1_tweets_text_words_freq']

# for w in smi1_tweets_text_words_fdist_list:
#	smi1_tweets_text_words_freq.append(smi1_tweets_text_words_fdist_list.count(w))
	

print('---')
print('Word Frequency Distribution from List and Counts - Try 2')
# print(smi1_tweets_text_words_freq)
print('---')
print('---')
# print('List\n' + str(smi1_tweets_text_words_freq) + '\n')
print('---')
print('---')
# print('Frequencies\n' + str(smi1_tweets_text_words_freq) + '\n')
print('---')
print('---')
# print('Pairs\n' + str(list(zip(smi1_tweets_text_words_fdist_list, smi1_tweets_text_words_freq)))
print('---')

# TABLE PLOT NEED TO DO 

# PIE PLOT NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Words - Pie')
plt.ioff()
# plt.pie(smi1_tweets_text_words_fdist[:6], labels=smi1_tweets_text_words_fdist, colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_tweets_text_words_fdist[:6].plot(kind='pie', colors='#73C2FB', startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_words, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_102_SMI1_Tweets_Text_Words_fdist_df_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Words - Bars')
plt.ioff()
# smi1_tweets_text_words_fdist.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_102_SMI1_Tweets_Text_Words_fdist_df_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################### NEED TO FIX

# TUPLE TO DATAFRAME

# tweets_text_words_fdist_df = pd.DataFrame.from_records(tweets_text_words_fdist, columns=['tweets_text_words', 'tweets_text_words_freq'])
# tweets_text_words_fdist_df = pd.DataFrame.from_items(tweets_text_words_fdist)
# tweets_text_words_fdist_df = pd.DataFrame(tweets_text_words_fdist, index=[0])
# tweets_text_words_fdist_df = pd.DataFrame([tweets_text_words_fdist])
# tweets_text_words_fdist_df = pd.DataFrame(list(tweets_text_words_fdist), columns=['tweets_text_words', 'tweets_text_words_freq'], index['tweets_text_words', 'tweets_text_words_freq'])

# tweets_text_words_fdist_df = pd.DataFrame(tweets_text_words_fdist, columns=['tweets_text_words', 'tweets_text_words_freq'])
# a_tweets_text_words_fdist_df = tweets_text_words_fdist_df.pivot('tweets_text_words', 'tweets_text_words_freq')


# pd.DataFrame.from_dict(list(tweets_text_words_fdist.items()), columns=['tweets_words', 'tweets_words_frequency_counts'])
# pd.DataFrame.from_dict(tweets_text_words_fdist, orient='index')

# tweets_text_words_fdist_d_f = list(tweets_text_words_fdist, name='tweets_words_frequency_counts')

# tweets_text_words_fdist_d_f.index.name = 'tweets_words_frequency_counts' 

# tweets_text_words_fdist_df = pd.DataFrame(tweets_text_words_fdist, index=[0])

print('---')
print('Tweets_words Frequency Distribution DataFrame')
# print(tweets_text_words_fdist_df)
print('---')

print('FINISHED PRINTING WORD FREQUENCIES')

############ df_tweets_words_fdist is a tuple!!! NEED TO CHANGE TO DF and PLOT DUPLE!!!!


print('---')
print('DF tweets_words Frequency Distribution - fdist ')
# print(tweets_text_words_fdist_df)
print('---')

print('---')
print('Frequency Distribution of tweets_words')
# print(tweets_text_words_fdist_df.head(10))
print('---')

# tweets_text_words_fdist_df.to_csv('4_5A_103_SMI1_Tweets_Text_Words_fdist_df_CSV.csv', sep=';', encoding='utf-8', index=True)
# tweets_text_words_fdist_df.to_excel('4_5A_103_SMI1_Tweets_Text_Words_fdist_df.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# NEED TO DO TABLE PLOT

# PLOT NEED TO DO 

# BOX PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Words - Box')
plt.ioff()
# tweets_text_words_fdist_df.plotbox() 
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_103_SMI1_Tweets_Text_Words_fdist_df_PLOT_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Words - Pie')
plt.ioff()
# plt.pie(tweets_text_words_fdist_df[:6], labels=tweets_text_words_fdist_df, colors='#73C2FB',startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
tweets_text_words_fdist_df[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_words, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_103_SMI1_Tweets_Text_Words_fdist_df_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## PLOT 2 TEST ## NEED TO DO FIX NOT WORKING

print('PLOT2 WORD DIST TEST - NEED TO FIX')

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Words')
plt.ioff()
# tweets_text_words_fdist_df.plot(10,cumulative=False alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
tweets_text_words_fdist_df[:10].plot(alpha=0.9)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_103_SMI1_Tweets_Text_Words_fdist_df_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT NEED TO DO

## BAR PLOT ## NEED TO DO FIX NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Frequency Distribution of Words - Bars')
plt.ioff()
# tweets_text_words_fdist_df.plot.bars(10,cumulative=False, alpha=0.9)  # CHANGE TO BARS?   ########### NEED TO FIX -SHOWING FEW
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_103_SMI1_Tweets_Text_Words_fdist_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

print('Box Plot Test')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Word Frequency Distribution - Box')
plt.ioff()
# plt.plot(tweets_text_words_fdist_df) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_103_SMI1_Tweets_Text_Words_fdist_DF_Box_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#######################################################################

# BAR PLOTS ######### NEED TO DO!!!!!!!!!!!!!

print('Bar Plot Test')

value_counts_text = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)

# Create DataFrame

value_counts_text_df = pd.DataFrame(value_counts_text, columns =['item', 'word_number_value', 'tweets_words_by_percentage'])
value_counts_text_df

print('---')
print('Tweets_words in Tweets and Values')
# print(value_counts_text_df)
print('---')

value_counts_text_df.to_csv('4_5A_104_SMI1_Value_Counts_Text_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# value_counts_text_df.to_excel('4_5A_104_SMI1_Value_Counts_Text_DF.xlxs', header=True)

# top_tweets_words_fdist = tweets_words_fdist.sort_values(ascending=False)

# value_counts_df_tweets_words_fdist = pd.value_counts([value_counts_text], ascending=False, normalize=True)
# top_tweets_words_fdist = value_counts_df_tweets_words_fdist.sort_values(ascending=False)  ######## NEED TO PUT FIX SORTING DUPLE

# TABLE PLOT NEED TO DO 

# BAR PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Word Frequency Distribution - Bars')
plt.ioff()
pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
plt.tight_layout(pad=2)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_104_SMI1_Top_Tweets_Words_Freqdists_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

##################################################

# PLOTS  ######### NEED TO DO!!!!!!!!!!!!! NOT WORKING

# value_counts_text = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)
# top_tweets_words_fdist = df_tweets_words_fdist.sort_values(ascending=False)

# value_counts_df_tweets_words_fdist = pd.value_counts(pd.DataFrame(df_tweets_words_fdist), ascending=False, normalize=True)
# top_tweets_words_fdist = pd.DataFrame(value_counts_df_tweets_words_fdist.sort_values(ascending=False))

# top_tweets_words_fdist_f = value_counts_df_tweets_words_fdist.sort_values(ascending=False)

## NEED TO DO SAVE INFO TO CSV!!!!

# top_tweets_words_fdist.to_csv('4_5A_104_SMI1_Top_Tweets_Value_Counts_Words_fdist_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# top_tweets_words_fdist.to_excel('4_5A_104_SMI1_Top_Tweets_Value_Counts_Words_fdist.xlsx', header=True)

# TABLE PLOT NEED TO DO 

# BAR PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Word Frequency Distribution - Bars')
plt.ioff()
# top_tweets_words_fdist[:10].plot.bar(alpha=0.9)
# value_counts_df_tweets_words_fdist[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_104_SMI1_Top_Tweets_Words_Value_Counts_Fdists_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

## NEED TO DO SCREENNAME STAS!!!!!!!!!!!!!!

############################################################################################################

# Value Counts screenNames   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_screenname = pd.value_counts(tweets_smi_1['screenName'], ascending=False, normalize=True)

smi1_value_counts_screenname = value_counts_screenname.sort_values(ascending=False)

print(value_counts_screenname)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics of ScreenNames - Grouped')
print(smi1_value_counts_screenname.describe().head)
print('---')

smi1_value_counts_screenname_df = pd.DataFrame(value_counts_screenname, columns =['screenname'])

smi1_value_counts_screenname_df.to_csv('4_5A_105_SMI1_ScreenNames_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# smi1_value_counts_screenname_df.to_excel('4_5A_105_SMI1_Screennames_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Value Counts')
# smi1_value_counts_screenname.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_screenname[:10].plot(alpha=0.9)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_105_SMI1_Top_ScreenNames_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Value Counts - Pie')
plt.ioff()
# plt.pie(smi1_value_counts_screenname[:6], labels=smi1_tweets_text_words_fdist['screenname'], colors='#73C2FB',startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_screenname[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_screenname, bbox_to_anchor=(1.05, 1.15), loc='upper right', borderaxespad=0.2)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_105_SMI1_Top_ScreenNames_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Value Counts - Bars')
plt.ioff()
# smi1_value_counts_screenname[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_105_SMI1_Top_ScreenNames_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# screennames FREQ DISTRIBUTION

smi1_screennames = tweets_smi_1['screenName']

# Calculate frequency distribution
smi1_screennames_fdist = nltk.FreqDist(smi1_screennames)

# Output top 50 tweets_words

for smi1_screennames, frequency in smi1_screennames_fdist.most_common(10):
    print(u'{};{}'.format(smi1_screennames, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_screennames_fdist_df = pd.DataFrame(smi1_screennames_fdist)

smi1_screennames_fdist_df = pd.DataFrame([smi1_screennames_fdist])

print('---')
print('ScreenNames Frequency Distribution D')
print('smi1_screennames_fdist_df.head(10)')
print('---')

smi1_screennames_fdist_df.to_csv('4_5A_106_SMI1_Screennames_Freq_Dist_CSV.csv', sep=';', encoding='utf-8', index=True)
# smi1_screennames_fdist_df.to_excel('4_5A_106_SMI1_Screennames_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames Frequency Distribution 4')
plt.ioff()
# smi1_screennames_fdist.plot(10,cumulative=False, alpha=0.9)  
# plt.plot(fdist)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_106_4_SMI1_Screennames_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames Frequency Distribution - Box')
plt.ioff()
# plt.plot(smi1_screennames_fdist)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_106_SMI1_ScreenNames_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE CHART ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames Frequency Distribution - Pie')
plt.ioff()
# smi1_screennames_fdist[:6], labels=top_smi1_screennames_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_screennames_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_screennames_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_106_SMI1_ScreenNames_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOTS  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_screennames_fdist = smi1_screennames_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Screennames Frequency Distribution - Bars')
plt.ioff()
# smi1_screennames_fdist.plot.bar(alpha=0.9)
plt.xlabel('ScreenNames')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_106_SMI1_ScreenNames_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

## NEED TO DO MENTIONS STAS!!!!!!!!!!!!!!

############################################################################################################


# Value Counts All Mentions   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_mentions = pd.value_counts(tweets_smi_1['mentions'], ascending=False, normalize=True)

smi1_value_counts_mentions = value_counts_mentions.sort_values(ascending=False)

print(value_counts_mentions)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Mentions')
print(smi1_value_counts_mentions.describe().head)
print('---')

smi1_value_counts_mentions_df = pd.DataFrame(value_counts_mentions, columns =['mentions'])

smi1_value_counts_mentions_df.to_csv('4_5A_107B_SMI1_Mentions_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# smi1_value_counts_mentions_df.to_excel('4_5A_107B_SMI1_Mentions_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts')
# smi1_value_counts_mentions.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_mentions[:10].plot(alpha=0.9)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_107B_SMI1_Top_Mentions_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Pie')
# plt.pie(smi1_value_counts_mentions[:6], labels=smi1_tweets_text_words_fdist['mentions'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
smi1_value_counts_mentions[:6].plot(kind='pie', colors='#73C2FB', startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_mentions, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_107B_SMI1_Top_Mentions_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# PLOT BARS

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Bars')
smi1_value_counts_mentions[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_107B_SMI1_Top_Mentions_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# MENTIONS FREQ DISTRIBUTION

smi1_mentions = tweets_smi_1['mentions']

# Calculate frequency distribution
smi1_mentions_fdist = nltk.FreqDist(smi1_mentions)

# Output top 50 tweets_words

for smi1_mentions, frequency in smi1_mentions_fdist.most_common(10):
    print(u'{};{}'.format(smi1_mentions, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_mentions_fdist_df = pd.DataFrame(smi1_mentions_fdist)

smi1_mentions_fdist_df = pd.DataFrame([smi1_mentions_fdist])

print('---')
print('Frequency Distribution of Mentions 5')
print('smi1_mentions_fdist_df.head(10)')
print('---')

smi1_mentions_fdist_df.to_csv('4_5A_108_SMI1_Mentions_Freq_Dist_CSV.csv', sep=';', encoding='utf-8', index=True)
# smi1_mentions_fdist_df.to_excel('4_5A_108_SMI1_Mentions_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution')
# smi1_mentions_fdist.plot(10,cumulative=False, alpha=0.9)  
# plt.plot(fdist)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_108_SMI1_Mentions_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution - Box')
# plt.plot(smi1_mentions_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_108_SMI1_Mentions_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE CHART ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution - Pie')
# smi1_mentions_fdist[:6], labels=top_smi1_mentions_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_mentions_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_mentions_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_5A_108_SMI1_Mentions_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOTS  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_mentions_fdist = smi1_mentions_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Frequency Distribution - Bars')
plt.ioff()
# smi1_mentions_fdist.plot.bar(alpha=0.9)
plt.xlabel('Mentions')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_108_SMI1_Mentions_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################


## NEED TO DO Hashtag STAS!!!!!!!!!!!!!!

############################################################################################################

# Value Counts All Hashtags   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_hashtags = pd.value_counts(tweets_smi_1['hashtags'], ascending=False, normalize=True)

smi1_value_counts_hashtags = value_counts_hashtags.sort_values(ascending=False)

print(value_counts_hashtags)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Hashtags')
print(smi1_value_counts_hashtags.describe().head)
print('---')

smi1_value_counts_hashtags_df = pd.DataFrame(value_counts_hashtags, columns =['hashtags'])

smi1_value_counts_hashtags_df.to_csv('4_5A_109_SMI1_Hashtags_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# smi1_value_counts_hashtags_df.to_excel('4_5A_109_SMI1_Hashtags_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts')
# smi1_value_counts_hashtags.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_hashtags[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_109_SMI1_Top_Hashtags_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Pie')
# plt.pie(smi1_value_counts_hashtags[:6], labels=smi1_tweets_text_words_fdist['hashtags'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_hashtags[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_hashtags, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_5A_109_SMI1_Top_Hashtags_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Hashtags Value Counts - Bars')
smi1_value_counts_hashtags[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_109_SMI1_Top_Hashtags_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Hashtags FREQ DISTRIBUTION

smi1_hashtags = tweets_smi_1['hashtags']

# Calculate frequency distribution
smi1_hashtags_fdist = nltk.FreqDist(smi1_hashtags)

# Output top 50 tweets_words

for smi1_hashtags, frequency in smi1_hashtags_fdist.most_common(10):
    print(u'{};{}'.format(smi1_hashtags, frequency))

# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_hashtags_fdist_df = pd.DataFrame(smi1_hashtags_fdist)

smi1_hashtags_fdist_df = pd.DataFrame([smi1_hashtags_fdist])

print('---')
print('Frequency Distribution of Hashtags')
print('smi1_hashtags_fdist_df.head(10)')
print('---')

smi1_hashtags_fdist_df.to_csv('4_5A_110_SMI1_Hashtags_Freq_Dist_CSV.csv', sep=';', encoding='utf-8', index=True)
# smi1_hashtags_fdist_df.to_excel('4_5A_110_SMI1_Hashtags_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution 4')
plt.ioff()
# smi1_hashtags_fdist.plot(10,cumulative=False, alpha=0.9)  
# plt.plot(fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_110_4_SMI1_Hashtags_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution - Box')
plt.ioff()
# plt.plot(smi1_hashtags_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_110_SMI1_Hashtags_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE CHART ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution - Pie')
plt.ioff()
# smi1_hashtags_fdist[:6], labels=top_smi1_hashtags_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_hashtags_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# # plt.legend(smi1_hashtags_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_5AB_110_SMI1_Hashtags_Freq_Dist_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOTS  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_hashtags_fdist = smi1_hashtags_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Hashtags Frequency Distribution - Bars')
plt.ioff()
# smi1_hashtags_fdist.plot.bar(alpha=0.9)
plt.xlabel('Hashtags')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_110_SMI1_Hashtags_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################

## NEED TO DO Emojis_Unicode STAS!!!!!!!!!!!!!!

############################################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Value Counts All Emojis Unicode   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].encode('unicode-escape')

value_counts_emojis_unicode = pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True)

smi1_value_counts_emojis_unicode = value_counts_emojis_unicode.sort_values(ascending=False)

print(value_counts_emojis_unicode)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Emojis Unicode')
print(smi1_value_counts_emojis_unicode.describe().head)
print('---')

smi1_value_counts_emojis_unicode_df = pd.DataFrame(value_counts_emojis_unicode, columns =['emojis_unicode'])

smi1_value_counts_emojis_unicode_df.to_csv('4_5A_111_SMI1_Emojis_Unicode_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# smi1_value_counts_emojis_unicode_df.to_excel('4_5A_111_SMI1_Emojis_Unicode_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
# smi1_value_counts_emojis_unicode.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_emojis_unicode[:8].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_111_SMI1_Top_Emojis_Unicode_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
# plt.pie(smi1_value_counts_emojis_unicode[:6], labels=smi1_tweets_text_words_fdist['emojis_unicode'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_emojis_unicode[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_emojis_unicode, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_111_SMI1_Top_Emojis_Unicode_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
smi1_value_counts_emojis_unicode[:8].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_111_SMI1_Top_Emojis_Unicode_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLES

del smi1_value_counts_emojis_unicode
del smi1_value_counts_emojis_unicode_df

#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Emojis Unicode FREQ DISTRIBUTION

smi1_emojis_unicode = tweets_smi_1['emojis_unicode']

# Calculate frequency distribution
smi1_emojis_unicode_fdist = nltk.FreqDist(smi1_emojis_unicode)

# Output top 50 tweets_words

for smi1_emojis_unicode, frequency in smi1_emojis_unicode_fdist.most_common(10):
    print(u'{};{}'.format(smi1_emojis_unicode, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_emojis_unicode_fdist_df = pd.DataFrame(smi1_emojis_unicode_fdist)

smi1_emojis_unicode_fdist_df = pd.DataFrame([smi1_emojis_unicode_fdist])

print('---')
print('Frequency Distribution of Emojis Unicode')
print(smi1_emojis_unicode_fdist_df.head(10))
print('---')

smi1_emojis_unicode_fdist_df.to_csv('4_5A_111_SMI1_Emojis_Unicode_Freq_Dist_CSV.csv', sep=';', encoding='utf-8', index=True)
# smi1_emojis_unicode_fdist_df.to_excel('4_5A_111_SMI1_Emojis_Unicode_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution 12')
smi1_emojis_unicode_fdist.plot(10,cumulative=False, alpha=0.9)  
# plt.plot(fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_111_12_SMI1_Emojis_Unicode_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Box')
# plt.plot(smi1_emojis_unicode_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_111_SMI1_Emojis_Unicode_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE CHART ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Pie')
# smi1_emojis_unicode_fdist[:6], labels=top_smi1_emojis_unicode_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_emojis_unicode_fdist[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_emojis_unicode_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_111_SMI1_Emojis_Unicode_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOTS  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_emojis_unicode_fdist = smi1_emojis_unicode_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Bars')
smi1_emojis_unicode_fdist[:8].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_111_SMI1_Emojis_Unicode_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLES

del smi1_emojis_unicode_fdist
del smi1_emojis_unicode_fdist_df

############################################################################################################

## NEED TO DO Emojis Converted STAS!!!!!!!!!!!!!!

############################################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Value Counts All Emojis Converted   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_emojis_converted = pd.value_counts(tweets_smi_1['emojis_converted'], ascending=False, normalize=True)

smi1_value_counts_emojis_converted = value_counts_emojis_converted.sort_values(ascending=False)

print(value_counts_emojis_converted)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Emojis Converted')
print(smi1_value_counts_emojis_converted.describe().head)
print('---')

smi1_value_counts_emojis_converted_df = pd.DataFrame(value_counts_emojis_converted, columns =['emojis_converted'])

smi1_value_counts_emojis_converted_df.to_csv('4_5A_112_SMI1_Emojis_Converted_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# smi1_value_counts_emojis_converted_df.to_excel('4_5A_112_SMI1_Emojis_Converted_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
# smi1_value_counts_emojis_converted.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_emojis_converted[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_112_SMI1_Top_Emojis_Converted_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
# plt.pie(smi1_value_counts_emojis_converted[:6], labels=smi1_tweets_text_words_fdist['emojis_converted'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_emojis_converted[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_emojis_converted, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_112_SMI1_Top_Emojis_Converted_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
# smi1_value_counts_emojis_converted[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_112_SMI1_Top_Emojis_Converted_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLES

del smi1_value_counts_emojis_converted
del smi1_value_counts_emojis_converted_df 

#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Emojis Converted FREQ DISTRIBUTION

smi1_emojis_converted = tweets_smi_1['emojis_converted']

# Calculate frequency distribution
smi1_emojis_converted_fdist = nltk.FreqDist(smi1_emojis_converted)

# Output top 50 tweets_words

for smi1_emojis_converted, frequency in smi1_emojis_converted_fdist.most_common(10):
    print(u'{};{}'.format(smi1_emojis_converted, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_emojis_converted_fdist_df = pd.DataFrame(smi1_emojis_converted_fdist)

smi1_emojis_converted_fdist_df = pd.DataFrame([smi1_emojis_converted_fdist])

print('---')
print('Frequency Distribution of Emojis Converted')
print(smi1_emojis_converted_fdist_df.head(10))
print('---')

smi1_emojis_converted_fdist_df.to_csv('4_5A_112_13_SMI1_Emojis_Converted_Freq_Dist_CSV.csv', sep=';', encoding='utf-8', index=True)
# smi1_emojis_converted_fdist_df.to_excel('4_5A_112_13_SMI1_Emojis_Converted_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution 13')
# smi1_emojis_converted_fdist.plot(10,cumulative=False, alpha=0.9) 
# plt.plot(fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_112_13_SMI1_Emojis_Converted_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Box')
# plt.plot(smi1_emojis_converted_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_112_13_SMI1_Emojis_Converted_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE CHART ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Pie')
# smi1_emojis_converted_fdist[:6], labels=top_smi1_emojis_converted_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_emojis_converted_fdist[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_emojis_converted_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# plt.show()
plt.savefig('4_5A_112_13_SMI1_Emojis_Converted_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOTS  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_emojis_converted_fdist = smi1_emojis_converted_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Bars')
# smi1_emojis_converted_fdist.plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_112_13_SMI1_Emojis_Converted_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###########################################################################################################

### EMOJIS GRAPHICAL STATS 3 ????? !!! NEED TO FIX OR IS IT UNICODE ?

###########################################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Value Counts All Emojis Graphical   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# tweets_smi_1['emojis_graphical'] = tweets_smi_1['emojis_converted'].encode('unicode-escape')

value_counts_emojis_graphical_3 = pd.value_counts(tweets_smi_1['emojis_converted'], ascending=False, normalize=True)

smi1_value_counts_emojis_graphical_3 = value_counts_emojis_graphical_3.sort_values(ascending=False)

print(value_counts_emojis_graphical_3)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Emojis Graphical_3')
print(smi1_value_counts_emojis_graphical_3.describe().head)
print('---')

smi1_value_counts_emojis_graphical_3_df = pd.DataFrame(value_counts_emojis_graphical_3, columns =['emojis_graphical'])

smi1_value_counts_emojis_graphical_3_df.to_csv('4_5A_113_SMI1_Emojis_Graphical_3_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# smi1_value_counts_emojis_graphical_3_df.to_excel('4_5A_113_SMI1_Emojis_Graphical_3_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
# smi1_value_counts_emojis_graphical_3.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_emojis_graphical_3[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_113_SMI1_Top_Emojis_Graphical_3_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
# plt.pie(smi1_value_counts_emojis_graphical_3[:6], labels=smi1_tweets_text_words_fdist['emojis_graphical'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_emojis_graphical_3[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_emojis_graphical_3, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_113_SMI1_Top_Emojis_Graphical_3_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
smi1_value_counts_emojis_graphical_3[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_113_SMI1_Top_Emojis_Graphical_3_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Emojis Graphical FREQ DISTRIBUTION

smi1_emojis_graphical_3 = tweets_smi_1['emojis_converted']

# Calculate frequency distribution
smi1_emojis_graphical_3_fdist = nltk.FreqDist(smi1_emojis_graphical_3)

# Output top 50 tweets_words

for smi1_emojis_graphical_3, frequency in smi1_emojis_graphical_3_fdist.most_common(10):
    print(u'{};{}'.format(smi1_emojis_graphical_3, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_emojis_graphical_3_fdist_df = pd.DataFrame(smi1_emojis_graphical_3_fdist)

smi1_emojis_graphical_3_fdist_df = pd.DataFrame([smi1_emojis_graphical_3_fdist])

print('---')
print('Frequency Distribution of Emojis Graphical_3')
print(smi1_emojis_graphical_3_fdist_df.head(10))
print('---')

smi1_emojis_graphical_3_fdist_df.to_csv('4_5A_113_SMI1_Emojis_Graphical_3_Freq_Dist_CSV.csv', sep=';', encoding='utf-8', index=True)
# smi1_emojis_graphical_3_fdist_df.to_excel('4_5A_113_SMI1_Emojis_Graphical_3_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution 14')
# smi1_emojis_graphical_fdist_3.plot(10,cumulative=False, alpha=0.9)  
# plt.plot(fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_113_14_SMI1_Emojis_Graphical_3_Freq_Dist.png', bbox_inches='tight')
plt.close()
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Box')
# plt.plot(smi1_emojis_graphical_3_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_113_SMI1_Emojis_Graphical_3_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE CHART ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Pie')
# smi1_emojis_graphical_3_fdist[:6], labels=top_smi1_emojis_graphical_3_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_emojis_graphical_3_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_emojis_graphical_3_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_113_SMI1_Emojis_Graphical_3_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOTS  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_emojis_graphical_3_fdist = smi1_emojis_graphical_3_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Emojis Frequency Distribution - Bars')
# smi1_emojis_graphical_fdis_3t.plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_113_SMI1_Emojis_Graphical_3_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

## NEED TO DO LANGUAGE STAS!!!!!!!!!!!!!! _3

############################################################################################################

# Value Counts All Languages   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_languages_3 = pd.value_counts(tweets_smi_1['language'], ascending=False, normalize=True)

smi1_value_counts_languages_3 = value_counts_languages_3.sort_values(ascending=False)


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Value Counts Languages_3')
print(smi1_value_counts_languages_3.describe().head)
print('---')


smi1_value_counts_languages_3_percentages = (smi1_value_counts_languages_3 * 100)/number_total_tweets

smi1_value_counts_list = [[smi1_value_counts_languages_3, smi1_value_counts_languages_3, smi1_value_counts_languages_3_percentages]]

smi1_value_counts_languages_3_df = pd.DataFrame(value_counts_languages_3, columns =['languages', 'languages_count', 'languages_percentage'])

smi1_value_counts_languages_3_df.to_csv('4_5A_160_SMI1_Languages_3_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# smi1_value_counts_languages_3_df.to_excel('4_5A_160_SMI1_Languages_3_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Languages Value Counts')
# smi1_value_counts_languages.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_languages_3[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_160_SMI1_Top_Languages_3_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Languages Value Counts - Pie')
# plt.pie(smi1_value_counts_languages_3[:6], labels=smi1_tweets_text_words_fdist['languages'], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_languages_3[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['language'], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_160_SMI1_Top_Languages_3_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Languages Value Counts - Bars')
smi1_value_counts_languages_3[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_160_SMI1_Top_Languages_3_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# Languages FREQ DISTRIBUTION

smi1_languages = tweets_smi_1['language']

# Calculate frequency distribution
smi1_languages_fdist = nltk.FreqDist(smi1_languages)

# Output top 50 tweets_words

for smi1_languages, frequency in smi1_languages_fdist.most_common(10):
    print(u'{};{}'.format(smi1_languages, frequency))
  
# SAVE TO CSV  #################################################### NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_languages_fdist_df = pd.DataFrame(smi1_languages_fdist)

smi1_languages_fdist_df = pd.DataFrame([smi1_languages_fdist])

print('---')
print('Frequency Distribution of Languages')
print('smi1_languages_fdist_df.head(10)')
print('---')

smi1_languages_fdist_df.to_csv('4_5A_161_SMI1_Languages_Freq_Dist_CSV.csv', sep=';', encoding='utf-8', index=True)
# smi1_languages_fdist_df.to_excel('4_5A_161_SMI1_Languages_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Languages Frequency Distribution')
# smi1_languages_fdist.plot(10,cumulative=False, alpha=0.9)  
# plt.plot(fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_161_SMI1_Languages_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Languages Frequency Distribution - Box')
# plt.plot(smi1_languages_fdist)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_161_SMI1_Languages_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE CHART ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Languages Frequency Distribution - Pie')
# smi1_languages_fdist[:6], labels=top_smi1_languages_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_languages_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_languages_fdist, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_161_SMI1_Languages_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOTS  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_languages_fdist = smi1_languages_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Languages Frequency Distribution - Bars')
# smi1_languages_fdist.plot.bar(alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_161_SMI1_Languages_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

############################################################################################################

# NEED FREQ DIST EMOJIS, IMAGE LINK< NEED TO DO MISSING HASHTAFS MENTIONS !!!! < ETC

############################################################################################################
############################################################################################################

print('---')
print('Loading Libs 67')
print('---')

## NEED TO DO MISSING MENTIONS AND HASTAGS!!!!

# missing_mentions = pd.DataFrame(missing_mentions)

# quant_stats_smi_tweets_1 = go.Figure(data=[go.Table(header=dict(values=['Tweets by JAMESCHARLES', 'Tweets by JEFFREESTAR', 'Tweets by MANNYMUA733', 'Tweets by MICHELLEPHAN', 'Tweets by NIKKIETUTORIALS', 'Tweets by ZOELLA', 'Tweets by AUDIENCE']),
#                 cells=dict(values=[[number_tweets_by_jamescharles, number_tweets_by_jeffreestar, number_tweets_by_mannymua733, number_tweets_by_michellephan, number_tweets_by_nikkietutorials, number_tweets_by_zoella, 'number_tweets_by_audience']]))])

# quant_stats_smi_tweets_1.show()

# quant_stats_smi_tweets_1.to_csv('4_5A_165_SMI1_Quant_Stats_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# quant_stats_smi_tweets_1.to_excel('4_5A_165_SMI1_Quant_Stats.xlsx', header=True)

# Plot ## NEED TO DO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets SMIs - Audience')
# plt.plot(quant_stats_smi_tweets_1)
# plt.imshow(quant_stats_smi_tweets_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_165_SMI1_Quant_Stats_SMI_Tweets_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets SMIs Audience - Pie')
# plt.pie(top_retweets_tweets[:6], labels=top_retweets_tweets, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# quant_stats_smi_tweets_1.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(top_retweets_tweets, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_165_SMI1_Quant_Stats_SMI_Tweets_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT ## NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets SMIs vs Audience - Bars')
# plt.plot.bar(quant_stats_smi_tweets_1)
# quant_stats_smi_tweets_1_df['tweets_about_smi_number'].plot.bar(alpha=0.9)
# ax.bar(tweets_about_percentages_df['tweets_about_smi_item'], tweets_about_percentages_df['tweets_about_smi_number'])
plt.xlabel('SMI / Audience')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_165_SMI1_Quant_Stats_SMI_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

####################################################################################################################################################

# This selects the top 5 highest average points among all Tweets: # NEED TO DO

# Mean ScreenName

# smi1_screenname_mean = statistics.mean(tweets_smi_1['screenName'])
# smi1_screenname_mean

# smi1_screenname_mean.sort_values(by='screenName', ascending=False).head  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest ScreenName Average Points Among All Tweets:')
# print(smi1_screenname_mean.sort_values(by="screenName').head)
print('--')

# smi1_screenname_mean_sort_values_df = pd.DataFrame(smi1_screenname_mean().sort_values(by="screenName'))

# smi1_screenname_mean_sort_values_df.to_csv('4_5A_166_SM1_Screenname_Mean_Sort_Values_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# PLOT Tplt.plot  ######## NEED TO DO FIX!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest ScreenNames Average Points')
# plt.plot(smi1_screenname_mean_sort_values_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_166_SMI1_Screenname_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Highest ScreenName Average Points - Pie')
# plt.pie(smi1_screenname_mean_sort_values_df.most_common(10), labels=screenname_mean_sort_values_df.most_common(10), colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_screenname_mean_sort_values_df.most_common(10), bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_166_SMI1_Screenname_Mean_Sort_Values_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# BAR PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest ScreenName Average Points - Bars')
# smi1_screenname_mean_sort_values_df[:10].plot.bar(alpha=0.9)
plt.xlabel('ScreenName')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_166_SMI1_Screenname_Mean_Sort_Values_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################

# This selects the top 5 highest average points among all Tweets:

# smi1_favorites_mean().sort_values(by='favorites',ascending=True).head  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest Favorites Average Points Among All Tweets:')
# print(smi1_favorites_mean().sort_values(by='favorites',ascending=True).head)
print('---')


# smi1_favorites_mean_sort_values_favorites_df = pd.DataFrame(smi1_favorites_mean().sort_values(by='favorites',ascending=True))

# smi1_favorites_mean_sort_values_favorites_df.to_csv('4_5A_167_SMI1_Favorites_Mean_Sort_Values_Favorites_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# smi1_favorites_mean_sort_values_favorites_df.to_excel('4_5A_167_SMI1_Favorites_Mean_Sort_Values_Favorites_DF.xlsx', header=True)

# PLOT plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Favorites Average Points')
# plt.plot(smi1_favorites_mean_sort_values_favorites_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_167_SMI1_Favorites_Mean_Sort_Values_Favorites_df.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Favorites Average Points - Pie')
# plt.pie(smi1_favorites_mean_sort_values_favorites_df.most_common(10), labels=smi1_favorites_mean_sort_values_favorites_df.most_common(10), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_favorites_mean_sort_values_favorites_df[:6], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_167_SMI1_Favorites_Mean_Sort_Values_Favorites_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# BAR PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Favorites Average Points - Bars')
# smi1_screenname_mean_sort_values_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_167_SMI1_Favorites_Mean_Sort_Values_Favorites_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################

# This selects the top 5 highest average points among all Tweets:

# smi1_retweets_mean().sort_values(by='retweets',ascending=True).head  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 Highest Retweets Average Points Amongst All Tweets:')
# print(smi1_retweets_mean().sort_values(by='retweets',ascending=True).head)
print('---')

# smi1_retweets_mean_sort_values_retweets_df = pd.DataFrame(smi1_retweets_mean().sort_values(by='retweets',ascending=True))

# smi1_retweets_mean_sort_values_retweets_df.to_csv('4_5A_168_SMI1_Retweets_Mean_Sort_Values_Retweets_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot  ######## NEED TO DO FIX!!!!!!!!!

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Retweets - Grouped')
# plt.plot(smi1_languages.describe())
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_168_SMI1_Retweets_Mean_Sort_Values_Retweets_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO BOX PLOT


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Retweets Grouped - Pie')
# plt.pie(smi1_languages.describe(), labels=smi1_languages.describe(), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_languages.describe(), bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_168_SMI1_Retweets_Mean_Sort_Values_Retweets_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# BAR PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Retweets Average Points - Bars')
# smi1_languages.describe().plot.bar(alpha=0.9)
plt.xlabel('Retweets')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_168_SMI1_Retweets_Mean_Sort_Values_Retweets_DF_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#########################################################################################################################################################

# Number of tweets_words in text

number_of_tweets_words = len(smi1_tweets_text_words_fdist)
number_of_tweets_words

print('---')
print('Number of tweets_words Analyzed : No Stop Words')
print(number_of_tweets_words)
print('---')

number_of_tweets_words_df = pd.DataFrame([number_of_tweets_words])

number_of_tweets_words_df.to_csv('4_5A_169_SMI1_Number_of_Tweets_Words_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# number_of_tweets_words_df.to_excel('4_5A_169_SMI1_Number_of_Tweets_Words_DF.xlsx, header=True)

# PLOT TABLE plt.plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Text')
# plt.plot(number_of_tweets_words_df.describe())
# plt.plot(number_of_tweets_words_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_169_SMI1_Number_of_Tweets_Words_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO DO BOX PLOT


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Text - Pie')
# plt.pie(number_of_tweets_words_df[:6], labels=number_of_tweets_words_df, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(number_of_tweets_words_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_5A_169_SMI1_Number_of_Tweets_Words_DF_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO


###################################################################################################################

# STATISTICS DF # NEED TO DO 

# initialize list of Lists 

# quant_stats_1_pairs = [['Mean Favorites', median_favorites, 'Median Retweets', median_retweets, 'Mode Favorites', mode_favorites, 'Mode Retweets', mode_retweets], ['Variance Favorites', variance_favorites, 'Variance Retweets', variance_retweets, 'Population Variance Favorites', pvariance_favorites, 'Population Variance Retweets', pvariance_retweets, 'Standard Deviation Retweets', stdev_retweets, 'Population Standard Deviation Favorites', pstdev_favorites, 'Population Standard Deviation Retweets', pstdev_retweets, 'Skewness Favorites', skewness_favorites, 'Skewness Retweets', skewness_retweets, 'Percentiles Favorites (25, 50, 75)', quantiles_favorites, 'Percentiles Retweets (25, 50, 75)', quantiles_retweets, 'Ranges Favorites', ptp_favorites, 'Ranges Retweets', ptp_retweets, 'Correlation Coefficient - Pearson Regression', corr_coef_favs_rts_pearson, 'Linear Regession', r_linar_reg],['Number of Tweets Analyzed', number_tweets, 'Number of Unique Tweets Analyzed', number_unique_tweets, 'Number of tweets_words in Text', number_of_tweets_words, 'List Unique Followers ReTweeting, Commenting, Engaged', number_unique_engaged_users, 'Number of Users Who Favorite', number_unique_tweets_with_favorites, 'Number of Unique Tweets with Retweets', 'number_unique_retweets_users', 'List Unique Hashtags', 'number_unique_hashtags', 'List Unique Mentions', 'number_unique_mentions', 'List Unique Emojis Unicode', 'number_unique_emojis_unicode', 'List Unique Emojis Converted', 'number_unique_emojis_converted', 'List Unique Language', 'number_unique_languages', 'Summary Statistics All Favorites / Desc', 'summ_stats_all_favs_desc', 'Summary Statistics All Retweets / Desc', 'summ_stats_all_rts_desc']]

# Create the pandas DataFrame 
# quant_stats_measures_1 = pd.DataFrame(quant_stats_1_pairs, columns = ['Measures of Centrality', 'Measures of Variability', 'General User Stats', 'Other Stats']) 

# quant_stats_measures_1.to_csv('4_5A_170_SMI1_Quant_Stats_Measures_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# quant_stats_measures_1.to_excel('4_5A_170_SMI1_Quant_Stats_Measures.xlsx', header=True)

### NEED TO DO PLOT?????????????????

############################################################################################################

### FROM tweets_words ABOVE

print('---')
print('Loading Libs 70')
print('---')

fdist_2 = FreqDist(word)
# print(fdist_2)

fdist_2.most_common(10)

print('---')
print('Frequency Distribution of Tweets_words - Most Common 10')
print(fdist_2.most_common(10))
print('---')

df_fdist_2_df = pd.DataFrame([fdist_2])

df_fdist_2_df.to_csv('4_5A_171_SMI1_Word_Freq_Dist_CSV.csv', sep=';', encoding='utf-8', index=True)
# df_fdist_2_df.to_excel('4_5A_171_SMI1_Word_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# NEED TO DO - TABLE PLOT 

# PLOT

# Frequency Distribution Plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tweets_words')
# fdist_2.plot(10,cumulative=False, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_171_SMI1_Word_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Word Frequency Distribution - Box')
# plt.plot(FreqDist(word))
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_171_SMI1_Word_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))      ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Word Frequency Distribution - Pie')
# plt.pie(FreqDist(word)[:6], labels=FreqDist(word), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(FreqDist(word), bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
# plt.show()
plt.savefig('4_5A_171_SMI1_Word_Freq_Dist_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

###############################################################################################################


# Summary Statistics of all screenNames          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_screenname = tweets_smi_1['screenName'].describe()

print('---')
print('Summary Statistics of All ScreenNames')
print(tweets_smi_1['screenName'].describe().head)
print('---')

smi1_screenname_describe_df = pd.DataFrame(smi1_screenname)

smi1_screenname_describe_df.to_csv('4_5A_172_SMI1_Screenname_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot NEED TO DO

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All ScreenNames')
plt.plot(tweets_smi_1['hashtags'].describe())
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_172_SMI1_ScreenName_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# PIE PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All ScreenNames - Pie')
# plt.pie(tweets_smi_1['hashtags'].describe(), colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweets_smi_1['hashtags'].describe(), bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)
# plt.legend(smi1_hashtags, loc=3)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_172_SMI1_ScreenName_Describe_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

##########################################################################################################

# Summary Statistics of all Text          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_text = tweets_smi_1['text'].describe()

print('---')
print('Summary Statistics of All Text')
print(smi1_text.describe().head)
print('---')

smi1_text_describe_df = pd.DataFrame(smi1_text)

smi1_text_describe_df.to_csv('4_5A_173_SM1_Text_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot NEED TO DO

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Text')
# plt.plot(smi1_hashtags.describe())
# plt.plot(smi1_text_describe_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_173_SMI1_Text_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO

############################################################################################################


# missing_hashtags_1

# Summary Statistics of all Hashtags          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_hashtags = tweets_smi_1['hashtags'].describe()

print('---')
print('Summary Statistics of All Hashtags')
# print(tweets_smi_1['missing_hashtags'].describe().head)
print('---')

smi1_hashtags_describe_df = pd.DataFrame([smi1_hashtags])

# smi1_missing_hashtags_describe_df.to_csv('4_5A_174_SMI1_missing_hashtags_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# smi1_missing_hashtags_describe_df.to_excel()

# PLOT TABLE ## NEED TO DO 

# plt.plot

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Mentions - Grouped')
# plt.plot(tweets_smi_1['missing_hashtags'].describe())
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_174_SMI1_missing_Hashtags_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO

############################################################################################################


# Summary Statistics of all Mentions          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_mentions.describe().head


# smi1_mentions_describe_df = pd.DataFrame(smi1_mentions.describe())

# smi1_mentions_describe_df.to_csv('4_5A_175_SM1_mentions_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of all Mentions - Grouped')
# plt.plot(smi1_mentions.describe())
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_175_SMI1_Mentions_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO


############################################################################################################

# Summary Statistics of all Emojis Unicode          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_emojis_unicode.describe().head

print('---')
print('Summary Statistics of All Emojis Unicode')
# print(smi1_emojis_unicode.describe())
print('---')


# smi1_emojis_unicode_describe_df = pd.DataFrame(smi1_emojis_unicode.describe())

# smi1_emojis_unicode_describe_df.to_csv('4_5A_176_SM1_Emojis_Unicode_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Emojis Unicode - Grouped')
# plt.plot(smi1_emojis_unicode_df.describe())
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_176_SMI1_Emojis_Unicode_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO

############################################################################################################


# Summary Statistics of all Emojis Converted          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_emojis_converted.describe().head

smi1_emojis_converted_describe_df = pd.DataFrame(smi1_emojis_converted.describe())

smi1_emojis_converted_describe_df.to_csv('4_5A_177_SMI1_Emojis_Converted_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO TABLE 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Emojis Converted - Grouped')
# plt.plot(smi1_emojis_converted_describe_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_177_SMI1_Emojis_Converted_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO

############################################################################################################

# This selects the top 5 highest average points among all Tweets:

# smi1_screenname.mean().sort_values(by="screenname",ascending=True).head  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

# smi1_screenname_describe_df = pd.DataFrame(smi1_screenname.mean().sort_values(by="screenname",ascending=True).describe())

# smi1_screenname_describe.to_csv('4_5A_178_SMI1_Screenname_Describe_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Average Points ScreenNames')
# plt.plot(smi1_screenname_mean_sort_values_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_178_SMI1_Screenname_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(20,10))
# plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Average Points ScreenNames - Pie')
# plt.pie(smi1_screenname_mean_sort_values_df[:6], colors=colors_blue, labels=smi1_screenname_mean_sort_values_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=smi1_screenname_mean_sort_values_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend(smi1_screenname_mean_sort_values_df, loc=3)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5A_178_SMI1_Screenname_Mean_Sort_Values_DF_Pie.png', bbox_inches='tight')
# plt.close(fig='all')
# plt.clf()

# BAR PLOT - NEED TO DO

############################################################################################################


# This selects the top 5 highest average points among all Tweets:

smi1_hashtags_mean_values = smi1_hashtags.mean().sort_values(by='hashtags',ascending=True)  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

smi1_hashtags_mean_sort_values = smi1_hashtags_mean_values.sort_values(by='hashtags',ascending=True)

smi1_hashtags_mean_sort_values_df = pd.DataFrame(smi1_hashtags_mean_sort_values)

smi1_hashtags_mean_sort_values_df.to_csv('4_5A_179_SMI1_Hashtags_Mean_Sort_Values_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Average Points Hashtags')
# plt.plot(smi1_hashtags_mean_sort_values_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_179_SMI1_Hashtags_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Average Points Hashtags - Pie')
plt.pie(smi1_hashtags_mean_sort_values_df[:6], colors=colors_blue, labels=smi1_hashtags_mean_sort_values_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_hashtags_mean_sort_values_df[:6], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend(smi1_hashtags_mean_sort_values_df, loc=3)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5A_179_SMI1_Hashtags_Mean_Sort_Values_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

############################################################################################################

# This selects the top 5 highest average points among all Tweets:

smi1_mentions.mean().sort_values(by='mentions',ascending=True).head  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

smi1_mentions_mean_sort_values_df = pd.DataFrame(smi1_mentions.mean().sort_values(by='mentions',ascending=True))

smi1_mentions_mean_sort_values_df.to_csv('4_5A_140_SMI1_Mentions_Mean_Sort_Values_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Average Points Mentions')
# plt.plot(smi1_mentions_mean_sort_values_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_140_SMI1_Mentions_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO

############################################################################################################

# This selects the top 5 highest average points among all Tweets:

# smi1_emojis_unicode.mean().sort_values(by='emojis_unicode',ascending=True).head  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

smi1_emojis_unicode_mean_sort_values_df = pd.DataFrame(smi1_emojis_unicode.mean().sort_values(by='emojis_unicode',ascending=True))

smi1_emojis_unicode_mean_sort_values_df.to_csv('4_5A_144_SMI1_Emojis_Unicode_Mean_Sort_Values_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Highest Average Points Emojis')
plt.plot(smi1_emojis_unicode_mean_sort_values_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_144_SMI1_Emojis_Unicode_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO

############################################################################################################


# This selects the top 5 highest average points among all Tweets:

# smi1_emojis_converted.mean().sort_values(by='emojis_converted',ascending=True).head  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

smi1_emojis_converted_sort_values_df = pd.DataFrame(smi1_emojis_converted.mean().sort_values(by='emojis_converted',ascending=True))

smi1_emojis_converted_mean_sort_values_df.to_csv('4_5A_145_SMI1_Emojis_converted_mean_Sort_Values_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Highest Average Emojis Converted')
plt.plot(smi1_emojis_converted_mean_sort_values_df[:10])
pplt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_145_SMI1_Emojis_Converted_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

############################################################################################################


# This selects the top 5 highest average points among all Tweets:

smi1_languages.mean().sort_values(by='language',ascending=True).head ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


smi1_languages_mean_sort_values_df = pd.DataFrame(smi1_languages.mean().sort_values(by='mentions',ascending=True))

smi1_languages_mean_sort_values_df.to_csv('4_5A_146_SMI1_Languages_Mean_Sort_Values_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Highest Average Languages')
plt.plot(smi1_languages_mean_sort_values_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_146_SMI1_Languages_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO


#############################################################################################################

############ NEED TO DO = WHAT ABOUT THE OTHER VARIABLES?????????

# List Unique Hashtags ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!


total_hashtags = tweets_smi_1['hashtags']    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_total_hashtags = len(total_hashtags)
number_total_hashtags

print('---')
print('List Total Hashtags')
print(number_total_hashtags)
print('---')

unique_hashtags = tweets_smi_1['hashtags'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_hashtags = len(unique_hashtags)
number_unique_hashtags

print('---')
print('List Unique Hashtags')
print(number_unique_hashtags)
print('---')


number_unique_hashtags_df = pd.DataFrame(number_unique_hashtags, columns=['number_unique_hashtags'])

number_unique_hashtags_df.to_csv('4_5A_147_SMI1_Number_Unique_Hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# number_unique_hashtags_df.to_excel('4_5A_147_SMI1_Number_Unique_Hashtags_DF.xlsx', header=True)

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Hashtags')
plt.plot(number_unique_hashtags_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_147_SMI1_Number_Unique_Hashtags_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Hashtags - Pie')
plt.pie(number_unique_hashtags_df[:6], colors=colors_blue, labels=number_unique_hashtags_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(number_unique_hashtags_df[:6], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend(number_unique_hashtags_df, loc=3)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5A_147_SMI1_Number_Unique_Hashtags_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

###############################################################################################################

# List Unique MISSING Hashtags ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!


hashtags_1 = pd.DataFrame(hashtags_1)
missing_unique_hashtags = hashtags_1.unique()

missing_number_unique_mentions = len(missing_unique_hashtags)
missing_number_unique_hashtags

print('---')
print('Missing Unique Hashtags')
# print(missing_number_unique_hashtags)
print('---')

missing_number_unique_hashtags_df = pd.DataFrame([missing_number_unique_hashtags])

missing_number_unique_hashtags_df.to_csv('4_5A_148_SMI1_Missing_Number_Unique_Hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Hashtags')
plt.plot(missing_number_unique_hashtags_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_148_SMI1_Missing_Number_Unique_Hashtags_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO

###############################################################################################################

# List Unique Mentions ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!

total_mentions = tweets_smi_1['mentions']   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_total_mentions = len(total_mentions)
number_total_mentions

print('---')
print('Number Total Mentions')
print(number_total_mentions)
print('---')

unique_mentions = tweets_smi_1['mentions'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_mentions = len(unique_mentions)
number_unique_mentions

print('---')
print('Number Unique Mentions')
print(number_unique_mentions)
print('---')

number_unique_mentions_df = pd.DataFrame([number_unique_mentions])

number_unique_mentions_df.to_csv('4_5A_149_SMI1_Number_Unique_Mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Mentions')
plt.plot(number_unique_mentions_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_149_SMI1_Number_Unique_Mentions_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO

###############################################################################################################


# List MISSING Unique Mentions ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!


mentions_1 = pd.DataFrame(mentions_1)
missing_unique_mentions = mentions_1.unique()

missing_number_unique_mentions = len(missing_unique_mentions)
missing_number_unique_mentions

print('---')
print('Missing Unique Number of Mentions')
# print(missing_number_unique_mentions)
print('---')

missing_number_unique_mentions_df = pd.DataFrame([missing_number_unique_mentions])

missing_number_unique_mentions_df.to_csv('4_5A_150_SMI1_Missing_Number_Unique_Mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Mentions')
plt.plot(missing_number_unique_mentions_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_150_SMI1_Missing_Number_Unique_Mentions_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO

###############################################################################################################

# List Unique Emojis Unicode

total_emojis_unicode = tweets_smi_1['emojis_unicode']    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_total_emojis_unicode = len(total_emojis_unicode)
number_total_emojis_unicode

print('---')
print('Number Unique Emojis Unicode')
print(number_unique_emojis_unicode)
print('---')

unique_emojis_unicode = tweets_smi_1['emojis_unicode'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_emojis_unicode = len(unique_emojis_unicode)
number_unique_emojis_unicode

print('---')
print('Number Unique Emojis Unicode')
print(number_unique_emojis_unicode)
print('---')

number_unique_emojis_unicode_df = pd.DataFrame([number_unique_emojis_unicode])

number_Unique_Emojis_Unicode_DF.to_csv('4_5A_151A_SMI1_Number_Unique_Emojis_Unicode_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Emojis Unicode')
plt.plot(number_unique_emojis_unicode_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_151A_SMI1_Number_Unique_Emojis_Unicode_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO


###############################################################################################################

# List Unique Emojis Unicode

total_emojis_unicode = tweets_smi_1['emojis_unicode']    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_total_emojis_unicode = len(total_emojis_unicode)
number_total_emojis_unicode

print('---')
print('Number Unique Emojis Unicode')
print(number_unique_emojis_unicode)
print('---')

unique_emojis_unicode = tweets_smi_1['emojis_unicode'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_emojis_unicode = len(unique_emojis_unicode)
number_unique_emojis_unicode

print('---')
print('Number Unique Emojis Unicode')
print(number_unique_emojis_unicode)
print('---')

number_unique_emojis_unicode_df = pd.DataFrame([number_unique_emojis_unicode])

number_unique_emojis_unicode_df.to_csv('4_5_151B_SMI1_Number_Unique_Emojis_Unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Emojis')
plt.ioff()
plt.plot(number_unique_emojis_unicode_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_151B_SMI1_Number_Unique_Emojis_Unicode_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

###############################################################################################################

# List Unique MISSING Emojis Unicode ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!


missing_emojis_unicode_1 = pd.DataFrame(missing_emojis_1)
missing_unique_emojis_unicode = missing_emojis_unicode_1.unique()

missing_number_unique_emojis_unicode = len(missing_unique_emojis_unicode)
missing_number_unique_emojis_unicode

print('---')
print('Missing Number Emojis Unicode')
# print(missing_number_unique_emojis_unicode)
print('---')

missing_number_unique_emojis_unicode_df = pd.DataFrame([missing_number_unique_emojis_unicode])

missing_number_unique_emojis_unicode_df.to_csv('4_5A_152_SMI1_Missing_Number_Unique_Emojis_Unicode_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to.excel()

## NEED TO PLOT - FIX!!! ADD TO ALL EMOJIS

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Emojis Unicode')
plt.plot(missing_number_unique_emojis_unicode_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_152_SMI1_Missing_Number_Unique_Emojis_Unicode_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO

###############################################################################################################

# List Unique Emojis Converted

unique_emojis_converted = tweets_smi_1['emojis_converted'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_emojis_converted = len(unique_emojis_converted)
number_unique_emojis_converted

print('---')
print('Number Unique Emojis Converted')
print(number_unique_emojis_converted)
print('---')

number_unique_emojis_converted_df = pd.DataFrame([number_unique_emojis_converted])

number_unique_emojis_converted_df.to_csv('4_5A_153_SMI1_Number_Unique_Emojis_Converted_DF_CSV.csv', sep=';', encoding='utf-8', index=True)

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Emojis Converted')
plt.plot(number_unique_emojis_converted_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_153_SMI1_Number_Unique_Emojis_Converted_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO


#####################################

# initialize list of Lists 
numbers_more_values = [['Values for Hashtags', number_total_hashtags, number_unique_hashtags], ['Values for Mentions', number_total_mentions, number_unique_mentions], ['Values for Emojis', number_total_emojis_unicode, number_unique_emojis_unicode]] 
 
# Create the pandas DataFrame 
numbers_hashtags_df = pd.DataFrame(numbers_more_values, columns = ['total_values', 'unique_values']) 

numbers_hashtags_df.to_csv('4_5A_154_SMI1_More_Values_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# numbers_hashtags_df.to_excel('4_5A_154_SMI1_More_Values.xlsx', header=True)

###############################################################################################################

# List Unique Language

unique_languages = tweets_smi_1['language'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_unique_languages = len(unique_languages)
number_unique_languages

print('---')
print('Number Unique Languages')
print(number_unique_languages)
print('---')

number_unique_languages_df = pd.DataFrame([number_unique_languages])

number_unique_languages_df.to_csv('4_5A_154_SMI1_Number_Unique_Languages_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Unique Languages')
plt.plot(number_unique_languages_df[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_154_SMI1_Number_Unique_Languages_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

# PIE PLOT - NEED TO DO

# BAR PLOT - NEED TO DO



#######################################################################################


# https://tutswiki.com/pandas-cookbook/chapter2/

# DATES WITH MOST Tweets

# This is necessary to show lots of columns in pandas 0.12. 
# Not necessary in pandas 0.13.
# pd.set_option('display.width', 5000) 
# pd.set_option('display.max_columns', 60)

# plt.rcParams['figure.figsize'] = (15, 5)

#####################################################################################################

# Most Common Tweet Date

# METHOD 1

value_counts_date = pd.value_counts(tweets_smi_1['created'], ascending=False, normalize=True)

def get_counts(sequence):  
	counts = defaultdict(int) # values will initialize to 0  
	for x in sequence:    
		counts[x] += 1  
	return counts


def top_counts(count_dict, n=10):  
	value_key_pairs = [(count, tz) for tz, count in count_dict.items()]  
	value_key_pairs.sort()  
	return value_key_pairs[-n:] 

counts_created_1 = get_counts(tweets_smi_1['created'])

top_counts_created_1 = top_counts(counts_created)

print('---')
print('Most Common Tweet Date - 1C')
# print('counts_created_1')
print('---')

##############################################

# METHOD 2

counts_created_2 = Counter(tweets_smi_1['created'])

print('---')
print('Most Common Tweet Date - 2C')
# print('counts_created_2')
print('---')

###########################################################


### NEED TO PLOT

# SAVE TO CSV   ######################################  NEED TO SAVE DATE ON FIRST COLUMN / SECOND COUNT

value_counts_date.to_csv('4_5A_160_SMI1_C_df_Top_Dates_and_No_Tweets_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# value_counts_date = value_counts_date.to_excel('4_5A_160_SMI1_C_df_Top_Dates_and_No_Tweets.xlsx', header=True) # Only argument is a string of the output file path


# value_counts_date

print('---')
print('Value Counts Date')
# print(value_counts_date)
print('---')

# TABLE PLOT NEED TO DO 

# PIE PLOT NEED TO DO

# BAR PLOTS

# TOP DATES WITH TWEET COUNT

top_dates_tweets = value_counts_date.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Dates Where Users Activity for an SMI - Bars')
top_dates_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Dates')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_160_C_SMI1_Top_Tweet_Dates_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################################


## NEED TO DO FAVS AND Retweets FOR THOSE DATES!!

# _df _df = pd.DataFrame()

# .to_csv('4_5A_.csv', sep=';', encoding='utf-8', index=True)
# excel

#####################################################################################################

# TREEMAPS

# Treemap Plotting


# Large plot
# matplotlib.rcParams['figure.figsize'] = (16.0, 9.0)

# Use ggplot style

style.use('ggplot') 

# BY Favorites

treemap_favs = tweets_smi_1.sort_values(by='favorites', ascending=False)

# Find Percentage

treemap_favs['fav_percentage'] = round(100 * treemap_favs['network_weight'] / sum(treemap_favs['network_weight']), 2)

# Create Treemaps Labels

treemap_favs['text'] = treemap_favs['text'] + '(' + treemap_favs['fav_percentage'].astype('str') + '%)'

print('---')
print('Tree Maps Favs 3')
print(treemap_favs['fav_percentage'].head(10)) ## NEED TO DO - FIX
print('---')

# Get Axis and Figure

fig, ax = plt.subplots()

# Colormap

# cmap = matplotlib.cm.coolwarm

# Min and Max Values

mini_favs = min(treemap_favs['network_weight'])
maxi_favs = max(treemap_favs['network_weight'])

# Finding Colors for each tile

# norm_favs = plt.colors.Normalize(vmini=mini_favs, vmax=maxi_favs)
colors = [cmap(norm(value)) for value in treemap_favs['network_weight']]

# Plotting


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()
# squarify.plot(sizes=treemap_favs['network_weight'], label=treemap_favs['text'], alpha=0.8, color=colors)

# Removing Axis

plt.axis('off')

# Invert Y-Axis

plt.gca().invert_yaxis()     ############## NEED TO FIX

# NEED TABLE AND SAVE TO EXCEL AND CSV - NEED TO DO

# PIE PLOT ## NEED TO DO - NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Texts by Favorites- Pie') # fontsize=32
plt.pie(treemap_favs)
# plt.legend(treemap_fav, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# plt.show()
plt.savefig('4_5A_121_SMI1_10_3_Most_Repeteaded_Tweet_Text_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BARS PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Texts by Favorites - Bars') # fontsize=32
treemap_favs.plot.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_121_SMI1_10_3_Most_Repeteaded_Tweet_Text_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PLOT ## NEED TO DO - NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Texts by Favorites') # fontsize=32
plt.plot(treemap_favs)
# plt.legend(treemap_fav, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# plt.show()
plt.savefig('4_5A_121_SMI1_10_3_Most_Repeteaded_Tweet_Text_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/


# Most Common Tweet Text

value_counts_text = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True)

df_value_counts_text = pd.DataFrame([value_counts_text])

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

df_value_counts_text.to_csv('4_5A_122_4_SMI1_df_Top_Text_and_No_Tweets_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# df_value_counts_text.to_excel('4_5A_122_4_SMI1_df_Top_Text_and_No_Tweets.xlsx', header=True)

## NEED TO PLOT

# value_counts_text

print('---')
print('Most Common Tweet Text 4')
print(value_counts_text)
print('---')

## NEED TO DO FAVS AND Retweets FOR THEM!!!

# NEED TO DO TABLE PLOT

# PIE PLOT ## NEED TO DO - NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Content of Text - Pie') # fontsize=32
# plt.pie(top_texts_tweets[:6])
# plt.legend(top_texts_tweets[:6], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_122_4_SMI1_10_Most_Repeteaded_Tweet_Text_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOTS 

# MOST FREQUENT TEXT IN Tweets

top_texts_tweets = value_counts_text.sort_values(ascending=False)

print('---')
print('Most Frequent Complete Text in Tweets - Bars')
# print(value_counts_text.sort_values(ascending=False))
print('---')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Content of Text - Bars')
top_texts_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Most Repeated / Shared / Text Content')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_122_4_SMI1_10_Most_Repeteaded_Tweet_Text_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PLOT ## NEED TO DO - NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Content of Text') # fontsize=32
plt.plot(top_texts_tweets[:6])
# plt.legend(top_texts_tweets[:6], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_122_4_SMI1_10_Most_Repeteaded_Tweet_Text_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/


# Most Common Hashtags

value_counts_hashtags = pd.value_counts(tweets_smi_1['hashtags'], ascending=False, normalize=True)

## NEED TO PLOT

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_hashtags.to_csv('4_5A_123_SMI1_df_Top_Hashtags_and_No_Tweets_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# value_counts_hashtags.to_excel('4_5A_123_SMI1_df_Top_Hashtags_and_No_Tweets.xlsx', header=True)

value_counts_hashtags

print('---')
print('---Most Common Hashtags')
# print(pd.value_counts(tweets_smi_1['hashtags'], ascending=False, normalize=True))
print('---')

# TABLE AND FRAME DF NEED TO DO 

# PIE PLOT NEED TO DO 

# BAR PLOTS 

# MOST FREQUENT HASHTAGS IN Tweets

top_hashtags_tweets = value_counts_hashtags.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Hashtags - Bars')
top_hashtags_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Most Repeated / Shared / Hashtags')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_123_SMI1_10_Most_Repeteaded_Hashtags_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### NEED TO PUT FAVS AND RTS!!!

# _df _df = pd.DataFrame()

# .to_csv('4_5A_.csv', sep=';', encoding='utf-8', index=True)
# excel

###############################################################################################################

# BAR PLOTS

# TOP NUMBERS OF HASHTAGS IN Tweets 

top_hashtags_tweets = value_counts_hashtags.sort_values(ascending=False)

print('---')
print('Most Common Tweet Hashtags')
# print(pd.value_counts(tweets_smi_1['hashtags'], ascending=False, normalize=True))
print('---')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Hashtags Used - Bars')
top_hashtags_tweets[:10].plot.bar(alpha=0.9)
plt.xticks(rotation=50)
plt.xlabel('Hashtags')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_124_SMI1_Top_Tweet_Hashtags_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')

top_hashtags_tweets_df = pd.DataFrame(top_hashtags_tweets)

top_hashtags_tweets_df.to_csv('4_5A_124_SMI1_Top_Hashtags_Tweets_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Common Tweet Mentions

value_counts_mentions = pd.value_counts(tweets_smi_1['mentions'], ascending=False, normalize=True)
value_counts_mentions


# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_mentions.to_csv('4_5A_147_SMI1_df_Top_Mentions_and_No_Tweets_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# value_counts_mentions.to_excel('4_5A_147_SMI1_df_Top_Mentions_and_No_Tweets.xlsx', header=True)


print('---')
print('Most Common Tweet Mentions')
# print(pd.value_counts(tweets_smi_1['mentions'], ascending=False, normalize=True))
print('---')

top_mentions_tweets_df = pd.DataFrame(top_mentions_tweets)

top_mentions_tweets_df.to_csv('4_5A_148_SMI1_Top_mentions_tweets_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
#.to_ excel()

# TABLE PLOT NEED TO DO 

# PIE PLOT ###### NEED TO DO

# BAR PLOTS

# TOP NUMBERS OF MENTIONS IN Tweets 

top_mentions_tweets = value_counts_mentions.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Mentions Used - Bars')
top_mentions_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Mentions')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_148_SMI1_Top_Tweet_Mentions_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/


# Most Commons Emojis Unicode

value_counts_emojis_unicode = pd.value_counts(tweets_smi_1['emojis_unicode'], ascending=False, normalize=True)
value_counts_emojis_unicode

print('---')
print('Most Commons Emojis Unicode')
# print(value_counts_emojis_unicode)
print('---')

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_emojis_unicode.to_csv('4_5A_149_SMI1_df_Top_Emojis_Unicode_and_No_Tweets_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# value_counts_emojis_unicode.to_excel('4_5A_149_SMI1_df_Top_Emojis_Unicode_and_No_Tweets.xlsx', header=True)

## NEED TO PLOT

##########################################################################################################

top_emojis_unicode_tweets_df = pd.DataFrame(top_emojis_unicode_tweets)

top_emojis_unicode_tweets_df.to_csv('4_5A_150_SMI1_Top_Emojis_Unicode_Tweets_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# NEED TO DO PIE PLOT

# PLOT BARS

# TOP NUMBERS OF EMOJIS UNICODE IN Tweets 

top_emojis_unicode_tweets = value_counts_emojis_unicode.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis - Bars')
top_emojis_unicode_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_150_SMI1_Top_Tweet_Emojis_Unicode_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################################

## nEED TO DO --------- FAVS AND RTS!!!

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Commons Emojis Converted

value_counts_emojis_converted = pd.value_counts(tweets_smi_1['emojis_converted'], ascending=False, normalize=True)
value_counts_emojis_converted

print('---')
print('Most Common Emojis - Converted')
# print(value_counts_emojis_converted)
print('---')

top_emojis_converted_tweets_df = pd.DataFrame(top_emojis_converted_tweets)

top_emojis_converted_tweets_df.to_csv('4_5A_151_SMI1_Top_Emojis_Converted_Tweets_df_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_emojis_converted.to_csv('4_5A_151_SMI1_df_Top_Emojis_Converted_and_No_Tweets_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# value_counts_emojis_converted.to_excel('4_5A_151_SMI1_df_Top_Emojis_Converted_and_No_Tweets.xlsx', header=True)


## NEED TO PLOT

# BAR PLOTS

# TOP NUMBERS OF EMOJIS CONVERTED IN Tweets 

top_emojis_converted_tweets = value_counts_emojis_converted.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis - Bars')
top_emojis_converted_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_151_SMI1_Top_Tweet_Emojis_Converted_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/


# Most Common Tweet Languages

value_counts_language = pd.value_counts(tweets_smi_1['language'], ascending=False, normalize=True)

## NEED TO PLOT

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_language.to_csv('4_5A_155_SMI1_df_Top_Language_and_No_Tweets_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# value_counts_language.to_excel('4_5A_155_SMI1_df_Top_Language_and_No_Tweets.xlsx', header=True)

value_counts_language

print('---')
print('Most Common Tweet Languages')
# print(value_counts_language)
print('---')

percentage_tweets_language_df = pd.DataFrame(percentage_tweets_language)


## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets Languages - Pie')
# plt.pie(percentage_tweets_language[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentage_tweets_language[:6], autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(percentage_tweets_language, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5A_155_SMI1_Percentage_Tweets_Language_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOTS

# TOP NUMBERS OF LANGUAGE IN Tweets 

top_languages_tweets = value_counts_language.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Common Languages Used - Bars')
top_languages_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_155_SMI1_Top_Tweet_Languages_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################

# PERCENTAGE OF Tweets BY TOP USERS

percentage_tweets_screenname = (tweets_smi_1['screenName'].value_counts(normalize=True) * 100)
percentage_tweets_screenname

print('---')
print('Percentage of Tweets by Top Users - ScreenName')
# print(percentage_tweets_screenname)
print('---')

percentage_tweets_screenname_df = pd.DataFrame(percentage_tweets_screenname)

percentage_tweets_screenname_df.to_csv('4_5A_157_SMI1_Percentage_Tweets_Screenname_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets by ScreenName - Pie')
# plt.pie(percentage_tweets_screenname[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentage_tweets_screenname[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(percentage_tweets_screenname, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5A_157_SMI1_Percentage_Tweets_ScreenName_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO

########################################################################################################

# PERCENTAGE OF Tweets WITH Retweets

percentage_tweets_retweets = (tweets_smi_1['retweets'].value_counts(normalize=True) * 100)

print('---')
print('Percentage of Tweets with Retweets')
# print(percentage_tweets_retweets)
print('---')

percentage_tweets_retweets_df = pd.DataFrame(percentage_tweets_retweets)

percentage_tweets_retweets_df.to_csv('4_5A_158_SMI1_Percentage_Tweets_Retweets_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Retweets - Pie')
# plt.pie(percentage_tweets_retweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentage_tweets_retweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(percentage_tweets_retweets, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5A_158_SMI1_Percentage_Tweets_Retweets_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO

########################################################################################################

# PERCENTAGE OF Tweets WITH HASHTAGS

percentage_tweets_hashtags = (tweets_smi_1['hashtags'].value_counts(normalize=True) * 100)
percentage_tweets_hashtags

print('---')
print('Percentage of Tweets with Hashtags')
# print(percentage_tweets_hashtags)
print('---')

percentage_tweets_hashtags_df = pd.DataFrame(percentage_tweets_hashtags)

percentage_tweets_hashtags_df.to_csv('4_5A_159_SMI1_Percentage_Tweets_Hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

## NEED TO PLOT

# TABLE PLOT NEED TO DO

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Hashtags - Pie')
# plt.pie(percentage_tweets_hashtags[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentage_tweets_hashtags[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(percentage_tweets_hashtags, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5A_159_SMI1_Percentage_Tweets_Hashtags_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT 

# NEED TO DO

########################################################################################################

percentage_tweets_screenname = (tweets_smi_1['screenName'].value_counts(normalize=True) * 100)
percentage_tweets_screenname

# PERCENTAGE OF Tweets WITH EMOJIS_UNICODE

print('---')
print('Percentage of Tweets with Emojis - Unicode')
# print(percentage_tweets_emojis_unicode)
print('---')


## NEED TO PLOT 

percentage_tweets_emojis_unicode_df = pd.DataFrame(percentage_tweets_emojis_unicode)

percentage_tweets_emojis_unicode_df.to_csv('4_5A_160_SMI1_Percentage_Tweets_Emojis_Unicode_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Emojis Unicode - Pie')
# plt.pie(percentage_tweets_emojis_unicode[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentage_tweets_emojis_unicode[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(percentage_tweets_emojis_unicode, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_160_SMI1_Percentage_Tweets_Emojis_Unicode_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO

########################################################################################################

# PERCENTAGE OF Tweets WITH EMOJIS_CONVERTED

percentage_tweets_emojis_converted = (tweets_smi_1['emojis_converted'].value_counts(normalize=True) * 100)
percentage_tweets_emojis_converted

print('---')
print('Percentage of Tweets with Emojis Converted')
# print(percentage_tweets_emojis_converted)
print('---')

percentage_tweets_emojis_converted_df = pd.DataFrame(percentage_tweets_emojis_converted)

percentage_tweets_emojis_converted_df.to_csv('4_5A_161_SMI1_Percentage_Tweets_Emojis_Converted_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Emojis Converted - Pie')
# plt.pie(percentage_tweets_emojis_converted[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentage_tweets_emojis_converted[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(percentage_tweets_emojis_converted, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_161_SMI1_Percentage_Tweets_Emojis_Converted_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')

# BAR PLOT # NEED TO DO

########################################################################################################

# PERCENTAGE OF Tweets WITH IMAGES

percentage_tweets_image_link = (tweets_smi_1['image_link'].value_counts(normalize=True) * 100)
percentage_tweets_image_link

print('---')
print('Percentage of Tweets with Image Link')
# print(percentage_tweets_image_link)
print('---')

percentage_tweets_image_link_df = pd.DataFrame(percentage_tweets_image_link)

percentage_tweets_image_link_df.to_csv('4_5_162_SMI1_Percentage_Tweets_Image_Link_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets with Image Link - Pie')
# plt.pie(percentage_tweets_image_link[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentage_tweets_image_link[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentage_tweets_image_link, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_162_SMI1_Percentage_Tweets_Image_Link_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO




########################################################################################################

# PERCENTAGE OF LANGUAGES

percentage_tweets_languages = (tweets_smi_1['language'].value_counts(normalize=True) * 100)
percentage_tweets_languages

print('---')
print('Percentage of Tweets Languages')
# print(percentage_tweets_languages)
print('---') 

percentage_tweets_languages_df = pd.DataFrame(percentage_tweets_languages)

percentage_tweets_languages_df.to_csv('4_5A_163_SMI1_Percentage_Tweets_Languages_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# percentage_tweets_languages_df.to_excel()

# TABLE PLOT NEED TO DO 

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Tweets Languages - Pie')
# plt.pie(percentages_tweets_languages[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentage_tweets_languages[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(percentage_tweets_languages, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_165_SMI1_Percentage_Tweets_Languages_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO

########################################################################################################

# PLOT PERCENTAGES MEASURES Favorites, Retweets, MENTIONS, HASHTAGS, EMOJIS, IMAGE_LINKLANGUAGES   ### NEED TO DO

# List of List  ########## NEED TO DO DATAFRAME

percentages_of_measures_df = pd.DataFrame(percentages_of_measures)

print('---')
print('Percentage of Measures')
# print('percentages_of_measures')
print('---')


percentages_of_measures_df.to.csv('4_5A_164_SMI1_Percentages_of_Measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentages of Measures - Pie')
# plt.pie(percentages_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentages_of_measures_df[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(percentages_of_measures_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_164_SMI1_Percentages_of_Measures_df_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO

################################################ NEED TO DO TABLE WITH COUNTS AND PERCENTAGES OF THE ABOVE!!!!!!

# _df _df = pd.DataFrame()

# .to_csv('4_5A_.csv', sep=';', encoding='utf-8', index=True)
# excel

############################################################################################################

# https://matplotlib.org/3.1.1/gallery/pie_and_polar_charts/pie_and_donut_labels.html#sphx-glr-gallery-pie-and-polar-charts-pie-and-donut-labels-py
# https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplt.pie.html

##############################################################################################################

# PIE CHART : PERCENTAGE OF Favorites / Top

percentages_favorites_tweets = tweets_smi_1['favorites'].size().sort_values(ascending=False)

print('--')
print('Percentage of Favorite Tweets')
# print(percentages_favorites_tweets)
print('--')

percentages_favorites_tweets_df = pd.DataFrame(percentages_favorites_tweets)

percentages_favorites_tweets_df.to_csv('4_5A_165_SMI1_Percentages_Favorites_Tweets_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# to_excel()

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Favorites - Pie')
# plt.pie(percentages_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentages_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(percentages_favorites_tweets, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_165_SMI1_Percentages_Favorites_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

####################################################################################################################

# https://plot.ly/python/pie-charts/

# PIE CHART : PERCENTAGE OF Retweets / Top

percentages_retweets_tweets = tweets_smi_1['retweets'].size().sort_values(ascending=False)


print('--')
print('Percentage of retweets - Top')
# print(smi1_retweets.size().sort_values(ascending=False))
print('--')

percentages_retweets_tweets_df = pd.DataFrame(percentages_retweets_tweets)

percentages_retweets_tweets_df.to_csv('4_5A_167_SMI1_Percentages_Retweets_tweets_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# to_excel()

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Retweets - Pie')
# plt.pie(percentages_retweets_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentages_retweets_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(percentages_retweets_tweets, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_167_SMI1_Percentage_retweets_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO


####################################################################################################################
########################################################################################################

# PIE CHART: PERCENTAGE OF HASHTAGS

smi1_hashtags_size_sort_values_df = pd.DataFrame(smi1_hashtags.size().sort_values(ascending=False))

smi1_hashtags_size_sort_values_df.to_csv('4_5A_169_SMI1_Hashtags_size_sort_values_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Hashtags - Pie')
plt.pie(smi1_hashtags.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(smi1_hashtags, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_169_SMI1_Percentage_Hashtags_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')

# BAR PLOT # NEED TO DO


########################################################################################################

# PIE CHART: PERCENTAGE OF MENTIONS ## NEED TO FIX


smi1_mentions_size_sort_values_df = pd.DataFrame(tweets_smi_1['mentions'].size().sort_values(ascending=False))

smi1_mentions_size_sort_values_df.to_csv('4_5A_170_SMI1_mentions_size_sort_values_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Mentions - Pie')
plt.pie(smi1_mentions.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(smi1_mentions, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
# centre_circle = plt.Circle((0,0),0.70,fc='white')
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_170_SMI1_Percentage_Mentions_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')

# BAR PLOT # NEED TO DO

########################################################################################################

# PIE CHART: PERCENTAGE OF EMOJIS_UNICODE ## NEED TO FIX

smi1_emojis_unicode_size_sort_values_df = pd.DataFrame(tweets_smi_1['emojis_unicode'].size().sort_values(ascending=False))

smi1_emojis_unicode_size_sort_values_df.to_csv('4_5A_170_SMI1_emojis_unicode_size_sort_values_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Emojis - Pie')
plt.pie(smi1_emojis_unicode.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(smi1_emojis_unicode, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
# centre_circle = plt.Circle((0,0),0.70,fc='white')
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# plt.show()
plt.savefig('4_5A_172_SMI1_Percentage_Emojis_Unicode_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO

########################################################################################################

smi1_emojis_converted_size_sort_values_df = pd.DataFrame(tweets_smi_1['emojis_converted'].size().sort_values(ascending=False))

smi1_emojis_converted_size_sort_values_df.to_csv('4_5A_170_SMI1_Emojis_Converted_size_sort_values_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

# PIE CHART: PERCENTAGE OF EMOJIS_CONVERTED ## NEED TO FIX

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Emojis - Pie')
plt.pie(smi1_emojis_converted.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(smi1_emojis_converted, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
# centre_circle = plt.Circle((0,0),0.70,fc='white')
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_173_SMI1_Percentage_Emojis_Converted_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO 

########################################################################################################

# https://stackoverflow.com/questions/27898830/python-how-to-change-autopct-text-color-to-be-white-in-a-pie-chart
# https://medium.com/@kvnamipara/a-better-visualisation-of-pie-charts-by-matplotlib-935b7667d77f

# PIE CHART : PERCENTAGE OF LANGUAGES ## NEED TO FIX


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Languages - Pie')
plt.pie(smi1_languages.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(smi1_languages, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_174_SMI1_Percentage_Languages_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################################################################

# BAR PLOTS

# Number of Tweets / Date

# Prepare the data
created = tweets_smi_1.loc['created']
tweets_numbers = tweets_smi_1.loc['id']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Favorites / Time - Bars')
plt.plot(created, tweets_numbers, label='linear')
smi1_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_175_SMI1_Favorites_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


########################################################################################################

# BAR PLOTS

# Favorites


# Prepare the data

tweets_favs = tweets_smi_1.loc['network_weight']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Favorites / Time - Bars')
plt.plot(created, tweets_favs, label='linear')
# smi1_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_176_SMI1_Favorites_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


########################################################################################################

# BAR PLOTS

# Retweets


# Prepare the data
tweets_rts = tweets_smi_1.loc['retweets']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Retweets / Time - Bars')
plt.plot(created, tweets_rts, label='linear')
# tweets_rts.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_177_SMI1_Retweets_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

########################################################################################################

# BAR PLOTS

# HASTAGS


number_of_hashtags_in_tweets= tweets_smi_1.loc['hashtags']

# BAR PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Hashtags / Time - Bars')
# plt.plot(created, number_of_hashtags_in_tweets, label='linear')
smi1_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Count')
ax.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_178_SMI1_Hashtags_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


smi1_favorites.size_sort_values_df = pd.DataFrame(smi1_favorites.size().sort_values(ascending=False))

smi1_favorites.size_sort_values_df.to_csv('4_5A_178_SMI1_favorites.size_sort_values_df_CSV.csv', sep=';', encoding='utf-8', index=True)
# .to_excel()

########################################################################################################

# MENTIONS PLOTS BAR

# MENTIONS

number_of_mentions_in_tweets = tweets_smi_1.loc['mentions']


# Plot the data ## NEED TO FIX 

# TABLE PLOT NEED TO DO 
# BAR PLOT NEED TO DO

# BAR PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Mentions / Time - Bars')
smi1_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Number of Mentions')
plt.plot(created, number_of_mentions_in_tweets, label='linear')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_179_SMI1_Mentions_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


number_of_mentions_in_tweets = pd.DataFrame([number_of_mentions_in_tweets])

number_of_mentions_in_tweets.to_csv('4_5A_179_SMI1_Number_of_Mentions_in_Tweets_CSV.csv')
# .to_excel()

########################################################################################################

# LINE PLOTS

# Numer of Retweets / Favorites

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# Plot with differently-colored markers.
plt.plot(created, tweets_rts, 'b-', label='Retweets')
plt.plot(created, tweets_favs, 'r-', label='Favorites')

# Create legend.
# plt.legend(loc='upper left')
plt.xlabel('Year')
plt.ylabel('Retweets / Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_180_SMI1_Retweets_VS_Favorites_Time_Line_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# # https://www.datacamp.com/community/tutorials/wordcloud-python

# PIE PLOT NEED TO DO

# BAR PLOT

# Number of Favorites of Tweets

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Favorites - Bars')
smi1_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)

# plt.show()
plt.savefig('4_5A_180_SMI1_Number_Favorites_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


########################################################################################################


# # https://www.datacamp.com/community/tutorials/wordcloud-python  ## NEED TO DO PLOT 2 VARIABLE!!!!!!!!

# BAR PLOT
 
# Number of Favorites / Retweets of Tweets

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Favorites / Retweets - Bars')
smi1_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Favorites / Retweets')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_181_SMI1_Number_Favorites_Retweets_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################


# # https://www.datacamp.com/community/tutorials/wordcloud-python

# BAR PLOT

# Number of Retweets of Tweets

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Retweets - Bars')
smi1_retweets.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Retweets')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
ax.grid(True)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_182_SMI1_Number_Retweets_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################

# # https://www.datacamp.com/community/tutorials/wordcloud-python

# BAR PLOT

# Most Commom Languages 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Languages - Bars')
smi1_languages.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
 
# plt.show()
plt.savefig('4_5A_183_SMI1_Language_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################################


df_tweets_smi_processes_tokens_1 = tweets_words

df_tweets_smi_processes_tokens_1_fdist = FreqDist(df_tweets_smi_processes_tokens_1)
print(df_tweets_smi_processes_tokens_1_fdist)

df_tweets_smi_processes_tokens_1_fdist_most_common_2 = df_tweets_smi_processes_tokens_1_fdist.most_common(2)

## NEED TO PLOT????????????

print('--')
print('Word Frequency Distribution')
print(df_tweets_smi_processes_tokens_1_fdist.most_common(2))
print('--')

df_tweets_smi_processes_tokens_1_fdist_most_common_2 = pd.DataFrame(df_tweets_smi_processes_tokens_1_fdist_most_common_2)

df_tweets_smi_processes_tokens_1_fdist_most_common_2.to_csv('4_5A_184_SMI1_df_Tweets_SMI_Processes_Tokens_1_fdist_most_common_CSV.csv')
# df_tweets_smi_processes_tokens_1_fdist_most_common_2.to_excel()

# TABLE PLOT NEED TO DO

# PIE PLOT NEED TO DO 

# PLOT

# Frequency Distribution Plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Word Frequencies')
SMI1_Word_Freq_Graph = df_tweets_smi_processes_tokens_1_fdist.plot(10,cumulative=False, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_184_SMI1_df_Tweets_SMI_Processes_Tokens_1_fdist_Most_Common.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# ourcodingclub.github.io/tutorials/topic-modelling-python/

# Hashtag Correlations

# Take the rows from the hashtag colum 

# hashtags_list_df = tweets_smi_1[tweets_smi_1.hashtags.apply(lambda hashtags_list: hashtags_list !=[]), ['hashtag']]

# Create a dataframe where each of the hashtags has its own row via list comprehension

flattened_hashtags_df = pd.DataFrame(
#	[hashtag in hashtags_list in hashtags_list_df.hashtags
	[hashtag in tweets_smi_1['hashtags']
#	for hashtag in hashtags_list], 
	for hashtag in tweets_smi_1['hashtags']],
	columns=['hashtag'])

# Number of Unique Hashtags

number_unique_hashtags = flattened_hashtags_df['hashtag'].unique().size

# Count the appereances of each hashtag

popular_hashtags = flattened_hashtags_df.groupby('hashtags').size()\
					 .reset_index('counts')\
					 .sort_values('counts', ascending=False)\
					 .reset_index(drop=True)



popular_hashtags.to_csv('4_5A_183_SMI1_Popular_Hashtags_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# popular_hashtags.to_excel('4_4_183_SMI1_Popular_Hashtags.xlsx', header=True)

# Number of total_favoritess each hashtag appears

hashtag_counts = flattened_hashtags_df.groupby('hashtags').size()\
					 .reset_index('counts')\
					 .counts


# Define bins for histogram

hashtags_bins = np.arrange(0,counts.max()+2, 5)-0.5

# Plot Histogram of tweet counts

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Popular Hashtags - Histogram')
plt.hist(hashtag_counts, bins = hashtags_bins)
plt.xlabels = np.arrange(1,hashtag_counts.max()+1, 1)
plt.xlabel('Hashtag Number of Appearances')
plt.ylabel('Frequency')
plt.yscale('log', nonposy='clip')
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_183_SMI1_popular_hashtags_Hist_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# TABLE ## NEED TO DO

# plot.legend()

# PIE PLOT 

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Popular Hashtags - Pie')
plt.pie(hashtag_counts, colors=colors_blue, labels=tweets_numbers_item_values_df['tweets_by_item_description'], startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.xlabel('Number of Repeated Retweets vs Unique Tweets')
# plt.ylabel('Count')
# plt.legend(labels=tweets_numbers_item_values_df['tweets_by_item_description'], bbox_to_anchor=(0.7, 0.7), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5A_183_SMI1_Popular_Hashtags_PLT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT ## NEED TO DO # FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Popular Hashtags - Bars')
hashtag_counts.plot.bar
plt.xlabel('Hashtags')
plt.ylabel('Frequency')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_183_SMI1_popular_hashtags_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###############################################################################################################
#
#                      CLUSTER ANALYSIS AND TIME SERIES ###################### NEED TO DO!!!!!!!!!!!
#
###############################################################################################################

############################################################################################

# ADD IMAGE LINK FIELD  

# METHOD 1  ######## Need to fix

# total_favorites_zones = [rec['tz'] for rec in records if 'tz' in rec]
# total_favorites_zones[:10]

# def get_counts(sequence):
#    counts = {}
#    for x in sequence:
#        if x in counts:
#            counts[x] += 1
#        else:
#            counts[x] = 1
#    return counts


# def get_counts2(sequence):
#    counts = defaultdict(int) # values will initialize to 0
#    for x in sequence:
#        counts[x] += 1
#   return counts

###################

def top_counts(count_dict, n=10):
    value_key_pairs = [(count, tz) for tz, count in count_dict.items()]
    value_key_pairs.sort()
    return value_key_pairs[-n:] 

# top_counts(counts)

###########

# METHOD 3

# counts = Counter(total_favorites_zones)

# counts.most_common(10)

############################################################################################################
##############################################################################################################################################

# Lexicon Normalization

# Lexicon normalization considers another type of noise in the text. For example, connection, connected, connecting word reduce to a 
# common word "connect". It reduces derivationally related forms of a word to a common root word.

# Stemming

# Stemming is a process of linguistic normalization, which reduces tweets_words to their word root word or chops off the derivational affixes. 
# For example, connection, connected, connecting word reduce to a common word "connect".

# The most common algorithm for stemming English, and one that has repeatedly been shown to be empirically very effective, is Porter’s algorithm
# (Porter 1980). The entire algorithm is too long and intricate to present here, but we will indicate its general nature. Porter’s algorithm consists of 5 phases
# of word reductions, applied sequentially. Within each phase there are various conventions to select rules, such as selecting the rule from each rule
# group that applies to the longest suffix. In the first phase, this convention is used with the Following rule group:

# (2.1) Rule Example
# SSES → SS caresses → caress
# IES → I ponies → poni
# SS → SS caress → caress
# S → cats → cat


print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

# STEMMING ## NEED TO DO 

tweets_text_words_porter = PorterStemmer().stem(tweets_text_words)  #### NOT WORKING NEED TO DO 

tweets_text_words_lancaster = LancasterStemmer().stem(tweets_text_words) #### NOT WORKING NEED TO DO

tweets_text_words_snowball = SnowballStemmer('english').stem(tweets_text_words)

# Initialize the List

tweets_text_words_stemmer = (['Porter', tweets_text_words_porter], ['Lancaster', tweets_text_words_lancaster], ['Snowball', tweets_text_words_snowball])

print('---')
print('Stemming Method Head')
print(tweets_text_words_stemmer_df.head)
print('---')

# Create the pandas DataFrame 
tweets_text_words_stemmer_df = pd.DataFrame(selected_tweets_words_counts, columns = ['stemming_method', 'stems']) 

tweets_text_words_stemmer_df.to_csv('4_5A_210_SMI1_Tweets_Text_Words_Stemmer_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# tweets_text_words_stemmer_df.to_excel('4_5A_210_SMI1_Tweets_Text_Words_Stemmer_DF.xlsx', header=True)


# TABLE PLOT NEED TO DO 

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Stemmer Methods')
# tweets_text_words_stemmer_df.plot(10,cumulative=False, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_210_SMI1_Tweets_Text_Words_Stemmer_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Stemmer Methods - Pie')
# plt.pie(tweets_text_words_stemmer_df[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(tweets_text_words_stemmer_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_210_SMI1_Tweets_Text_Words_Stemmer_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT # NEED TO DO


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Stemmer Methods - Bars')
tweets_text_words_stemmers_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_210_SMI1_Tweets_Text_Words_Stemmer_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################################################################
###################################################################################################################

# DRAWING PARSE TREE ## NEED TO DO 

# USING NLTK 

# fp_text_c_tagged = nltk.pos_tag(fp_text_c_sentence_tokens)

# text_nltk = tweets_smi_1['text']
text_nltk = fp_text_c

tokenized_text=sent_tokenize(text_nltk)

tokenized_text_df = pd.DataFrame(tokenized_text)

print('---')
print(tokenized_text_df.head)
print('---')
# NEED TO DO ARRIBA?????

tokenized_text_df.to_csv('4_5A_211_SMI1_Tokenized_Sent_CSV.csv', sep=';', encoding='utf-8', index=True)
# tokenized_text_df.to_excel('4_5A_211_SMI1_Tokenized_Sent.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# tokenized_word=word_tokenize(fp_text_c)
tokenized_word= nltk.word_tokenize(fp_text_c)


fp_text_c_tagged = nltk.pos_tag(fp_text_c_sentence_tokens)


# PLOT  # NEED COUNT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentences')
# tokenized_text.plot(10,cumulative=False, alpha=0.9)
sns.distplot(tokenized_text)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_211_SMI1_Freq_Dist_Tokenized_Sentences.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentences - Pie')
# plt.pie(tokenized_text[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(tokenized_text, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5A_211_SMI1_Freq_Dist_Tokenized_Sentences_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOT # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentences - Bars')
# tokenized_text[:10].plot.bar(alpha=0.9)
plt.xlabel('Sentences')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_211_SMI1_Freq_Dist_Tokenized_Sentences_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################
####################################################################################################################
####################################################################################################################

# Pie: PERCENTAGE Retweets

smi1_retweets_size_sort_values_df = pd.DataFrame(smi1_retweets_size_sort_values)

smi1_retweets_size_sort_values_df.to_csv('4_4_208_SMI1_retweets_size_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Retweets - Pie')
plt.pie(smi1_retweets.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, radius=1.0, startangle=90, rotatelabels=False)
plt.legend(smi1_retweets, loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_208_SMI1_Percentage_Retweets_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO


########################################################################################################

# Pie: PERCENTAGE OF HASHTAGS

smi1_hashtags_size_sort_values_df = pd.DataFrame(tweets_smi_1['hashtags'].size().sort_values(ascending=False))

smi1_hashtags_size_sort_values_df.to_csv('4_4_209_SMI1_Hashtags_size_sort_values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Hashtags - Pie')
plt.pie(smi1_hashtags.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, radius=1.0, startangle=90, rotatelabels=False)
plt.legend(smi1_hashtags, loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_209_SMI1_Percentage_Hashtags_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO


########################################################################################################

# Pie: PERCENTAGE OF MENTIONS ## NEED TO FIX

smi1_mentions_size_sort_values_df = pd.DataFrame(tweets_smi_1['mentions'].size().sort_values(ascending=False))

smi1_mentions_size_sort_values_df.to_csv('4_4_210_SMI1_mentions_size_sort_values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Mentions - Pie')
plt.pie(smi1_mentions.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_mentions, loc='upper right', borderaxespad=0.)

# Draw circle
# centre_circle = plt.Circle((0,0),0.70,fc='white')
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_210_SMI1_Percentage_Mentions_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

# Pie: PERCENTAGE OF EMOJIS_UNICODE ## NEED TO FIX

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Emojis - Pie')
plt.pie(smi1_emojis_unicode.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_emojis_unicode, loc='upper right', borderaxespad=0.)

# Draw circle
# centre_circle = plt.Circle((0,0),0.70,fc='white')
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_212_SMI1_Percentage_Emojis_Unicode_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

# Pie: PERCENTAGE OF EMOJIS_CONVERTED ## NEED TO FIX

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Emojis - Pie')
plt.pie(smi1_emojis_converted.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_emojis_converted, loc='upper right', borderaxespad=0.)

# Draw circle
# centre_circle = plt.Circle((0,0),0.70,fc='white')
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_213_SMI1_Percentage_Emojis_Converted_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO 

########################################################################################################

# https://stackoverflow.com/questions/27898830/python-how-to-change-autopct-text-color-to-be-white-in-a-pie-chart
# https://medium.com/@kvnamipara/a-better-visualisation-of-pie-charts-by-matplotlib-935b7667d77f

# Pie : PERCENTAGE OF LANGUAGES ## NEED TO FIX

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Languages - Pie')
plt.pie(smi1_languages.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_languages, loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_214_SMI1_Percentage_Languages_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################################################################################################

###################################################################################################################
# towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24

# TOPIC MODELLING 

# LDA Latent Dirichhlet Allocation
                           

###################################################################################################################

# Word Statistics 

word_1 == 'love'
word_2 == 'hate'
word_3 == 'like' # NEED TO ADD LIKED
word_4 == 'brand'
word_5 == 'buy'
word_6 == 'fuck'
word_7 == 'thanks' # NEED TO ADD THANK YOU
word_8 == 'friend'
word_9 == 'follow'
word_10 == 'bitch'
word_11 == 'sister'
word_12 == 'video' # NEED TO ADD VIDEOS
word_13 == 'omg'
word_14 == 'good'
word_15 == 'bad'
word_16 == 'makeup'
word_17 == 'youtube'
word_18 == 'new'
word_19 == 'christmas'
word_20 == 'nigger'
word_21 == 'racist'
word_22 == 'homophobic'
word_23 == 'recommend'
word_24 == 'celebrity'
word_25 == 'review'

word_1_query = df.query('Text == word_1')
number_word_1 = word_1_query

word_2_query = df.query('Text == word_2')
number_word_2 = len(word_2_query)

word_3_query = df.query('Text == word_3')
number_word_3 = len(word_3_query)
  
word_4_query = df.query('Text == word_4')
number_word_4 = len(word_4_query)
 
word_5_query = df.query('Text == word_5')
number_word_5 = len(word_5_query)
 
word_6_query = df.query('Text == word_6')
number_word_6 = len(word_6_query)
 
word_7_query = df.query('Text == word_7')
number_word_7 = len(word_7_query)
 
word_8_query = df.query('Text == word_8')
number_word_8 = len(word_8_query)
 
word_9_query = df.query('Text == word_9')
number_word_9 = len(word_9_query)
 
word_10_query = df.query('Text == word_10')
number_word_10 = len(word_10_query)

word_11_query = df.query('Text == word_11')
number_word_11 = len(word_11_query)

word_12_query = df.query('Text == word_12')
number_word_12 = len(word_12_query)

word_13_query = df.query('Text == word_13')
number_word_13 = len(word_13_query)

word_14_query = df.query('Text == word_14')
number_word_14 = len(word_14_query)

word_15_query = df.query('Text == word_15')
number_word_15 = len(word_15_query)

word_16_query = df.query('Text == word_16')
number_word_16 = len(word_16_query)

word_17_query = df.query('Text == word_17')
number_word_17 = len(word_17_query)

word_18_query = df.query('Text == word_18')
number_word_18 = len(word_18_query)

word_19_query = df.query('Text == word_19')
number_word_19 = len(word_19_query)

word_20_query = df.query('Text == word_20')
number_word_20 = len(word_20_query)

word_21_query = df.query('Text == word_21')
number_word_21 = len(word_21_query)

word_22_query = df.query('Text == word_22')
number_word_22 = len(word_22_query)

word_23_query = df.query('Text == word_23')
number_word_23 = len(word_23_query)

word_24_query = df.query('Text == word_24')
number_word_24 = len(word_24_query)

word_25_query = df.query('Text == word_25')
number_word_25 = len(word_25_query)

 
# initialize list of Lists 
selected_tweets_words_counts = [[word_1, number_word_1], [word_2, number_word_2], [word_3, number_word_3], [word_4, number_word_4], [word_5, number_word_5], [word_6, number_word_6], [word_7, number_word_7], [word_8, number_word_8], [word_9, number_word_9], [word_10, number_word_10], [word_11, number_word_11], [word_12, number_word_12], [word_13, number_word_13], [word_14, number_word_14], [word_15, number_word_15], [word_16, number_word_16], [word_17, number_word_17], [word_18, number_word_18], [word_19, number_word_19], [word_20, number_word_20], [word_21, number_word_21], [word_22, number_word_22], [word_23, number_word_23], [word_24, number_word_24], [word_25, number_word_25]] 
 
# Create the pandas DataFrame 
df_selected_tweets_words_counts = pd.DataFrame(selected_tweets_words_counts, columns = ['tweets_words', 'Counts']) 

df_selected_tweets_words_counts.to_csv('4_4_239_SMI1_Selected_Tweets_Words_counts_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# df_selected_tweets_words_counts.to_excel('4_4_239_SMI1_Selected_Tweets_Words_counts.xlsx', header=True)


# Selected tweets_words Plot

# TABLE PLOT NEED TO DO 

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies')
df_selected_tweets_words_counts.plot(10,cumulative=False, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_239_SMI1_Selected_Tweets_Words_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies - Pie')
plt.pie(df_selected_tweets_words_counts[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.legend(df_selected_tweets_words_counts, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_239_SMI1_Selected_Tweets_Words_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO



###################################################################################################################
#
# 	       TOPIC MODELLING : LDA Latent Dirichhlet Allocation
#                                                 
###################################################################################################################

# towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24

# Word Statistics
 

word_1 = r'love'
word_2 = r'hate'
word_3 = r'like' # NEED TO ADD LIKED
word_4 = r'brand'
word_5 = r'buy'
word_6 = r'trust'
word_7 = r'thanks' # NEED TO ADD THANK YOU
word_8 = 'friend'
word_9 = 'follow'
word_10 = 'bitch'
word_11 = 'sister'
word_12 = 'video' # NEED TO ADD VIDEOS
word_13 = 'omg'
word_14 = 'good'
word_15 = 'bad'
word_16 = 'use'
word_17 = 'youtube'
word_18 = 'drama'
word_19 = 'collab'
word_20 = 'queen'
word_21 = 'slay'
word_22 = 'queen'
word_23 = 'recommend'
word_24 = 'review'
word_25 = 'share'
word_26 = 'ily'
word_26 = 'help'
word_27 = 'feel'
word_28 = 'friend'
word_29 = 'learn'
word_30 = 'teach'
word_31 = 'celebrity'
word_32 = 'smi' 
word_33 = 'jamescharles'
word_34 = 'jeffreestar'
word_35 = 'mannymua733'
word_36 = 'michellephan'
word_37 = 'nikkietutorials'
word_38 = 'zoella'
word_39 = 'bethanymota'
word_40 = 'glamlifeguru'
word_41 = 'jenna_marbles'
word_42 = 'yuya'
word_43 = 'together'
word_44 = 'fuck'
word_45 = 'beautycommunity'
word_46 = 'homophobic'
word_47 = 'nigger'
word_48 = 'racist'
word_49 = 'christmas'
# word_50 = ''


######

tweets_smi_1['word_1_query'] = tweets_smi_1['text'].str.findall(word_1, flags=re.IGNORECASE)

# tweets_smi_1['word_1_query_count'] = len(tweets_smi_1['text'].str.findall(word_1, flags=re.IGNORECASE))

# tweets_smi_1['word_1_query_count'] = len(tweets_smi_1['text'].str.findall(word_1, flags=re.IGNORECASE))  # word_1_query =


print('---')
print('Tweets SMI 1 word_1 query DF LEN')
print(tweets_smi_1['word_1_query'].head)
print('---')

word_2_query = tweets_smi_1['text'].str.findall(word_2, flags=re.IGNORECASE)
word_3_query = tweets_smi_1['text'].str.findall(word_3, flags=re.IGNORECASE)
word_4_query = tweets_smi_1['text'].str.findall(word_4, flags=re.IGNORECASE)
word_5_query = tweets_smi_1['text'].str.findall(word_5, flags=re.IGNORECASE)
word_6_query = tweets_smi_1['text'].str.findall(word_6, flags=re.IGNORECASE)
word_7_query = tweets_smi_1['text'].str.findall(word_7, flags=re.IGNORECASE)
word_8_query = tweets_smi_1['text'].str.findall(word_8, flags=re.IGNORECASE)
word_9_query = tweets_smi_1['text'].str.findall(word_9, flags=re.IGNORECASE)
word_10_query = tweets_smi_1['text'].str.findall(word_10, flags=re.IGNORECASE)
word_11_query = tweets_smi_1['text'].str.findall(word_11, flags=re.IGNORECASE)
word_12_query = tweets_smi_1['text'].str.findall(word_12, flags=re.IGNORECASE)
word_13_query = tweets_smi_1['text'].str.findall(word_13, flags=re.IGNORECASE)
word_14_query = tweets_smi_1['text'].str.findall(word_14, flags=re.IGNORECASE)
word_15_query = tweets_smi_1['text'].str.findall(word_15, flags=re.IGNORECASE)
word_16_query = tweets_smi_1['text'].str.findall(word_16, flags=re.IGNORECASE)
word_17_query = tweets_smi_1['text'].str.findall(word_17, flags=re.IGNORECASE)
word_18_query = tweets_smi_1['text'].str.findall(word_18, flags=re.IGNORECASE)
word_19_query = tweets_smi_1['text'].str.findall(word_19, flags=re.IGNORECASE)
word_20_query = tweets_smi_1['text'].str.findall(word_20, flags=re.IGNORECASE)
word_21_query = tweets_smi_1['text'].str.findall(word_21, flags=re.IGNORECASE)
word_22_query = tweets_smi_1['text'].str.findall(word_22, flags=re.IGNORECASE)
word_23_query = tweets_smi_1['text'].str.findall(word_23, flags=re.IGNORECASE)
word_24_query = tweets_smi_1['text'].str.findall(word_24, flags=re.IGNORECASE)
word_25_query = tweets_smi_1['text'].str.findall(word_25, flags=re.IGNORECASE)
word_26_query = tweets_smi_1['text'].str.findall(word_26, flags=re.IGNORECASE)
word_27_query = tweets_smi_1['text'].str.findall(word_27, flags=re.IGNORECASE)
word_28_query = tweets_smi_1['text'].str.findall(word_28, flags=re.IGNORECASE)
word_29_query = tweets_smi_1['text'].str.findall(word_29, flags=re.IGNORECASE)
word_30_query = tweets_smi_1['text'].str.findall(word_30, flags=re.IGNORECASE)
word_31_query = tweets_smi_1['text'].str.findall(word_31, flags=re.IGNORECASE)
word_32_query = tweets_smi_1['text'].str.findall(word_32, flags=re.IGNORECASE)
word_33_query = tweets_smi_1['text'].str.findall(word_33, flags=re.IGNORECASE)
word_34_query = tweets_smi_1['text'].str.findall(word_34, flags=re.IGNORECASE)
word_35_query = tweets_smi_1['text'].str.findall(word_35, flags=re.IGNORECASE)
word_36_query = tweets_smi_1['text'].str.findall(word_36, flags=re.IGNORECASE)
word_37_query = tweets_smi_1['text'].str.findall(word_37, flags=re.IGNORECASE)
word_38_query = tweets_smi_1['text'].str.findall(word_38, flags=re.IGNORECASE)
word_39_query = tweets_smi_1['text'].str.findall(word_39, flags=re.IGNORECASE)
word_40_query = tweets_smi_1['text'].str.findall(word_40, flags=re.IGNORECASE)
word_41_query = tweets_smi_1['text'].str.findall(word_41, flags=re.IGNORECASE)
word_42_query = tweets_smi_1['text'].str.findall(word_42, flags=re.IGNORECASE)
word_43_query = tweets_smi_1['text'].str.findall(word_43, flags=re.IGNORECASE)
word_44_query = tweets_smi_1['text'].str.findall(word_44, flags=re.IGNORECASE)
word_45_query = tweets_smi_1['text'].str.findall(word_45, flags=re.IGNORECASE)
word_46_query = tweets_smi_1['text'].str.findall(word_46, flags=re.IGNORECASE)
word_47_query = tweets_smi_1['text'].str.findall(word_47, flags=re.IGNORECASE)
word_48_query = tweets_smi_1['text'].str.findall(word_48, flags=re.IGNORECASE)
word_49_query = tweets_smi_1['text'].str.findall(word_49, flags=re.IGNORECASE)
# word_50_query = tweets_smi_1['text'].str.findall(word_50, flags=re.IGNORECASE)
# word_51_query = tweets_smi_1['text'].str.findall(word_51, flags=re.IGNORECASE)
# word_52_query = tweets_smi_1['text'].str.findall(word_52, flags=re.IGNORECASE)

# number_word_1 = word_1_query

############################  tweets_smi_1['number_word_1'] = tweets_smi_1['word_1_query'].apply(lambda x: collections.Counter(x))
number_word_2 = len(word_2_query)
number_word_3 = len(word_3_query)
number_word_4 = len(word_4_query)
number_word_5 = len(word_5_query)
number_word_6 = len(word_6_query)
number_word_7 = len(word_7_query)
number_word_8 = len(word_8_query)
number_word_9 = len(word_9_query)
number_word_10 = len(word_10_query)
number_word_11 = len(word_11_query)
number_word_12 = len(word_12_query)
number_word_13 = len(word_13_query)
number_word_14 = len(word_14_query)
number_word_15 = len(word_15_query)
number_word_16 = len(word_16_query)
number_word_17 = len(word_17_query)
number_word_18 = len(word_18_query)
number_word_19 = len(word_19_query)
number_word_20 = len(word_20_query)
number_word_21 = len(word_21_query)
number_word_22 = len(word_22_query)
number_word_23 = len(word_23_query)
number_word_24 = len(word_24_query)
number_word_25 = len(word_25_query)
number_word_26 = len(word_26_query)
number_word_27 = len(word_27_query)
number_word_28 = len(word_28_query)
number_word_29 = len(word_29_query)
number_word_30 = len(word_30_query)
number_word_31 = len(word_31_query)
number_word_32 = len(word_32_query)
number_word_33 = len(word_33_query)
number_word_34 = len(word_34_query)
number_word_35 = len(word_35_query)
number_word_36 = len(word_36_query)
number_word_37 = len(word_37_query)
number_word_38 = len(word_38_query)
number_word_39 = len(word_39_query)
number_word_40 = len(word_40_query)
number_word_41 = len(word_41_query)
number_word_42 = len(word_42_query)
number_word_43 = len(word_43_query)
number_word_44 = len(word_44_query)
number_word_45 = len(word_45_query)
number_word_46 = len(word_46_query)
number_word_47 = len(word_47_query)
number_word_48 = len(word_48_query)
number_word_49 = len(word_49_query)

print('---')
print('Selected Counts Word:')
print(word_1)
print(tweets_smi_1['number_word_1'].head)
print('---')
print('word_1_query:')
print(word_1_query)
print('---')
print('---')
print('Count Word 1')
print(number_word_1)
print('---')


# METHOD 1 : TEXTBLOB

# tweets_smi_1['text'] = tweets_smi_1['text'].to_string()

word_query_numbers = pd.DataFrame()

# word_query_numbers['word_1_query'] = tweets_smi_1['text'].count('word_1')

print('----')
print('OJO word_query_numbers word_1_query')
# print(word_query_numbers['word_1_query'])
print('----')

########################

# initialize list of Lists 
selected_tweets_words_counts = [[word_1, number_word_1], [word_2, number_word_2], [word_3, number_word_3], [word_4, number_word_4], [word_5, number_word_5], [word_6, number_word_6], [word_7, number_word_7], [word_8, number_word_8], [word_9, number_word_9], [word_10, number_word_10], [word_11, number_word_11], [word_12, number_word_12], [word_13, number_word_13], [word_14, number_word_14], [word_15, number_word_15], [word_16, number_word_16], [word_17, number_word_17], [word_18, number_word_18], [word_19, number_word_19], [word_20, number_word_20], [word_21, number_word_21], [word_22, number_word_22], [word_23, number_word_23], [word_24, number_word_24], [word_25, number_word_25], [word_26, number_word_26], [word_27, number_word_27], [word_28, number_word_28], [word_29, number_word_29], [word_30, number_word_30], [word_31, number_word_31], [word_32, number_word_32], [word_33, number_word_33], [word_34, number_word_34], [word_35, number_word_35], [word_36, number_word_36], [word_37, number_word_37], [word_38, number_word_38], [word_39, number_word_39], [word_40, number_word_40], [word_41, number_word_41], [word_42, number_word_42], [word_43, number_word_43], [word_44, number_word_44], [word_45, number_word_45], [word_46, number_word_46], [word_47, number_word_47], [word_48, number_word_48], [word_49, number_word_49]] 
 
# Create the pandas DataFrame 
selected_tweets_words_counts_df = pd.DataFrame(selected_tweets_words_counts, columns = ['selected_words', 'selected_words_counts']) 

selected_tweets_words_counts_df.to_csv('4_5_197_SMI1_Selected_Tweets_Words_Counts_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# selected_tweets_words_counts_df.to_excel('4_5_197_SMI1_Selected_Tweets_Words_Counts_DF.xlsx', header=True)


# TABLE PLOT NEED TO DO 

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies')
# selected_tweets_words_counts_df['selected_words_counts'].plot(alpha=0.9)
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_197_SMI1_Selected_Tweets_Words_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies Textblob - Pie')
# plt.pie(selected_tweets_words_counts_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.legend(selected_tweets_words_counts_df['selected_words'], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_197_SMI1_Selected_Tweets_Words_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies Textblob - Bars')
# selected_tweets_words_counts_df.plot.bar(x=selected_tweets_words_counts_df, edgecolor='white', label=' ', alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_197_SMI1_Selected_Tweets_Words_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#######################################################################

# jakevdp.github.io/PythonDataScienceHandbook/03.10-working-with-strings.html

# SEARCH AND PLOT WORD 1 LOVE

###           NEED TO DO!!!!!!!!!!!!!!!
###
###

# Create the pandas DataFrame 
selected_tweets_words_counts_df = pd.DataFrame(selected_tweets_words_counts, columns = ['selected_words', 'selected_words_counts']) 

selected_tweets_words_counts_df.to_csv('4_5_197_SMI1_Selected_Tweets_Words_Counts_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# selected_tweets_words_counts_df.to_excel('4_5_197_SMI1_Selected_Tweets_Words_Counts_DF.xlsx', header=True)


# Retweets OVER TIME

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Retweets Over Time')
tweets_smi_1.set_index('created')['retweets'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_185_SMI1_Retweets_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Retweets Over Time')
# tweets_smi_1.set_indexbar('created')['retweets'].plot(kind='bar', edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Retweets_Time_All_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################
############################################################################################################
############################################################################################################

# PATTERN WORD LOVE ETC

word_list = ['love', 'hate', 'like','brand', 'buy', 'trust', 'thanks', 'friend', 'follow', 'bitch', 'sister', 'video', 'omg', 'good', 'bad', 'use', 'youtube', 'drama', 'collab', 'queen', 'slay', 'queen', 'recommend', 'review', 'share', 'ily', 'help', 'feel', 'friend', 'learn', 'teach', 'celebrity', 'smi', 'jamescharles', 'jeffreestar', 'mannymua733', 'michellephan', 'nikkietutorials', 'zoella', 'bethanymota', 'glamlifeguru', 'jenna_marbles', 'yuya', 'together', 'fuck', 'beautycommunity', 'homophobic', 'nigger', 'racist', 'christmas']

tweets_smi_1['love_count'] = tweets_smi_1['love_count'].fillna('0')
tweets_smi_1['love_count'] = tweets_smi_1['text'].str.findall(word_1, flags=re.IGNORECASE) 


print('----------')
print('TEXT HEAD')
print(tweets_smi_1['text'].head)
print('-----------------------------------')

print('----------')
print('LOVE HEAD')
print(tweets_smi_1['love_count'].head)
print('-----------------------------------')

# selected_words_frequencies = selected_words_frequencies.sort_values(0, ascending=False).rename(columns={0: 'word_freq'}

# selected_words_frequencies_df = pd.DataFrame(selected_words_frequencies)

selected_words_frequencies_df.to_csv('4_5_195_SMI1_Selected_Words_Frequencies_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# selected_words_frequencies_df.to_excel('4_5_195_SMI1_Selected_Words_Frequencies_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)

# TABLE PLOT NEED TO DO 

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies')
# selected_words_frequencies_df.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_197_SMI1_selected_words_frequencies_df_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies Textblob - Pie')
# plt.pie(selected_words_frequencies, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.legend(selected_tweets_words_counts_df['selected_words'], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_197_SMI1_Selected_Words_Frequencies_df_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies Textblob - Bars')
selected_words_frequencies.plt.plot.bar(color='#73C2FB', edgecolor='white', label=' ', alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_197_SMI1_selected_words_frequencies_df_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###############################################################

##############################################################################################################

# _df _df = pd.DataFrame()
# .to_csv('4_4_.csv', sep='\t', encoding='utf-8', index=True)
# excel

############################################################################################

## SENTIMENT ANALYSIS

# tweets_smi_1.parse() #Parse the article
# ('punkt')   #1 total_favorites download of the sentence tokenizer
# tweets_smi_1.nlp() # Keyword extraction wrapper

obj = TextBlob(tweets_words)

# returns the sentiment of text
# by returning a value between -1.0 and 1.0

sentiment = obj.sentiment.polarity
print(sentiment)

if sentiment == 0:
  print('The Text is neutral')
elif sentiment > 0:
  print('The Text is positive')
else:
  print('The Text is negative')

# Create the pandas DataFrame 
df_sentiment = pd.DataFrame(sentiment) 

df_sentiment.to_csv('4_4_240_SMI1_df_sentiment_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# df_sentiment.to_excel('4_4_240_SMI1_df_sentiment.xlsx', header=True)

# Sentiment Plot

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment DF')
df_sentiment.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_240_SMI1_DF_Sentiment_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment DF - Pie')
plt.pie(df_sentiment[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.legend(df_sentiment, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_240_SMI1_DF_Sentiment_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO


print('MAIN SMI:')
print(main_smi)
print('-------------------------')

###############################################################################################################

# USE PACKAGE CORPUS

###############################################################################################################

print('---')
print('Loading Libs 71')
print('---')

# https://towardsdatascience.com/practical-statistics-visualization-with-python-plotly-770e96e35067

# USING CUFFLNKS

# from plotly.offline import init_notebook_mode, iplot
# import plotly.figure_factory as ff

import cufflinks
cufflinks.go_offline()
cufflinks.set_config_file(world_readable=True, theme='pearl')


#############        plotly.tools.set_credentials_file(username='XXX', api_key='XXX')

# init_notebook_mode(connected=True)

pd.set_option('display.max_columns', 100)
# df = pd.read_csv('house_train.csv')
# df.drop('Id', axis=1, inplace=True)
# df.head()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

##########################################################################################################################


# USING NLTK 

# from nltk.tokenize import sent_tokenize

# text_nltk = tweets_smi_1['text']
tokenized_text_sent= nltk.sent_tokenize(fp_text)

tokenized_text_sent.to_csv('4_4_241_SMI1_Tokenized_Sent_CSV.csv', sep='\t', encoding='utf-8', index=True)
# tokenized_text_sent.to_excel('4_4_241_SMI1_Tokenized_Sent.xlsx', header='frequency_distribution') # Only argument is a string of the output file path


# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentences')
tokenized_text_sent.plot(10,cumulative=False, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_241_SMI1_Freq_Dist_Tokenized_Sentences.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sent - Pie')
plt.pie(tokenized_text_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.legend(tokenized_text_sent, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_241_SMI1_Freq_Dist_Tokenized_Sent_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO


###################################################################################

# Word Tokenization

# Word tokenizer breaks Text paragraph into tweets_words.

tokenized_tweets_words = nltk.word_tokenize(text)
# print(tokenized_word.head)

# tokenized_tweets_words = mosestokenizer.MosesTokenizer(text)

tokenized_tweets_words.to_csv('4_4_242_SMI1_Tokenized_Tweets_Words_CSV.csv', sep='\t', encoding='utf-8', index=True)
# tokenized_tweets_words.to_excel('4_4_242_SMI1_Tokenized_Tweets_Words.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Words')
tokenized_tweets_words.plot(10,cumulative=False, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_242_SMI1_Freq_Dist_Tokenized_Tweets_Words.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Words - Pie')
plt.pie(tokenized_tweets_words[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.legend(tokenized_tweets_words, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_242_SMI1_Freq_Dist_Tokenized_Tweets_Words_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

#########################################################################################################################################################

# NOT WORKING !!

# Stoptweets_words considered as noise in the text. Text may contain stop tweets_words such as is, am, are, this, a, an, the, etc.
# In NLTK for removing stoptweets_words, you need to create a list of stoptweets_words and filter out your list of tokens from these tweets_words.

# NEED TO DO - NOT WORKING!!!!!!!!!!!

# stop_tweets_words = nltk.corpus.stoptweets_words.tweets_words('english')

# stop_tweets_words = stoptweets_words.tweets_words('english')

print('---')
print('Stop tweets_words NOT WORKING NEED TO FIX')
# print(stop_tweets_words)
print('---')

# filtered_sent=[]
# for w in tokenized_tweets_words:
#    if w not in stop_tweets_words:
#      filtered_sent.append(w)
# print("Tokenized Sentence:",tokenized_sent)
# print("Filterd Sentence:",filtered_sent)

# tokenized_sent.to_csv('4_4_243_SMI1_Tokenized_Sent_No_Stoptweets_words_CSV.csv', sep='\t', encoding='utf-8', index=True)
# tokenized_sent.to_excel('4_4_243_SMI1_Tokenized_Sent_No_Stoptweets_words.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# PLOT TOKENIZED SENT - 1 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentiment - No Stoptweets_words')
# tokenized_sent.plot(10,cumulative=False, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_243_SMI1_Freq_Dist_Tokenized_Sent.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentiment - Pie')
# plt.pie(tokenized_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(tokenized_sent, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_243_SMI1_Freq_Dist_Tokenized_Sent_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

############################################################################

# filtered_sent.to_csv('4_4_244_SMI1_Filtered_Tweets_Words_CSV.csv', sep='\t', encoding='utf-8', index=True)
# filtered_sent.to_excel('4_4_244_SMI1_Filtered_Tweets_Words.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# PLOT SENTIMENT OR SENTENCES????????? - 2

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Filtered Sent')
# filtered_sent.plot(10,cumulative=False, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_244_SMI1_Freq_Dist_Filtered_Sent.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Filtered Sent - Pie')
plt.pie(filtered_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.legend(filtered_sent, bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_244_SMI1_Freq_Dist_Filtered_Sent_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

##############################################################################################################################################

# Lexicon Normalization

# Lexicon normalization considers another type of noise in the text. For example, connection, connected, connecting word reduce to a 
# common word "connect". It reduces derivationally related forms of a word to a common root word.

# Stemming

# Stemming is a process of linguistic normalization, which reduces tweets_words to their word root word or chops off the derivational affixes. 
# For example, connection, connected, connecting word reduce to a common word "connect".


ps = PorterStemmer()

stemmed_tweets_words=[]
for w in filtered_sent:
    stemmed_tweets_words.append(ps.stem(w))

print("Filtered Sentence:",filtered_sent)
# print("Stemmed Sentence:",stemmed_tweets_words)

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

#############################################################################################################

# ADD IMAGE LINK FIELD 

# METHOD 1 ######## Need to fix

total_favorites_zones = [rec['tz'] for rec in records if 'tz' in rec]
total_favorites_zones[:10]

def get_counts(sequence):
    counts = {}
    for x in sequence:
        if x in counts:
            counts[x] += 1
        else:
            counts[x] = 1
    yield counts

# from collections import defaultdict
# from collections import Counter

def get_counts2(sequence):
    counts = defaultdict(int) # values will initialize to 0
    for x in sequence:
        counts[x] += 1
    yield counts

###################

def top_counts(count_dict, n=10):
    value_key_pairs = [(count, tz) for tz, count in count_dict.items()]
    value_key_pairs.sort()
    yield value_key_pairs[-n:] 

top_counts(counts)

###########

# METHOD 3



# NEED TO DO - FIX PLOTLY

############################################################################################################################

# This selects the top 5 highest average points among all Tweets:

# smi1_screenname.mean().sort_values(by="screenname",ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

# smi1_screenname_describe_df = pd.DataFrame(smi1_screenname.mean().sort_values(by="screenname",ascending=True).describe())

# smi1_screenname_describe.to_csv('4_4_178_SMI1_ScreenName_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Average Points ScreenNames')
# plt.plot(smi1_screenname_mean_sort_values_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_178_SMI1_Screenname_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################


# This selects the top 5 highest average points among all Tweets:

# NEED TO DO COUNTS!!!


smi1_hashtags_mean_sort_values_df = pd.DataFrame(tweets_smi_1['hashtags'].mean().sort_values(by='hashtags',ascending=True))

# smi1_hashtags_mean_sort_values_df.to_csv('4_4_179_SMI1_Hashtags_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_hashtags_mean_sort_values_df.to_excel()

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Average Points Hashtags')
# plt.plot(smi1_hashtags_mean_sort_values_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_179_SMI1_Hashtags_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################

# This selects the top 5 highest average points among all Tweets:

# NEED TO DO COUNTS!!!

# mean().sort_values(by='mentions',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

# smi1_mentions_mean_sort_values_df = pd.DataFrame(smi1_mentions.mean().sort_values(by='mentions',ascending=True))

# smi1_mentions_mean_sort_values_df.to_csv('4_4_180_SMI1_Mentions_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_mentions_mean_sort_values_df.to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Average Points Mentions')
# plt.plot(smi1_mentions_mean_sort_values_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_180_SMI1_Mentions_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################

# This selects the top 5 highest average points among all Tweets:

# NEED TO DO COUNTS 

# smi1_emojis_unicode.mean().sort_values(by='emojis_unicode',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

# smi1_emojis_unicode_mean_sort_values_df = pd.DataFrame(smi1_emojis_unicode.mean().sort_values(by='emojis_unicode',ascending=True))

# smi1_emojis_unicode_mean_sort_values_df.to_csv('4_4_184_SMI1_Emojis_Unicode_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_emojis_unicode_mean_sort_values_df.to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Highest Average Points Emojis')
# plt.plot(smi1_emojis_unicode_mean_sort_values_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_184_SMI1_Emojis_Unicode_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################
############################################################################################################
############################################################################################################


# This selects the top 5 highest average points among all Tweets:

# smi1_emojis_converted.mean().sort_values(by='emojis_converted',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

# smi1_emojis_converted_sort_values_df = pd.DataFrame(smi1_emojis_converted.mean().sort_values(by='emojis_converted',ascending=True))

# smi1_emojis_converted_mean_sort_values_df.to_csv('4_4_185_SMI1_Emojis_Converted_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Highest Average Emojis')
# plt.plot(smi1_emojis_converted_mean_sort_values_df)
pplt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_185_SMI1_Emojis_Converted_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')




############################################################################################################

# This selects the top 5 highest average points among Total Tweets:

# smi1_screenname.mean().sort_values(by="screenname",ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

smi1_screenname_describe_df = pd.DataFrame(smi1_screenname.mean().sort_values(by="screenname",ascending=True).describe())

smi1_screenname_describe.to_csv('4_5_178_SMI1_Screenname_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Average Points ScreenNames')
# plt.plot(smi1_screenname_mean_sort_values_df[:10], edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_178_SMI1_Screenname_Mean_Sort_Values_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Highest Average Points ScreenNames - Pie')
plt.pie(smi1_screenname_mean_sort_values_df, colors=colors_blue, labels=smi1_screenname_mean_sort_values_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=smi1_screenname_mean_sort_values_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
plt.legend(smi1_screenname_mean_sort_values_df, loc=3)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_178_SMI1_Screenname_Mean_Sort_Values_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

############################################################################################################


# This selects the top 5 highest average points among Total Tweets:

smi1_hashtags.mean().sort_values(by='hashtags',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

smi1_hashtags_mean_sort_values_df = pd.DataFrame(smi1_hashtags.mean().sort_values(by='hashtags',ascending=True))

smi1_hashtags_mean_sort_values_df.to_csv('4_5_179_SMI1_Hashtags_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Average Points Hashtags')
# plt.plot(smi1_hashtags_mean_sort_values_df[:10], edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_179_SMI1_Hashtags_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Average Points Hashtags - Pie')
plt.pie(smi1_hashtags_mean_sort_values_df, colors=colors_blue, labels=smi1_hashtags_mean_sort_values_df, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_hashtags_mean_sort_values_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
plt.legend(smi1_hashtags_mean_sort_values_df, loc=3)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_179_SMI1_Hashtags_Mean_Sort_Values_DF_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

############################################################################################################

# This selects the top 5 highest average points among Total Tweets:

smi1_mentions.mean().sort_values(by='mentions',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

smi1_mentions_mean_sort_values_df = pd.DataFrame(smi1_mentions.mean().sort_values(by='mentions',ascending=True))

smi1_mentions_mean_sort_values_df.to_csv('4_5_140_SMI1_Mentions_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Average Points Mentions')
# plt.plot(smi1_mentions_mean_sort_values_df[:10], edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_140_SMI1_Mentions_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################

# This selects the top 5 highest average points among Total Tweets:

# smi1_emojis_unicode.mean().sort_values(by='emojis_unicode',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

smi1_emojis_unicode_mean_sort_values_df = pd.DataFrame(smi1_emojis_unicode.mean().sort_values(by='emojis_unicode',ascending=True))

smi1_emojis_unicode_mean_sort_values_df.to_csv('4_5_144_SMI1_Emojis_Unicode_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Highest Average Points Emojis')
plt.plot(smi1_emojis_unicode_mean_sort_values_df[:10], edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_144_SMI1_Emojis_Unicode_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################


# This selects the top 5 highest average points among Total Tweets:

# smi1_emojis_converted.mean().sort_values(by='emojis_converted',ascending=True).head()  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!!

smi1_emojis_converted_sort_values_df = pd.DataFrame(smi1_emojis_converted.mean().sort_values(by='emojis_converted',ascending=True))

smi1_emojis_converted_mean_sort_values_df.to_csv('4_5_145_SMI1_Emojis_converted_mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Highest Average Emojis')
plt.plot(smi1_emojis_converted_mean_sort_values_df[:10], edgecolor='white', label=' ', alpha=0.9)
pplt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_145_SMI1_Emojis_Converted_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


print('---')
print('tweets_smi_1 Text HEAD 2F')
print(tweets_smi_1['text'].head)
# print(tweets_smi_1['text'].dtypes)
print('-----------------------------------------------------------------------')


############################################################################################################


# This selects the top 5 highest average points among Total Tweets:

smi1_languages.mean().sort_values(by='language',ascending=True).head() ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


smi1_languages_mean_sort_values_df = pd.DataFrame(smi1_languages.mean().sort_values(by='mentions',ascending=True))

smi1_languages_mean_sort_values_df.to_csv('4_5_146_SMI1_Languages_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Highest Average Languages')
plt.plot(smi1_languages_mean_sort_values_df[:10], edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_146_SMI1_Languages_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

############################################################################################################


# This selects the top 5 highest average points among all Tweets:

# NEED TO DO COUNTS

# smi1_languages.mean().sort_values(by='language',ascending=True).head() ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_languages_mean_sort_values_df = pd.DataFrame(smi1_languages.mean().sort_values(by='mentions',ascending=True))

# smi1_languages_mean_sort_values_df.to_csv('4_4_186_SMI1_Languages_Mean_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_languages_mean_sort_values_df.to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Highest Average Languages')
# plt.plot(smi1_languages_mean_sort_values_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_186_SMI1_Languages_Mean_Sort_Values_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Highest Average Languages - Bars')
# plt.bar(smi1_languages_mean_sort_values_df)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_186_SMI1_Languages_Mean_Sort_Values_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#########################################################################################
#######################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# DATES WITH MOST Tweets

# Most Common Tweet Date

# METHOD 1

value_counts_date = pd.value_counts(tweets_smi_1['created'], ascending=False, normalize=True)


def get_counts(sequence):  
	counts = defaultdict(int) # values will initialize to 0  
	for x in sequence:    
		counts[x] += 1  
	yield counts


def top_counts(count_dict, n=10):  
	value_key_pairs = [(count, tz) for tz, count in count_dict.items()]  
	value_key_pairs.sort()  
	yield value_key_pairs[-n:] 

counts_created_1 = get_counts(tweets_smi_1['created'])

top_counts_created_1 = top_counts(counts_created_1)

print('---')
print('Most Common Tweet Date - 1D')
# print('counts_created_1')
print('---')

##############################################

# METHOD 2

counts_created_2 = Counter(tweets_smi_1['created'])

value_counts_date = pd.DataFrame(counts_created_2, columns=['value_counts_date'])

print('---')
print('Most Common Tweet Date - 2D')
# print(counts_created_2.head)
print('---')

###########################################################


### NEED TO PLOT

# SAVE TO CSV   ######################################  NEED TO SAVE DATE ON FIRST COLUMN / SECOND COUNT

value_counts_date.to_csv('4_4_200_SMI1_D_df_Top_Dates_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_date = value_counts_date.to_excel('4_4_200_SMI1_D_df_Top_Dates_and_No_Tweets.xlsx', header=True) # Only argument is a string of the output file path

# value_counts_date

print('---')
print('Value Counts Date')
print(value_counts_date.head)
print('---')

print('---')
print('Value Counts Date DTypes')
print(value_counts_date.dtypes)
print('---')

# TABLE PLOT NEED TO DO 

# Pie NEED TO DO

# Bars

# TOP DATES WITH TWEET COUNT

top_dates_tweets = value_counts_date.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Dates For Users Activity for an SMI - Bars')
top_dates_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Dates')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_200_D_SMI1_Top_Tweet_Dates_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#####################################################################################################

# TREEMAPS

# Treemap Plotting

# import squarify

# Large plot
# matplotlib.rcParams['figure.figsize'] = (16.0, 9.0)

# Use ggplot style

style.use('ggplot') 

# BY Favorites

treemap_favs = tweets_smi_1.sort_values(by='favorites', ascending=False)

# Find Percentage

treemap_favs['fav_percentage'] = round(100 * treemap_favs['favorites'] / sum(treemap_favs['favorites']), 2)

# Create Treemaps Labels

treemap_favs['text'] = treemap_favs['text'] + '(' + treemap_favs['fav_percentage'].astype('str') + '%)'

print('---')
print('Tree Maps Favs 4')
print(treemap_favs['fav_percentage'].head(10)) ## NEED TO DO - FIX
print('---')

# Get Axis and Figure

fig, ax = plt.subplots(1, 1) 
plt.ioff()

# Colormap

# cmap = plt.cm.coolwarm

# Min and Max Values

mini_favs = min(treemap_favs['favorites'])
maxi_favs = max(treemap_favs['favorites'])

# Finding Colors for each tile

# norm_favs = plt.colors.Normalize(vmini=mini_favs, vmax=maxi_favs)
# colors = [plt.cmap(norm(value)) for value in treemap_favs['favorites']]

colors = 'Blues'

# Plotting

# squarify.plot(sizes=treemap_favs['favorites'], label=treemap_favs['text'], alpha=0.8, color=colors)

# Removing Axis

plt.axis('off')

# Invert Y-Axis

plt.gca().invert_yaxis()     ############## NEED TO FIX

# NEED TABLE AND SAVE TO EXCEL AND CSV - NEED TO DO

# Pie ## NEED TO DO - NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Texts by Favorites - Pie') # fontsize=32
# plt.plot(treemap_favs, alpha=0.9)
# plt.legend(treemap_fav, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_121_SMI1_10_4_Most_Repeteaded_Tweet_Text_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Texts by Favorites - Bars') # fontsize=32
treemap_favs.plot.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_121_SMI1_10_4_Most_Repeteaded_Tweet_Text_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##################################################################################################

# MOST FREQUENT TEXT IN Tweets

top_texts_tweets = value_counts_text.sort_values(ascending=False)

print('---')
print('Most Frequent Complete Text - Bars')
# print(value_counts_text.sort_values(ascending=False).head)
print('---')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Content of Text - Bars')
top_texts_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Most Repeated / Shared / Text Content')
# plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_122_SMI1_10_Most_Repeteaded_Tweet_Text_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

########################################################################################################


# PLOT PERCENTAGES MEASURES Favorites, Retweets, MENTIONS, HASHTAGS, EMOJIS, IMAGE_LINKLANGUAGES   ### NEED TO DO

# List of List  ########## NEED TO DO DATAFRAME

percentages_of_measures_df = pd.DataFrame(percentages_of_measures)

print('---')
print('Percentage of Measures')
# print('percentages_of_measures')
print('---')


percentages_of_measures_df.to.csv('4_5_164_SMI1_Percentages_of_Measures_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentages of Measures - Pie')
# plt.pie(percentages_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(percentages_of_measures_df[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(percentages_of_measures_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_164_SMI1_Percentages_of_Measures_df_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

################################################ NEED TO DO TABLE WITH COUNTS AND PERCENTAGES OF THE ABOVE!!!!!!

# _df _df = pd.DataFrame()

# .to_csv('4_5_.csv', sep='\t', encoding='utf-8', index=True)
# excel

########################################################################################################

# PLOT PERCENTAGES MEASURES Favorites, Retweets, MENTIONS, HASHTAGS, EMOJIS, IMAGE_LINKLANGUAGES   ### NEED TO DO

# List of List  ########## NEED TO DO DATAFRAME

percentages_of_measures_df = pd.DataFrame(percentages_of_measures)

print('---')
print('Percentage of Measures')
# print('percentages_of_measures')
print('---')

percentages_of_measures_df.to.csv('4_4_204_SMI1_Percentages_of_Measures_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# .to_excel()

# TABLE PLOT NEED TO DO 

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentages of Measures - Pie')
# plt.pie(percentages_favorites_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.pie(percentages_of_measures_df[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(percentages_of_measures_df, loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_204_SMI1_Percentages_of_Measures_df_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

################################################ NEED TO DO TABLE WITH COUNTS AND PERCENTAGES OF THE ABOVE!!!!!!

# _df _df = pd.DataFrame()

# .to_csv('4_4_.csv', sep='\t', encoding='utf-8', index=True)
# excel

############################################################################################################

# https://matplotlib.org/3.1.1/gallery/pie_and_polar_charts/pie_and_donut_labels.html#sphx-glr-gallery-pie-and-polar-charts-pie-and-donut-labels-py
# https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplt.pie.html

##############################################################################################################

# Pie : PERCENTAGE OF Friends / Top

percentages_friends_tweets = tweets_smi_1['friends_count'].size().sort_values(ascending=False)

print('--')
print('Percentage of friends Tweets')
print(percentages_friends_tweets.head)
print('--')

percentages_friends_tweets_df = pd.DataFrame(percentages_friends_tweets)

percentages_friends_tweets_df.to_csv('4_4_205_SMI1_Percentages_Friends_Tweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# to_excel()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Friends - Pie')
plt.pie(percentages_friends_tweets[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.legend(percentages_friends_tweets, loc='upper right', borderaxespad=0.)
# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_205_SMI1_Percentages_Friends_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

###############################################################################################################

# METHOD 1 MISSING emojis_converted

fp_missing_emojis_converted = tweets_smi_1['missing_emojis_converted'].to_string()

# fp_missing_emojis_converted = fp_missing_emojis_converted_temp.to_string()

tweets_text_missing_emojis_converted = nltk.word_tokenize(fp_missing_emojis_converted)

value_counts_missing_emojis_converted = pd.value_counts(tweets_text_missing_emojis_converted, ascending=False, normalize=True) 

smi1_value_counts_missing_emojis_converted = value_counts_missing_emojis_converted.sort_values(ascending=False)

# smi1_value_counts_missing_emojis_converted_freq_dist = tweets_text_missing_emojis_converted.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts missing_emojis_converted - Frequency')
# print(smi1_value_counts_missing_emojis_converted.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts missing_emojis_converted')
print(smi1_value_counts_missing_emojis_converted.describe().head)
print('---')

smi1_value_counts_missing_emojis_converted_df = pd.DataFrame(smi1_value_counts_missing_emojis_converted, columns=['missing_emojis_converted_frequency'])

smi1_value_counts_missing_emojis_converted_df.to_csv('4_4_43_100_SMI1_Value_Counts_Missing_Emojis_Converted_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_missing_emojis_converted_df.to_excel('4_4_43_100_SMI1_Value_Counts_Missing_Emojis_Converted_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
plt.plot(smi1_value_counts_missing_emojis_converted[:10], alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_missing_emojis_converted_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))     ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
smi1_value_counts_missing_emojis_converted[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(smi1_value_counts_missing_emojis_converted, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Missing_Emojis_Converted_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
smi1_value_counts_missing_emojis_converted[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Missing_Emojis_Converted_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


################################################################################################
################################################################################################


df_tweets_smi_processes_tokens_1_fdist = FreqDist(fp_text)

# print(df_tweets_smi_processes_tokens_1_fdist.head)

df_tweets_smi_processes_tokens_1_fdist_most_common_2 = df_tweets_smi_processes_tokens_1_fdist.most_common(2)

## NEED TO PLOT????????????

print('--')
print('Word Frequency Distribution')
print(df_tweets_smi_processes_tokens_1_fdist.most_common(2))
print('--')

df_tweets_smi_processes_tokens_1_fdist_most_common_2 = pd.DataFrame(df_tweets_smi_processes_tokens_1_fdist_most_common_2)

df_tweets_smi_processes_tokens_1_fdist_most_common_2.to_csv('4_4_224_SMI1_df_tweets_smi_processes_tokens_1_fdist_most_common_CSV.csv')
# .to_excel()

# TABLE PLOT NEED TO DO

# Pie NEED TO DO 

# PLOT

# Frequency Distribution Plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Word Frequencies')
SMI1_Word_Freq_Graph = df_tweets_smi_processes_tokens_1_fdist.plot(10,cumulative=False, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_224_SMI1_df_tweets_smi_processes_tokens_1_fdist_most_common.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################

# SNS SEABORN RELATIONSHIPS PLOTS Following

rel_graphs_total_followers_following = sns.FacetGrid(tweets_smi_1, col='followers', hue='following', palette='Set2')


# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships Followers / Following - Scatter')
sns.FacetGrid(tweets_smi_1, col='followers', hue='following', palette='Set2')
# rel_graphs_total_followers_following.map(plt.scatter, 'year', 'followers', alpha=0.9)
# sns.lmplot(x='created', y='followers', hue='following', data=tweets_smi_1)
# rel_graphs_total_favorites_following_following.add_legend()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_0_SMI1_Rel_Graphs_Followers_Following_Faceted_Scattered_1.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################

# CENTRALITY MEASURES: SUMMARY STATISTICS

print('Centrality Measures')

# Mean total_favorites

mean_total_favorites = statistics.mean(tweets_smi_1['favorites'])
# mean_total_favorites.pd.astype(np.int32, errors='ignore')

print('---')
print('Mean total_favorites')
print(statistics.mean(tweets_smi_1['favorites']))
print('---')


mean_total_favorites_df = pd.DataFrame([mean_total_favorites], columns=['mean_total_favorites'])

mean_total_favorites_df.to_csv('4_4_1_SMI1_Mean_Total_Favorites_1_CSV.csv', sep='\t', encoding='utf-8', index=True)
# mean_total_favorites_df.to_excel('4_4_1_SMI1_Mean_Total_Favorites_1.xlxs', header=True)

# NEED TO DO TABLE PLOT


# BOX PLOT 3 ########## NEED TO FIX  

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale()
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean Favorites - Box')
# plt.boxplot(tweets_smi_1['favorites'], patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_1_SMI1_Mean_Total_Favorites_Box_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Median total_favorites

median_total_favorites = statistics.median(tweets_smi_1['favorites'])
median_total_favorites

print('---')
print('Median total_favorites')
print(median_total_favorites)
print('---')

median_total_favorites_df = pd.DataFrame([median_total_favorites], columns=['median_total_favorites'])

median_total_favorites_df.to_csv('4_4_2_SMI1_Median_Total_Favorites_1_CSV.csv', sep='\t', encoding='utf-8', index=True)
# median_total_favorites_df.to_excel('4_4_2_SMI1_Median_Total_Favorites_1.xlsx', header=True)

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO DO FIX ############### NEED TO FIX PLOT BOX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Median Favorites - Box')
# (statistics.median(tweets_smi_1['favorites'])).boxplot(grid=True)
# (statistics.median(tweets_smi_1['favorites'])).plot(kind=box)
plt.ioff()
# plt.plot(median_total_favorites)
# plt.boxplot(statistics.median(tweets_smi_1['favorites']), vert=False, notch=False, showfliers=False)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_2_SMI1_Median_Total_Favorites_Box_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()


#################################################################################################################

# Mean followers

mean_followers = statistics.mean(tweets_smi_1['followers'])
mean_followers

print('---')
print('Mean Followers ')
print(mean_followers)
print('---')

mean_followers_df = pd.DataFrame([mean_followers], columns=['mean_followers'])

mean_followers_df.to_csv('4_4_3_SMI1_Mean_Followers_CSV.csv', sep='\t', encoding='utf-8', index=True)
# mean_followers_df.to_excel('4_4_3_SMI1_Mean_Followers.xlsx', header=True)

# NEED TO DO TABLE PLOT

# BOX PLOT 3 ########## NEED TO FIX  

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale()
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean Followers No Fliers - Box')
# plt.boxplot(tweets_smi_1['followers'], patch_artist=True, vert=False, notch=False, showfliers=False)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_3_SMI1_Mean_Followers_Box_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

#################################################################################################################

# Median followers

median_followers = statistics.median(tweets_smi_1['followers'])
median_followers

print('---')
print('Median Followers ')
print(statistics.median(tweets_smi_1['followers']))
print('---')

median_followers_df = pd.DataFrame([median_followers], columns=['median_followers'])

median_followers_df.to_csv('4_4_4_SMI1_Median_Followers_CSV.csv', sep='\t', encoding='utf-8', index=True)
# median_followers_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX ########## NEED TO FIX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Median Followers - Box')
# plt.boxplot(statistics.median(tweets_smi_1['followers']), vert=False, notch=False, showfliers=False) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_4_SMI1_Median_followers_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO


#################################################################################################################

# https://realpython.com/python-statistics/

# MEAN and MEDIAN BOXPLOT OF total_favorites AND Followers      ######## NEED TO DO!!!!

# NEED TO DO TABLE PLOT

# BOX PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean and Median of Favorites / Followers - Box')
tweets_smi_1.boxplot(column = 'total_favorites', grid=True) # , patch_artist=True, vert=False, notch=False, showfliers=True)
tweets_smi_1.boxplot(column = 'followers', grid=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_5_SMI1_Mean_and_Median_of_Total_Favorites_Followers_Box_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

#################################################################################################################

# Mode total_favorites

mode_total_favorites = statistics.mode(tweets_smi_1['favorites'])
mode_total_favorites

print('---')
print('Mode total_favorites')
print(statistics.mode(tweets_smi_1['favorites']))
print('---')

mode_total_favorites_df = pd.DataFrame([mode_total_favorites], columns=['mode_total_favorites'])

mode_total_favorites_df.to_csv('4_4_6_SMI1_Mode_Total_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# mode_total_favorites_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mode Favorites - Box')
# plt.boxplot(statistics.mode(tweets_smi_1['favorites']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_6_SMI1_Mode_Total_Favorites_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mode Favorites - Bars')
mode_total_favorites_df.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_6_SMI1_Mode_Total_Favorites_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf() 

#################################################################################################################


# Mode followers

mode_followers = statistics.mode(tweets_smi_1['followers'])
mode_followers

print('---')
print('Mode Followers ')
print(statistics.mode(tweets_smi_1['followers']))
print('---')

mode_followers_df = pd.DataFrame([mode_followers], columns=['mode_followers'])

mode_followers_df.to_csv('4_4_7_SMI1_Mode_Followers_CSV.csv', sep='\t', encoding='utf-8', index=True)
# mode_followers_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mode Followers - Box')
# plt.boxplot(statistics.mode(tweets_smi_1['followers']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_7_SMI1_Mode_Followers_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mode Followers - Bars')
mode_followers_df.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_7_SMI1_Mode_Followers_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


##########################################################################

# Population Variance total_favorites

pvariance_total_favorites = statistics.pvariance(tweets_smi_1['favorites'])
pvariance_total_favorites

pvariance_total_favorites_df = pd.DataFrame([pvariance_total_favorites])

print('---')
print('Population Variance total_favorites')
print(statistics.pvariance(tweets_smi_1['favorites']))
print('---')

pvariance_total_favorites_df.to_csv('pvariance_Total_Favorites_10_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# pvariance_total_favorites_df.to_excel()

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Population Variance Favorites - Box')
plt.ioff()
# plt.plot(statistics.pvariance(tweets_smi_1['favorites']), alpha=0.9) 
# plt.boxplot(statistics.pvariance(tweets_smi_1['favorites']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_10_SMI1_pvariance_Total_Favorites_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO


#################################################################################################################

# Population Variance followers

pvariance_followers = statistics.pvariance(tweets_smi_1['followers'])
pvariance_followers

print('---')
print('Population Variance Followers ')
print(statistics.pvariance(tweets_smi_1['followers']))
print('---')

pvariance_followers_df = pd.DataFrame([pvariance_followers], columns = ['pvariance_reetweets'])

pvariance_followers_df.to_csv('4_4_11_SMI1_pvariance_followers_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# pvariance_followers_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Population Variance Followers - Box')
plt.ioff()
# plt.plot(statistics.pvariance(tweets_smi_1['followers']), alpha=0.9)
# plt.boxplot(statistics.pvariance(tweets_smi_1['followers']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_11_SMI1_pvariance_followers_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Standard Deviation total_favorites

stdev_total_favorites = statistics.stdev(tweets_smi_1['favorites'])
stdev_total_favorites

print('---')
print('Standard Deviation total_favorites')
print(statistics.stdev(tweets_smi_1['favorites']))
print('---')

stdev_total_favorites_df = pd.DataFrame([stdev_total_favorites], columns=['stdev_total_favorites'])

stdev_total_favorites_df.to_csv('4_4_12_SMI1_stdev_Total_Favorites_df_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# stdev_total_favorites_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Standard Deviation Favorites - Box')
plt.ioff()
# plt.plot(statistics.stdev(tweets_smi_1['favorites']), alpha=0.9) 
# plt.boxplot(statistics.stdev(tweets_smi_1['favorites']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_12_SMI1_Stdev_Total_Favorites_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################################################################################################

# Standard Deviation followers

stdev_followers = statistics.stdev(tweets_smi_1['followers'])
stdev_followers

print('---')
print('Standard Deviation Followers ')
print(statistics.stdev(tweets_smi_1['followers']))
print('---')

stdev_followers_df = pd.DataFrame([stdev_followers], columns=['stdev_followers'])

stdev_followers_df.to_csv('4_4_13_SMI1_stdev_Followers_df_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# stdev_followers_df.to_excel('4_4_13_SMI1_stdev_Followers_df.xlsx', sep='\t', encoding='utf-8', index=True, header=True)

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Standard Deviation Followers - Box')
plt.ioff()
# plt.boxplot(statistics.stdev(tweets_smi_1['followers']), patch_artist=True, vert=False, notch=False, showfliers=True) 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_13_SMI1_Stdev_Followers_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLO NEED TO DO

#################################################################################################################

# Population Standard Deviation total_favorites

pstdev_total_favorites = statistics.pstdev(tweets_smi_1['favorites'])
pstdev_total_favorites

print('---')

print('Standard Deviation total_favorites')
print(statistics.pstdev(tweets_smi_1['favorites']))
print('---')

pstdev_total_favorites_df = pd.DataFrame([pstdev_total_favorites])

pstdev_total_favorites_df.to_csv('4_4_14_SMI1_pstdev_Total_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Population Standard Deviation Favorites - Box')
plt.ioff()
# plt.plot(statistics.pstdev(tweets_smi_1['favorites']))
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_14_SMI1_pstdev_Total_Favorites_Box.png', bbox_inches='tight')
# plt.close(fig='all')
# plt.clf()

# Bars NEED TO DO

#################################################################################################################

# Population Standard Deviation followers

pstdev_followers = statistics.pstdev(tweets_smi_1['followers'])
pstdev_followers

print('---')
print('Population Standard Deviation Followers ')
print(statistics.pstdev(tweets_smi_1['followers']))
print('---')

pstdev_followers_df = pd.DataFrame([pstdev_followers])

pstdev_followers_df.to_csv('4_4_15_SMI1_pstdev_followers_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True) ## NEED TO DO: SAVE AS CSV
# pstdev_followers_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Population Standard Deviation Followers - Box')
plt.ioff()
# plt.boxplot(statistics.pstdev(tweets_smi_1['followers']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_15_SMI1_pstdev_followers_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

#################################################################################################################

# Skewness total_favorites

# The sample skewness measures the asymmetry of a data sample. Usually, negative skewness values indicate that there�s 
# a dominant tail on the left side, which you can see with the first set. Positive skewness values correspond to a 
# longer or fatter tail on the right side, which you can see in the second set. If the skewness is close to 0 
# (for example, between -0.5 and 0.5), then the dataset is considered quite symmetrical.


skewness_total_favorites = scipy.stats.skew(tweets_smi_1['favorites'], bias=False)
skewness_total_favorites

print('---')
print('Skewness total_favorites')
print(scipy.stats.skew(tweets_smi_1['favorites'], bias=False))
print('---')

skewness_total_favorites_df = pd.DataFrame([skewness_total_favorites], columns=['skewness_total_favorites'])

skewness_total_favorites_df.to_csv('4_4_16_SMI1_Skewness_Total_Favorites_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# skewness_total_favorites_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10)) 
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Skewness Favorites - Box')
plt.ioff()
# plt.boxplot(scipy.stats.skew(tweets_smi_1['favorites']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_16_SMI1_Skewness_Total_Favorites_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

#################################################################################################################

# Skewness followers

skewness_followers = scipy.stats.skew(tweets_smi_1['followers'], bias=False)
skewness_followers

print('---')
print('Skewness Followers ')
print(scipy.stats.skew(tweets_smi_1['followers'], bias=False))
print('---')

skewness_followers_df = pd.DataFrame([skewness_followers], columns=['skewness_followers'])

skewness_followers_df.to_csv('4_4_17_SMI1_Skewness_followers_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# skewness_followers_df.to_excel()

# NEED TO DO TABLE PLOT


# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Skewness Followers - Box')
plt.ioff()
# plt.boxplot(scipy.stats.skew(tweets_smi_1['followers']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_17_SMI1_Skewness_Followers_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO
 
#################################################################################################################

# Percentiles total_favorites

# The sample ?? percentile is the element in the dataset such that ??% of the elements in the dataset are less than or 
# equal to that value.

quantiles_total_favorites = np.percentile(tweets_smi_1['favorites'], [25, 50, 75])
quantiles_total_favorites

print('---')
print('Percentiles total_favorites')
print(np.percentile(tweets_smi_1['favorites'], [25, 50, 75]))
print('---')


quantiles_total_favorites_df = pd.DataFrame(quantiles_total_favorites, columns = ['quantiles_total_favorites'])

quantiles_total_favorites_df.to_csv('4_4_18_SMI1_Quantiles_Total_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# quantiles_total_favorites_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO DO - FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentiles Favorites - Box')
plt.ioff()
plt.plot(quantiles_total_favorites, alpha=0.9) # , [25, 50, 75]).box.plot(alpha=0.9) 
plt.xticks(rotation=50)
# plt.boxplot(quantiles_total_favorites_df, patch_artist=True, vert=False, notch=False, showfliers=True)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_18_SMI1_Quantiles_Total_Favorites_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentiles Favorites - Bars')
plt.ioff()
# (np.percentile(tweets_smi_1['favorites'], [25, 50, 75])).plot.bar(alpha=0.9) # , [25, 50, 75]).plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_18_SMI1_Quantiles_Total_Favorites_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################################################################################################

# Percentiles followers

quantiles_followers = np.percentile(tweets_smi_1['followers'], [25, 50, 75])
quantiles_followers

print('---')
print('Percentiles Followers ')
print(np.percentile(tweets_smi_1['followers'], [25, 50, 75]))
print('---')

quantiles_followers_df = pd.DataFrame(quantiles_followers, columns=['quantiles_followers'])

quantiles_followers_df.to_csv('4_4_19_SMI1_Quantiles_Followers_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True) ## NEED TO FINISH
# quantiles_followers_df.to_excel(('4_4_19_SMI1_Quantiles_Followers_DF.csv', sep='\t', encoding='utf-8', index=True)

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentiles Followers - Box')
plt.ioff()
# plt.boxplot(np.percentile(tweets_smi_1['followers'], [25, 50, 75]), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_19_SMI1_Quantiles_Followers_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentiles Followers - Bars')
plt.ioff()
# quantiles_followers_df.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_19_SMI1_Quantiles_Followers_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Ranges total_favorites

# The range of data is the difference between the maximum and minimum element in the dataset.

ptp_total_favorites = np.ptp(tweets_smi_1['favorites'])

print('---')
print('Ranges total_favorites')
print(np.ptp(tweets_smi_1['favorites']))
print('---')


ptp_total_favorites_df = pd.DataFrame([ptp_total_favorites], columns=['ranges_total_favorites'])

ptp_total_favorites_df.to_csv('4_4_20_SMI1_PTP_Ranges_Total_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# .to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Ranges Favorites - Box')
plt.ioff()
# plt.boxplot(np.ptp(tweets_smi_1['favorites']), patch_artist=True, vert=False, notch=False, showfliers=True)
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_20_SMI1_PTP_Total_Favorites_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Ranges Favorites - Bars')
ptp_total_favorites_df.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_20_SMI1_PTP_Total_Favorites_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Ranges followers

ptp_followers = np.ptp(tweets_smi_1['followers'])
ptp_followers

print('---')
print('Ranges Followers ')
print(np.ptp(tweets_smi_1['followers']))
print('---')

ptp_followers_df = pd.DataFrame([ptp_followers], columns=['ranges_followers'])

ptp_followers_df.to_csv('4_4_21_SMI1_ptp_Ranges_Followers_1_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# ptp_followers_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Ranges Followers - Box')
# plt.boxplot(np.ptp(tweets_smi_1['followers']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_21_SMI1_ptp_Followers_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Ranges Followers - Bars')
# ptp_followers_df.plt.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_21_SMI1_ptp_Followers_Bar_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################################################################################################

# SUMMARY OF DESCRIPTIVE STATISTICS total_favorites

# describe() returns an object that holds the Lists descriptive statistics:

# nobs: the number of observations or elements in your dataset
# minmax: the tuple with the minimum and maximum values of your dataset
# mean: the mean of your dataset
# variance: the variance of your dataset
# skewness: the skewness of your dataset
# kurtosis: the kurtosis of your dataset

print('---')
print('Statistical Summary for Descriptive Statistics total_favorites')
print(scipy.stats.describe(tweets_smi_1['favorites'], ddof=1, bias=False))
print('---')

summ_stats_result_total_favorites = scipy.stats.describe(tweets_smi_1['favorites'], ddof=1, bias=False)

summ_stats_result_total_favorites_df = pd.DataFrame(summ_stats_result_total_favorites)

# summ_stats_result_total_favorites

# summ_stats_result_total_favorites_df.to_csv('4_4_22_SMI1_Summ_Stats_Result_Total_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# summ_stats_result_total_favorites_df.to_excel('4_4_22_SMI1_Summ_Stats_Result_Total_Favorites_DF.xlsx', index=True, header=True) # Only argument is a string of the output file path

print('-- NEED TO DO SUMM STATS TABLE TO CSV')

# PLOT TABLE ################### NEED TO DO PLOT TO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Statistical Summary for Favorites')
# plt.plot(summ_stats_result_total_favorites)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_22_SMI1_Summ_Stats_Result_Total_Favorites.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

#################################################################################################################

# Summary Statistics of all total_favorites  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['favorites'].describe()

print('---')
print('Summary Statistics of All total_favorites - Method 2')
print(tweets_smi_1['favorites'].describe())
print('---')

# PLOT ################### NEED TO DO PLOT TO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Statistical Summary for Favorites')
plt.plot(tweets_smi_1['favorites'].describe(), alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_23_SMI1_Summ_Stats_Result_Total_Favorites_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################

# SUMMARY OF DESCRIPTIVE STATISTICS followers

summ_stats_result_followers = scipy.stats.describe(tweets_smi_1['followers'], ddof=1, bias=False)

summ_stats_result_followers_df = pd.DataFrame(summ_stats_result_followers)

print('---')
print('Statistical Summary for Descriptive Statistics Followers ')
print(scipy.stats.describe(tweets_smi_1['followers'], ddof=1, bias=False))
print('---')

summ_stats_result_followers_df.to_csv('4_4_24_SMI1_Summ_Stats_Result_Followers_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# summ_stats_result_followers_df.to_excel('4_4_24_SMI1_Summ_Stats_Result_Followers_DF.xlsx', index=True, header=True) # Only argument is a string of the output file path

# PLOT TABLE plt.plot # NEED TO DO FIX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Statistical Summary for Followers ')
# plt.plot(scipy.stats.describe(tweets_smi_1['followers'], ddof=1, bias=False, alpha=0.9))
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_24_SMI1_Summ_Stats_Result_Followers_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# summ_stats_result_followers

print('---')
print('Statistical Summary for Descriptive Statistics Followers ')
print(summ_stats_result_followers)
print('---')

print('-- NEED TO DO: SAVE TO CSV AND PRINT TABLES')

# NEED TO PLOT TABLE

#################################################################################################################

# STATS lists

# Mean lists

mean_lists = statistics.mean(tweets_smi_1['lists'])
mean_lists

print('---')
print('Mean lists')
print(mean_lists)
print('---')

mean_lists_df = pd.DataFrame([mean_lists], columns=['mean_lists'])

mean_lists_df.to_csv('4_4_3_SMI1_Mean_Lists_CSV.csv', sep='\t', encoding='utf-8', index=True)
# mean_lists_df.to_excel('4_4_3_SMI1_Mean_Lists.xlsx', header=True)

# NEED TO DO TABLE PLOT

# BOX PLOT 3 ########## NEED TO FIX  

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale()
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean Lists No Fliers - Box')
# plt.boxplot(tweets_smi_1['lists'], patch_artist=True, vert=False, notch=False, showfliers=False)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_3_SMI1_Mean_Lists_Box_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

#################

# Median lists

median_lists = statistics.median(tweets_smi_1['lists'])
median_lists

print('---')
print('Median Lists')
print(statistics.median(tweets_smi_1['lists']))
print('---')

median_lists_df = pd.DataFrame([median_lists], columns=['median_lists'])

median_lists_df.to_csv('4_4_4_SMI1_Median_Lists_CSV.csv', sep='\t', encoding='utf-8', index=True)
# median_lists_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX ########## NEED TO FIX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Median Lists - Box')
plt.boxplot(statistics.median(tweets_smi_1['lists']), vert=False, notch=False, showfliers=False) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_4_SMI1_Median_Lists_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Mode lists

mode_lists = statistics.mode(tweets_smi_1['lists'])
mode_lists

print('---')
print('Mode lists')
print(statistics.mode(tweets_smi_1['lists']))
print('---')

mode_lists_df = pd.DataFrame([mode_lists], columns=['mode_lists'])

mode_lists_df.to_csv('4_4_7_SMI1_Mode_Lists_CSV.csv', sep='\t', encoding='utf-8', index=True)
# mode_lists_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mode Lists - Box')
plt.boxplot(statistics.mode(tweets_smi_1['lists']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_7_SMI1_Mode_Lists_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mode Lists - Bars')
mode_lists_df.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_7_SMI1_Mode_Lists_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

##################################

# https://realpython.com/python-statistics/         

# Measures of Variability

print('Measures of Variability')

# The measures of central tendency aren�t sufficient to describe data. You�ll also need the measures of variability 
# that quantify the spread of data points. 

# Variance total_favorites

# The sample variance quantifies the spread of the data. It shows numerically how far the data points are from the mean.


##################################

# Variance lists

variance_lists = statistics.variance(tweets_smi_1['lists'])
variance_lists

print('---')
print('Variance lists')
print(statistics.variance(tweets_smi_1['lists']))
print('---')

variance_lists_df = pd.DataFrame([variance_lists])

variance_lists_df.to_csv('4_4_9_Variance_Lists_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# variance_lists_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Variance Lists - Box')
# plt.plot(statistics.variance(tweets_smi_1['lists']), alpha=0.9) 
plt.boxplot(statistics.variance(tweets_smi_1['lists']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_9_SMI1_Variance_Lists_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO


#################################################

# Population Variance lists

pvariance_lists = statistics.pvariance(tweets_smi_1['lists'])
pvariance_lists

print('---')
print('Population Variance lists')
print(statistics.pvariance(tweets_smi_1['lists']))
print('---')

pvariance_lists_df = pd.DataFrame([pvariance_lists], columns = ['pvariance_reetweets'])

pvariance_lists_df.to_csv('4_4_11_SMI1_pvariance_Lists_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# pvariance_lists_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Population Variance Lists - Box')
# plt.plot(statistics.pvariance(tweets_smi_1['lists']), alpha=0.9)
plt.boxplot(statistics.pvariance(tweets_smi_1['lists']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_11_SMI1_pvariance_Lists_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###########################################################################################

# Standard Deviation lists

stdev_lists = statistics.stdev(tweets_smi_1['lists'])
stdev_lists

print('---')
print('Standard Deviation lists')
print(statistics.stdev(tweets_smi_1['lists']))
print('---')

stdev_lists_df = pd.DataFrame([stdev_lists], columns=['stdev_lists'])

stdev_lists_df.to_csv('4_4_13_SMI1_stdev_Lists_df_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# stdev_lists_df.to_excel('4_4_13_SMI1_stdev_Lists_df.xlsx', sep='\t', encoding='utf-8', index=True, header=True)

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Standard Deviation Lists - Box')
plt.boxplot(statistics.stdev(tweets_smi_1['lists']), patch_artist=True, vert=False, notch=False, showfliers=True) 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_13_SMI1_Stdev_Lists_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLO NEED TO DO

#############################


# Population Standard Deviation lists

pstdev_lists = statistics.pstdev(tweets_smi_1['lists'])
pstdev_lists

print('---')
print('Population Standard Deviation lists')
print(statistics.pstdev(tweets_smi_1['lists']))
print('---')

pstdev_lists_df = pd.DataFrame([pstdev_lists])

pstdev_lists_df.to_csv('4_4_15_SMI1_pstdev_lists_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True) ## NEED TO DO: SAVE AS CSV
# pstdev_lists_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Population Standard Deviation Lists - Box')
plt.boxplot(statistics.pstdev(tweets_smi_1['lists']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_15_SMI1_pstdev_Lists_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

##########################################


# Skewness lists

skewness_lists = scipy.stats.skew(tweets_smi_1['lists'], bias=False)
skewness_lists

print('---')
print('Skewness lists')
print(scipy.stats.skew(tweets_smi_1['lists'], bias=False))
print('---')

skewness_lists_df = pd.DataFrame([skewness_lists], columns=['skewness_lists'])

skewness_lists_df.to_csv('4_4_17_SMI1_Skewness_Lists_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# skewness_lists_df.to_excel()

# NEED TO DO TABLE PLOT


# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Skewness Lists - Box')
plt.boxplot(scipy.stats.skew(tweets_smi_1['lists']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_17_SMI1_Skewness_lists_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

 
###############################################


# Percentiles lists

quantiles_lists = np.percentile(tweets_smi_1['lists'], [25, 50, 75])
quantiles_lists

print('---')
print('Percentiles lists')
print(np.percentile(tweets_smi_1['lists'], [25, 50, 75]))
print('---')

quantiles_lists_df = pd.DataFrame(quantiles_lists, columns=['quantiles_lists'])

quantiles_lists_df.to_csv('4_4_19_SMI1_Quantiles_Lists_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True) ## NEED TO FINISH
# quantiles_lists_df.to_excel(('4_4_19_SMI1_Quantiles_Lists_DF.csv', sep='\t', encoding='utf-8', index=True)

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentiles Lists - Box')
plt.boxplot(np.percentile(tweets_smi_1['lists'], [25, 50, 75]), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_19_SMI1_Quantiles_Lists_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentiles Lists - Bars')
# quantiles_lists_df.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_19_SMI1_Quantiles_Lists_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################

# Ranges lists

ptp_lists = np.ptp(tweets_smi_1['lists'])
ptp_lists

print('---')
print('Ranges lists')
print(np.ptp(tweets_smi_1['lists']))
print('---')

ptp_lists_df = pd.DataFrame([ptp_lists], columns=['ranges_lists'])

ptp_lists_df.to_csv('4_4_21_SMI1_ptp_Ranges_lists_1_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# ptp_lists_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Ranges Lists - Box')
plt.boxplot(np.ptp(tweets_smi_1['lists']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_21_SMI1_ptp_lists_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Ranges Lists - Bars')
# ptp_lists_df.plt.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_21_SMI1_ptp_Lists_Bar_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# SUMMARY OF DESCRIPTIVE STATISTICS total_favorites

# describe() returns an object that holds the Lists descriptive statistics:

# nobs: the number of observations or elements in your dataset
# minmax: the tuple with the minimum and maximum values of your dataset
# mean: the mean of your dataset
# variance: the variance of your dataset
# skewness: the skewness of your dataset
# kurtosis: the kurtosis of your dataset

#############################################

# SUMMARY OF DESCRIPTIVE STATISTICS lists

summ_stats_result_lists = scipy.stats.describe(tweets_smi_1['lists'], ddof=1, bias=False)

summ_stats_result_lists_df = pd.DataFrame(summ_stats_result_lists)

print('---')
print('Statistical Summary for Descriptive Statistics lists')
print(scipy.stats.describe(tweets_smi_1['lists'], ddof=1, bias=False))
print('---')

summ_stats_result_lists_df.to_csv('4_4_24_SMI1_Summ_Stats_Result_Lists_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# summ_stats_result_lists_df.to_excel('4_4_24_SMI1_Summ_Stats_Result_Lists_DF.xlsx', index=True, header=True) # Only argument is a string of the output file path

# PLOT TABLE plt.plot # NEED TO DO FIX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Statistical Summary for Lists')
# plt.plot(scipy.stats.describe(tweets_smi_1['lists'], ddof=1, bias=False, alpha=0.9))
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_24_SMI1_Summ_Stats_Result_Lists_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# summ_stats_result_lists

print('---')
print('Statistical Summary for Descriptive Statistics lists')
print(summ_stats_result_lists)
print('---')

print('-- NEED TO DO: SAVE TO CSV AND PRINT TABLES')

# NEED TO PLOT TABLE

#################################################################################################################

# Correlation Coefficient : Pearson

# The correlation coefficient, or Pearson product-moment correlation coefficient, is denoted by the symbol ??. The 
# coefficient is another measure of the correlation between data. You can think of it as a standardized covariance. 
# Here are some important facts about it:

# The value ?? > 0 indicates positive correlation.
# The value ?? < 0 indicates negative correlation.
# The value r = 1 is the maximum possible value of ??. It corresponds to a perfect positive linear relationship 
# between variables.
# The value r = -1 is the minimum possible value of ??. It corresponds to a perfect negative linear relationship 
# between variables.
# The value r 0, or when ?? is around zero, means that the correlation between variables is weak.

# pearsonr() returns a tuple with two numbers. The first one is ?? and the second is the ??-value.

corr_coef_total_favorites_followers_pearson = scipy.stats.pearsonr(tweets_smi_1['favorites'], tweets_smi_1['followers'])

corr_coef_total_favorites_followers_pearson_df = pd.DataFrame(corr_coef_total_favorites_followers_pearson)

corr_coef_total_favorites_followers_pearson_df.to_csv('4_4_25_SMI1_Corr_Coef_Total_Favorites_Followers_Pearson_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header='corr_coef_total_favorites_followers_pearson_df')
# corr_coef_total_favorites_followers_pearson_df.to_excel()

print('---')
print('Correlation Coefficient: Pearson Favorites vs Followers ')
print(corr_coef_total_favorites_followers_pearson)
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4)) 
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient: Pearson Favorites vs Followers - Box')
plt.boxplot(scipy.stats.pearsonr(tweets_smi_1['favorites'], tweets_smi_1['followers']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_25_SMI1_Corr_Coef_Total_Favorites_Followers_Pearson_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTERPLOT - NEED TO SET DIF COLORS FOR X AND Y!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10)) 
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient: Pearson Favorites vs Followers - Scatter')
# (scipy.stats.pearsonr(tweets_smi_1['favorites'], tweets_smi_1['followers'])).plot(alpha=0.9)
# corr_coef_total_favorites_followers_pearson_df.plot.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_25_SMI1_Corr_Coef_Total_Favorites_Followers_Pearson_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4)) 
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient: Pearson Favorites vs Followers - Bars')
# plt.plot(scipy.stats.pearsonr(tweets_smi_1['favorites'], tweets_smi_1['followers']))
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_25_SMI1_Corr_Coef_Total_Favorites_Followers_Pearson_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Correlation Coefficient Matrix

# Similar to the case of the covariance matrix, you can apply np.corrcoef() with x_ and y_ as the arguments and 
# get the correlation coefficient matrix:

corr_matrix_total_favorites_followers = np.corrcoef(tweets_smi_1['favorites'], tweets_smi_1['followers'])
corr_matrix_total_favorites_followers_df = pd.DataFrame(corr_matrix_total_favorites_followers)

print('---')
print('Correlation Coefficient Matrix total_favorites vs Followers ')
print(np.corrcoef(tweets_smi_1['favorites'], tweets_smi_1['followers']))
print('---')

corr_matrix_total_favorites_followers_df.to_csv('4_4_26_SMI1_Corr_Matrix_Total_Favorites_Followers_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# corr_matrix_total_favorites_followers_df.to_excel('4_4_26_SMI1_Corr_Matrix_Total_Favorites_Followers_DF.xlsx', index=True, header=True) # Only argument is a string of the output file path

# PLOT TABLE plt.plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient Matrix Favorites vs Followers')
plt.plot(corr_matrix_total_favorites_followers, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_26_SMI1_Corr_Matrix_Total_Favorites_Followers_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient Matrix Favorites vs Followers - Bars')
# corr_matrix_total_favorites_followers.plot.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_26_SMI1_Corr_Matrix_Total_Favorites_Followers_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Linear Regession

# inregress() takes x_ and y_, performs linear regression, and returns the results. slope and intercept define the equation of the regression line, while rvalue is the correlation coefficient. To access particular values from the result of linregress(), including the correlation coefficient, use dot notation:

linar_reg_total_favorites_followers = scipy.stats.linregress(tweets_smi_1['favorites'], tweets_smi_1['followers'])
r_linar_reg_total_favorites_followers = linar_reg_total_favorites_followers.rvalue
r_linar_reg_total_favorites_followers_df = pd.DataFrame([r_linar_reg_total_favorites_followers])

r_linar_reg_total_favorites_followers_df.to_csv('4_4_27_SMI1_R_Linear_Reg_Total_Favorites_Followers_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# r_linar_reg_total_favorites_followers_df.to_excel()

print('---')
print('Linear Regression total_favorites vs Followers ')
print(scipy.stats.linregress(tweets_smi_1['favorites'], tweets_smi_1['followers']))
print('---')

# PLOT ####### NEED TO FIX DO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale()
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Linear Regression Favorites vs Followers')
plt.plot(r_linar_reg_total_favorites_followers, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_27_SMI1_R_Linear_Reg_Total_Favorites_Followers_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Linear Regression Favorites vs Followers - Box')
plt.boxplot(scipy.stats.linregress(tweets_smi_1['favorites'], tweets_smi_1['followers']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_27_SMI1_R_Linear_Reg_Total_Favorites_Followers_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# SCATTERPLOT

r_reg_total_favorites_followers_array = scipy.stats.linregress(tweets_smi_1['favorites'], tweets_smi_1['followers'])

## NEED TO DO SCATTERPLOT NEED TO GET FDIF COLORS X AND Y 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10)) 
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Linear Regression Favorites vs Followers - Scatter')
plt.plot(scipy.stats.linregress(tweets_smi_1['favorites'], tweets_smi_1['followers']))
plt.scatter(tweets_smi_1['favorites'], tweets_smi_1['followers'], alpha=0.9)
plt.plot(r_linar_reg_total_favorites_followers)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_27_SMI1_Corr_Coef_Total_Favorites_Followers_Pearson_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS ####### NEED TO FIX DO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale()
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Linear Regression Favorites vs Followers - Bars')
# r_linar_reg_total_favorites_followers.bars.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_27_SMI1_R_Linear_Reg_Total_Favorites_Followers_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

#################################################################################

# ANALYSING THE DATA ########### NEED TO DO - GROUPED BY FAVS OR RETS OR IS IT REPETATED?

# Followers STATS

# MEAN

mean_df_followers_2 = tweets_smi_1['followers'].mean()

mean_df_followers_2_df = pd.DataFrame([mean_df_followers_2], columns=['mean_df_followers_2'])

mean_df_followers_2_df.to_csv('4_4_29_SMI1_Mean_df_Followers_2_df.csv')
# mean_df_followers_2_df.to_excel()

print('---')
print('Mean Followers ')
# print(tweets_smi_1['followers'].mean())
print('---')

############################################################

# BOX PLOT ########## NEED TO FIX 2 means 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10)) 
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean Favorites / Followers - Box')
plt.boxplot(tweets_smi_1['favorites'].mean(), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.boxplot(tweets_smi_1['followers'].mean(), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_28_SMI1_Mean_DF_Followers_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################################################

# MEDIAN

median_df_followers_2 = tweets_smi_1['followers'].median()
median_df_followers_2

median_df_followers_2_df = pd.DataFrame([median_df_followers_2], columns = ['median_followers'])

median_df_followers_2_df.to_csv('4_4_29_SMI1_Median_df_Followers_2_df.csv')
# median_df_followers_2_df.to_excel()

print('---')
print('Median Followers ')
print(tweets_smi_1['followers'].median())
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Median Followers - Box')
plt.boxplot(median_df_followers_2_df, patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_29_SMI1_Median_Df_Followers_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Median Followers - Bars')
# median_df_followers_2_df.plot.bars() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_29_SMI1_Median_Df_Followers_2_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################################################

# Standard Deviation

std_df_followers_2 = tweets_smi_1['followers'].std() 

std_df_followers_2_df = pd.DataFrame([std_df_followers_2], columns=['standard_deviation_followers'])

std_df_followers_2_df.to_csv('4_4_29_SMI1_std_df_Followers_2_CSV.csv')
# std_df_followers_2_df.to_excel()

print('---')
print('Standard Deviation Followers ')
print(tweets_smi_1['followers'].std())
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Standard Deviation Followers - Box')
# std_df_followers_2_df.plt.box()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_29_SMI1_Std_df_Followers_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Standard Deviation Followers - Bars')
# std_df_followers_2.plt.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_29_SMI1_Std_df_Followers_2_Bars.png', bbox_inches='tight')
# plt.close(fig='all')
# plt.clf()

##############################################################################

# MAXIMUM OF EACH ATTRIBUTE

max_df_followers_2 = tweets_smi_1['followers'].max()

max_df_followers_2_df = pd.DataFrame([max_df_followers_2], columns=['max_followers'])

max_df_followers_2_df.to_csv('4_4_29_SMI1_Max_df_followers_2_CSV.csv')
# std_df_followers_2_df.to_excel()

print('---')
print('Maximum of Each Attribute vs Followers ')
print(tweets_smi_1['followers'].max())
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Maximum of Each Attribute Followers - Box')
plt.plot(tweets_smi_1['followers'].max())
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_30_SMI1_Max_DF_Followers_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Maximum of Each Attribute Followers - Bars')
# (tweets_smi_1['followers'].max()).plot.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_30_SMI1_Max_DF_Followers_2_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################################################

# MINIMUM OF EACH ATTRIBUTE

min_df_followers_2 = tweets_smi_1['followers'].min()

min_df_followers_2_df = pd.DataFrame([min_df_followers_2])

min_df_followers_2_df.to_csv('4_4_30_SMI1_min_df_followers_2_df.csv')
# excel()

print('---')
print('Minimum of Each Attribute / Followers ')
print(tweets_smi_1['followers'].min())
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Minimum of Each Attribute / Followers - Box')
plt.plot(tweets_smi_1['followers'].min()) 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_30_SMI1_Min_DF_Followers_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################################################
 
# DESCRIPTIVE STATISTICS SUMMARY   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

df_tweets_smi_processes_describe_followers_1 = tweets_smi_1['followers'].describe()
df_tweets_smi_processes_describe_followers_1_df = pd.DataFrame(df_tweets_smi_processes_describe_followers_1)

# df_tweets_smi_processes_describe_followers_1_df.to_csv('4_4_31_SMI1_DF_Tweets_smi_Processes_Describe_followers_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header='df_tweets_smi_processes_describe_followers')
# df_tweets_smi_processes_describe_followers_1_df.to_excel('4_4_31_SMI1_DF_Tweets_smi_Processes_Describe_followers_DF.xlsx', index=False, header=True)

print('---')
print('Descriptive Statistics Summary Followers ')
print(tweets_smi_1['followers'].describe())
print('---')


# CREATE TABLE plt.plot ############# NEED TO FIX CREATING TABLES!!!!!!!!!!!!!!

# table_df_tweets_smi_processes_describe_followers_1 = ff.create_table(df_tweets_smi_processes_followers_1.describe(include=['O']).T)

# TABLE PLOT NEED TO DO

# df_tweets_smi_processes_describe_followers_1

# PLOT ??????????

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10)) 
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Descriptive Statistics Summary Followers ')
plt.plot(df_tweets_smi_processes_describe_followers_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_31_SMI1_DF_Tweets_smi_Processes_Describe_Followers.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff() 

# plt.figure(figsize=(14,10)) 
# plt.autoscale()
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Descriptive Statistics Summary Followers - Bars')
# df_tweets_smi_processes_describe_followers_1_df[:10].plot.bar(alpha=0.9)
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_31_SMI1_Describe_Summ_Stats_followers_Bars.png', bbox_inches='tight')
# plt.close(fig='all')
# plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10)) 
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Descriptive Statistics Summary Followers - Bars')
df_tweets_smi_processes_describe_followers_1[:10].plot.bar(alpha=0.9)
plt.xlabel('Values')
plt.ylabel('Measures')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_31_SMI1_DF_Tweets_SMI_Processes_Describe_followers_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################################################################################

# ANALYSING THE DATA  #########  NEED TO DO : REPEATED???

# total_favorites STATS

# MEAN

mean_df_total_favorites_2 = tweets_smi_1['favorites'].mean()

mean_df_total_favorites_2_df = pd.DataFrame([mean_df_total_favorites_2])

mean_df_total_favorites_2_df.to_csv('4_4_32_SMI1_Mean_df_Total_Favorites_2_df.csv')
# mean_df_total_favorites_2.to_excel()

print('---')
print('Mean total_favorites')
print(tweets_smi_1['favorites'].mean())
print('---')

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean Favorites - Box')
# plt.plot(tweets_smi_1['favorites'].mean()) 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_32_SMI1_Mean_DF_Total_Favorites_2_Box.png', bbox_inches='tight')
# plt.close(fig='all')
# plt.clf()


##############################################################################

# MEDIAN

median_df_total_favorites_2 = tweets_smi_1['favorites'].median()

print('---')
print('Median total_favorites')
print(tweets_smi_1['favorites'].median())
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Median Favorites - Box')
# plt.plot(tweets_smi_1['favorites'].median()) 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_32_SMI1_Median_Df_Total_Favorites_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################################################

# Standard Deviation

std_df_total_favorites_2 = tweets_smi_1['favorites'].std() 

print('---')
print('Standard Deviation total_favorites')
print(tweets_smi_1['favorites'].std())
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Standard Deviation Favorites - Box')
plt.plot(tweets_smi_1['favorites'].std()) 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_32_SMI1_Std_DF_Total_Favorites_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################################################

# MAXIMUM OF EACH ATTRIBUTE

max_df_total_favorites_2 = tweets_smi_1['favorites'].max()

max_df_total_favorites_2_df = pd.DataFrame([max_df_total_favorites_2])

# MINIMUM OF EACH ATTRIBUTE

min_df_total_favorites_2 = tweets_smi_1['favorites'].min()

min_df_total_favorites_2_df = pd.DataFrame([min_df_total_favorites_2])

min_df_total_favorites_2_df.to_csv('4_4_32_SMI1_Max_Min_df_Total_Favorites_2_df_CSV.csv', sep='\t', encoding='utf-8', index=False, header='df_tweets_smi_processes_describe_total_favorites_df')
# min_df_total_favorites_2_df.to_excel('4_4_32_SMI1_Max_Min_df_Total_Favorites_2_df.xlsx', header=True)

# MAX AND MIN


print('---')
print('Minimum of Each Attribute - total_favorites')
print(tweets_smi_1['favorites'].min())
print('---')

max_df_total_favorites_2_df = pd.DataFrame([max_df_total_favorites_2])

max_df_total_favorites_2_df.to_csv('4_4_32_Max_df_Total_Favorites_2_df_CSV.csv', sep='\t', encoding='utf-8', index=False, header='df_tweets_smi_processes_describe_total_favorites_df')
# max_df_total_favorites_2_df.to_excel('4_4_32_Max_df_Total_Favorites_2_df.xlsx', header=True)

print('---')
print('Maximum of Each Attribute - total_favorites')
print(tweets_smi_1['favorites'].max())
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Maximum of Each Attribute Favorites - Box')
plt.plot(tweets_smi_1['favorites'].max()) 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_32_SMI1_Max_DF_Total_Favorites_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################################################


# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Minimum of Each Attribute Favorites - Box')
plt.plot(tweets_smi_1['favorites'].min()) 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_32_SMI1_Min_DF_Total_Favorites_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################################################

# DESCRIPTIVE STATISTICS SUMMARY FAVS         ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

df_tweets_smi_processes_describe_total_favorites_1 = tweets_smi_1['favorites'].describe()

print('---')
print('Descriptive Statistics Summary total_favorites')
print(tweets_smi_1['favorites'].describe())
print('---')

df_tweets_smi_processes_describe_total_favorites_df = pd.DataFrame(df_tweets_smi_processes_describe_total_favorites_1)

# df_tweets_smi_processes_describe_total_favorites_df.to_csv('4_4_33_SMI1_DF_Tweets_SMI_Processes_Describe_Total_Favorites_CSV.csv', sep='\t', encoding='utf-8', index=False, header='df_tweets_smi_processes_describe_total_favorites_df')
# df_tweets_smi_processes_describe_total_favorites_df.to_excel('4_4_33_SMI1_DF_Tweets_SMI_Processes_Describe_total_favorites.xlsx', header=True)

# CREATE TABLE plt.plot ## NEED TO DO

# BOX PLOT NEED TO DO


# Bars

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Descriptive Statistics Favorites - Bars')
(tweets_smi_1['favorites'].describe()).plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_33_SMI1_DF_Tweets_smi_Processes_Describe_Total_Favorites_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################################################################################################

# DESCRIPTIVE STATISTICS SUMMARY FAVS         ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

df_tweets_smi_processes_describe_followers_1 = tweets_smi_1['followers'].describe()

print('---')
print('Descriptive Statistics Summary Followers ')
print(tweets_smi_1['followers'].describe())
print('---')

df_tweets_smi_processes_describe_followers_df_1 = pd.DataFrame(df_tweets_smi_processes_describe_followers_1)

# df_tweets_smi_processes_describe_followers_df_1.to_csv('4_4_34_SMI1_DF_Tweets_SMI_Processes_Describe_Followers_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# df_tweets_smi_processes_describe_followers_df_1.to_excel('4_4_34_SMI1_DF_Tweets_SMI_Processes_Describe_Followers_DF.xlsx', header=True)

# CREATE TABLE plt.plot ## NEED TO DO 

# table_df_tweets_smi_processes_describe_followers_1 = ff.create_table(df_tweets_smi_processes_followers_1.describe(include=['O']).T)

# NEED TO DO TABLE PLOT

# BOX PLOT NEED TO DO 

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Descriptive Statistics Followers - Bars')
(tweets_smi_1['followers'].describe()).plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_34_SMI1_DF_Tweets_smi_Processes_Describe_Followers_1_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################
#####

# METHOD 1 total_favorites

fp_total_favorites = tweets_smi_1['favorites'].to_string()

# fp_total_favorites = fp_total_favorites_temp.to_string()

tweets_text_total_favorites = nltk.word_tokenize(fp_total_favorites)

value_counts_total_favorites = pd.value_counts(tweets_text_total_favorites, ascending=False, normalize=True) 

smi1_value_counts_total_favorites = value_counts_total_favorites.sort_values(ascending=False)

# smi1_value_counts_total_favorites_freq_dist = tweets_text_total_favorites.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts total_favorites - Frequency')
# print(smi1_value_counts_total_favorites.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts total_favorites')
# print(smi1_value_counts_total_favorites.describe().head)
print('---')

smi1_value_counts_total_favorites_df = pd.DataFrame(smi1_value_counts_total_favorites, columns=['total_favorites_frequency'])

smi1_value_counts_total_favorites_df.to_csv('4_4_43_100_SMI1_Value_Counts_Total_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_total_favorites_df.to_excel('4_4_43_100_SMI1_Value_Counts_Total_Favorites_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Value Counts')
plt.plot(smi1_value_counts_total_favorites[:10], alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Total_Favorites_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Value Counts - Pie')
smi1_value_counts_total_favorites[:6].plot(kind='pie', colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(smi1_value_counts_total_favorites, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Total_Favorites_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Value Counts - Bars')
smi1_value_counts_total_favorites[:10].plot.bar(alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_total_favorites) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Total_Favorites_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Common Tweet total_favorites

value_counts_total_favorites = pd.value_counts(tweets_smi_1['favorites'], ascending=False, normalize=True)

print('---')
print('Most Common Tweets total_favorites')
# print(value_counts_total_favorites)
print('---')


# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_total_favorites.to_csv('4_4_43_75_SMI1_df_Top_Value_Counts_Total_Favorites_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_total_favorites.to_excel('4_4_43_75_SMI1_df_Top_Value_Counts_Total_Favorites.xlsx', index=False, header=True)

# value_counts_total_favorites

top_total_favorites_tweets = value_counts_total_favorites.sort_values(ascending=False)

# NEED TO PLOT TABLE

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Favorites - Pie') 
tweets_smi_1['favorites'].value_counts()[:6].plot(kind='pie', colors=colors_blue, startangle=70, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
plt.legend(labels=tweets_smi_1['favorites'], bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_75_SMI1_Top_Value_Counts_Total_Favorites_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars

# TOP NUMBERS OF total_favorites In Tweets 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Favorites - Bars')
top_total_favorites_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_75_SMI1_Top_Value_Counts_Total_Favorites_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###

value_counts_total_favorites = pd.DataFrame(value_counts_total_favorites)


print('---')
print('Value Counts total_favorites DF')
# print(value_counts_total_favorites.info)
print('---')

percentage_value_counts_total_favorites = pd.value_counts(tweets_smi_1['favorites'], normalize=True) * 100


# Inicialize List of Lists

value_counts_total_favorites_item = [['total_favorites', value_counts_total_favorites, percentage_tweets_repeated]]

# Create DataFrame

value_counts_total_favorites_item_df = pd.DataFrame(value_counts_total_favorites_item, columns =['total_favorites_number', 'total_favorites_counts', 'total_favorites_percentages'])


# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_total_favorites_item_df.to_csv('4_4_43_75_SMI1_Value_Counts_Total_Favorites_Item_df_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_total_favorites_item_df.to_excel('4_4_43_75_SMI1_Value_Counts_Total_Favorites_Item_df.xlsx', index=False, header=True)

# value_counts_total_favorites


# NEED TO PLOT TABLE

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Favorites - Pie')
# plt.pie(value_counts_total_favorites_item_df, labels=[top_total_favorites_tweets], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend[labels=value_counts_total_favorites_item_df, loc='upper right', borderaxespad=0.) 
# value_counts_total_favorites_item_df.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=value_counts_total_favorites_item_df, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_75_SMI1_Value_Counts_Total_Favorites_Item_df_Pie_Chart_PLT.png', bbox_inches='tight')
# plt.close(fig='all')
# plt.clf()


# Bars

# TOP NUMBERS OF total_favorites In Tweets 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Favorites - Bars')
# value_counts_total_favorites_item_df.plot.bar(alpha=0.9)
# plt.xlabel('Favorites')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_43_75_SMI1_Value_Counts_Total_Favorites_Item_df_Bars.png', bbox_inches='tight')
# plt.close(fig='all')
# plt.clf()


# Bars 

# NEED TP FOX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Followers - Bars')
plt.ioff()
tweets_smi_1['followers'].value_counts()[:6].plot.bar(alpha=0.9)
plt.xlabel('Number of Followers')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_76_SMI1_Top_Followers_Values_Number_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###
#############################################################################################
###########################################################################################################################################################

# Percentage of 

value_counts_total_favorites

value_counts_followers

percentage_value_counts_total_favorites = ((value_counts_total_favorites * 100)/number_total_tweets)
percentage_value_counts_total_favorites

print('---')
print('Top total_favorites Number Value Counts Percentages')
print(percentage_value_counts_total_favorites)
print('---')

percentage_value_counts_followers = ((value_counts_followers * 100)/number_total_tweets)
percentage_value_counts_followers

print('---')
print('Top Followers Number Value Counts Percentages')
print(percentage_value_counts_followers)
print('---')


# NEED TO DO - FIX - CHANGE

# users_favorite_retweet_list = [['total_favorites', value_counts_total_favorites, percentage_value_counts_total_favorites], ['followers', value_counts_followers, percentage_value_counts_followers], ['xx', 'xx', 'xx']]
users_favorite_retweet_list = [['total_favorites_value_counts', value_counts_total_favorites, percentage_value_counts_total_favorites], ['followers_value_counts', value_counts_followers, percentage_value_counts_followers]]


# Create the pandas DataFrame 
users_favorite_retweet_list_df = pd.DataFrame(users_favorite_retweet_list, columns = ['description_item_value', 'item_value_count', 'item_value_percentage']) 

print('--------')

print('Top total_favorites - Followers Number Value Counts Percentages DF - NEED TO FIX')
# print(users_favorite_retweet_list_df)
print('--------')

users_favorite_retweet_list_df.to_csv('4_4_37_77_SMI1_Users_Favorite_ReTweet_List_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# users_favorite_retweet_list_df.to_excel('4_4_37_77_SMI1_Users_Favorite_ReTweet_List_DF.xlsx', header=True)

# NEED TO DO PLOT!!!!!!!!!!!!!!!!

# TABLE PLOT

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Favorites - Pie')
plt.ioff()
plt.pie(users_favorite_retweet_list_df.value_counts()[:6], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(users_favorite_retweet_list_df, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_37_77_SMI1_Users_Favorite_ReTweet_List_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Favorites - Bars')
plt.ioff()
# users_favorite_retweet_list_df[:6].plot.bar(alpha=0.9)
plt.xlabel('Number of Favorites')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_37_77_SMI1_Users_Favorite_ReTweet_List_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###

# PLOT BARS - MULTIPLE - Tweets ABOUT AND BY SMI ## NEED TO DO - FIX 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

r1 = np.arange(len(tweets_smi_1['favorites'].value_counts()[:10]))
r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES // NEED TO CHANGE

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites / Retweets Value Counts - Bars')
plt.ioff()

plt.bar(r1, smi1_value_counts_total_favorites[:10], color='#73C2FB', edgecolor='white', label='Tweets About', alpha=0.9)
plt.bar(r2, smi1_value_counts_retweets[:10], color='blue', edgecolor='white', label='Tweets By Author', alpha=0.9)

plt.xticks(rotation=50)
plt.xlabel('Favorites / Retweets Number Value')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_37_77_SMI1_Users_Favorite_ReTweet_List_PLT_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##################################################################################################################

# top_screnname_followers = tweets_smi_1.groupby('screenName')[['followers_count']].sum()
# top_screenname_followers = top_screenname_followers.sort_values(ascending=False)[:10]

top_screnname_followers = tweets_smi_1['followers_count'].value_counts(ascending=False)

# NEED TO DO PLOT!!!!!!!!!!!!!!!!

# TABLE PLOT

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames by Tweet Number and Followers - Pie')
top_screnname_followers[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['screenName'], bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_37_77_SMI1_Top_Screenname_Followers_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames by Tweet Number and Followers - Bars')
plt.ioff()
top_screnname_followers[:10].plot.bar(alpha=0.9)
plt.xlabel('Number of Followers')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_37_77_SMI1_Top_ScreenName_Followers_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################################################################################################################

# top_screnname_following = tweets_smi_1.groupby('screenName')[['following']].sum()
# top_screenname_following = top_screenname_following.sort_values(ascending=False)[:10]

top_screnname_following = tweets_smi_1['following'].value_counts(ascending=False)

# NEED TO DO PLOT!!!!!!!!!!!!!!!!

# TABLE PLOT

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames by Tweet Number and Following - Pie')
top_screnname_following[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['screenName'], bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_37_77_SMI1_Top_ScreenName_Following_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames by Tweet Number and Following - Bars')
plt.ioff()
top_screnname_following[:10].plot.bar(alpha=0.9)
plt.xlabel('Number of Following')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_37_77_SMI1_Top_ScreenName_Following_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################################################################################################################
##################################################################################################################
####################################################################################################################
#########################################################################################

# CANDLESTICK GRAPH ######### NEED TO DO - NOT WORKING

candestick_data = tweets_smi_1

# candestick_data.append()

x = 0
y = len(tweets_smi_1['created'])

ohlc = []

# while x, y >> 0:
#	append_candlestick = created[x], total_favorites[x], followers[x]
#	ohlc.append(append_candlestick) 
#	x+=1

# candlestick_ohlc(ax1, ohlc)

# ax1.xaxis.set.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S))

# plt.figure(figsize=(14,10))

plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Created, Favorited and Followers - CandleStick')
plt.ioff()
# candlestick_ohlc(ax1, ohlc, width=0.4, colorup='#77d879', colordown='#db3f3f')
# ax1.xaxis.set.set_major_locator(mticker.MaxNLocator(10))
plt.xlabel('Date')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_37_78_SMI1_Created_Favorites_Followers_CandleStick.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################
##############################################################

# https://towardsdatascience.com/data-science-with-python-intro-to-loading-and-subsetting-data-with-pandas-9f26895ddd7f

#### TWEETS WITH NO total_favorites NOT UNIQUE

# SUBSETS

# Number of Tweets With total_favorites  ########### NEED TO FIX

tweets_with_total_favorites = tweets_smi_1[(tweets_smi_1['favorites'] != 0)]  ######### NEED TO ADD CONDITION - NOT WORKING

print('---')
print('Tweets With total_favorites Info -- SERIES VALUE')
# print(tweets_with_total_favorites)
print('---')

tweets_with_total_favorites_count = tweets_with_total_favorites.count()

print('---')
print('Tweets With total_favorites Count')
print(tweets_with_total_favorites_count)
print('---')


tweets_without_total_favorites_filter = tweets_smi_1[(tweets_smi_1['favorites'] == 0)]

# tweets_without_total_favorites_filter = pd.DataFrame(tweets_without_total_favorites_filter, columns=['tweets_withput_total_favorites_filter'])

number_tweets_without_total_favorites_filter = len(tweets_without_total_favorites_filter)
number_tweets_without_total_favorites_filter

print('---')
print('Number of Tweets Without total_favorites - FILTER')
# print(number_tweets_without_total_favorites_filter)
print('---')

percentage_tweets_without_total_favorites_filter = ((number_tweets_without_total_favorites_filter * 100)/number_total_tweets)
percentage_tweets_without_total_favorites_filter

print('---')
print('Percentage of Tweets Without total_favorites - Filter')
# print(percentage_tweets_without_total_favorites_filter)
print('---')

number_tweets_with_total_favorites_not_unique = number_total_tweets - number_tweets_without_total_favorites_filter
number_tweets_with_total_favorites_not_unique

print('---')
print('Number of Tweets With total_favorites')
# print(number_tweets_with_total_favorites_not_unique)
print('---')

percentage_tweets_with_total_favorites_not_unique = ((number_tweets_with_total_favorites_not_unique * 100)/number_total_tweets)
percentage_tweets_with_total_favorites_not_unique

print('---')
print('Percentage of Tweets With total_favorites')
# print(percentage_tweets_with_total_favorites_not_unique)
print('---')

number_tweets_no_total_favorites = number_total_tweets - number_tweets_with_total_favorites_not_unique

print('---')
print('Number of Tweets Without total_favorites')
# print(number_tweets_no_total_favorites)
print('---')

percentage_tweets_no_total_favorites = 100 - percentage_tweets_with_total_favorites_not_unique

print('---')
print('Percentage of Tweets Without total_favorites')
# print(percentage_tweets_no_total_favorites)
print('---')

##############

# Inicialize List of Lists TWEETS WITH total_favorites NOT UNIQUES total_favorites

tweet_info_total_favorites_not_unique = [['Tweets With Favs', number_tweets_with_total_favorites_not_unique, percentage_tweets_with_total_favorites_not_unique], ['Tweets With NO Favs', number_tweets_without_total_favorites_filter, percentage_tweets_without_total_favorites_filter]]

# Create DataFrame

tweet_info_total_favorites_not_unique_df = pd.DataFrame(tweet_info_total_favorites_not_unique, columns =['tweet_info_total_favorites_not_unique', 'number_tweet_info_total_favorites_not_unique', 'percentage_tweet_info_total_favorites_not_unique'])

print('---')
print('Tweet Info total_favorites NOT UNIQUE Information')
# print(tweet_info_total_favorites_not_unique_df)
print('---')

tweet_info_total_favorites_not_unique_df.to_csv('4_4_38_SMI1_Tweet_Info_Total_Favorites_Not_Unique_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_total_favorites_not_unique_df.to_excel('4_4_38_SMI1_Tweet_Info_Total_Favorites_Not_Unique_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets With Favorites Not Unique - Pie')
plt.ioff()
# plt.pie(tweet_info_total_favorites_df['number_tweet_info_total_favorites'], labels=tweet_info_total_favorites_df['tweet_info_total_favorites'])
plt.pie(tweet_info_total_favorites_not_unique_df['number_tweet_info_total_favorites_not_unique'], labels=tweet_info_total_favorites_not_unique_df['tweet_info_total_favorites_not_unique'], colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweet_info_total_favorites_not_unique_df['tweet_info_total_favorites_not_unique'], loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_38_SMI1_Tweet_Info_Total_Favorites_Not_Unique_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites Counts Not Unique - Bars')
plt.ioff()
tweet_info_total_favorites_not_unique_df['number_tweet_info_total_favorites_not_unique'].plot.bar(x=tweet_info_total_favorites_not_unique_df['number_tweet_info_total_favorites_not_unique'], alpha=0.9)
# ax.bar(tweet_info_total_favorites_not_unique_df['tweet_info_total_favorites_not_unique'], tweet_info_total_favorites_not_unique_df['number_tweet_info_total_favorites_not_unique'])
plt.xticks(rotation=50)
plt.xlabel('With Favorites / With No Favorites')
plt.ylabel('Count')
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_38_SMI1_Tweet_Info_Total_Favorites_Not_Unique_df_Counts_Bars_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################################################################################################

# Mode Following

mode_following = statistics.mode(tweets_smi_1['following'])
mode_following

print('---')
print('MAIN SMI Mode Following')
print(statistics.mode(tweets_smi_1['following']))
print('---')

mode_following_df = pd.DataFrame([mode_following], columns=['mode_following'])

mode_following_df.to_csv('4_4_7_SMI1_Mode_following_CSV.csv', sep='\t', encoding='utf-8', index=True)
# mode_following_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mode Following - Box')
plt.ioff()
plt.boxplot(mode_following_df, patch_artist=True, vert=False, notch=False, showfliers=False)
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_7_SMI1_Mode_following_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mode Following - Bars')
plt.ioff()
# mode_following_df.plot.bars(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_7_SMI1_Mode_following_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

#################################################################################################################

# https://realpython.com/python-statistics/         

# Measures of Variability

print('Measures of Variability')

# The measures of central tendency aren�t sufficient to describe data. You�ll also need the measures of variability 
# that quantify the spread of data points. 

# Variance Followers

# The sample variance quantifies the spread of the data. It shows numerically how far the data points are from the mean.

variance_followers = statistics.variance(tweets_smi_1['followers_count'])
variance_followers

variance_followers_df = pd.DataFrame([variance_followers], columns=['variance_followers'])

variance_followers_df.to_csv('4_4_8_SMI1_Variance_followers_CSV.csv', sep='\t', encoding='utf-8', index=True)
# variance_followers_df.to_excel('4_4_8_SMI1_Variance_followers.xlsx', header=True)

print('---')
print('Variance Followers ')
print(statistics.variance(tweets_smi_1['followers_count']))
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Variance Followers - Box')
plt.ioff()
# plt.boxplot(statistics.variance(tweets_smi_1['followers_count']), patch_artist=True, vert=False, notch=False, showfliers=False)
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_8_SMI1_Variance_followers_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO 

#################################################################################################################

# Correlation Coefficient : Pearson

# The correlation coefficient, or Pearson product-moment correlation coefficient, is denoted by the symbol ??. The 
# coefficient is another measure of the correlation between data. You can think of it as a standardized covariance. 
# Here are some important facts about it:

# The value ?? > 0 indicates positive correlation.
# The value ?? < 0 indicates negative correlation.
# The value r = 1 is the maximum possible value of ??. It corresponds to a perfect positive linear relationship 
# between variables.
# The value r = -1 is the minimum possible value of ??. It corresponds to a perfect negative linear relationship 
# between variables.
# The value r � 0, or when ?? is around zero, means that the correlation between variables is weak.

# pearsonr() returns a tuple with two numbers. The first one is ?? and the second is the ??-value.

corr_coef_followers_following_pearson = scipy.stats.pearsonr(tweets_smi_1['followers'], tweets_smi_1['following'])

corr_coef_followers_following_pearson_df = pd.DataFrame(corr_coef_followers_following_pearson)

corr_coef_followers_following_pearson_df.to_csv('4_4_25_SMI1_Corr_Coef_followers_following_pearson_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header='corr_coef_followers_following_pearson_df')
# corr_coef_followers_following_pearson_df.to_excel()

print('---')
print('Correlation Coefficient: Pearson Followers vs Following')
print(corr_coef_followers_following_pearson)
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4)) 
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient: Pearson Followers vs Following - Box')
plt.ioff()
plt.plot(scipy.stats.pearsonr(tweets_smi_1['followers'], tweets_smi_1['following']), alpha=0.9)
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_25_SMI1_Corr_Coef_followers_following_pearson_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTERPLOT - NEED TO SET DIF COLORS FOR X AND Y!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10)) 
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient: Pearson Followers vs Following - Scatter')
plt.ioff()
# (scipy.stats.pearsonr(tweets_smi_1['followers'], tweets_smi_1['following'])).plot(alpha=0.9)
# corr_coef_followers_following_pearson_df.plot.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_25_SMI1_Corr_Coef_followers_following_pearson_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4)) 
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient: Pearson Followers vs Following - Bars')
plt.ioff()
# plt.plot(scipy.stats.pearsonr(tweets_smi_1['followers'], tweets_smi_1['following']))
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_25_SMI1_Corr_Coef_followers_following_pearson_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Correlation Coefficient Matrix

# Similar to the case of the covariance matrix, you can apply np.corrcoef() with x_ and y_ as the arguments and 
# get the correlation coefficient matrix:

corr_matrix_followers_following = np.corrcoef(tweets_smi_1['followers'], tweets_smi_1['following'])
corr_matrix_followers_following_df = pd.DataFrame(corr_matrix_followers_following)

print('---')
print('Correlation Coefficient Matrix Followers vs Following')
print(np.corrcoef(tweets_smi_1['followers'], tweets_smi_1['following']))
print('---')

corr_matrix_followers_following_df.to_csv('4_4_26_SMI1_Corr_Matrix_followers_following_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# corr_matrix_followers_following_df.to_excel('4_4_26_SMI1_Corr_Matrix_followers_following_DF.xlsx', index=True, header=True) # Only argument is a string of the output file path

# PLOT TABLE plt.plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient Matrix Followers vs Following')
plt.ioff()
plt.plot(corr_matrix_followers_following, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_26_SMI1_Corr_Matrix_followers_following_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient Matrix Followers vs Following - Bars')
plt.ioff()
# corr_matrix_followers_following.plot.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_26_SMI1_Corr_Matrix_followers_following_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars

# TOP NUMBERS OF value_followers_count 

top_followers_tweets = value_followers_count.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Value Followers - Bars')
top_followers_tweets[:10].plot.bars(alpha=0.9)
plt.xlabel('Followers')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_50_75_SMI1_Top_Value_Followers_Count_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##########################################################################################################################
#########################################################################################################################

# PLOT BARS - MULTIPLE - Tweets ABOUT AND BY SMI ## NEED TO DO - FIX 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

r1 = np.arange(len(tweets_smi_1['followers_count'].value_counts()[:10]))
r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES // NEED TO CHANGE

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers / Friends Value Counts - Bars')

plt.bar(r1, top_followers_tweets[:10], color='#73C2FB', edgecolor='white', label='Tweets About', alpha=0.9)
# plt.bar(r2, top_friends_tweets[:10], color='blue', edgecolor='white', label='Tweets By Author', alpha=0.9)

plt.xticks(rotation=50)
plt.xlabel('Followers / Friends Number')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_77_SMI1_Users_Followers_ReTweet_List_PLT_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#########################################################################################

# CANDLESTICK GRAPH ######### NEED TO DO - NOT WORKING

candestick_data = tweets_smi_1

# candestick_data.append()

x = 0
y = len(tweets_smi_1['created'])

ohlc = []

# while x, y >> 0:
#	append_candlestick = created[x], followers[x], friends[x]
#	ohlc.append(append_candlestick) 
#	x+=1

# candlestick_ohlc(ax1, ohlc)

# ax1.xaxis.set.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S))

# plt.figure(figsize=(14,10))

plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Created, Followers and Friends - CandleStick')
# candlestick_ohlc(ax1, ohlc, width=0.4, colorup='#77d879', colordown='#db3f3f')
# ax1.xaxis.set.set_major_locator(mticker.MaxNLocator(10))
plt.xlabel('Date')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_37_78_SMI1_Created_Followers_Friends_CandleStick.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##########################################################################################################


# Bars

# TOP NUMBERS OF Followers In Tweets 

top_followers_tweets = value_counts_followers.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Followers - Bars')
plt.ioff()
top_followers_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Followers')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_50_75_SMI1_Top_Value_Counts_Followers_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###
#######################################################################

# https://tutswiki.com/pandas-cookbook/chapter2


# Most Common Tweet Following

value_counts_following = pd.value_counts(tweets_smi_1['following'], ascending=False, normalize=True)

print('---')
print('Most Common Tweets Following')
# print(value_counts_following)
print('---')

value_counts_following_df = pd.DataFrame(value_counts_following)

print('---')
print('Most Common Tweets Following')
# print(value_counts_following_df)
print('---')

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_following.to_csv('4_4_50_76_SMI1_df_Top_Value_Counts_Following_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_following.to_excel('4_4_50_76_SMI1_df_Top_Value_Counts_Following.xlsx', header=True)

# value_counts_followers


# NEED TO DO PLOT!!!!!!!!!!!!!!!!

# TABLE PLOT

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Following - Pie')
# tweets_smi_1['following'].value_counts()[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['following'], bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_76_SMI1_Top_Following_Values_Number_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# NEED TP FOX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Following - Bars')
tweets_smi_1['following'].value_counts()[:6].plot.bar(alpha=0.9)
plt.xlabel('Number of Following')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_76_SMI1_Top_following_Values_Number_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###


percentage_value_counts_following = (value_counts_following * 100)/number_total_tweets

# Inicialize List of Lists

value_counts_following_item = [['following', value_counts_following, percentage_tweets_repeated]]

# Create DataFrame

value_counts_following_item_df = pd.DataFrame(value_counts_following_item, columns =['following_number', 'followings', 'following_percentages'])


# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

percentage_value_counts_following.to_csv('4_4_50_76_SMI1_value_counts_following_item_df_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_following_item_df.to_excel('4_4_50_75_SMI1_value_counts_following_item_df.xlsx', index=False, header=True)

# value_counts_following


# NEED TO PLOT TABLE

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Following - Pie')
# plt.pie(value_counts_following_item_df, labels=[top_following_tweets], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend[labels=value_counts_following_item_df, loc='upper right', borderaxespad=0.) 
# percentage_value_counts_following.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=percentage_value_counts_following, loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_75_SMI1_Value_Counts_Following_Item_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Following - Bars')
# percentage_value_counts_following.plot.bar(alpha=0.9)
plt.xlabel('Number of Following')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_75_SMI1_Value_Counts_following_Item_df_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##########################################################################################################################
#########################################################################################################################

# PLOT BARS - MULTIPLE - Tweets ABOUT AND BY SMI ## NEED TO DO - FIX 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

r1 = np.arange(len(tweets_smi_1['followers_count'].value_counts()[:10]))
r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES // NEED TO CHANGE

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers / Following Value Counts - Bars')

plt.bar(r1, top_followers_tweets[:10], color='#73C2FB', edgecolor='white', label='Tweets About', alpha=0.9)
# plt.bar(r2, top_following_tweets[:10], color='blue', edgecolor='white', label='Tweets By Author', alpha=0.9)

plt.xticks(rotation=50)
plt.xlabel('Followers / Following Number')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_77_SMI1_Users_Followers_ReTweet_List_PLT_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#########################################################################################

# CANDLESTICK GRAPH ######### NEED TO DO - NOT WORKING

candestick_data = tweets_smi_1

# candestick_data.append()

x = 0
y = len(tweets_smi_1['created'])

ohlc = []

# while x, y >> 0:
#	append_candlestick = created[x], followers[x], following[x]
#	ohlc.append(append_candlestick) 
#	x+=1

# candlestick_ohlc(ax1, ohlc)

# ax1.xaxis.set.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S))

# plt.figure(figsize=(14,10))

plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Created, Followers and Following - CandleStick')
# candlestick_ohlc(ax1, ohlc, width=0.4, colorup='#77d879', colordown='#db3f3f')
# ax1.xaxis.set.set_major_locator(mticker.MaxNLocator(10))
plt.xlabel('Date')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_37_78_SMI1_Created_Followers_Following_CandleStick.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###############################################################################################################
#
#                        CLUSTER ANALYSIS AND TIME SERIES ###################### NEED TO DO!!!!!!!!!!!
#   NEED TO FIX NOT WORKING
###############################################################################################################

# # https://www.datacamp.com/community/tutorials/wordcloud-python

# Favorites / Followers 

scatterplot_total_favorites_followers = scipy.stats.pearsonr(tweets_smi_1['favorites'], tweets_smi_1['followers'])

# SCATTERPLOT FACETED ON ONE VARIABLE / LANGUAGE - NEED TO DO 

## SCATTERPLOT FAV TIME LANGUAGE METHOD 1 - 1

# SCATTER PLOT   ## NEED TO FIX NOT WORKING

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites / Time / Language - Scatter')
plt.ioff()
# plt.scatter(scipy.stats.pearsonr(tweets_smi_1['favorites'], tweets_smi_1['followers']), colors=colors_blue, alpha=0.9)
plt.xlabel('Favorites / Time')
plt.ylabel('Language')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_195_SMI1_Scatterplot_Total_Favorites_Time_Language_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


### SCATTERPLOT Followers TIME LANGUAGE METHOD 1 -2 MEED TO DO
 
#### SCATTERPLOT - Method 2 total_favorites

# PLOT SCATTER

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites / Time / Language - Scatter Faceted')
plt.ioff()
scatterplot_total_favorites_total_favorites_language.map(plt.scatter, 'year', 'followers_count', alpha=0.9)
plt.xlabel('Favorites / Time')
plt.ylabel('Language')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_195_SMI1_Facetonevar_Total_Favorites_Time_Language_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# # #

# retweets / Followers 

scatterplot_retweets_followers_language = scipy.stats.pearsonr(tweets_smi_1['retweets'], tweets_smi_1['followers'])

# SCATTERPLOT FACETED ON ONE VARIABLE / LANGUAGE - NEED TO DO 

## SCATTERPLOT retweets TIME LANGUAGE METHOD 1 - 1

# SCATTER PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Retweets / Time / Language - Scatter')
plt.ioff()
# plt.scatter(scipy.stats.pearsonr(tweets_smi_1['retweets'], tweets_smi_1['followers']), colors=colors_blue, alpha=0.9)
plt.xlabel('Retweets')
plt.ylabel('Time')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_195_1_SMI1_Scatterplot_Total_Retweets_Time_Language_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


### SCATTERPLOT Followers TIME LANGUAGE METHOD 1 -2 MEED TO DO
 
#### SCATTERPLOT - Method 2 total_favorites

# PLOT SCATTER

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Retweets / Time / Language - Scatter Faceted')
plt.ioff()
scatterplot_retweets_total_favorites_language.map(plt.scatter, 'year', 'language', alpha=0.9)
plt.xlabel('Retweets / Time')
plt.ylabel('Language')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_195_SMI1_Facetonevar_Total_Retweets_Time_Language_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


### SCATTERPLOT METHOD 2 followers

# PLOT SCATTER

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Followers / Time / Language - Scatter Faceted')
plt.ioff()
# scatterplot_facetonevar_followers_total_favorites = figure_factory.create_facet_grid(df=tweets_smi_1, x='created', y='followers', facet_col='language')
plt.xlabel('Followers')
plt.ylabel('Time')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_195_SMI1_Facetonevar_Followers_Time_Language_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################################


# TWEETS OVER TIME

print('NEED TWEETS OVER TIME HEREEEEEEEEEEEEEEEEEEEEEE')

# Total Tweets OVER TIME

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Time Series: Tweets / Year')
# tweets_smi_1.groupby(['created']).sum(['total_tweets']).plot(alpha=0.9)
tweets_smi_1.groupby(['created']).plot(alpha=0.9)
# ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Time_Series_Total_Tweets_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# total_favorites PLOT NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Time Series: All Favorites / Year')
# tweets_smi_1['favorites'].sum().plot_date(alpha=0.9)
tweets_smi_1.groupby(['created'])['favorites'].plot(alpha=0.9)
ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Time_Series_All_Total_Favorites_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Followers Count PLOT NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Time Series: Followers / Year')
# tweets_smi_1['followers_count'].sum().plot_date(alpha=0.9)
tweets_smi_1.groupby(['screenName' == main_smi])['followers_count'].plot(alpha=0.9)
ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Time_Series_MAIN_SMI_Followers_Count_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# FOLLOWERS PLOT NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Time Series: Followers / Year')
# tweets_smi_1['followers'].sum().plot_date(alpha=0.9)
tweets_smi_1.groupby(['screenName' == main_smi])['followers'].plot(alpha=0.9)
ax.xaxis_date()
# ax.xaxis.set_major_formatter(formatter)
plt.xlabel('Year')
plt.ylabel('Counts')
# ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_185_SMI1_Time_Series_MAIN_SMI_Followers_Year_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#########################################################################################################################

# PLOT BARS - MULTIPLE - Tweets ABOUT AND BY SMI ## NEED TO DO - FIX 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

r1 = np.arange(len(tweets_smi_1['year'].unique()))
r2 = [x + barWidth for x in r1]
r3 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES // NEED TO CHANGE

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Total Tweets Favorites Followers / Year - Multiple Bars')

# plt.bar(r1, (tweets_smi_1['favorites'].sum()).groupby(['created']), color='#73C2FB', edgecolor='white', label='Tweets', alpha=0.9)
# plt.bar(r2, (tweets_smi_1['followers'].sum()).groupby(['created']), color='blue', edgecolor='white', label='total_favorites', alpha=0.9)
# plt.bar(r3, (tweets_smi_1['total_tweets'].sum()).groupby(['created']), color='orange', edgecolor='white', label='followers', alpha=0.9)

# tweets_about_percentages_df['tweets_about_smi_number'].plot.bar(alpha=0.9)
# ax.bar(tweets_about_percentages_df['tweets_about_smi_item'], tweets_about_percentages_df['tweets_about_smi_number'])
# tweets_by_percentages_df['number_tweets_by'].plot.bar(alpha=0.9)
# ax.bar(x + (2 * barWidth), tweets_by_percentages_df['tweets_by_smi'], tweets_by_percentages_df['number_tweets_by'])
# ax.bar(x + (2 * barWidth), tweets_by_percentages_df['tweets_by_smi'], tweets_by_percentages_df['number_tweets_by'])

plt.xticks(rotation=50)
plt.xlabel('Users Who Tweet / Followers / Following / Total Users')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_63_SMI1_Bars_Chart_Users_Total_Tweets_Total_Favorites_Followers_Year_PLT_BARS.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##################################################################################################################


########################################################################################################


# Pie NEED TO DO


# Bars

# Number of total_favorites of Tweets

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Favorites - Bars')
smi1_total_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_220_SMI1_Number_Total_Favorites_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################################################################################

# Pie NEED TO DO

# Bars

# Number of total_favorites of Tweets

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Favorites - Bars')
smi1_total_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_180_SMI1_Number_Total_Favorites_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars
 
# Number of total_favorites / Followers of Tweets


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Favorites / Followers - Bars')
smi1_total_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Favorites / Followers')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_181_SMI1_Number_Total_Favorites_Followers_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


########################################################################################################

## NEED TO DO PLOT 2 VARIABLE!!!!!!!!

# Bars
 
# Number of total_favorites / Followers of Tweets

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Favorites / Followers - Bars')
smi1_total_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Favs / followers')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_221_SMI1_Number_Total_Favorites_Followers_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



# Bars

# Number of Tweets / Date


# Prepare the data
created = tweets_smi_1.loc['created']
tweets_numbers = tweets_smi_1.loc['id']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Favorites / Time - Bars')
smi1_total_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_175_SMI1_Total_Favorites_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################################################################

# Bars

# total_favorites


# Prepare the data

tweets_total_favorites = tweets_smi_1.loc['favorites']

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Favorites / Time - Bars')
plt.plot(created, tweets_total_favorites, label='linear')
smi1_total_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_176_SMI1_Total_Favorites_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# # https://www.datacamp.com/community/tutorials/wordcloud-python

# PIE PLOT NEED TO DO

# BAR PLOT

# Number of total_favorites of Tweets

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Favorites - Bars')
smi1_total_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)

# plt.show()
plt.savefig('4_5A_180_SMI1_Number_Total_Favorites_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


########################################################################################################


# # https://www.datacamp.com/community/tutorials/wordcloud-python  ## NEED TO DO PLOT 2 VARIABLE!!!!!!!!

# BAR PLOT
 
# Number of total_favorites / Followers of Tweets

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Favorites / Followers - Bars')
smi1_total_favorites.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Favorites / Followers')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_181_SMI1_Number_Total_Favorites_Followers_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################


# Bars

# Number of Followers of Tweets

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Followers - Bars')
smi1_followers.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Followers')
plt.ylabel('Number of Tweets')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# ax.grid(True)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_222_SMI1_Number_followers_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################################

# Bars

# Most Commom Languages 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Languages - Bars')
smi1_languages.size().sort_values(ascending=False).plot.bar(alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_223_SMI1_Language_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###############################################################################################################
#
#                        CLUSTER ANALYSIS AND TIME SERIES ###################### NEED TO DO!!!!!!!!!!!
#
###############################################################################################################

sns.set()

# TIME SERIES 

total_favorites_created_df = tweets_smi_1[['created','total_favorites','followers','total_tweets']].copy

# total_favorites_created_df.month = pd.to_datetime(total_favorites_created_df.month)

# total_favorites_created_df.set_index('month', inplace=True)

# PLOT NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Time Series: Created')
(tweets_smi_1['created'], tweets_smi_1['favorites']).plot(alpha=0.9)
(tweets_smi_1['created'], tweets_smi_1['followers']).plot(alpha=0.9)
(tweets_smi_1['created'], tweets_smi_1['total_tweets']).plot(alpha=0.9)
plt.xlabel('Year')
plt.ylabel('Counts')
ax1.grid(True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_225_SMI1_Time_Series_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#######################################################################################################

# https://towardsdatascience.com/an-end-to-end-project-on-total_favorites-series-analysis-and-forecasting-with-python-4835e6bf050b
# https://pythonplot.com/

# PLOT total_favorites OVER TIME NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites Over Time')
tweets_smi_1.set_index('created')['favorites'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_226_SMI1_Total_Favorites_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Followers OVER TIME

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Followers Over Time')
tweets_smi_1.set_index('created')['followers'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_227_SMI1_Followers_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# total_favorites / Followers OVER TIME #################################### NEED TO DO!!!!!!!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites / Followers Over Time')
tweets_smi_1.set_index('created')['favorites'].plot(color='#73C2FB', alpha=0.9)
tweets_smi_1.set_index('created')['followers'].plot(color='blue', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_228_SMI1_Total_Favorites_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### NEED TO DO FOR SMI VS AUDIENCE!!!!!!!!!!!!!

############################################################################################################

# FIRST AND LAST DATES

smi1_first_date = tweets_smi_1['created'].min()

print('---')
print('Firt Date')
print(tweets_smi_1['created'].min())
print('---')


# initialize list of Lists 
smi1_tweet_date_ranges = [['First Date', smi1_first_date], ['Last Date', smi1_last_date]] 
 
# Create the pandas DataFrame 
smi1_tweet_date_ranges_df = pd.DataFrame(textblob_sentiments, columns = ['date_item', 'sentiment_polarity', 'sentiment_positiveness']) 

smi1_tweet_date_ranges_df.to_csv('4_5_229_SMI1_Tweet_Date_Ranges_df_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# smi1_tweet_date_ranges_df.to_excel('4_5_229_SMI1_Tweet_Date_Ranges_df.xlsx', header=True)


# PLOT TABLE # NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Date Ranges')
smi1_tweet_date_ranges_df.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_229_SMI1_Tweet_Date_Ranges_df_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Date Ranges - Pie')
plt.pie(smi1_tweet_date_ranges_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
plt.legend(smi1_tweet_date_ranges_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_229_SMI1_Tweet_Date_Ranges_df_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Date Ranges - Bars')
textblob_sentiment_df.plot.bar(alpha=0.9)
plt.xlabel('Date')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_5_229_SMI1_Tweet_Date_Ranges_df_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Summary Statistics of all Dates   ## NEED TO FIX AND PUT TABLE WITH COUNT NEXT TO THEM!!!! 

smi1_created.describe()
smi1_created.describe().head()

print('---')
print('Summary Statistics of all Dates')
# print(smi1_created.describe().head)
print('---')

# smi1_created_describe_df = pd.DataFrame([smi1_created.describe()])

# smi1_created_describe_df.to_csv('4_4_229_SMI1_Created_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE NEED TO DO 

# plt.plot

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of All Dates - Grouped')
# plt.plot(smi1_created.describe())
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_229_SMI1_DF_Tweets_Processes_Describe_Created_g_1.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################
############################################################################################################

# This selects the Top 5 highest average points among Total Tweets:

smi1_created.mean().sort_values(by="created",ascending=True)  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('Top 5 highest Created average points among Total Tweets:')
print('smi1_created.mean().sort_values(by="created",ascending=True).head()')
print('---')


# smi1_created_mean_sort_values_created = pd.DataFrame(smi1_created.mean().sort_values(by="created",ascending=True))

# smi1_created_mean_sort_values_created.to_csv('4_4_230_SMI1_Created_Mean_Sort_Values_Created_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

######################################################################################

# SCATTERPLOT FACETED ON ONE VARIABLE / LANGUAGE - NEED TO DO 

## SCATTERPLOT FAV TIME LANGUAGE METHOD 1 - 1

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites / Time / Language - Scatter')
# plt.scatter(scipy.stats.pearsonr(tweets_smi_1['favorites'], tweets_smi_1['followers']), alpha=0.9)
plt.xlabel('Favorites / Time')
plt.ylabel('Language')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_230_SMI1_Scatterplot_Total_Favorites_Time_Language_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


### SCATTERPLOT Followers TIME LANGUAGE METHOD 1 -2 MEED TO DO
 

#### SCATTERPLOT - Method 2 total_favorites

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Followers / Time / Language - Scatter Faceted')
# plt.scatter(scipy.stats.pearsonr(tweets_smi_1['followers'], tweets_smi_1['language']), alpha=0.9)
plt.xlabel('Followers / Time')
plt.ylabel('Language')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_230_SMI1_Scatterplot_Facetonevar_Followers_Time_Language_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### SCATTERPLOT METHOD 2 followers

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))

plt.suptitle(main_smi, y=1.0)
plt.title('Followers / Time / Language - Scatter Faceted')
scatterplot_facetonevar_followers_total_favorites = figure_factory.create_facet_grid(df=tweets_smi_1, x='created', y='followers', facet_col='language')
plt.xlabel('Followers / Time')
plt.ylabel('Language')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_230_SMI1_Scatterplot_Facetonevar_Followers_Time_Language_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


################################################################################

# Seaborn visualization library

sns.set(color_codes=True)

# Stratification Plot

# Another way to get more information out of a dataset is to divide it into smaller, more uniform subsets, and analyze each of these �strata� on its own. We will create a new HouseAge column, then partition the data into HouseAge strata, and construct side-by-side boxplots of the sale price within each stratum.

tweets_smi_1.set['YearP'] = 2020 - tweets_smi_1.set['created']
tweets_smi_1.set["YearGrp"] = pd.cut(tweets_smi_1.set.YearP, [2005, 2010, 2015, 2020]) # Create age strata based on these cut points

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Stratification Plot for Changes in Favorites / Year')
sns.boxplot(x="year", y="total_favorites", data=tweets_smi_1.set)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_231_SMI1_Strats_Total_Favorites_Time.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################################################################################################################


# Stratification Plot

# Another way to get more information out of a dataset is to divide it into smaller, more uniform subsets, and analyze each of these �strata� on its own. We will create a new HouseAge column, then partition the data into HouseAge strata, and construct side-by-side boxplots of the sale price within each stratum.

# tweets_smi_1.set['YearP'] = 2020 - tweets_smi_1.set['created']
# tweets_smi_1.set["YearGrp"] = pd.cut(tweets_smi_1.set.YearP, [2005, 2010, 2015, 2020]) # Create age strata based on these cut points

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Changes in Followers / Year - Box')
sns.boxplot(x="YearGrp", y="followers", data=tweets_smi_1.set)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_232_SMI1_Strats_Followers_Total_Favorites_Box_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##################################################################################################################

# Scatter Plot Faceted on Two Variables

#################################################################################################################
#################################################################################################################

# Seaborn visualization library

# screenName author_id created followerstotal_favorites Text latitude longitude Mentions hashtags id url emojis_unicode emojis_converted image_link language

tweets_smi_1_numeric = pd.DataFrame(tweets_smi_1)
# del tweets_smi_1_numeric['screenName']
# df.drop(['column_nameA', 'column_nameB'], axis=1, inplace=True)
# del tweets_smi_1_numeric['screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', 'url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language']

# tweets_smi_1_numeric.drop('screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language', axis=1, inplace=True)

tweets_smi_1_numeric.drop('screenName', axis=1, inplace=True)
tweets_smi_1_numeric.drop('text', axis=1, inplace=True)
tweets_smi_1_numeric.drop('reply_to_screen_name', axis=1, inplace=True)
tweets_smi_1_numeric.drop('is_retweet', axis=1, inplace=True)
tweets_smi_1_numeric.drop('mentions', axis=1, inplace=True)
tweets_smi_1_numeric.drop('hashtags', axis=1, inplace=True)
tweets_smi_1_numeric.drop('is_quote', axis=1, inplace=True)
tweets_smi_1_numeric.drop('emojis_unicode', axis=1, inplace=True)
tweets_smi_1_numeric.drop('emojis_converted', axis=1, inplace=True)
tweets_smi_1_numeric.drop('is_friend', axis=1, inplace=True)
tweets_smi_1_numeric.drop('is_follower', axis=1, inplace=True)
tweets_smi_1_numeric.drop('language', axis=1, inplace=True)
tweets_smi_1_numeric.drop('mentions_screen_name', axis=1, inplace=True)
tweets_smi_1_numeric.drop('quoted_screen_name', axis=1, inplace=True)
tweets_smi_1_numeric.drop('location', axis=1, inplace=True)
tweets_smi_1_numeric.drop('location_name', axis=1, inplace=True)
tweets_smi_1_numeric.drop('country', axis=1, inplace=True)
tweets_smi_1_numeric.drop('photo_video', axis=1, inplace=True)
tweets_smi_1_numeric.drop('hashtags_total', axis=1, inplace=True)
tweets_smi_1_numeric.drop('mentions_total', axis=1, inplace=True)
tweets_smi_1_numeric.drop('missing_geo', axis=1, inplace=True)
tweets_smi_1_numeric.drop('missing_country', axis=1, inplace=True)
tweets_smi_1_numeric.drop('missing_geo_orig', axis=1, inplace=True)
tweets_smi_1_numeric.drop('missing_geo_total', axis=1, inplace=True)
tweets_smi_1_numeric.drop('total_missing_geo', axis=1, inplace=True)
tweets_smi_1_numeric.drop('missing_country_orig', axis=1, inplace=True)
tweets_smi_1_numeric.drop('missing_country_total', axis=1, inplace=True)
tweets_smi_1_numeric.drop('total_missing_country', axis=1, inplace=True)
tweets_smi_1_numeric.drop('missing_emojis_unicode', axis=1, inplace=True)
tweets_smi_1_numeric.drop('emojis_unicode_orig', axis=1, inplace=True)
tweets_smi_1_numeric.drop('emojis_unicode_total', axis=1, inplace=True)
tweets_smi_1_numeric.drop('total_emojis_unicode', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('', axis=1, inplace=True)


print('++++++++++++++++++++++++++')
print('tweets_smi_1_numeric DTYPES FOR SNS REL PLOT')
print(tweets_smi_1_numeric.dtypes)
print('++++++++++++++++++++++++++')

# tweets_smi_1_numeric.drop(['screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', 'url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language'], axis=1, inplace=True)
# tweets_smi_1_numeric = tweets_smi_1[['author_id', 'created', 'followers', 'total_favorites', 'id']]

# Create the default pairplot

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Pair Plot of SMI Numeric Data')
# sns.pairplot(tweets_smi_1_numeric)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_233_SMI1_Pair_Plot_Numeric.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('creating plots')

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

#######################################################################################
#################################################################################################################

# STATS NETWORK WEIGHT

# Mean network_weight

mean_network_weight = statistics.mean(tweets_smi_1['network_weight'])
mean_network_weight

print('---')
print('Mean Network Weight')
print(mean_network_weight)
print('---')

mean_network_weight_df = pd.DataFrame([mean_network_weight], columns=['mean_network_weight'])

mean_network_weight_df.to_csv('4_4_3_SMI1_Mean_Network_weight_CSV.csv', sep='\t', encoding='utf-8', index=True)
# mean_network_weight_df.to_excel('4_4_3_SMI1_Mean_Network_weight.xlsx', header=True)

# NEED TO DO TABLE PLOT

# BOX PLOT 3 ########## NEED TO FIX  

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale()
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean Network Weight - No Fliers - Box')
plt.boxplot(tweets_smi_1['network_weight'], patch_artist=True, vert=False, notch=False, showfliers=False)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_3_SMI1_Mean_Network_Weight_Box_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

#################

# Median network_weight

median_network_weight = statistics.median(tweets_smi_1['network_weight'])
median_network_weight

print('---')
print('Median Network_Weight')
print(statistics.median(tweets_smi_1['network_weight']))
print('---')

median_network_weight_df = pd.DataFrame([median_network_weight], columns=['median_network_weight'])

median_network_weight_df.to_csv('4_4_4_SMI1_Median_network_weight_CSV.csv', sep='\t', encoding='utf-8', index=True)
# median_network_weight_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX ########## NEED TO FIX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Median Network Weight - Box')
plt.boxplot(statistics.median(tweets_smi_1['network_weight']), vert=False, notch=False, showfliers=False) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_4_SMI1_Median_network_weight_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Mode network_weight

mode_network_weight = statistics.mode(tweets_smi_1['network_weight'])
mode_network_weight

print('---')
print('Mode network_weight')
print(statistics.mode(tweets_smi_1['network_weight']))
print('---')

mode_network_weight_df = pd.DataFrame([mode_network_weight], columns=['mode_network_weight'])

mode_network_weight_df.to_csv('4_4_7_SMI1_Mode_Network_Weight_CSV.csv', sep='\t', encoding='utf-8', index=True)
# mode_network_weight_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mode Network Weight - Box')
plt.boxplot(statistics.mode(tweets_smi_1['network_weight']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_7_SMI1_Mode_Network_Weight_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mode Network Weight - Bars')
mode_network_weight_df.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_7_SMI1_Mode_Network_Weight_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

##################################

# https://realpython.com/python-statistics/         

# Measures of Variability

print('Measures of Variability')

# The measures of central tendency aren�t sufficient to describe data. You�ll also need the measures of variability 
# that quantify the spread of data points. 

# Variance Favorites

# The sample variance quantifies the spread of the data. It shows numerically how far the data points are from the mean.


##################################

# Variance network_weight

variance_network_weight = statistics.variance(tweets_smi_1['network_weight'])
variance_network_weight

print('---')
print('Variance network_weight')
print(statistics.variance(tweets_smi_1['network_weight']))
print('---')

variance_network_weight_df = pd.DataFrame([variance_network_weight])

variance_network_weight_df.to_csv('4_4_9_Variance_network_weight_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# variance_network_weight_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Variance Network Weight - Box')
# plt.plot(statistics.variance(tweets_smi_1['network_weight']), alpha=0.9) 
plt.boxplot(statistics.variance(tweets_smi_1['network_weight']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_9_SMI1_Variance_network_weight_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO


#################################################

# Population Variance network_weight

pvariance_network_weight = statistics.pvariance(tweets_smi_1['network_weight'])
pvariance_network_weight

print('---')
print('Population Variance network_weight')
print(statistics.pvariance(tweets_smi_1['network_weight']))
print('---')

pvariance_network_weight_df = pd.DataFrame([pvariance_network_weight], columns = ['pvariance_reetweets'])

pvariance_network_weight_df.to_csv('4_4_11_SMI1_pvariance_network_weight_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# pvariance_network_weight_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Population Variance Network Weight - Box')
# plt.plot(statistics.pvariance(tweets_smi_1['network_weight']), alpha=0.9)
plt.boxplot(statistics.pvariance(tweets_smi_1['network_weight']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_11_SMI1_pvariance_network_weight_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###########################################################################################

# Standard Deviation network_weight

stdev_network_weight = statistics.stdev(tweets_smi_1['network_weight'])
stdev_network_weight

print('---')
print('Standard Deviation network_weight')
print(statistics.stdev(tweets_smi_1['network_weight']))
print('---')

stdev_network_weight_df = pd.DataFrame([stdev_network_weight], columns=['stdev_network_weight'])

stdev_network_weight_df.to_csv('4_4_13_SMI1_stdev_network_weight_df_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# stdev_network_weight_df.to_excel('4_4_13_SMI1_stdev_network_weight_df.xlsx', sep='\t', encoding='utf-8', index=True, header=True)

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Standard Deviation Network Weight - Box')
plt.boxplot(statistics.stdev(tweets_smi_1['network_weight']), patch_artist=True, vert=False, notch=False, showfliers=True) 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_13_SMI1_Stdev_network_weight_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLO NEED TO DO

#############################


# Population Standard Deviation network_weight

pstdev_network_weight = statistics.pstdev(tweets_smi_1['network_weight'])
pstdev_network_weight

print('---')
print('Population Standard Deviation network_weight')
print(statistics.pstdev(tweets_smi_1['network_weight']))
print('---')

pstdev_network_weight_df = pd.DataFrame([pstdev_network_weight])

pstdev_network_weight_df.to_csv('4_4_15_SMI1_pstdev_Network_Weight_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True) ## NEED TO DO: SAVE AS CSV
# pstdev_network_weight_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Population Standard Deviation Network Weight - Box')
plt.boxplot(statistics.pstdev(tweets_smi_1['network_weight']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_15_SMI1_pstdev_Network_Weight_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

##########################################


# Skewness network_weight

skewness_network_weight = scipy.stats.skew(tweets_smi_1['network_weight'], bias=False)
skewness_network_weight

print('---')
print('Skewness network_weight')
print(scipy.stats.skew(tweets_smi_1['network_weight'], bias=False))
print('---')

skewness_network_weight_df = pd.DataFrame([skewness_network_weight], columns=['skewness_network_weight'])

skewness_network_weight_df.to_csv('4_4_17_SMI1_Skewness_Network_Weight_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# skewness_network_weight_df.to_excel()

# NEED TO DO TABLE PLOT


# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Skewness Network Weight - Box')
plt.boxplot(scipy.stats.skew(tweets_smi_1['network_weight']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_17_SMI1_Skewness_Network_Weight_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

 
###############################################


# Percentiles network_weight

quantiles_network_weight = np.percentile(tweets_smi_1['network_weight'], [25, 50, 75])
quantiles_network_weight

print('---')
print('Percentiles network_weight')
print(np.percentile(tweets_smi_1['network_weight'], [25, 50, 75]))
print('---')

quantiles_network_weight_df = pd.DataFrame(quantiles_network_weight, columns=['quantiles_network_weight'])

quantiles_network_weight_df.to_csv('4_4_19_SMI1_Quantiles_network_weight_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True) ## NEED TO FINISH
# quantiles_network_weight_df.to_excel(('4_4_19_SMI1_Quantiles_network_weight_DF.csv', sep='\t', encoding='utf-8', index=True)

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentiles Network Weight - Box')
plt.boxplot(np.percentile(tweets_smi_1['network_weight'], [25, 50, 75]), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_19_SMI1_Quantiles_Network_Weight_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentiles Network Weight - Bars')
# quantiles_network_weight_df.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_19_SMI1_Quantiles_Network_Weight_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################

# Ranges network_weight

ptp_network_weight = np.ptp(tweets_smi_1['network_weight'])
ptp_network_weight

print('---')
print('Ranges network_weight')
print(np.ptp(tweets_smi_1['network_weight']))
print('---')

ptp_network_weight_df = pd.DataFrame([ptp_network_weight], columns=['ranges_network_weight'])

ptp_network_weight_df.to_csv('4_4_21_SMI1_ptp_Ranges_Network_Weight_1_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# ptp_network_weight_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Ranges Network Weight - Box')
plt.boxplot(np.ptp(tweets_smi_1['network_weight']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_21_SMI1_ptp_Network_Weight_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Ranges Network Weight - Bars')
# ptp_network_weight_df.plt.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_21_SMI1_ptp_network_weight_Bar_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#############################################

# SUMMARY OF DESCRIPTIVE STATISTICS network_weight

summ_stats_result_network_weight = scipy.stats.describe(tweets_smi_1['network_weight'], ddof=1, bias=False)

summ_stats_result_network_weight_df = pd.DataFrame(summ_stats_result_network_weight)

print('---')
print('Statistical Summary for Descriptive Statistics network_weight')
print(scipy.stats.describe(tweets_smi_1['network_weight'], ddof=1, bias=False))
print('---')

summ_stats_result_network_weight_df.to_csv('4_4_24_SMI1_Summ_Stats_Result_Network_Weight_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# summ_stats_result_network_weight_df.to_excel('4_4_24_SMI1_Summ_Stats_Result_Network_Weight_DF.xlsx', index=True, header=True) # Only argument is a string of the output file path

# PLOT TABLE plt.plot # NEED TO DO FIX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Statistical Summary for Network Weight')
# plt.plot(scipy.stats.describe(tweets_smi_1['network_weight'], ddof=1, bias=False, alpha=0.9))
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_24_SMI1_Summ_Stats_Result_Network_Weight_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# summ_stats_result_network_weight

print('---')
print('Statistical Summary for Descriptive Statistics network_weight')
print(summ_stats_result_network_weight)
print('---')

print('-- NEED TO DO: SAVE TO CSV AND PRINT TABLES')

# NEED TO PLOT TABLE


#################################################################################################################
#################################################################################################################

# python-graph-gallery.com/320-basic-network-from-pandas-data-frame/
# datacamp.com/community/tutorials/social-networ-analysis-python

# CREATE NETWORK SCREENNAME_missing_geo

# tweets_smi_1_n = tweets_smi_1_n.set_index('screenName', 'missing_geo', 'missing_geo_total', inplace=True)

G_screenname_missing_geo = nx.MultiDiGraph()

# Create Connections between nodes

G_screenname_missing_geo = nx.from_pandas_edgelist(tweets_smi_1_n, 'missing_geos_tuple', 'screenName', ['network_weight'])

# G_screenname_missing_geo = nx.from_pandas_edgelist(smi1_matrix_missing_geo, 'screenName', 'value', ['network_weight'], create_using=nx.DiGraph())

# GET NETWORK STATISTICS

G_screenname_missing_geo_nodes_number = len(G_screenname_missing_geo.nodes())

print('---')
print('G_screenname_missing_geo_nodes_number:')
print(G_screenname_missing_geo_nodes_number)
print('---')

G_screenname_missing_geo_edges_number = len(G_screenname_missing_geo.edges())

print('---')
print('G_screenname_missing_geo_edges_number:')
print(G_screenname_missing_geo_edges_number)
print('---')

G_screenname_missing_geo_average_clustering = nx.average_clustering(G_screenname_missing_geo)

print('---')
print('G_screenname_missing_geo_average_clustering:')
print(G_screenname_missing_geo_average_clustering)
print('---')


# G_screenname_missing_geo_eccentricity = nx.eccentricity(G_screenname_missing_geo)

print('---')
print('G_screenname_missing_geo_eccentricity:')
# print(G_screenname_missing_geo_eccentricity)
print('---')

# initialize list of Lists 
screenname_missing_geo_network_numbers = [['G_screenname_missing_geo_nodes_number', G_screenname_missing_geo_nodes_number], ['G_screenname_missing_geo_edges_number', G_screenname_missing_geo_edges_number], ['G_screenname_missing_geo_average_clustering', G_screenname_missing_geo_average_clustering], ['G_screenname_missing_geo_eccentricity', 'G_screenname_missing_geo_eccentricity']]
 
# Create the pandas DataFrame 
screenname_missing_geo_network_numbers_df = pd.DataFrame(screenname_missing_geo_network_numbers, columns = ['screenname_missing_geo_network_numbers_item', 'screenname_missing_geo_network_numbers_value']) 

screenname_missing_geo_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Missing_Geo_Network_Numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_missing_geo_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Missing_Geo_Network_Numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_missing_geo_betweenness_centrality = nx.betweenness_centrality(G_screenname_missing_geo)

print('---')
print('G_screenname_missing_geo_betweenness_centrality:')
# print(G_screenname_missing_geo_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_missing_geo_closeness_centrality = nx.closeness_centrality(G_screenname_missing_geo)

print('---')
print('G_screenname_missing_geo_closeness_centrality:')
# print(G_screenname_missing_geo_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_missing_geo_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_missing_geo)

print('---')
print('G_screenname_missing_geo_eigenvector_centrality:')
# print(G_screenname_missing_geo_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_missing_geo_network_measures = [['G_screenname_missing_geo_betweenness_centrality', 'G_screenname_missing_geo_betweenness_centrality'], ['G_screenname_missing_geo_closeness_centrality', 'G_screenname_missing_geo_closeness_centrality'], ['G_screenname_missing_geo_eigenvector_centrality', 'G_screenname_missing_geo_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_missing_geo_network_measures_df = pd.DataFrame(screenname_missing_geo_network_measures, columns = ['screenname_missing_geo_network_measures_item', 'screenname_missing_geo_network_measures_value']) 

# screenname_missing_geo_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Missing_Geo_Network_Measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_missing_geo_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Missing_Geo_Network_Measures_DF.xlsx', header=True)

# NETWORK SCREENNAME_missing_geo

G_screenname_missing_geo_network_info = nx.info(G_screenname_missing_geo)

# Create the pandas DataFrame 
# screenname_missing_geo_network_info_df = pd.DataFrame(G_screenname_missing_geo_network_info, columns = ['G_screenname_missing_geo_network_info']) 

# screenname_missing_geo_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Missing_Geo_Network_Info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_missing_geo_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Missing_Geo_Network_Info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_missing_geo_network INFO')
print(G_screenname_missing_geo_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
# fig, ax = plt.subplots()
plt.ioff()

plt.figure(figsize=(40,30))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenName Location - Network Graph')
nx.draw(G_screenname_missing_geo, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.7, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
 
# plt.show()
plt.savefig('4_5A_180_SMI1_ScreenName_Missing_Geo_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network 1A')
print('---')

######################################################################################################

# NETWORK MAIN_SMI INFLUENCER SMI ONLY

# CREATE NETWORK MAIN_SMI SCREENNAME_missing_geo

# smi1_matrix_missing_geo_main_smi_1 = tweets_smi_1_n[(smi1_matrix_missing_geo['screenName'] == main_smi_1)]

G_screenname_missing_geo_main_smi = nx.MultiDiGraph()

# Create Connections between nodes

# G_screenname_missing_geo_main_smi = nx.from_pandas_edgelist(smi1_matrix_missing_geo_main_smi_1, 'screenName', 'missing_geo', ['network_weight'])

G_screenname_missing_geo_main_smi = nx.from_pandas_edgelist(tweets_main_smi_1, 'screenName', 'missing_geos_tuple', ['network_weight'], create_using=nx.DiGraph())

# GET NETWORK STATISTICS

G_screenname_missing_geo_main_smi_nodes_number = len(G_screenname_missing_geo_main_smi.nodes())

print('---')
print('G_screenname_missing_geo_main_smi_nodes_number:')
print(G_screenname_missing_geo_main_smi_nodes_number)
print('---')

G_screenname_missing_geo_main_smi_edges_number = len(G_screenname_missing_geo_main_smi.edges())

print('---')
print('G_screenname_missing_geo_main_smi_edges_number:')
print(G_screenname_missing_geo_main_smi_edges_number)
print('---')

G_screenname_missing_geo_main_smi_average_clustering = nx.average_clustering(G_screenname_missing_geo_main_smi)

print('---')
print('G_screenname_missing_geo_main_smi_average_clustering:')
print(G_screenname_missing_geo_main_smi_average_clustering)
print('---')


# G_screenname_missing_geo_main_smi_eccentricity = nx.eccentricity(G_screenname_missing_geo_main_smi)

print('---')
print('G_screenname_missing_geo_main_smi_eccentricity:')
# print(G_screenname_missing_geo_main_smi_eccentricity)
print('---')

# initialize list of Lists 
screenname_missing_geo_main_smi_network_numbers = [['G_screenname_missing_geo_main_smi_nodes_number', G_screenname_missing_geo_main_smi_nodes_number], ['G_screenname_missing_geo_main_smi_edges_number', G_screenname_missing_geo_main_smi_edges_number], ['G_screenname_missing_geo_main_smi_average_clustering', G_screenname_missing_geo_main_smi_average_clustering], ['G_screenname_missing_geo_main_smi_eccentricity', 'G_screenname_missing_geo_main_smi_eccentricity']]
 
# Create the pandas DataFrame 
screenname_missing_geo_main_smi_network_numbers_df = pd.DataFrame(screenname_missing_geo_main_smi_network_numbers, columns = ['screenname_missing_geo_main_smi_network_numbers_item', 'screenname_missing_geo_main_smi_network_numbers_value']) 

screenname_missing_geo_main_smi_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Missing_Geo_Main_SMI_Network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_missing_geo_main_smi_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Missing_Geo_Main_SMI_Network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_missing_geo_main_smi_betweenness_centrality = nx.betweenness_centrality(G_screenname_missing_geo_main_smi)

print('---')
print('G_screenname_missing_geo_main_smi_betweenness_centrality:')
# print(G_screenname_missing_geo_main_smi_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_missing_geo_main_smi_closeness_centrality = nx.closeness_centrality(G_screenname_missing_geo_main_smi)

print('---')
print('G_screenname_missing_geo_main_smi_closeness_centrality:')
# print(G_screenname_missing_geo_main_smi_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_missing_geo_main_smi_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_missing_geo_main_smi)

print('---')
print('G_screenname_missing_geo_main_smi_eigenvector_centrality:')
# print(G_screenname_missing_geo_main_smi_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_missing_geo_main_smi_network_measures = [['G_screenname_missing_geo_main_smi_betweenness_centrality', 'G_screenname_missing_geo_main_smi_betweenness_centrality'], ['G_screenname_missing_geo_main_smi_closeness_centrality', 'G_screenname_missing_geo_main_smi_closeness_centrality'], ['G_screenname_missing_geo_main_smi_eigenvector_centrality', 'G_screenname_missing_geo_main_smi_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_missing_geo_main_smi_network_measures_df = pd.DataFrame(screenname_missing_geo_main_smi_network_measures, columns = ['screenname_missing_geo_main_smi_network_measures_item', 'screenname_missing_geo_main_smi_network_measures_value']) 

# screenname_missing_geo_main_smi_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Missing_Geo_Main_SMI_Network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_missing_geo_main_smi_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Missing_Geo_Main_SMI_Network_measures_DF.xlsx', header=True)

# NETWORK MAIN_SMI

G_screenname_missing_geo_main_smi_network_info = nx.info(G_screenname_missing_geo_main_smi)

# Create the pandas DataFrame 
# screenname_missing_geo_main_smi_network_info_df = pd.DataFrame(G_screenname_missing_geo_main_smi_network_info, columns = ['G_screenname_missing_geo_main_smi_network_info']) 

# screenname_missing_geo_main_smi_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Missing_Geo_Main_SMI_Network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_missing_geo_main_smi_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Missing_Geo_Main_SMI_Network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_missing_geo_main_smi_network INFO')
print(G_screenname_missing_geo_main_smi_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Main SMI ScreenName Location - Network Graph')
nx.draw(G_screenname_missing_geo_main_smi, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.7, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
 
# plt.show()
plt.savefig('4_5A_180_SMI1_ScreenName_Missing_Geo_Main_SMI_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



########################################################################

print('GOING TO START MATRIXXXXXXXXXXXXXXXXXXXXXX CONVERSIONS')


#######################################################################################################
#######################################################################################################
#######################################################################################################
#####################################################################################################

print('--------------------------------------------------')
print(' ----- MATRIX Hashtags -- OJO TOTAL')
print('--------------------------------------------------')

tweets_smi_1['hashtags'] = pd.DataFrame(tweets_smi_1['hashtags_total'])

# CREATE MATRIX hashtags

matrix_hashtags_unique = []

# matrix_hashtags = tweets_smi_1[['screenName', 'lists', 'hashtags']].copy()

matrix_hashtags = pd.DataFrame(tweets_smi_1[['screenName', 'lists', 'hashtags']])

# ######################matrix_hashtags = matrix_hashtags.reset_index()
# matrix_hashtags = matrix_hashtags.drop(columns='author_id')
# matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].astype(str, errors='ignore')
############ matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].replace('\]', '')
# ## matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].str.replace('\[', '')


# matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].str.replace('\'', '')

# [' ']

# SAVE TO FILE

# matrix_hashtags.to_csv('1_6_1_SMI1_Matrix_Hashtags_BEFORE_SPLIT_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_hashtags.to_csv('1_6_1_SMI1_Matrix_Hashtags_BEFORE_SPLIT_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)


# matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].str.split(',', n=20, expand=True)

matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].apply(lambda x: x.str.split(','))

# matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].astype(str, errors='ignore')

# matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].str.replace(',', ' ')
matrix_hashtags['hashtags'] = matrix_hashtags['hashtags'].fillna('[]')

# hashtags_unique = tweets_smi_1['hashtags'].unique() # axis=1 -> TO MOVE HORIZONTALLY

print('---')
print('Hashtags DIVIDED Head New DataFrame')
print(matrix_hashtags.head(20))
print('---')

print('---')
print('Matrix hashtags dtypes')
print(matrix_hashtags.dtypes)
print('---')

print('---')
print('Matrix hashtags Shape AFTER SPLIT')
print(matrix_hashtags.shape)
print('---')

# SAVE TO FILE

matrix_hashtags.to_csv('1_6_1_SMI1_Matrix_Hashtags_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_hashtags.to_csv('1_6_1_SMI1_Matrix_Hashtags_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)

# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

# matrix_hashtags_unique = matrix_hashtags['hashtags'].apply(lambda x: x.unique())

# matrix_hashtags_unique = removeDupWithoutOrder(matrix_hashtags['hashtags'])
# matrix_hashtags_unique = matrix_hashtags['hashtags'].apply(lambda x: removeDupWithoutOrder(x))

# matrix_hashtags_unique = matrix_hashtags_unique.astype(str, errors='ignore')

matrix_hashtags_unique = pd.DataFrame(matrix_hashtags_unique)

print('---------')
print('matrix_hashtags_unique head')
print(matrix_hashtags_unique.head(20))
print('-------------------------------')

matrix_hashtags_unique = pd.DataFrame(matrix_hashtags_unique)


# SAVE TO CSV 

matrix_hashtags_unique.to_csv('1_6_1_SMI1_Matrix_hashtags_Unique_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_hashtags_unique.to_csv('1_6_1_SMI1_Matrix_hashtags_Unique_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

########################

# MATRIX TRANSPOSE hashtags 

matrix_hashtags_transposed = matrix_hashtags

matrix_hashtags_transposed = matrix_hashtags_transposed.melt(id_vars = ['screenName', 'lists'])

# matrix_hashtags_transposed = matrix_hashtags_transposed.astype(str, errors='ignore')

matrix_hashtags_transposed = matrix_hashtags_transposed.drop(columns='variable')

matrix_hashtags_unique['hashtags'] = matrix_hashtags['hashtags'].unique()

# matrix_hashtags_transposed['hashtags'] = matrix_hashtags_transposed.groupby('screenName')

print('---')
print('Head Missing hashtags MA')
print(matrix_hashtags_transposed.head)
print('---')

# SAVE TO CSV 

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

matrix_hashtags_transposed.to_csv('1_6_1_SMI1_Matrix_Hashtags_Transposed_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_hashtags_transposed.to_csv('1_6_1_SMI1_Matrix_Hashtags_Transposed_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)


#####################################################################################################
#####################################################################################################

print('--------------------------------------------------')
print(' ----- MATRIX Mentions -- OJO TOTAL')
print('--------------------------------------------------')

tweets_smi_1['mentions'] = pd.DataFrame(tweets_smi_1['mentions_total'])

# CREATE MATRIX mentions

matrix_mentions_unique = []

# matrix_mentions = tweets_smi_1[['screenName', 'lists', 'mentions']].copy()

matrix_mentions = pd.DataFrame(tweets_smi_1[['screenName', 'lists', 'mentions']])

# ######################matrix_mentions = matrix_mentions.reset_index()
# matrix_mentions = matrix_mentions.drop(columns='author_id')
# matrix_mentions['mentions'] = matrix_mentions['mentions'].astype(str, errors='ignore')
############ matrix_mentions['mentions'] = matrix_mentions['mentions'].replace('\]', '')
# ## matrix_mentions['mentions'] = matrix_mentions['mentions'].str.replace('\[', '')


# matrix_mentions['mentions'] = matrix_mentions['mentions'].str.replace('\'', '')

# [' ']

# SAVE TO FILE

# matrix_mentions.to_csv('1_6_1_SMI1_matrix_mentions_BEFORE_SPLIT_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_mentions.to_csv('1_6_1_SMI1_matrix_mentions_BEFORE_SPLIT_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)


# matrix_mentions['mentions'] = matrix_mentions['mentions'].str.split(',', n=20, expand=True)

matrix_mentions['mentions'] = matrix_mentions['mentions'].apply(lambda x: x.str.split(','))

# matrix_mentions['mentions'] = matrix_mentions['mentions'].astype(str, errors='ignore')

# matrix_mentions['mentions'] = matrix_mentions['mentions'].str.replace(',', ' ')
matrix_mentions['mentions'] = matrix_mentions['mentions'].fillna('[]')

# mentions_unique = tweets_smi_1['mentions'].unique() # axis=1 -> TO MOVE HORIZONTALLY

print('---')
print('mentions DIVIDED Head New DataFrame')
print(matrix_mentions.head(20))
print('---')

print('---')
print('Matrix mentions dtypes')
print(matrix_mentions.dtypes)
print('---')

print('---')
print('Matrix mentions Shape AFTER SPLIT')
print(matrix_mentions.shape)
print('---')

# SAVE TO FILE

matrix_mentions.to_csv('1_6_1_SMI1_matrix_mentions_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_mentions.to_csv('1_6_1_SMI1_matrix_mentions_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)

# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

# matrix_mentions_unique = matrix_mentions['mentions'].apply(lambda x: x.unique())

# matrix_mentions_unique = removeDupWithoutOrder(matrix_mentions['mentions'])
# matrix_mentions_unique = matrix_mentions['mentions'].apply(lambda x: removeDupWithoutOrder(x))

# matrix_mentions_unique = matrix_mentions_unique.astype(str, errors='ignore')

matrix_mentions_unique = pd.DataFrame(matrix_mentions_unique)

print('---------')
print('matrix_mentions_unique head')
print(matrix_mentions_unique.head(20))
print('-------------------------------')

matrix_mentions_unique = pd.DataFrame(matrix_mentions_unique)


# SAVE TO CSV 

matrix_mentions_unique.to_csv('1_6_1_SMI1_Matrix_mentions_Unique_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_mentions_unique.to_csv('1_6_1_SMI1_Matrix_mentions_Unique_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

########################

# MATRIX TRANSPOSE mentions 

matrix_mentions_transposed = matrix_mentions

matrix_mentions_transposed = matrix_mentions_transposed.melt(id_vars = ['screenName', 'lists'])

matrix_mentions_transposed = matrix_mentions_transposed.drop(columns='variable')

# matrix_mentions_transposed = matrix_mentions_transposed.astype(str, errors='ignore')

matrix_mentions_unique['mentions'] = matrix_mentions['mentions'].unique()

# matrix_mentions_transposed['mentions'] = matrix_mentions_transposed.groupby('screenName')

print('---')
print('Head Missing mentions MA')
print(matrix_mentions_transposed.head)
print('---')

# SAVE TO CSV 

# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

matrix_mentions_transposed.to_csv('1_6_1_SMI1_matrix_mentions_transposed_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_mentions_transposed.to_csv('1_6_1_SMI1_matrix_mentions_transposed_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

#####################################################################################################
#####################################################################################################

print('--------------------------------------------------')
print(' ----- MATRIX emojis_unicode -- OJO TOTAL')
print('--------------------------------------------------')

tweets_smi_1['emojis_unicode'] = pd.DataFrame(tweets_smi_1['emojis_unicode_total'])

# CREATE MATRIX emojis_unicode

matrix_emojis_unicode_unique = []

# matrix_emojis_unicode = tweets_smi_1[['screenName', 'lists', 'emojis_unicode']].copy()

matrix_emojis_unicode = pd.DataFrame(tweets_smi_1[['screenName', 'lists', 'emojis_unicode']])

# ######################matrix_emojis_unicode = matrix_emojis_unicode.reset_index()
# matrix_emojis_unicode = matrix_emojis_unicode.drop(columns='author_id')
# matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].astype(str, errors='ignore')
############ matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].replace('\]', '')
# ## matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].str.replace('\[', '')


# matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].str.replace('\'', '')

# [' ']

# SAVE TO FILE

# matrix_emojis_unicode.to_csv('1_6_1_SMI1_matrix_emojis_unicode_BEFORE_SPLIT_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_unicode.to_csv('1_6_1_SMI1_matrix_emojis_unicode_BEFORE_SPLIT_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)


# matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].str.split(',', n=20, expand=True)

matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].apply(lambda x: x.str.split(','))

# matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].astype(str, errors='ignore')

# matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].str.replace(',', ' ')
matrix_emojis_unicode['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].fillna('[]')


# emojis_unicode_unique = tweets_smi_1['emojis_unicode'].unique() # axis=1 -> TO MOVE HORIZONTALLY

print('---')
print('Emojis DIVIDED Head New DataFrame')
print(matrix_emojis_unicode.head(20))
print('---')

print('---')
print('Matrix emojis_unicode dtypes')
print(matrix_emojis_unicode.dtypes)
print('---')

print('---')
print('Matrix emojis_unicode Shape AFTER SPLIT')
print(matrix_emojis_unicode.shape)
print('---')

# SAVE TO FILE

matrix_emojis_unicode.to_csv('1_6_1_SMI1_matrix_emojis_unicode_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_unicode.to_csv('1_6_1_SMI1_matrix_emojis_unicode_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

# matrix_emojis_unicode_unique = matrix_emojis_unicode['emojis_unicode'].apply(lambda x: x.unique())

# matrix_emojis_unicode_unique = removeDupWithoutOrder(matrix_emojis_unicode['emojis_unicode'])
# matrix_emojis_unicode_unique = matrix_emojis_unicode['emojis_unicode'].apply(lambda x: removeDupWithoutOrder(x))

# matrix_emojis_unicode_unique = matrix_emojis_unicode_unique.astype(str, errors='ignore')

matrix_emojis_unicode_unique = pd.DataFrame(matrix_emojis_unicode_unique)

print('---------')
print('matrix_emojis_unicode_unique head')
print(matrix_emojis_unicode_unique.head(20))
print('-------------------------------')

matrix_emojis_unicode_unique = pd.DataFrame(matrix_emojis_unicode_unique)


# SAVE TO CSV 

matrix_emojis_unicode_unique.to_csv('1_6_1_SMI1_Matrix_emojis_unicode_Unique_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_unicode_unique.to_csv('1_6_1_SMI1_Matrix_emojis_unicode_Unique_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

########################

# MATRIX TRANSPOSE emojis_unicode 

matrix_emojis_unicode_transposed = matrix_emojis_unicode

matrix_emojis_unicode_transposed = matrix_emojis_unicode_transposed.melt(id_vars = ['screenName', 'lists'])

matrix_emojis_unicode_transposed = matrix_emojis_unicode_transposed.drop(columns='variable')

# matrix_emojis_unicode_transposed = matrix_emojis_unicode_transposed.astype(str, errors='ignore')

matrix_emojis_unicode_unique['emojis_unicode'] = matrix_emojis_unicode['emojis_unicode'].unique()

# matrix_emojis_unicode_transposed['emojis_unicode'] = matrix_emojis_unicode_transposed.groupby('screenName')

print('---')
print('Head Missing emojis_unicode MA')
print(matrix_emojis_unicode_transposed.head)
print('---')

# SAVE TO CSV 

# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

matrix_emojis_unicode_transposed.to_csv('1_6_1_SMI1_matrix_emojis_unicode_transposed_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_unicode_transposed.to_csv('1_6_1_SMI1_matrix_emojis_unicode_transposed_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

#############################################################################################################
#####################################################################################################

print('--------------------------------------------------')
print(' ----- MATRIX emojis_converted -- OJO TOTAL')
print('--------------------------------------------------')

# tweets_smi_1['emojis_converted'] = pd.DataFrame(tweets_smi_1['emojis_converted_total'])

tweets_smi_1['emojis_converted'] = pd.DataFrame(tweets_smi_1['emojis_converted']) # OJO LO PUSDE ASI PORQUE NO TENGO LOS EMOJIS CONVETED AUN!!!!

# CREATE MATRIX emojis_converted

matrix_emojis_converted_unique = []

# matrix_emojis_converted = tweets_smi_1[['screenName', 'lists', 'emojis_converted']].copy()

matrix_emojis_converted = pd.DataFrame(tweets_smi_1[['screenName', 'lists', 'emojis_converted']])

# ######################matrix_emojis_converted = matrix_emojis_converted.reset_index()
# matrix_emojis_converted = matrix_emojis_converted.drop(columns='author_id')
# matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].astype(str, errors='ignore')
############ matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].replace('\]', '')
# ## matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].str.replace('\[', '')


# matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].str.replace('\'', '')

# [' ']

# SAVE TO FILE

# matrix_emojis_converted.to_csv('1_6_1_SMI1_matrix_emojis_converted_BEFORE_SPLIT_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_converted.to_csv('1_6_1_SMI1_matrix_emojis_converted_BEFORE_SPLIT_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)


# matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].str.split(',', n=20, expand=True)

matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].apply(lambda x: x.str.split(','))

# matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].astype(str, errors='ignore')

# matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].str.replace(',', ' ')
matrix_emojis_converted['emojis_converted'] = matrix_emojis_converted['emojis_converted'].fillna('[]')


# emojis_converted_unique = tweets_smi_1['emojis_converted'].unique() # axis=1 -> TO MOVE HORIZONTALLY

print('---')
print('Emojis DIVIDED Head New DataFrame')
print(matrix_emojis_converted.head(20))
print('---')

print('---')
print('Matrix emojis_converted dtypes')
print(matrix_emojis_converted.dtypes)
print('---')

print('---')
print('Matrix emojis_converted Shape AFTER SPLIT')
print(matrix_emojis_converted.shape)
print('---')

# SAVE TO FILE

matrix_emojis_converted.to_csv('1_6_1_SMI1_matrix_emojis_converted_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_converted.to_csv('1_6_1_SMI1_matrix_emojis_converted_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

# matrix_emojis_converted_unique = matrix_emojis_converted['emojis_converted'].apply(lambda x: x.unique())

# matrix_emojis_converted_unique = removeDupWithoutOrder(matrix_emojis_converted['emojis_converted'])
# matrix_emojis_converted_unique = matrix_emojis_converted['emojis_converted'].apply(lambda x: removeDupWithoutOrder(x))

# matrix_emojis_converted_unique = matrix_emojis_converted_unique.astype(str, errors='ignore')

matrix_emojis_converted_unique = pd.DataFrame(matrix_emojis_converted_unique)

print('---------')
print('matrix_emojis_converted_unique head')
print(matrix_emojis_converted_unique.head(20))
print('-------------------------------')

matrix_emojis_converted_unique = pd.DataFrame(matrix_emojis_converted_unique)


# SAVE TO CSV 

matrix_emojis_converted_unique.to_csv('1_6_1_SMI1_Matrix_emojis_converted_Unique_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_converted_unique.to_csv('1_6_1_SMI1_Matrix_emojis_converted_Unique_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

########################

# MATRIX TRANSPOSE emojis_converted 

matrix_emojis_converted_transposed = matrix_emojis_converted

matrix_emojis_converted_transposed = matrix_emojis_converted_transposed.melt(id_vars = ['screenName', 'lists'])

matrix_emojis_converted_transposed = matrix_emojis_converted_transposedastype(str)

matrix_emojis_converted_transposed = matrix_emojis_converted_transposed.drop(columns='variable')

matrix_emojis_converted_unique['emojis_converted'] = matrix_emojis_converted['emojis_converted'].unique()

# matrix_emojis_converted_transposed['emojis_converted'] = matrix_emojis_converted_transposed.groupby('screenName')

print('---')
print('Head Missing emojis_converted MA')
print(matrix_emojis_converted_transposed.head)
print('---')

# SAVE TO CSV 

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

matrix_emojis_converted_transposed.to_csv('1_6_1_SMI1_matrix_emojis_converted_transposed_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_emojis_converted_transposed.to_csv('1_6_1_SMI1_matrix_emojis_converted_transposed_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)


#####################################################################################################
#####################################################################################################

print('--------------------------------------------------')
print(' ----- MATRIX Missing_geo -- OJO TOTAL')
print('--------------------------------------------------')

tweets_smi_1['missing_geo'] = pd.DataFrame(tweets_smi_1['missing_geo_total'])

# CREATE MATRIX missing_geo

matrix_missing_geo_unique = []

# matrix_missing_geo = tweets_smi_1[['screenName', 'lists', 'missing_geo']].copy()

matrix_missing_geo = pd.DataFrame(tweets_smi_1[['screenName', 'lists', 'missing_geo']])

# ######################matrix_missing_geo = matrix_missing_geo.reset_index()
# matrix_missing_geo = matrix_missing_geo.drop(columns='author_id')
# matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].astype(str, errors='ignore')
############ matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].replace('\]', '')
# ## matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].str.replace('\[', '')


# matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].str.replace('\'', '')

# [' ']

# SAVE TO FILE

# matrix_missing_geo.to_csv('1_6_1_SMI1_matrix_missing_geo_BEFORE_SPLIT_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_geo.to_csv('1_6_1_SMI1_matrix_missing_geo_BEFORE_SPLIT_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)


# matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].str.split(',', n=20, expand=True)

matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].apply(lambda x: x.str.split(','))

# matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].astype(str, errors='ignore')

# matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].str.replace(',', ' ')
matrix_missing_geo['missing_geo'] = matrix_missing_geo['missing_geo'].fillna('[]')


# missing_geo_unique = tweets_smi_1['missing_geo'].unique() # axis=1 -> TO MOVE HORIZONTALLY

print('---')
print('missing_geo DIVIDED Head New DataFrame')
print(matrix_missing_geo.head(20))
print('---')

print('---')
print('Matrix missing_geo dtypes')
print(matrix_missing_geo.dtypes)
print('---')

print('---')
print('Matrix missing_geo Shape AFTER SPLIT')
print(matrix_missing_geo.shape)
print('---')

# SAVE TO FILE

matrix_missing_geo.to_csv('1_6_1_SMI1_matrix_missing_geo_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_geo.to_csv('1_6_1_SMI1_matrix_missing_geo_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

# matrix_missing_geo_unique = matrix_missing_geo['missing_geo'].apply(lambda x: x.unique())

# matrix_missing_geo_unique = removeDupWithoutOrder(matrix_missing_geo['missing_geo'])
# matrix_missing_geo_unique = matrix_missing_geo['missing_geo'].apply(lambda x: removeDupWithoutOrder(x))

# matrix_missing_geo_unique = matrix_missing_geo_unique.astype(str, errors='ignore')

matrix_missing_geo_unique = pd.DataFrame(matrix_missing_geo_unique)

print('---------')
print('matrix_missing_geo_unique head')
print(matrix_missing_geo_unique.head(20))
print('-------------------------------')

matrix_missing_geo_unique = pd.DataFrame(matrix_missing_geo_unique)


# SAVE TO CSV 

matrix_missing_geo_unique.to_csv('1_6_1_SMI1_Matrix_missing_geo_Unique_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_geo_unique.to_csv('1_6_1_SMI1_Matrix_missing_geo_Unique_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

########################

# MATRIX TRANSPOSE missing_geo 

matrix_missing_geo_transposed = matrix_missing_geo

matrix_missing_geo_transposed = matrix_missing_geo_transposed.melt(id_vars = ['screenName', 'lists'])

matrix_missing_geo_transposed = matrix_missing_geo_transposed.drop(columns='variable')

# matrix_missing_geo_transposed = matrix_missing_geo_transposed.astype(str, errors='ignore')

matrix_missing_geo_unique['missing_geo'] = matrix_missing_geo['missing_geo'].unique()

# matrix_missing_geo_transposed['missing_geo'] = matrix_missing_geo_transposed.groupby('screenName')

print('---')
print('Head Missing missing_geo MA')
print(matrix_missing_geo_transposed.head)
print('---')

# SAVE TO CSV 

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

matrix_missing_geo_transposed.to_csv('1_6_1_SMI1_matrix_missing_geo_transposed_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_geo_transposed.to_csv('1_6_1_SMI1_matrix_missing_geo_transposed_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

#######################################################################################################
#####################################################################################################

print('--------------------------------------------------')
print(' ----- MATRIX missing_country -- OJO TOTAL')
print('--------------------------------------------------')

tweets_smi_1['missing_country'] = pd.DataFrame(tweets_smi_1['missing_country_total'])

# CREATE MATRIX missing_country

matrix_missing_country_unique = []

# matrix_missing_country = tweets_smi_1[['screenName', 'lists', 'missing_country']].copy()

matrix_missing_country = pd.DataFrame(tweets_smi_1[['screenName', 'lists', 'missing_country']])

# ######################matrix_missing_country = matrix_missing_country.reset_index()
# matrix_missing_country = matrix_missing_country.drop(columns='author_id')
# matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].astype(str, errors='ignore')
############ matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].replace('\]', '')
# ## matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].str.replace('\[', '')


# matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].str.replace('\'', '')

# [' ']

# SAVE TO FILE

# matrix_missing_country.to_csv('1_6_1_SMI1_matrix_missing_country_BEFORE_SPLIT_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_country.to_csv('1_6_1_SMI1_matrix_missing_country_BEFORE_SPLIT_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)


# matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].str.split(',', n=20, expand=True)

matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].apply(lambda x: x.split(','))

# matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].astype(str, errors='ignore')

# matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].str.replace(',', ' ')
matrix_missing_country['missing_country'] = matrix_missing_country['missing_country'].fillna('[]')


# missing_country_unique = tweets_smi_1['missing_country'].unique() # axis=1 -> TO MOVE HORIZONTALLY

print('---')
print('missing_country DIVIDED Head New DataFrame')
print(matrix_missing_country.head(20))
print('---')

print('---')
print('Matrix missing_country dtypes')
print(matrix_missing_country.dtypes)
print('---')

print('---')
print('Matrix missing_country Shape AFTER SPLIT')
print(matrix_missing_country.shape)
print('---')

# SAVE TO FILE

matrix_missing_country.to_csv('1_6_1_SMI1_matrix_missing_country_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_country.to_csv('1_6_1_SMI1_matrix_missing_country_TXT.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

# matrix_missing_country_unique = matrix_missing_country['missing_country'].apply(lambda x: x.unique())

# matrix_missing_country_unique = removeDupWithoutOrder(matrix_missing_country['missing_country'])
# matrix_missing_country_unique = matrix_missing_country['missing_country'].apply(lambda x: removeDupWithoutOrder(x))

# matrix_missing_country_unique = matrix_missing_country_unique.astype(str, errors='ignore')

matrix_missing_country_unique = pd.DataFrame(matrix_missing_country_unique)

print('---------')
print('matrix_missing_country_unique head')
print(matrix_missing_country_unique.head(20))
print('-------------------------------')

matrix_missing_country_unique = pd.DataFrame(matrix_missing_country_unique)


# SAVE TO CSV 

matrix_missing_country_unique.to_csv('1_6_1_SMI1_Matrix_missing_country_Unique_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_country_unique.to_csv('1_6_1_SMI1_Matrix_missing_country_Unique_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

########################

# MATRIX TRANSPOSE missing_country 

matrix_missing_country_transposed = matrix_missing_country

matrix_missing_country_transposed = matrix_missing_country_transposed.melt(id_vars = ['screenName', 'lists'])

matrix_missing_country_transposed = matrix_missing_country_transposed.drop(columns='variable')

# matrix_missing_country_transposed = matrix_missing_country_transposed.astype(str, errors='ignore')

matrix_missing_country_unique['missing_country'] = matrix_missing_country['missing_country'].unique()

# matrix_missing_country_transposed['missing_country'] = matrix_missing_country_transposed.groupby('screenName')

print('---')
print('Head Missing missing_country MA')
print(matrix_missing_country_transposed.head)
print('---')

# SAVE TO CSV 

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

matrix_missing_country_transposed.to_csv('1_6_1_SMI1_matrix_missing_country_transposed_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# matrix_missing_country_transposed.to_csv('1_6_1_SMI1_matrix_missing_country_transposed_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)


#######################################################################################################


tweets_smi_1['lists'] = tweets_smi_1['lists'].fillna(0)
# tweets_smi_1['followers'] = tweets_smi_1['followers'].fillna(0)
# tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].fillna(0)
# tweets_smi_1['following'] = tweets_smi_1['following'].fillna(0)

tweets_smi_1['lists'] = tweets_smi_1['lists'].replace('nan', '0')
tweets_smi_1['lists'] = tweets_smi_1['lists'].replace('Nan', '0')
# tweets_smi_1['followers'] = tweets_smi_1['followers'].replace('nan', '0')
# tweets_smi_1['followers'] = tweets_smi_1['followers'].replace('Nan', '0')
# tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].replace('nan', '0')
# tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].replace('Nan', '0')
# tweets_smi_1['following'] = tweets_smi_1['following'].replace('nan', '0')
# tweets_smi_1['following'] = tweets_smi_1['following'].replace('Nan', '0')

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].astype(str, errors='ignore')

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].astype(str, errors='ignore')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].astype(str, errors='ignore')
# tweets_smi_1['language'] = tweets_smi_1['language'].astype(str, errors='ignore')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore')

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace('\[,\]', '')
tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(',,', '')

tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].replace('\[,\]', '')

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].astype(str, errors='ignore')
# tweets_smi_1['country'] = tweets_smi_1['country'].astype(str, errors='ignore')

tweets_smi_1['lists'] = tweets_smi_1['lists'].astype(np.int32, errors='ignore')
# tweets_smi_1['followers'] = tweets_smi_1['followers'].astype(np.int32, errors='ignore')
# tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(np.int64, errors='ignore')
# tweets_smi_1['following'] = tweets_smi_1['following'].astype(np.int32, errors='ignore')

# tweets_smi_1['created'] = pd.to_datetime(tweets_smi_1['created'])
# tweets_smi_1['created'] = tweets_smi_1['created'].to_datetime()

# tweets_smi_1 = pd.DataFrame(tweets_smi_1)
tweets_smi_1['lists'] = tweets_smi_1['lists'].fillna(0)
# tweets_smi_1['followers'] = tweets_smi_1['followers'].fillna(0)

print('---')
print(tweets_smi_1.head(10))
print(tweets_smi_1.dtypes)
print('---')

#############################################################################################################

# value_counts_bigram_text = pd.value_counts(bigrams_text, ascending=False, bins=2)


value_counts_bigram_text = collections.Counter(bigrams_text) 

# .rename_axis('value_counts_bigrams_text_items').reset_index(name='value_counts_bigrams_text_counts')


# value_counts_bigram_text = pd.DataFrame(value_counts_bigram_text)

# value_counts_bigram_text = value_counts_bigram_text.astype(str)
# value_counts_bigram_text = value_counts_bigram_text.to_string()
# value_counts_bigram_text = value_counts_bigram_text.replace(')', ');')

# value_counts_bigram_text = value_counts_bigram_text['value_counts_bigrams_text_items'].str.cut('\)')

print('bbbbbbbbbbbbbbbbbb')
print('value_counts_bigram_text head dtypes')
# print(value_counts_bigram_text.head)
# print(value_counts_bigram_text.dtypes)
# print(value_counts_bigram_text.info)
print('bbbbbbbbbbbbbbbbbb')

# value_counts_bigram_text = value_counts_bigram_text.rename(columns={0:'value_counts_bigrams_text_items', 1:'value_counts_bigrams_text_counts'})

# value_counts_bigram_text['value_counts_bigrams_text_items'] = value_counts_bigram_text['value_counts_bigrams_text_items'].astype(str)
# value_counts_bigram_text['value_counts_bigrams_text_items'] = value_counts_bigram_text['value_counts_bigrams_text_items'].to_string()
# value_counts_bigram_text['value_counts_bigrams_text_items'] = value_counts_bigram_text['value_counts_bigrams_text_items'].str.replace(')', ');')

# value_counts_bigram_text = value_counts_bigram_text['value_counts_bigrams_text_items'].astype(str).apply(lambda x: x.str.split(';'))

# value_counts_bigram_text = value_counts_bigram_text.rename(columns={1:'value_counts_bigrams_text_counts'})


print('bbbbbbbbbbbbbbbbbb')
print('value_counts_bigram_text head dtypes')
# print(value_counts_bigram_text.head)
# print(value_counts_bigram_text.dtypes)
# print(value_counts_bigram_text.info)
print('bbbbbbbbbbbbbbbbbb')

# value_counts_bigram_text = value_counts_bigram_text['value_counts_bigram_text_items'].astype(str, errors='ignore')

value_counts_bigram_text = value_counts_bigram_text['value_counts_bigrams_text_counts'].sort_values(ascending=False)

# value_counts_bigram_text = value_counts_bigram_text.apply(lambda x: x.str.split(';').astype(str, errors='ignore'))

# value_counts_bigram_text = value_counts_bigram_text.rename(columns={0:'value_counts_bigrams_text_items', 1:'value_counts_bigrams_text_counts'})

value_counts_bigram_text.to_csv('4_5A_201_SMI1_value_counts_bigram_text_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# value_counts_bigram_text.to_excel('4_5A_201_SMI1_value_counts_bigram_text.xlsx', index=True, header=True)

print('---')
print('value_counts_bigram_text HEAD')
print(value_counts_bigram_text.head)
print('---')

print('---')
print('value_counts_bigram_text dtypes')
print(value_counts_bigram_text.dtypes)
print('---')

# value_counts_bigram_text['value_counts_bigrams_text_items'] = value_counts_bigram_text['value_counts_bigrams_text_items'].astype(str, errors='ignore')

#####

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Text Value Counts')
plt.ioff()
value_counts_bigram_text[:10].plot(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Bigram_Value_Counts_Bigram_Text_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Text Value Counts - Pie')
plt.ioff()
value_counts_bigram_text[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
# plt.legend(value_counts_bigram_text, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.) 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Value_Counts_Bigram_Text_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Text Value Counts - Bars')
plt.ioff()
value_counts_bigram_text[:10].plot.bar(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Value_Counts_Bigram_Text_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# value_counts_bigrams_text_items value_counts_bigrams_text_counts

#############################################################################################################

# value_counts_bigram_hashtags = pd.value_counts(bigrams_hashtags, ascending=False, normalize=True) 

value_counts_bigram_hashtags = collections.Counter(bigrams_hashtags) 

value_counts_bigram_hashtags = value_counts_bigram_hashtags.sort_values(ascending=False)

value_counts_bigram_hashtags_df = pd.DataFrame(value_counts_bigram_hashtags, columns=['value_counts_bigrams_hashtags'])

value_counts_bigram_hashtags_df.to_csv('4_5A_201_SMI1_value_counts_bigram_hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# value_counts_bigram_hashtags_df.to_excel('4_5A_201_SMI1_value_counts_bigram_hashtags_DF.xlsx', index=True, header=True)

# print('---')
print('value_counts_bigram_hashtags_df info')
print(value_counts_bigram_hashtags_df.info)
print('---')

# print('---')
print('value_counts_bigram_hashtags_df shape')
print(value_counts_bigram_hashtags_df.shape)
print('---')

# CREATE SEPERATE BIGRAMS DATAFRAMES 

# value_counts_bigram_hashtags_df = value_counts_bigram_hashtags_df.astype(str, errors='ignore')

# seperate_value_counts_bigram_hashtags = [value_counts_bigram_hashtags_df[:0], value_counts_bigram_hashtags_df[:1]]

# value_counts_bigram_hashtags_df = value_counts_bigram_hashtags_df['value_counts_bigrams'].apply(list)

# seperate_value_counts_bigram_hashtags_df = pd.DataFrame.from_items(value_counts_bigram_hashtags, columns=['items_counts_bigrams', 'number_counts_bigrams'])
# seperate_value_counts_bigram_hashtags_df[['value_bigrams_hashtags', 'value_counts_bigrams_hashtags']] = pd.DataFrame(value_counts_bigram_hashtags_df['value_counts_bigrams'].tolist(),index=value_counts_bigram_hashtags_df)
# seperate_value_counts_bigram_hashtags_df = seperate_value_counts_bigram_hashtags_df.join(value_counts_bigram_hashtags_df_temp)
# seperate_value_counts_bigram_hashtags_df.to_csv('4_5A_201_SMI1_seperate_value_counts_bigram_hashtags_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# seperate_value_counts_bigram_hashtags_df.to_excel('4_5A_201_SMI1_seperate_value_counts_bigram_hashtags_DF.xlsx', index=True, header=True)

# print('---')
print('seperate_value_counts_bigram_hashtags_df head')
# print(seperate_value_counts_bigram_hashtags_df.head)
print('---')

# print('---')
print('value_counts_bigram_hashtags_df info')
print(value_counts_bigram_hashtags_df.info)
print('---')

# print('---')
print('value_counts_bigram_hashtags_df shape')
print(value_counts_bigram_hashtags_df.shape)
print('---')

#####

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Hashtags Value Counts')
plt.ioff()
value_counts_bigram_hashtags[:10].plot(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Bigram_Value_Counts_Bigram_Hashtags_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Hashtags Value Counts - Pie')
plt.ioff()
value_counts_bigram_hashtags[:7].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.7, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['hashtags'], bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Value_Counts_Bigram_Hashtags_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Hashtags Value Counts - Bars')
plt.ioff()
value_counts_bigram_hashtags[:10].plot.bar(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Value_Counts_Bigram_Hashtags_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#############################################################################################################

# value_counts_bigram_mentions = pd.value_counts(bigrams_mentions, ascending=False, bins=2).reset_index().rename(columns={0:'bigrams_mentions_text','bigrams_mentions':'bigrams_mentions_count'})

value_counts_bigram_mentions = pd.value_counts(bigrams_mentions, ascending=False, normalize=True)

value_counts_bigram_mentions = value_counts_bigram_mentions.sort_values(ascending=False)

value_counts_bigram_mentions_df[['bigrams_mentions_text','bigrams_mentions_count']] = pd.DataFrame(value_counts_bigram_mentions)

print('value_counts_bigram_mentions_df DTYPES')
print(value_counts_bigram_mentions_df.dtypes)
print('---')

print('value_counts_bigram_mentions_df info')
print(value_counts_bigram_mentions_df.info)
print('---')

print('value_counts_bigram_mentions_df shape')
print(value_counts_bigram_mentions_df.shape)
print('---')

value_counts_bigram_mentions_df = value_counts_bigram_mentions_df.str.split(';')

# value_counts_bigram_mentions_df = value_counts_bigram_mentions_df.rename(columns={0:'bigrams_mentions_text','bigrams_mentions':'bigrams_mentions_count'})

value_counts_bigram_mentions_df['bigrams_mentions_count'] = value_counts_bigram_mentions_df['bigrams_mentions_count'].astype(np.int32, errors='ignore')
# value_counts_bigram_mentions_df['bigrams_mentions_text'] = value_counts_bigram_mentions_df['bigrams_mentions_text'].astype(str, errors='ignore')

value_counts_bigram_mentions_df['bigrams_mentions_text'] = value_counts_bigram_mentions_df['bigrams_mentions_text'].replace('\(', '')
value_counts_bigram_mentions_df['bigrams_mentions_text'] = value_counts_bigram_mentions_df['bigrams_mentions_text'].replace('\)', '')

# value_counts_bigram_mentions_df['bigrams_mentions_count'] = value_counts_bigram_mentions_df['bigrams_mentions_count'].astype(np.int32, errors='ignore')

value_counts_bigram_mentions_df.to_csv('4_5A_201_SMI1_value_counts_bigram_mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# value_counts_bigram_mentions_df.to_excel('4_5A_201_SMI1_value_counts_bigram_mentions_DF.xlsx', index=True, header=True)

print('value_counts_bigram_mentions_df DTYPES 2')
print(value_counts_bigram_mentions_df.dtypes)
print('---')

print('value_counts_bigram_mentions_df info')
print(value_counts_bigram_mentions_df.info)
print('---')

print('value_counts_bigram_mentions_df shape')
print(value_counts_bigram_mentions_df.shape)
print('---')

# CREATE SEPERATE BIGRAMS DATAFRAMES 

# value_counts_bigram_mentions_df = value_counts_bigram_mentions_df.astype(str, errors='ignore')

# seperate_value_counts_bigram_mentions = [value_counts_bigram_mentions_df[:0], value_counts_bigram_mentions_df[:1]]

# value_counts_bigram_mentions_df = value_counts_bigram_mentions_df['value_counts_bigrams'].apply(list)

# seperate_value_counts_bigram_mentions_df = pd.DataFrame.from_items(value_counts_bigram_mentions, columns=['items_counts_bigrams', 'number_counts_bigrams'])
# seperate_value_counts_bigram_mentions_df[['value_bigrams_mentions', 'value_counts_bigrams_mentions']] = pd.DataFrame(value_counts_bigram_mentions_df['value_counts_bigrams'].tolist(),index=value_counts_bigram_mentions_df)
# seperate_value_counts_bigram_mentions_df = seperate_value_counts_bigram_mentions_df.join(value_counts_bigram_mentions_df_temp)
# seperate_value_counts_bigram_mentions_df.to_csv('4_5A_201_SMI1_seperate_value_counts_bigram_mentions_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# seperate_value_counts_bigram_mentions_df.to_excel('4_5A_201_SMI1_seperate_value_counts_bigram_mentions_DF.xlsx', index=True, header=True)

# print('---')
print('seperate_value_counts_bigram_mentions_df head')
# print(seperate_value_counts_bigram_mentions_df.head)
print('---')

# print('---')
print('value_counts_bigram_mentions_df info')
print(value_counts_bigram_mentions_df.info)
print('---')

# print('---')
print('value_counts_bigram_mentions_df shape')
print(value_counts_bigram_mentions_df.shape)
print('---')

#####

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Mentions Value Counts')
value_counts_bigram_mentions[:10].plot(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Bigram_Value_Counts_Bigram_Mentions_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Mentions Value Counts - Pie')
value_counts_bigram_mentions[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.7, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['mentions'], bbox_to_anchor=(1.9, 0.4), loc=1, borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Value_Counts_Bigram_Mentions_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Mentions Value Counts - Bars')
value_counts_bigram_mentions[:10].plot.bar(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_Value_Counts_Bigram_Mentions_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#############################################################################################################

value_counts_bigram_emojis_unicode = pd.value_counts(bigrams_emojis_unicode, ascending=False, normalize=True) 

value_counts_bigram_emojis_unicode = value_counts_bigram_emojis_unicode.sort_values(ascending=False)

value_counts_bigram_emojis_unicode_df = pd.DataFrame(value_counts_bigram_emojis_unicode, columns=['bigrams_emojis_unicode', 'value_counts_bigrams_emojis_unicode'])

value_counts_bigram_emojis_unicode_df.to_csv('4_5A_201_SMI1_value_counts_bigram_emojis_unicode_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# value_counts_bigram_emojis_unicode_df.to_excel('4_5A_201_SMI1_value_counts_bigram_emojis_unicode_DF.xlsx', index=True, header=True)

print('---')
print('value_counts_bigram_emojis_unicode_df info')
print(value_counts_bigram_emojis_unicode_df.info)
print('---')

print('---')
print('value_counts_bigram_emojis_unicode_df shape')
print(value_counts_bigram_emojis_unicode_df.shape)
print('---')

# CREATE SEPERATE BIGRAMS DATAFRAMES 

# value_counts_bigram_emojis_unicode_df = value_counts_bigram_emojis_unicode_df.astype(str, errors='ignore')

# seperate_value_counts_bigram_emojis_unicode = [value_counts_bigram_emojis_unicode_df[:0], value_counts_bigram_emojis_unicode_df[:1]]

# value_counts_bigram_emojis_unicode_df = value_counts_bigram_emojis_unicode_df['value_counts_bigrams'].apply(list)

# seperate_value_counts_bigram_emojis_unicode_df = pd.DataFrame.from_items(value_counts_bigram_emojis_unicode, columns=['items_counts_bigrams', 'number_counts_bigrams'])
# seperate_value_counts_bigram_emojis_unicode_df[['value_bigrams_emojis_unicode', 'value_counts_bigrams_emojis_unicode']] = pd.DataFrame(value_counts_bigram_emojis_unicode_df['value_counts_bigrams'].tolist(),index=value_counts_bigram_emojis_unicode_df)
# seperate_value_counts_bigram_emojis_unicode_df = seperate_value_counts_bigram_emojis_unicode_df.join(value_counts_bigram_emojis_unicode_df_temp)
# seperate_value_counts_bigram_emojis_unicode_df.to_csv('4_5A_201_SMI1_seperate_value_counts_bigram_emojis_unicode_DF_CSV.csv', sep=';', encoding='utf-8', index=True, header=True)
# seperate_value_counts_bigram_emojis_unicode_df.to_excel('4_5A_201_SMI1_seperate_value_counts_bigram_emojis_unicode_DF.xlsx', index=True, header=True)

print('---')
print('seperate_value_counts_bigram_emojis_unicode_df head')
# print(seperate_value_counts_bigram_emojis_unicode_df.head)
print('---')

print('---')
print('value_counts_bigram_emojis_unicode_df info')
print(value_counts_bigram_emojis_unicode_df.info)
print('---')

print('---')
print('value_counts_bigram_emojis_unicode_df shape')
print(value_counts_bigram_emojis_unicode_df.shape)
print('---')

#####

# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Emojis Value Counts')
value_counts_bigram_emojis_unicode[:10].plot(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_bigram_value_counts_bigram_emojis_unicode_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))    ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Emojis Value Counts - Pie')
value_counts_bigram_emojis_unicode[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['emojis_unicode'], bbox_to_anchor=(1.0, 1), loc=1, borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_value_counts_bigram_emojis_unicode_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Bigram Emojis Value Counts - Bars')
value_counts_bigram_emojis_unicode[:10].plot.bar(alpha=0.9)
plt.xlabel('Bigram')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Top_value_counts_bigram_emojis_unicode_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



###############################################################################################

# TREEMAPS 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mentions Bigrams - Treemap')
squarify.plot(sizes=value_counts_bigram_mentions_df['bigrams_mentions_count'], label=value_counts_bigram_mentions_df['bigrams_mentions_text'], alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Bigrams_Treemap_mentions.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################

# TREEMAPS 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Text Bigrams - Treemap')
plt.ioff()
squarify.plot(sizes=value_counts_bigram_text.value_counts_bigrams_text_items, label=value_counts_bigram_text.value_counts_bigrams_text_counts, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5A_201_SMI1_Text_Bigrams_Treemap.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#############################################################################################################


# METHOD 2: 

tweets_smi_1['word_1_query'] = tweets_smi_1.query('text == "love"')

tweets_smi_1['number_word_1'] = pd.value_counts(tweets_smi_1['word_1_query'], ascending=False, normalize=True)

print('------------------------------------------------------------')
print('------------------------------------------------------------')
print('Word 1 Query:')
print(tweets_smi_1['word_1_query'])
print('------------------------------------------------------------')
print('Word 1 Query NUMEBR:')
print(tweets_smi_1['number_word_1'])
print('-------------------------------------------------------------')
print('-------------------------------------------------------------')


word_2_query = tweets_smi_1.query('text == "word_2"')
number_word_2 = len(word_2_query)

word_3_query = tweets_smi_1.query('text == "word_3"')
number_word_3 = len(word_3_query)
  
word_4_query = tweets_smi_1.query('text == "word_4"')
number_word_4 = len(word_4_query)
 
word_5_query = tweets_smi_1.query('text == "word_5"')
number_word_5 = len(word_5_query)
 
word_6_query = tweets_smi_1.query('text == "word_6"')
number_word_6 = len(word_6_query)
 
word_7_query = tweets_smi_1.query('text == "word_7"')
number_word_7 = len(word_7_query)
 
word_8_query = tweets_smi_1.query('text == "word_8"')
number_word_8 = len(word_8_query)
 
word_9_query = tweets_smi_1.query('text == "word_9"')
number_word_9 = len(word_9_query)
 
word_10_query = tweets_smi_1.query('text == "word_10"')
number_word_10 = len(word_10_query)

word_11_query = tweets_smi_1.query('text == "word_11"')
number_word_11 = len(word_11_query)

word_12_query = tweets_smi_1.query('text == "word_12"')
number_word_12 = len(word_12_query)

word_13_query = tweets_smi_1.query('text == "word_13"')
number_word_13 = len(word_13_query)

word_14_query = tweets_smi_1.query('text == "word_14"')
number_word_14 = len(word_14_query)

word_15_query = tweets_smi_1.query('text == "word_15"')
number_word_15 = len(word_15_query)

word_16_query = tweets_smi_1.query('text == "word_16"')
number_word_16 = len(word_16_query)

word_17_query = tweets_smi_1.query('text == "word_17"')
number_word_17 = len(word_17_query)

word_18_query = tweets_smi_1.query('text == "word_18"')
number_word_18 = len(word_18_query)

word_19_query = tweets_smi_1.query('text == "word_19"')
number_word_19 = len(word_19_query)

word_20_query = tweets_smi_1.query('text == "word_20"')
number_word_20 = len(word_20_query)

word_21_query = tweets_smi_1.query('text == "word_21"')
number_word_21 = len(word_21_query)

word_22_query = tweets_smi_1.query('text == "word_22"')
number_word_22 = len(word_22_query)

word_23_query = tweets_smi_1.query('text == "word_23"')
number_word_23 = len(word_23_query)

word_24_query = tweets_smi_1.query('text == "word_24"')
number_word_24 = len(word_24_query)

word_25_query = tweets_smi_1.query('text == "word_25"')
number_word_25 = len(word_25_query)

word_26_query = tweets_smi_1.query('text == "word_26"')
number_word_26 = len(word_26_query)

word_27_query = tweets_smi_1.query('text == "word_27"')
number_word_27 = len(word_27_query)

 
# initialize list of Lists 
selected_tweets_words_counts = [[word_1, number_word_1], [word_2, number_word_2], [word_3, number_word_3], [word_4, number_word_4], [word_5, number_word_5], [word_6, number_word_6], [word_7, number_word_7], [word_8, number_word_8], [word_9, number_word_9], [word_10, number_word_10], [word_11, number_word_11], [word_12, number_word_12], [word_13, number_word_13], [word_14, number_word_14], [word_15, number_word_15], [word_16, number_word_16], [word_17, number_word_17], [word_18, number_word_18], [word_19, number_word_19], [word_20, number_word_20], [word_21, number_word_21], [word_22, number_word_22], [word_23, number_word_23], [word_24, number_word_24], [word_25, number_word_25], [word_26, number_word_26], [word_27, number_word_27]] 
 
# Create the pandas DataFrame 
selected_tweets_words_counts_df = pd.DataFrame(selected_tweets_words_counts, columns = ['tweets_words', 'Counts']) 

selected_tweets_words_counts_df.to_csv('4_5A_211_SMI1_Selected_Tweets_Words_Counts_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# selected_tweets_words_counts_df.to_excel('4_5A_211_SMI1_Selected_Tweets_Words_Counts_DF.xlsx', header=True)

# Selected tweets_words Plot


# TABLE PLOT NEED TO DO 

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies')
# selected_tweets_words_counts_df.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_211_SMI1_Selected_Tweets_Words_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies - Pie')
# plt.pie(selected_tweets_words_counts_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.4, labeldistance=1.7, colors=colors_blue, startangle=90)
# plt.legend(selected_tweets_words_counts_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_211_SMI1_Selected_Tweets_Words_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOT # NEED TO DO

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies - Bars')
selected_tweets_words_counts_df.plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_211_SMI1_Selected_Tweets_Words_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


################################################################################################################
################################################################################################################
#################################################################################

# YEAR PLOT SNS FOLLOWERS Lists total_favorites TOTAL_TWEETS LISTS // NEED TO DO NEED TO FIX !!!

################################################################################
################################################################################################################
################################################################################################################




# SNS SEABORN RELATIONSHIPS PLOTS 


# SCATTER PLOT PLOT 1 ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships Created / Lists - Scatter')
sns.relplot(x='created', y='lists', data=tweets_smi_1) 
# sns.lmplot(x='created', y='total_favorites', hue='followers', data=tweets_smi_1)
# rel_graphs_total_favorites_follower_follower.add_legend()
# rel_graphs_total_favorites_follower_follower.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_0_SMI1_Rel_Graphs_Created_Lists_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################

# SCATTER PLOT PLOT 2 ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships Favorites / Followers - Scatter')
# sns.FacetGrid(tweets_smi_1, col='total_favorites', hue='followers', palette='Set2')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_0_1_SMI1_Rel_Total_Favorites_Follower_Faceted_Scattered2.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################################################################################################
################################################################################

# SNS SEABORN RELATIONSHIPS PLOTS 


# SCATTER PLOT PLOT 1 ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships Created / Followers - Scatter')
sns.relplot(x='created', y='followers', data=tweets_smi_1) # followers_count
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_0_SMI1_Rel_Graphs_Created_Followers_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################

# SCATTER PLOT PLOT 2 ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships Favorites / Followers - Scatter2')
# sns.FacetGrid(tweets_smi_1, col='total_favorites', hue='followers', palette='Set2')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_0_2_SMI1_Rel_Total_Favorites_Follower_Faceted_Scatt2.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################

# SNS SEABORN RELATIONSHIPS PLOTS Following

rel_graphs_total_favorites_following = sns.FacetGrid(tweets_smi_1, col='followers', hue='following', palette='Set2')


# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships Followers / Following - Scatter')
# rel_graphs_total_favorites_following.map(plt.scatter, 'year', 'followers', alpha=0.9)
# sns.lmplot(x='created', y='followers', hue='following', data=tweets_smi_1)
# rel_graphs_total_favorites_following.add_legend()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_0_SMI1_Rel_Graphs_Followers_Following_Faceted_Scattered_2.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################################################################################################

# SEABORN PAIR PLOTS


rel_graphs_tweets_smi_1_followers = sns.PairGrid(tweets_smi_1, hue='followers', palette='Set2') 

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Followers - Scatter')
# tweets_smi_1.map(plt.scatter)
# rel_graphs_tweets_smi_1_followers.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_followers.add_legend()
# rel_graphs_tweets_smi_1_followers.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_01_SMI1_Rel_Graphs_Total_Followers_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############


# SEABORN PAIR PLOTS

# rel_graphs_tweets_smi_1_following = sns.PairGrid(tweets_smi_1, hue='following', palette='Set2') 

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Favorites - Scatter')
#5sns.pairplot(data=tweets_smi_1, hue='total_favorites')
# rel_graphs_tweets_smi_1_following.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_following.add_legend()
# rel_graphs_tweets_smi_1_following.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_01_SMI1_Rel_Graphs_Total_Favorites_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Followers - Scatter')
# sns.pairplot(data=tweets_smi_1, hue='followers')
# rel_graphs_tweets_smi_1_following.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_following.add_legend()
# rel_graphs_tweets_smi_1_following.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_01_SMI1_Rel_Graphs_Total_followers_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################################################################################################

# SEABORN PAIR PLOTS

rel_graphs_tweets_smi_1 = sns.PairGrid(tweets_smi_1, palette='Set2') 

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.figure(figsize=(16,14))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships Total - Scatter')
rel_graphs_tweets_smi_1.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1.add_legend()
# rel_graphs_tweets_smi_1.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_01_SMI1_Rel_Graphs_Total_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############

# SEABORN PAIR PLOTS followers

rel_graphs_tweets_smi_1_followers = sns.PairGrid(tweets_smi_1, hue='followers', palette='Set2') 

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Followers - Scatter')
# tweets_smi_1.map(plt.scatter)
# rel_graphs_tweets_smi_1_followers.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_followers.add_legend()
# rel_graphs_tweets_smi_1_followers.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_02_SMI1_rel_graphs_total_follower_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############

# SEABORN PAIR PLOTS

# rel_graphs_tweets_smi_1_following = sns.PairGrid(tweets_smi_1, hue='following', palette='Set2') 

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Favorites - Scatter')
#5sns.pairplot(data=tweets_smi_1, hue='total_favorites')
# rel_graphs_tweets_smi_1_following.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_following.add_legend()
# rel_graphs_tweets_smi_1_following.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_02_SMI1_Rel_Graphs_Total_Favorites_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Followers - Scatter')
# sns.pairplot(data=tweets_smi_1, hue='followers')
# rel_graphs_tweets_smi_1_following.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_following.add_legend()
# rel_graphs_tweets_smi_1_following.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_02_SMI1_Rel_Graphs_Total_followers_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###########################################################################################################

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Lists - Scatter')
# sns.pairplot(data=tweets_smi_1, hue='lists')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_02_SMI1_rel_graphs_Lists_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Main SMI Followers - Scatter')
# sns.pairplot(data=tweets_smi_1, hue='followers_count')
# rel_graphs_tweets_smi_1_following.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_following.add_legend()
# rel_graphs_tweets_smi_1_following.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_02_SMI1_rel_graphs_total_followers_count_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Main SMI Following - Scatter')
# sns.pairplot(data=tweets_smi_1, hue='following')
# rel_graphs_tweets_smi_1_following.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_following.add_legend()
# rel_graphs_tweets_smi_1_following.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_02_SMI1_Rel_Graphs_total_following_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Year - Scatter')
# sns.pairplot(data=tweets_smi_1, hue='year')
# rel_graphs_tweets_smi_1_following.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_following.add_legend()
# rel_graphs_tweets_smi_1_following.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_02_SMI1_Rel_Graphs_Total_Year_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

################################################################################################################
################################################################################################################
###################################################################################################################
#
# 		        TOPIC MODELLING : LSA Latent Semantic Analysis
#                                                 
###################################################################################################################

# analyticsvidhya.com/blob/2018/10/stewise-guide-topic-modeling-latent-semantic-analysis/




##############################################################################################################

# _df _df = pd.DataFrame()
# .to_csv('4_5A_.csv', sep=';', encoding='utf-8', index=True)
# excel

#####################################################################################################
#####################################################################################################
#
#				EMOJIS OPERATIONS AND CONVERSION 
#
######################################################################################################

# MISSING EMOJIS COMPLETE METHOD GOOD =)

pattern_emojis_unicode = r'<\U([A-Z0-9]+)'
tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['text'].str.findall(r'pattern_emojis_unicode', flags=re.IGNORECASE)

print('---')
print('Head Missing Emojis Unicode from find all')
print(tweets_smi_1['missing_emojis_unicode'].head)
print('---')

# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore')

tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].fillna('0')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].fillna('0')
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].fillna('0')

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace(r'\u', r', \U') # NEED TO SEPERATE EMOJIS ???? OR IS IT JUST ONE?


# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace(r'c\\u', r'c, u\u')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace(r'd\\u', r'd, u\u')
tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace('\[\]', '')
tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace('\[', '')
tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace('\]', '')

# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace('\[\]', '')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace('\[', '')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace('\]', '')


# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.replace('\[\]', '')
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.replace('\[', '')
# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.replace('\]', '')

tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.replace(' ', ', ')

tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.lstrip()
tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.lstrip()
tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.lstrip()

missing_emojis_unicode = pd.DataFrame(tweets_smi_1['missing_emojis_unicode'])

# SAVE TO CSV 

missing_emojis_unicode.to_csv('1_6_1_SMI1_missing_emojis_unicode_0_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# missing_emojis_unicode.to_csv('1_6_1_SMI1_missing_emojis_unicode_0_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

print('Head Missing Emojis Unicode')
print(tweets_smi_1['missing_emojis_unicode'].head)
print('---')

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['missing_emojis_unicode']

# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('@', ' ')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('#', ' ')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('\?', ' ')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('   ', ' ')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace(',', ' ')

################# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('\"', '')

# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('\ ', ' ')
## tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('/', ' ')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('\.', ' ')

# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace(',', ' ')

# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace(';', ' ')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('\&', ' ')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('\^', ' ')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('\=', ' ')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace(': ', ' ')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('\)', ' ')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('\(', ' ')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('<', ' ')

print('---')
print('tweets_smi_1 : missing_emojis_unicode : shape')
# print(tweets_smi_1['missing_emojis_unicode'].shape)
print('---')

tweets_smi_1['missing_emojis_unicode'] = list(tweets_smi_1['missing_emojis_unicode'])
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore')

tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].fillna('0')
tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.lstrip()
tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.rstrip()
tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace('\'nan\'', '')
tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace('NaN', '')

# tweets_smi_1['total_emojis_unicode'] = tweets_smi_1['total_emojis_unicode'].astype(str, errors='ignore')

tweets_smi_1['total_emojis_unicode'] = tweets_smi_1['total_emojis_unicode'].fillna('0')
tweets_smi_1['total_emojis_unicode'] = tweets_smi_1['total_emojis_unicode'].str.lstrip()
tweets_smi_1['total_emojis_unicode'] = tweets_smi_1['total_emojis_unicode'].str.rstrip()
tweets_smi_1['total_emojis_unicode'] = tweets_smi_1['total_emojis_unicode'].str.replace('\'nan\'', '')
tweets_smi_1['total_emojis_unicode'] = tweets_smi_1['total_emojis_unicode'].str.replace('NaN', '')

# tweets_smi_1['emojis_unicode_orig'] = tweets_smi_1['emojis_unicode_orig'].astype(str, errors='ignore')

tweets_smi_1['emojis_unicode_orig'] = tweets_smi_1['emojis_unicode_orig'].fillna('0')
tweets_smi_1['emojis_unicode_orig'] = tweets_smi_1['emojis_unicode_orig'].str.lstrip()
tweets_smi_1['emojis_unicode_orig'] = tweets_smi_1['emojis_unicode_orig'].str.rstrip()
tweets_smi_1['emojis_unicode_orig'] = tweets_smi_1['emojis_unicode_orig'].str.replace('\'nan\'', '')
tweets_smi_1['emojis_unicode_orig'] = tweets_smi_1['emojis_unicode_orig'].str.replace('NaN', '')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore')
tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace('\'', '"')
tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace('\'', '"')

#######################################################################################################

# MAKE TOTAL emojis_unicode

total_emojis_unicode = pd.DataFrame()

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].to_string()
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].to_string()


tweets_smi_1['emojis_unicode_orig'] = tweets_smi_1['emojis_unicode'].copy()

tweets_smi_1['emojis_unicode'] = tweets_smi_1[['emojis_unicode_orig', 'missing_emojis_unicode']].astype(str, errors='ignore').apply(' '.join, axis=1)
tweets_smi_1['emojis_unicode_total'] = tweets_smi_1[['emojis_unicode_orig', 'missing_emojis_unicode']].apply(' '.join, axis=1)

tweets_smi_1['total_emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore') + ',' + tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore')

# COMBINE COLLUMNS

#### tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace(' ', ',')
######### tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace(' ', ',')


##################### tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace('\"', '')


print('Head TOTAL emojis_unicode_total: OJO REVISAR 5')
print(tweets_smi_1['emojis_unicode_total'].head)
print('---')

# tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace(',,', ',')
# tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace(',,', ',')

# tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace('   ', ' ', regex=True)
############################ tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace('\'', '', regex=True)
tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace('\'nan\'', 'NONE')
tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace('NaN', 'NONE')
tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace('\'0\'', '')

# tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace(', ,', ',')
# tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace('\]', '')
# tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace('\[', '')

# tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.replace('\[', '')

tweets_smi_1['emojis_unicode_total'] = tweets_smi_1['emojis_unicode_total'].str.lstrip()

tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode_total'] 

print('---')
print('tweets_smi_1 emojis_unicode head')
print(tweets_smi_1['emojis_unicode'].head(20))
print('---')

#############################################################################################

print('------------------------------------------------------------------------------')
print('Head TOTAL emojis_unicode:')
print('------------------------------------------------------------------------------')
print(tweets_smi_1['emojis_unicode'].head)
print('---')

total_emojis_unicode = pd.DataFrame()

total_emojis_unicode[['created', 'screenName', 'emojis_unicode']] = tweets_smi_1[['created', 'screenName', 'emojis_unicode']].copy()
# total_emojis_unicode = tweets_smi_1['created'].copy()
# total_emojis_unicode['screenName'] = tweets_smi_1['screenName']
# total_emojis_unicode['emojis_converted'] = tweets_smi_1['emojis_unicode']

# SAVE DATAFRAME TO CSV 

total_emojis_unicode.to_csv('1_6_1_SMI1_Total_emojis_unicode_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# total_emojis_unicode.to_csv('1_6_1_SMI1_Total_emojis_unicode_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

# SAVE DATAFRAME TO CSV 

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

## DELETE VARIABLE

del total_emojis_unicode

###################

tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace('\[', '')
tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace('\]', '')

tweets_smi_1['number_emojis_unicode'] = tweets_smi_1['emojis_unicode'].apply(lambda x: len(x))

tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace('\[', ' ')
tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace('\]', '')

tweets_smi_1['number_missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].apply(lambda x: len(x))

tweets_smi_1['number_total_emojis_unicode'] = tweets_smi_1['number_emojis_unicode'] + tweets_smi_1['number_missing_emojis_unicode']


print('number_emojis_unicode HEAD ')
print(tweets_smi_1['number_emojis_unicode'].head)
print('---')

print('---')
print('number_missing_emojis_unicode HEAD ')
print(tweets_smi_1['number_missing_emojis_unicode'].head)
print('---')


print('number_TOTAL_emojis_unicode HEAD ')
print(tweets_smi_1['number_total_emojis_unicode'].head)
print('---')


print('number_emojis_converted HEAD ')
# print(tweets_smi_1['number_emojis_converted'].head)
print('---')

########### tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace(' ', ',')
############# tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.replace(' ', ',')

# SAVE DATAFRAME TO CSV 

# tweets_smi_1.to_csv('1_6_1_16A_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_16A_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# stweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

###############################################################################################################

# COMPLETE EMOJIS_UNICODE: METHOD 1

# extract groups having pattern followed by any character


pattern_emojis_unicode = r'u<\U000([A-Z0-9]+)'

# pattern_emojis_unicode = r'\<\U000([1f600-1ffff]+)\]'
# pattern_emojis_unicode = r'\[u\\([A-Z0-9]+)\]'
# pattern_emojis_unicode = r'[^\U0001f600-\U0001ffff]'
# pattern_emojis_unicode = r'u[\U0001f600-\U0001ffff]'

# pattern_emojis_unicode = r'\[u\(U0001f600-<\U0001ffff\)]+'

# pattern_emojis_unicode = '\\U-\\0001f\\U007f\u0080-\udbff\udfff'

## pattern_emojis_unicode = r'u(0001f600-0001ffff)+'

# pattern_emojis_unicode = re.compile("["
#		u"\0001f600-\U0001ffff]"
#	"]+", flags=re.UNICODE)

# pattern_emojis_unicode = '[^\w\s,]'

# pattern_emojis_unicode = re.compile("["u"\U0001f600-\U0001ffff""]+", 

print('---')
print('Tweets SMI to String Text:')
# print(tweets_smi_1['missing_emojis_unicode'].head)
print('---')

# tweets_smi_1['missing_emojis_unicode'] = re.findall(pattern_emojis_unicode, tweets, flags=re.IGNORECASE)

def extract_emoji(str):
	yield ''.join(c for c in str if c in emoji.UNICODE_EMOJI)

def slip_count(text):
	emoji_list = []
	data = regex.findall(r'\X', text)
	for word in data:
		if any(char in emoji.UNICODE_EMOJI for char in word):
			emoji_list.append(word)
	yield emoji_list

# tweets_smi_1['missing_emojis_unicode'] = extract_emoji(tweets_smi_1['text'])

tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].fillna('0')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace('nan', '')
### tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace(b'\"', b'')
### tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace(b'\'', '')



print('---')
print('Missing Emojis Head:')
# print(missing_emojis_unicode.head)
print('---')


###################################################################################################
################################################################################################################
#
#			CONVERT EMOJIS FROM UNICODE THE GRAPHICAL
#
##############################################################################################################
###################################################################################################################################

# EMOJIS UNICODE


# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('~', ' ')

############## tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore').str.replace('000', u'<U+000')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('000', u'<U+000')


tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].replace('000', r'\U000')

# tweets_smi_1['total_emojis_unicode'] = tweets_smi_1['total_emojis_unicode'].astype(str, errors='ignore').str.replace('000', u'<U+000')

# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('\'nan\']"', ' ')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('\'nan\']', ' ')

# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace(']', '')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore').str.replace('[', '')

# RECHANGE THE PATTERN 

# tweets_smi_1['missing_emojis_unicode'] = " ".str.join(tweets_smi_1['missing_emojis_unicode_temp'])
# tweets_smi_1['missing_emojis_unicode'] = str(u' '.join(tweets_smi_1['missing_emojis_unicode_temp']))

print('---')
print('Head Missing Emojis Unicode')
# print(tweets_smi_1['missing_emojis_unicode'].head)
print('---')

# SAVE TO FILE

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].to_string()
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].to_string()

tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(r'0\\U', r'0, u\\U')
tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'1\\U', b'1, u\\U')
tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'2\\U', b'2, u\\U')
tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'3\\U', b'3, u\\U')
tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'4\\U', b'4, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'5\\U', b'5, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'6\\U', b'6, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'7\\U', b'7, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'8\\U', b'8, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'9\\U', b'9, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'a\\U', b'a, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'b\\U', b'b, u\\U')

tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(r'c\U', r'c, u\U')

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'd\\U', b'd, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'e\\U', b'e, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'f\\U', b'f, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'g\\U', b'g, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'h\\U', b'h, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'i\\U', b'i, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'j\\U', b'j, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'k\\U', b'k, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'l\\U', b'l, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'm\\U', b'm, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'n\\U', b'n, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'o\\U', b'o, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'p\\U', b'p, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'q\\U', b'q, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'r\\U', b'r, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b's\\U', b's, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b't\\U', b't, u\\U')
#################### # tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'u\\U', b'u, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'v\\U', b'v, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'w\\U', b'w, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'x\\U', b'x, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'y\\U', b'y, u\\U')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'z\\U', b'z, u\\U')

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'u2764', b'u0001f497, ') # HEARTH
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'u2665', b'u0001f497, ')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'u2728', b'u0001feb60, ') # SPARKLE
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'ufe0f', b'u0001f642, ') # SMILING FACE
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'u270d', b'u0001fe0f, ') # HAND WRITTING

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'u\', b'u')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'u\u', b', u\\U')

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace(',,', ',')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace(' 0 ', '')

######################## tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace(' ', ', ', regex=True)

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore').str.replace('[', '')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].astype(str, errors='ignore').str.replace(']', '')



########################################################################################################

######################### tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'\"', b'')
######################### tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(b'\'', b'')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace('[', '')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(']', '')
tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace('nan', 'NONE')
tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace('NaN', 'NONE')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace(',', ' ')

####

##################### tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace(b'\"', b'')
##################### tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace(b'\'', b'')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace('[', '')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace(']', '')
tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace('nan', 'NONE')
tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace('NaN', 'NONE')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.replace(',', ' ')

tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].fillna('0')


# missing_emojis_unicode = missing_emojis_unicode.str.replace('[', '')
# missing_emojis_unicode = missing_emojis_unicode.str.replace(']', '')


print('---')
print('Missing Emojis Head')
print(tweets_smi_1['missing_emojis_unicode'].head)
print('---')

missing_emojis_unicode = pd.DataFrame(tweets_smi_1['missing_emojis_unicode'])


# SAVE DATAFRAME TO CSV 

missing_emojis_unicode.to_csv('1_6_1_SMI1_missing_emojis_unicode_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# missing_emojis_unicode.to_csv('1_6_1_SMI1_missing_emojis_unicode_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

# missing_emojis_unicode.head(10)



#############################################################################################################
#############################################################################################

# CONVERT EMOJIS #################################################################

######### for emojis in tweets_smi_1['total_emojis_unicode'].items():
	# tweets_smi_1['total_emojis_unicode'] = tweets_smi_1['total_emojis_unicode'].apply(lambda x: x.str.decode('unicode-escape').encode('ASCII').astype(str, errors='ignore'))
#	emojis.decode('utf-8').encode('ascii', 'ignore')  # .encode('utf_8') # ('unicode-escape') # .encode('ASCII')

# tweets_smi_1['total_emojis_unicode'] = twemoji.parse(tweets_smi_1['total_emojis_unicode'])

for emoji in tweets_smi_1['total_emojis_unicode']:
	emoji.encode('unicode-escape')
	# return tweets_smi_1['total_emojis_unicode']

#

print('---')
print('tweets_smi_1 total_emojis_unicode head')
print(tweets_smi_1['total_emojis_unicode'].head(20))
print('---')

##########################################################################################################################

# SAVE TO CSV 

# missing_emojis_unicode_converted.to_csv('1_6_1_SMI1_missing_emojis_unicode_converted_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# missing_emojis_unicode_converted.to_csv('1_6_1_SMI1_missing_emojis_unicode_converted_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

############################################################################################################################

##########################################################################################################

# CHANGE MISSING EMOJIS TO UNICODE / GRAPHIC

tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].replace(u'uu', u'<U+')
tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].replace(u'uu', u'<U+')

# emoji_test = emoji.emojize(U+1F600)

# U0001f999

# <\U0001
# ([A-Z0-9]+)

print('---')
print('EMOJI CHANGED TEST - NOT WORKING ------------------------------------------------------')
print('emoji_test')
print('\U0001F600')
print('---')

# <u+0001f1e8> <u+999>
# u\u<U+<U+000

# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].to_string()
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].astype(str, errors='ignore')


# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.decode('ASCII')

# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].apply(lambda x: x.decode('utf-8'))

# missing_emojis_unicode_converted = tweets_smi_1['missing_emojis_unicode']

def emoji_convert(emojis):
	for emoji in emojis:
		emoji.decode('utf-8').encode('ascii', 'ignore')
		# emoji.encode('utf-8').decode('unicode-escape')
		# emoji.encode('ASCII').decode('unicode-escape')
	yield emoji

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].apply(lambda x: x.encode('utf-8'))

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].apply(lambda x: emoji_convert(x))

# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].str.encode('utf-8')
# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].apply(lambda x: x.encode('utf-8', 'ignore').decode('utf-8','ignore'))

# tweets_smi_1['missing_emojis_unicode'] = tweets_smi_1['missing_emojis_unicode'].decode('utf-8')

print('------------------------------------------------------------------------------')
print('Head TOTAL emojis_unicode NEW CONVERSION:')
print('------------------------------------------------------------------------------')
print(tweets_smi_1['emojis_unicode'].head)
print('---')

total_emojis_unicode_new_conv = pd.DataFrame()

total_emojis_unicode_new_conv[['created', 'screenName', 'emojis_unicode']] = tweets_smi_1[['created', 'screenName', 'emojis_unicode']].copy()
# total_emojis_unicode_new_conv = tweets_smi_1['created'].copy()
# total_emojis_unicode_new_conv['screenName'] = tweets_smi_1['screenName']
# total_emojis_unicode_new_conv['emojis_converted'] = tweets_smi_1['emojis_unicode']

# SAVE DATAFRAME TO CSV 

total_emojis_unicode_new_conv.to_csv('1_6_1_SMI1_total_emojis_unicode_new_conv_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# total_emojis_unicode_new_conv.to_csv('1_6_1_SMI1_total_emojis_unicode_new_conv_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

# SAVE DATAFRAME TO CSV 

# tweets_smi_1.to_csv('1_6_1_300_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_300_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)


#########################################################################################


# TOTAL FIELDS TO LIST TO_LIST

tweets_smi_1['mentions'] = list(tweets_smi_1['mentions'])
tweets_smi_1['hashtags'] = list(tweets_smi_1['hashtags'])
tweets_smi_1['emojis_unicode'] = list(tweets_smi_1['emojis_unicode'])
tweets_smi_1['hashtags_total'] = list(tweets_smi_1['hashtags_total'])
tweets_smi_1['mentions_total'] = list(tweets_smi_1['mentions_total'])
# tweets_smi_1['emojis_unicode_total'] = list(tweets_smi_1['emojis_unicode_total'])



######################################################################################################
######################################################################################################
#
# 			SNA NETWORK INFLUENCER SMI ONLY
#
######################################################################################################
######################################################################################################

# CREATE NETWORK MAIN_SMI SCREENNAME_MENTIONS

tweets_main_smi_1 = tweets_smi_1_n[(tweets_smi_1_n['screenName'] == main_smi_1)]

# tweets_main_smi_1 = tweets_smi_1_n

print('4444444444444444444---')
print('tweets_main_smi_1 HEAD')
print(tweets_main_smi_1.head(10))
print('44444444444444444---')
print('tweets_main_smi_1 DTYPES')
print(tweets_main_smi_1.dtypes)
print('44444444444444444---')


# G_screenname_mentions_main_smi = nx.MultiDiGraph()

G_screenname_mentions_main_smi = nx.Graph()

# G_screenname_mentions_main_smi = nx.ego_graph()

# Create Connections between nodes

# G_screenname_mentions_main_smi = nx.from_pandas_edgelist(tweets_main_smi_1, 'screenName', 'mentions_network')

# G_screenname_mentions_main_smi = nx.from_pandas_edgelist(tweets_main_smi_1, 'mentions', 'screenName', ['network_weight'])

G_screenname_mentions_main_smi = nx.from_pandas_edgelist(tweets_main_smi_1, 'mentions_tuple', 'screenName', ['network_weight'])
G_screenname_mentions_main_smi = nx.ego_graph(G_screenname_mentions_main_smi, main_smi_1, center=True)

# GET NETWORK STATISTICS

G_screenname_mentions_main_smi_nodes_number = len(G_screenname_mentions_main_smi.nodes())

print('---')
print('G_screenname_mentions_main_smi_nodes_number:')
print(G_screenname_mentions_main_smi_nodes_number)
print('---')

G_screenname_mentions_main_smi_edges_number = len(G_screenname_mentions_main_smi.edges())

print('---')
print('G_screenname_mentions_main_smi_edges_number:')
print(G_screenname_mentions_main_smi_edges_number)
print('---')

G_screenname_mentions_main_smi_average_clustering = nx.average_clustering(G_screenname_mentions_main_smi)

print('---')
print('G_screenname_mentions_main_smi_average_clustering:')
print(G_screenname_mentions_main_smi_average_clustering)
print('---')


# G_screenname_mentions_main_smi_eccentricity = nx.eccentricity(G_screenname_mentions_main_smi)

print('---')
print('G_screenname_mentions_main_smi_eccentricity:')
# print(G_screenname_mentions_main_smi_eccentricity)
print('---')

# initialize list of Lists 
screenname_mentions_main_smi_network_numbers = [['G_screenname_mentions_main_smi_nodes_number', G_screenname_mentions_main_smi_nodes_number], ['G_screenname_mentions_main_smi_edges_number', G_screenname_mentions_main_smi_edges_number], ['G_screenname_mentions_main_smi_average_clustering', G_screenname_mentions_main_smi_average_clustering], ['G_screenname_mentions_main_smi_eccentricity', 'G_screenname_mentions_main_smi_eccentricity']]
 
# Create the pandas DataFrame 
screenname_mentions_main_smi_network_numbers_df = pd.DataFrame(screenname_mentions_main_smi_network_numbers, columns = ['screenname_mentions_main_smi_network_numbers_item', 'screenname_mentions_main_smi_network_numbers_value']) 

screenname_mentions_main_smi_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Mentions_main_smi_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_mentions_main_smi_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Mentions_main_smi_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_mentions_main_smi_betweenness_centrality = nx.betweenness_centrality(G_screenname_mentions_main_smi)

print('---')
print('G_screenname_mentions_main_smi_betweenness_centrality:')
# print(G_screenname_mentions_main_smi_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_mentions_main_smi_closeness_centrality = nx.closeness_centrality(G_screenname_mentions_main_smi)

print('---')
print('G_screenname_mentions_main_smi_closeness_centrality:')
# print(G_screenname_mentions_main_smi_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_mentions_main_smi_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_mentions_main_smi)

print('---')
print('G_screenname_mentions_main_smi_eigenvector_centrality:')
# print(G_screenname_mentions_main_smi_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_mentions_main_smi_network_measures = [['G_screenname_mentions_main_smi_betweenness_centrality', 'G_screenname_mentions_main_smi_betweenness_centrality'], ['G_screenname_mentions_main_smi_closeness_centrality', 'G_screenname_mentions_main_smi_closeness_centrality'], ['G_screenname_mentions_main_smi_eigenvector_centrality', 'G_screenname_mentions_main_smi_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_mentions_main_smi_network_measures_df = pd.DataFrame(screenname_mentions_main_smi_network_measures, columns = ['screenname_mentions_main_smi_network_measures_item', 'screenname_mentions_main_smi_network_measures_value']) 

# screenname_mentions_main_smi_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Mentions_main_smi_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_mentions_main_smi_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Mentions_main_smi_network_measures_DF.xlsx', header=True)

# NETWORK MAIN_SMI

G_screenname_mentions_main_smi_network_info = nx.info(G_screenname_mentions_main_smi)

# Create the pandas DataFrame 
# screenname_mentions_main_smi_network_info_df = pd.DataFrame(G_screenname_mentions_main_smi_network_info, columns = ['G_screenname_mentions_main_smi_network_info']) 

# screenname_mentions_main_smi_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Mentions_main_smi_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_mentions_main_smi_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Mentions_main_smi_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_mentions_main_smi_network INFO')
print(G_screenname_mentions_main_smi_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Main SMI ScreenName Mentions - Network Graph')
nx.draw(G_screenname_mentions_main_smi, with_labels=False, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.7, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_180_SMI1_ScreenName_Mentions_Main_SMI_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############

# PLOT NETWORK Bread First Search

# G_screenname_mentions_main_smi_bfs = nx.bfs_tree(G_screenname_mentions_main_smi, 'main_smi')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Main SMI ScreenName Mentions - Bread-First Search')
# nx.draw(G_screenname_mentions_main_smi_bfs, with_labels=False, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.7, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_180_SMI1_ScreenName_Mentions_Main_SMI_Bread_First_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#############

print('---')
print('Done Graph Network A..')
print('---')

G_screenname_mentions_main_smi_network_info_bridges = list(nx.bridges(G_screenname_mentions_main_smi))


# Create the pandas DataFrame 
G_screenname_mentions_main_smi_network_info_bridges_df = pd.DataFrame(G_screenname_mentions_main_smi_network_info_bridges) 

G_screenname_mentions_main_smi_network_info_bridges_df.to_csv('4_5A_181_SMI1_G_screenname_mentions_main_smi_network_info_bridges_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_mentions_main_smi_network_info_df.to_excel('4_5A_181_SMI1_G_screenname_mentions_main_smi_network_info_bridges_DF.xlsx', header=True)


# PLOT BRIDGES NETWORK GRAPH

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.figure(figsize=(40,30))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Main SMI ScreenName Mentions BRIDGES - Network Graph')
nx.draw(G_screenname_mentions_main_smi, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.7, font_size=12)
nx.bridges(G_screenname_mentions_main_smi, main_smi)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_181_SMI1_ScreenName_Mentions_Main_SMI_BRIDGES_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Bridges Graph Network ..')
print('---')


######################################################################################################

# NETWORK INFLUENCER SMI ONLY

# CREATE NETWORK MAIN_SMI SCREENNAME_hashtags

# smi1_matrix_hashtags_main_smi_1 = tweets_smi_1_n[(smi1_matrix_hashtags['screenName'] == main_smi_1)]

# G_screenname_hashtags_main_smi = nx.MultiDiGraph()

G_screenname_hashtags_main_smi = nx.Graph()

# Create Connections between nodes

# G_screenname_hashtags_main_smi = nx.from_pandas_edgelist(tweets_main_smi_1, 'screenName', 'value', ['network_weight'])

G_screenname_hashtags_main_smi = nx.from_pandas_edgelist(tweets_main_smi_1, 'hashtags_tuple', 'screenName', ['network_weight'])
G_screenname_hashtags_main_smi = nx.ego_graph(G_screenname_hashtags_main_smi, main_smi_1, center=True)

# GET NETWORK STATISTICS

G_screenname_hashtags_main_smi_nodes_number = len(G_screenname_hashtags_main_smi.nodes())

print('---')
print('G_screenname_hashtags_main_smi_nodes_number:')
print(G_screenname_hashtags_main_smi_nodes_number)
print('---')

G_screenname_hashtags_main_smi_edges_number = len(G_screenname_hashtags_main_smi.edges())

print('---')
print('G_screenname_hashtags_main_smi_edges_number:')
print(G_screenname_hashtags_main_smi_edges_number)
print('---')

G_screenname_hashtags_main_smi_average_clustering = nx.average_clustering(G_screenname_hashtags_main_smi)

print('---')
print('G_screenname_hashtags_main_smi_average_clustering:')
print(G_screenname_hashtags_main_smi_average_clustering)
print('---')


# G_screenname_hashtags_main_smi_eccentricity = nx.eccentricity(G_screenname_hashtags_main_smi)

print('---')
print('G_screenname_hashtags_main_smi_eccentricity:')
# print(G_screenname_hashtags_main_smi_eccentricity)
print('---')

# initialize list of Lists 
screenname_hashtags_main_smi_network_numbers = [['G_screenname_hashtags_main_smi_nodes_number', G_screenname_hashtags_main_smi_nodes_number], ['G_screenname_hashtags_main_smi_edges_number', G_screenname_hashtags_main_smi_edges_number], ['G_screenname_hashtags_main_smi_average_clustering', G_screenname_hashtags_main_smi_average_clustering], ['G_screenname_hashtags_main_smi_eccentricity', 'G_screenname_hashtags_main_smi_eccentricity']]
 
# Create the pandas DataFrame 
screenname_hashtags_main_smi_network_numbers_df = pd.DataFrame(screenname_hashtags_main_smi_network_numbers, columns = ['screenname_hashtags_main_smi_network_numbers_item', 'screenname_hashtags_main_smi_network_numbers_value']) 

screenname_hashtags_main_smi_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Hashtags_main_smi_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_hashtags_main_smi_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Hashtags_main_smi_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_hashtags_main_smi_betweenness_centrality = nx.betweenness_centrality(G_screenname_hashtags_main_smi)

print('---')
print('G_screenname_hashtags_main_smi_betweenness_centrality:')
# print(G_screenname_hashtags_main_smi_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_hashtags_main_smi_closeness_centrality = nx.closeness_centrality(G_screenname_hashtags_main_smi)

print('---')
print('G_screenname_hashtags_main_smi_closeness_centrality:')
# print(G_screenname_hashtags_main_smi_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_hashtags_main_smi_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_hashtags_main_smi)

print('---')
print('G_screenname_hashtags_main_smi_eigenvector_centrality:')
# print(G_screenname_hashtags_main_smi_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_hashtags_main_smi_network_measures = [['G_screenname_hashtags_main_smi_betweenness_centrality', 'G_screenname_hashtags_main_smi_betweenness_centrality'], ['G_screenname_hashtags_main_smi_closeness_centrality', 'G_screenname_hashtags_main_smi_closeness_centrality'], ['G_screenname_hashtags_main_smi_eigenvector_centrality', 'G_screenname_hashtags_main_smi_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_hashtags_main_smi_network_measures_df = pd.DataFrame(screenname_hashtags_main_smi_network_measures, columns = ['screenname_hashtags_main_smi_network_measures_item', 'screenname_hashtags_main_smi_network_measures_value']) 

# screenname_hashtags_main_smi_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Hashtags_main_smi_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_hashtags_main_smi_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Hashtags_main_smi_network_measures_DF.xlsx', header=True)

# NETWORK MAIN_SMI

G_screenname_hashtags_main_smi_network_info = nx.info(G_screenname_hashtags_main_smi)

# Create the pandas DataFrame 
# screenname_hashtags_main_smi_network_info_df = pd.DataFrame(G_screenname_hashtags_main_smi_network_info, columns = ['G_screenname_hashtags_main_smi_network_info']) 

# screenname_hashtags_main_smi_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Hashtags_main_smi_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_hashtags_main_smi_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Hashtags_main_smi_network_info_DF.xlsx', header=True)


print('--- nEED TO SAVE')
print(main_smi)
print('screenname_hashtags_main_smi_network INFO')
print(G_screenname_hashtags_main_smi_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(40,30))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Main SMI ScreenName Hashtags - Network Graph')
nx.draw(G_screenname_hashtags_main_smi, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.7, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_180_SMI1_ScreenName_hashtags_main_smi_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network ..')
print('---')


#######################################################################################################
######################################################################################################

# NETWORK INFLUENCER SMI ONLY

# CREATE NETWORK MAIN_SMI SCREENNAME_emojis_unicode

# smi1_matrix_emojis_unicode_main_smi_1 = tweets_smi_1_n[(smi1_matrix_emojis_unicode['screenName'] == main_smi_1)]

G_screenname_emojis_unicode_main_smi = nx.MultiDiGraph()

# Create Connections between nodes

# G_screenname_emojis_unicode_main_smi = nx.from_pandas_edgelist(smi1_matrix_emojis_unicode_main_smi_1, 'screenName', 'value', ['network_weight'])

G_screenname_emojis_unicode_main_smi = nx.from_pandas_edgelist(tweets_main_smi_1, 'screenName', 'emoji_unicodes_tuple', ['network_weight'], create_using=nx.DiGraph())
G_screenname_emojis_unicode_main_smi = nx.ego_graph(G_screenname_emojis_unicode_main_smi, main_smi_1, center=True)

# GET NETWORK STATISTICS

G_screenname_emojis_unicode_main_smi_nodes_number = len(G_screenname_emojis_unicode_main_smi.nodes())

print('---')
print('G_screenname_emojis_unicode_main_smi_nodes_number:')
print(G_screenname_emojis_unicode_main_smi_nodes_number)
print('---')

G_screenname_emojis_unicode_main_smi_edges_number = len(G_screenname_emojis_unicode_main_smi.edges())

print('---')
print('G_screenname_emojis_unicode_main_smi_edges_number:')
print(G_screenname_emojis_unicode_main_smi_edges_number)
print('---')

G_screenname_emojis_unicode_main_smi_average_clustering = nx.average_clustering(G_screenname_emojis_unicode_main_smi)

print('---')
print('G_screenname_emojis_unicode_main_smi_average_clustering:')
print(G_screenname_emojis_unicode_main_smi_average_clustering)
print('---')


# G_screenname_emojis_unicode_main_smi_eccentricity = nx.eccentricity(G_screenname_emojis_unicode_main_smi)

print('---')
print('G_screenname_emojis_unicode_main_smi_eccentricity:')
# print(G_screenname_emojis_unicode_main_smi_eccentricity)
print('---')

# initialize list of Lists 
screenname_emojis_unicode_main_smi_network_numbers = [['G_screenname_emojis_unicode_main_smi_nodes_number', G_screenname_emojis_unicode_main_smi_nodes_number], ['G_screenname_emojis_unicode_main_smi_edges_number', G_screenname_emojis_unicode_main_smi_edges_number], ['G_screenname_emojis_unicode_main_smi_average_clustering', G_screenname_emojis_unicode_main_smi_average_clustering], ['G_screenname_emojis_unicode_main_smi_eccentricity', 'G_screenname_emojis_unicode_main_smi_eccentricity']]
 
# Create the pandas DataFrame 
screenname_emojis_unicode_main_smi_network_numbers_df = pd.DataFrame(screenname_emojis_unicode_main_smi_network_numbers, columns = ['screenname_emojis_unicode_main_smi_network_numbers_item', 'screenname_emojis_unicode_main_smi_network_numbers_value']) 

screenname_emojis_unicode_main_smi_network_numbers_df.to_csv('4_5A_180_SMI1_screenname_emojis_unicode_main_smi_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_unicode_main_smi_network_numbers_df.to_excel('4_5A_180_SMI1_screenname_emojis_unicode_main_smi_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_emojis_unicode_main_smi_betweenness_centrality = nx.betweenness_centrality(G_screenname_emojis_unicode_main_smi)

print('---')
print('G_screenname_emojis_unicode_main_smi_betweenness_centrality:')
# print(G_screenname_emojis_unicode_main_smi_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_emojis_unicode_main_smi_closeness_centrality = nx.closeness_centrality(G_screenname_emojis_unicode_main_smi)

print('---')
print('G_screenname_emojis_unicode_main_smi_closeness_centrality:')
# print(G_screenname_emojis_unicode_main_smi_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_emojis_unicode_main_smi_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_emojis_unicode_main_smi)

print('---')
print('G_screenname_emojis_unicode_main_smi_eigenvector_centrality:')
# print(G_screenname_emojis_unicode_main_smi_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_emojis_unicode_main_smi_network_measures = [['G_screenname_emojis_unicode_main_smi_betweenness_centrality', 'G_screenname_emojis_unicode_main_smi_betweenness_centrality'], ['G_screenname_emojis_unicode_main_smi_closeness_centrality', 'G_screenname_emojis_unicode_main_smi_closeness_centrality'], ['G_screenname_emojis_unicode_main_smi_eigenvector_centrality', 'G_screenname_emojis_unicode_main_smi_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_emojis_unicode_main_smi_network_measures_df = pd.DataFrame(screenname_emojis_unicode_main_smi_network_measures, columns = ['screenname_emojis_unicode_main_smi_network_measures_item', 'screenname_emojis_unicode_main_smi_network_measures_value']) 

# screenname_emojis_unicode_main_smi_network_measures_df.to_csv('4_5A_180_SMI1_screenname_emojis_unicode_main_smi_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_unicode_main_smi_network_measures_df.to_excel('4_5A_180_SMI1_screenname_emojis_unicode_main_smi_network_measures_DF.xlsx', header=True)

# NETWORK MAIN_SMI

G_screenname_emojis_unicode_main_smi_network_info = nx.info(G_screenname_emojis_unicode_main_smi)

# Create the pandas DataFrame 
# screenname_emojis_unicode_main_smi_network_info_df = pd.DataFrame(G_screenname_emojis_unicode_main_smi_network_info, columns = ['G_screenname_emojis_unicode_main_smi_network_info']) 

# screenname_emojis_unicode_main_smi_network_info_df.to_csv('4_5A_180_SMI1_screenname_emojis_unicode_main_smi_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_unicode_main_smi_network_info_df.to_excel('4_5A_180_SMI1_screenname_emojis_unicode_main_smi_network_info_DF.xlsx', header=True)

print('--- nEED TO SAVE')
print(main_smi)
print('screenname_emojis_unicode_main_smi_network INFO')
print(G_screenname_emojis_unicode_main_smi_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(40,30))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Main SMI ScreenName Emojis - Network Graph')
nx.draw(G_screenname_emojis_unicode_main_smi, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.7, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_180_SMI1_ScreenName_emojis_unicode_main_smi_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network ..')
print('---')

######################################################################################################

# NETWORK INFLUENCER SMI ONLY

# CREATE NETWORK MAIN_SMI SCREENNAME_emojis_converted

# smi1_matrix_emojis_converted_main_smi_1 = tweets_smi_1_n[(smi1_matrix_emojis_converted['screenName'] == main_smi_1)]

G_screenname_emojis_converted_main_smi = nx.MultiDiGraph()

# Create Connections between nodes

# G_screenname_emojis_converted_main_smi = nx.from_pandas_edgelist(smi1_matrix_emojis_converted_main_smi_1, 'screenName', 'value', ['network_weight'])

G_screenname_emojis_converted_main_smi = nx.from_pandas_edgelist(tweets_main_smi_1, 'screenName', 'emojis_converted_tuple', ['network_weight'], create_using=nx.DiGraph())
G_screenname_emojis_converted_main_smi = nx.ego_graph(G_screenname_emojis_converted_main_smi, main_smi_1, center=True)

# GET NETWORK STATISTICS

G_screenname_emojis_converted_main_smi_nodes_number = len(G_screenname_emojis_converted_main_smi.nodes())

print('---')
print('G_screenname_emojis_converted_main_smi_nodes_number:')
print(G_screenname_emojis_converted_main_smi_nodes_number)
print('---')

G_screenname_emojis_converted_main_smi_edges_number = len(G_screenname_emojis_converted_main_smi.edges())

print('---')
print('G_screenname_emojis_converted_main_smi_edges_number:')
print(G_screenname_emojis_converted_main_smi_edges_number)
print('---')

G_screenname_emojis_converted_main_smi_average_clustering = nx.average_clustering(G_screenname_emojis_converted_main_smi)

print('---')
print('G_screenname_emojis_converted_main_smi_average_clustering:')
print(G_screenname_emojis_converted_main_smi_average_clustering)
print('---')


# G_screenname_emojis_converted_main_smi_eccentricity = nx.eccentricity(G_screenname_emojis_converted_main_smi)

print('---')
print('G_screenname_emojis_converted_main_smi_eccentricity:')
# print(G_screenname_emojis_converted_main_smi_eccentricity)
print('---')

# initialize list of Lists 
screenname_emojis_converted_main_smi_network_numbers = [['G_screenname_emojis_converted_main_smi_nodes_number', G_screenname_emojis_converted_main_smi_nodes_number], ['G_screenname_emojis_converted_main_smi_edges_number', G_screenname_emojis_converted_main_smi_edges_number], ['G_screenname_emojis_converted_main_smi_average_clustering', G_screenname_emojis_converted_main_smi_average_clustering], ['G_screenname_emojis_converted_main_smi_eccentricity', 'G_screenname_emojis_converted_main_smi_eccentricity']]
 
# Create the pandas DataFrame 
screenname_emojis_converted_main_smi_network_numbers_df = pd.DataFrame(screenname_emojis_converted_main_smi_network_numbers, columns = ['screenname_emojis_converted_main_smi_network_numbers_item', 'screenname_emojis_converted_main_smi_network_numbers_value']) 

screenname_emojis_converted_main_smi_network_numbers_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Converted_Main_smi_network_numbers_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_converted_main_smi_network_numbers_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Converted_Main_smi_network_numbers_DF.xlsx', header=True)


# Betweenness Centrality

# G_screenname_emojis_converted_main_smi_betweenness_centrality = nx.betweenness_centrality(G_screenname_emojis_converted_main_smi)

print('---')
print('G_screenname_emojis_converted_main_smi_betweenness_centrality:')
# print(G_screenname_emojis_converted_main_smi_betweenness_centrality)
print('---')

# Closeness Centrality

# G_screenname_emojis_converted_main_smi_closeness_centrality = nx.closeness_centrality(G_screenname_emojis_converted_main_smi)

print('---')
print('G_screenname_emojis_converted_main_smi_closeness_centrality:')
# print(G_screenname_emojis_converted_main_smi_closeness_centrality)
print('---')

# Eigenvector Centrality

# G_screenname_emojis_converted_main_smi_eigenvector_centrality = nx.eigenvector_centrality(G_screenname_emojis_converted_main_smi)

print('---')
print('G_screenname_emojis_converted_main_smi_eigenvector_centrality:')
# print(G_screenname_emojis_converted_main_smi_eigenvector_centrality)
print('---')

# initialize list of Lists 
screenname_emojis_converted_main_smi_network_measures = [['G_screenname_emojis_converted_main_smi_betweenness_centrality', 'G_screenname_emojis_converted_main_smi_betweenness_centrality'], ['G_screenname_emojis_converted_main_smi_closeness_centrality', 'G_screenname_emojis_converted_main_smi_closeness_centrality'], ['G_screenname_emojis_converted_main_smi_eigenvector_centrality', 'G_screenname_emojis_converted_main_smi_eigenvector_centrality']] 
 
# Create the pandas DataFrame 
# screenname_emojis_converted_main_smi_network_measures_df = pd.DataFrame(screenname_emojis_converted_main_smi_network_measures, columns = ['screenname_emojis_converted_main_smi_network_measures_item', 'screenname_emojis_converted_main_smi_network_measures_value']) 

# screenname_emojis_converted_main_smi_network_measures_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Converted_main_smi_network_measures_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_converted_main_smi_network_measures_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Converted_main_smi_network_measures_DF.xlsx', header=True)

# NETWORK MAIN_SMI

G_screenname_emojis_converted_main_smi_network_info = nx.info(G_screenname_emojis_converted_main_smi)

# Create the pandas DataFrame 
# screenname_emojis_converted_main_smi_network_info_df = pd.DataFrame(G_screenname_emojis_converted_main_smi_network_info, columns = ['G_screenname_emojis_converted_main_smi_network_info']) 

# screenname_emojis_converted_main_smi_network_info_df.to_csv('4_5A_180_SMI1_Screenname_Emojis_Converted_main_smi_network_info_DF_CSV.csv', sep=';', encoding='utf-8', index=False, header=True)
# screenname_emojis_converted_main_smi_network_info_df.to_excel('4_5A_180_SMI1_Screenname_Emojis_Converted_main_smi_network_info_DF.xlsx', header=True)

print('--- nEED TO SAVE')
print(main_smi)
print('screenname_emojis_converted_main_smi_network INFO')
print(G_screenname_emojis_converted_main_smi_network_info)
print('---')

# colors_blue = ['#9DC6D8', '#00B3CA', '#7DD0B6', '#65ABC4', '#AACEE2', '#00ADCE', '#413BF7']

# PLOT NETWORK GRAPH

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(30,20))
plt.autoscale() 
plt.figure(figsize=(30,30))
plt.suptitle(main_smi, y=1.0)
plt.title('Main SMI ScreenName Emojis - Network Graph')
nx.draw(G_screenname_emojis_converted_main_smi, with_labels=True, radious='network_radious', node_color='#9DC6D8', edge_color='#413BF7', edge_cmap=plt.cm.Blues, alpha=0.7, font_size=12)
plt.xlabel('')
plt.ylabel('')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_180_SMI1_Screenname_Emojis_Converted_Main_SMI_Network_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Done Graph Network ..')
print('---')



print('---')
print('Done Graph Network ..')
print('---')

###############################################################################

# List Total number_emojis_unicode ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!


number_total_number_emojis_unicode = (count(tweets_smi_1['number_total_emojis_unicode'])).sum()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


print('---')
print('List Total number_emojis_unicode')
# print(number_total_number_emojis_unicode.head)
print('---')

number_total_number_emojis_unicode_df = pd.DataFrame([number_total_number_emojis_unicode], columns=['number_total_number_emojis_unicode'])

number_total_number_emojis_unicode_df.to_csv('4_4_43_SMI1_Number_Total_Number_Emojis_Unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# number_total_number_emojis_unicode_df.to_excel()

number_total_number_emojis_unicode_year = tweets_smi_1.groupby(['year'])['number_total_emojis_unicode'].sum()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


print('---')
print('List Total number_emojis_unicode Year')
# print(number_total_number_emojis_unicode_year.head)
print('---')

number_total_number_emojis_unicode_year_df = pd.DataFrame([number_total_number_emojis_unicode_year], columns=['number_total_number_emojis_unicode_year'])

number_total_number_emojis_unicode_year_df.to_csv('4_4_43_SMI1_Number_Total_Number_Emojis_Unicode_Year_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# number_total_number_emojis_unicode_df.to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Number Emojis - Year')
plt.plot(number_total_number_emojis_unicode_year_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Number_emojis_unicode_Year_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Number Emojis - Pie')
# plt.pie(tweet_info_retweets_df['number_total_number_emojis_unicode_df'], labels=number_total_number_emojis_unicode_df)
# plt.pie(number_total_number_emojis_unicode['number_total_number_emojis_unicode_df'], labels=number_total_number_emojis_unicode, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=number_total_number_emojis_unicode, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_number_emojis_unicode_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Number Emojis - Bars')
number_total_number_emojis_unicode_year_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Number_Emojis_Unicode_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###############################################################################################################

# METHOD 1 MISSING emojis_unicode

fp_missing_emojis_unicode = tweets_smi_1['missing_emojis_unicode'].to_string()

# fp_missing_emojis_unicode = fp_missing_emojis_unicode_temp.to_string()

tweets_text_missing_emojis_unicode = nltk.word_tokenize(fp_missing_emojis_unicode)

value_counts_missing_emojis_unicode = pd.value_counts(tweets_text_missing_emojis_unicode, ascending=False, normalize=True) 

smi1_value_counts_missing_emojis_unicode = value_counts_missing_emojis_unicode.sort_values(ascending=False)

# smi1_value_counts_missing_emojis_unicode_freq_dist = tweets_text_missing_emojis_unicode.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts missing_emojis_unicode - Frequency')
# print(smi1_value_counts_missing_emojis_unicode.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts missing_emojis_unicode')
print(smi1_value_counts_missing_emojis_unicode.describe().head)
print('---')

smi1_value_counts_missing_emojis_unicode_df = pd.DataFrame(smi1_value_counts_missing_emojis_unicode, columns=['missing_emojis_unicode_frequency'])

smi1_value_counts_missing_emojis_unicode_df.to_csv('4_4_43_100_SMI1_Value_Counts_Missing_Emojis_Unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_missing_emojis_unicode_df.to_excel('4_4_43_100_SMI1_Value_Counts_Missing_Emojis_Unicode_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts')
plt.plot(smi1_value_counts_missing_emojis_unicode[:10], alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Missing_Emojis_Unicode_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Pie')
smi1_value_counts_missing_emojis_unicode[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(smi1_value_counts_missing_emojis_unicode, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Missing_Emojis_Unicode_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Emojis Value Counts - Bars')
smi1_value_counts_missing_emojis_unicode[:10].plot.bar(alpha=0.9)
plt.xlabel('Emoji')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Missing_Emojis_Unicode_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# List Unique MISSING Emojis Unicode ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!


missing_emojis_unicode_1 = tweets_smi_1['missing_emojis_unicode']
missing_unique_emojis_unicode = missing_emojis_unicode_1.unique()

missing_number_unique_emojis_unicode = len(missing_unique_emojis_unicode)
missing_number_unique_emojis_unicode

print('---')
print('Missing Number Emojis Unicode')
# print(missing_number_unique_emojis_unicode)
print('---')

missing_number_unique_emojis_unicode_df = pd.DataFrame([missing_number_unique_emojis_unicode])

missing_number_unique_emojis_unicode_df.to_csv('4_4_43_192_SMI1_Missing_Number_Unique_Emojis_Unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to.excel()

## NEED TO PLOT - FIX!!! ADD TO ALL EMOJIS

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Emojis')
plt.plot(missing_number_unique_emojis_unicode_df, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_192_SMI1_Missing_Number_Unique_Emojis_Unicode_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Missing Number Unique Emojis - Bars')
missing_number_unique_emojis_unicode_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_192_SMI1_Missing_Number_Unique_Emojis_Unicode_DF_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###########################################################################################################

# https://www.datacamp.com/community/tutorials/wordcloud-python

# WORDCLOUD 

# SMI_WordCloud_1 = WordCloud(background_color="white",stoptweets_words=stoptweets_words,width=800, height=400).generate(' '.join(data))
SMI_WordCloud_1 = WordCloud(background_color='white').generate(' '.join(tweets_text_words))

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(8,6))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet WordCloud Visualization')
plt.imshow(SMI_WordCloud_1, interpolation='bilinear')
plt.axis('off')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3) 
# plt.show()
plt.savefig('4_5_199_SMI1_WordCloud_SB_1.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('----------')
print('TEXT HEAD F')
# print(tweets_smi_1['text'].head)
print('-----------------------------------')

###########################################################################################################################

# SENTIMENT POLARITY OVER TIME

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity Over Time')
# tweets_smi_1.set_index('created')['textblob_sentiment_polarity'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_185_SMI1_Sentiment_Polarity_Tweets.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Polarity Over Time - Bars')
# tweets_smi_1.set_index('created')['textblob_sentiment_polarity'].plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_185_SMI1_Sentiment_Polarity_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Subjectivity Over Time')
# tweets_smi_1.set_index('created')['textblob_sentiment_subjectivity'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_185_SMI1_Sentiment_Subjectivity_Tweets.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BARS

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Sentiment Subjectivity Over Time - Bars')
# tweets_smi_1.set_index('created')['textblob_sentiment_subjectivity'].plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_185_SMI1_Sentiment_Subjectivity_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Polarity / Subjectivity Over Time')
# tweets_smi_1.set_index('created')['textblob_sentiment_polarity'].plot(alpha=0.9)
# tweets_smi_1.set_index('created')['textblob_sentiment_subjectivity'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_186_SMI1_Polarity_Subjectivitys_Time_All.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# PLOT BARS - MULTIPLE - Tweets Followers AND Following NOT UNIQUE 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

# '#73C2FB', '#6593F5',

r1 = np.arange(len(tweet_info_followers_not_unique_df))
r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Polarity / Subjectivity Over Time - Bars')
# plt.bar(r1, tweets_smi_1.set_index('created')['textblob_sentiment_polarity'], color='#73C2FB', edgecolor='white', label='polarity', alpha=0.9)
# plt.bar(r2, tweets_smi_1.set_index('created')['textblob_sentiment_subjectivity'], color='blue', edgecolor='white', label='subjectivity', alpha=0.9)
plt.xticks(rotation=50)
plt.xlabel('Users with Followers, Users without Followers, Users with Following, Users without Following')
plt.ylabel('Count')
plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True)
# plt.show()
plt.savefig('4_4_40_SMI1_Tweet_Sentiment_Polarity_Subjectivity_df_Bar_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################################################################
################################################################################################
################################################################################################

# MOST POSITIVE TWEETS

positive_tweets_textblob = tweets_smi_1[(tweets_smi_1['textblob_sentiment_polarity'] == '1')]
most_positive_tweets_textblob = positive_tweets_textblob.value_counts(ascending=False)

print('-------------------------')
print('Most Positive Tweets Head')
print(most_positive_tweets_textblob[:10])
print('-------------------------')

print('-------------------------')
print('Most Positive Tweets DTYPES')
print(most_positive_tweets_textblob.dtypes)
print('-------------------------')

number_most_positive_tweets_textblob = len(most_positive_tweets_textblob)

# number_most_positive_tweets_textblob = most_positive_tweets_textblob['textblob_sentiment_polarity'].cumsum()

print('-------------------------')
print('Most Positive Tweets Len')
print(number_most_positive_tweets_textblob)
print('-------------------------')

most_positive_tweets_textblob.to_csv('4_5_201_10_SMI1_most_positive_tweets_textblob_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# most_positive_tweets_textblob.to_excel('4_5_201_10_SMI1_most_positive_tweets_textblob.xlsx', header=True)


# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Positive Tweets - Value Counts')
most_positive_tweets_textblob.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Positive_Tweets_Textblob_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Positive Tweets - Value Counts - Bars')
most_positive_tweets_textblob.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Positive_Tweets_Textblob_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# MOST NEGATIVE TWEETS

negative_tweets_textblob = tweets_smi_1[(tweets_smi_1['textblob_sentiment_polarity'] == '-1')]
most_negative_tweets_textblob = negative_tweets_textblob.value_counts(ascending=False)

print('-------------------------')
print('Most Negative Tweets Head')
print(most_negative_tweets_textblob[:10])
print('-------------------------')

print('-------------------------')
print('Most Negative Tweets DTYPES')
print(most_negative_tweets_textblob.dtypes)
print('-------------------------')

number_most_negative_tweets_textblob = len(most_negative_tweets_textblob)

# number_most_negative_tweets_textblob = most_negative_tweets_textblob['textblob_sentiment_polarity'].cumsum()

print('-------------------------')
print('Most Negative Tweets Len')
print(number_most_negative_tweets_textblob)
print('-------------------------')


most_negative_tweets_textblob.to_csv('4_5_201_10_SMI1_most_negative_tweets_textblob_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# most_negative_tweets_textblob.to_excel('4_5_201_10_SMI1_most_negative_tweets_textblob.xlsx', header=True)

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Negative Tweets - Value Counts')
most_negative_tweets_textblob.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Negative_Tweets_Textblob_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Negative Tweets - Value Counts - Bars')
most_negative_tweets_textblob.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Negative_Tweets_Textblob_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('----------')
print('TEXT HEAD H')
# print(tweets_smi_1['text'].head)
print('-----------------------------------')


################################################################################################

# MOST subjective TWEETS

subjective_tweets_textblob = tweets_smi_1[(tweets_smi_1['textblob_sentiment_subjectivity'] == '1')]
most_subjective_tweets_textblob = subjective_tweets_textblob.value_counts(ascending=False)

print('-------------------------')
print('Most subjective Tweets Head')
print(most_subjective_tweets_textblob[:10])
print('-------------------------')

print('-------------------------')
print('Most subjective Tweets DTYPES')
print(most_subjective_tweets_textblob.dtypes)
print('-------------------------')

number_most_subjective_tweets_textblob = len(most_subjective_tweets_textblob)

# number_most_subjective_tweets_textblob = most_subjective_tweets_textblob['textblob_sentiment_subjectivity'].cumsum()

print('-------------------------')
print('Most subjective Tweets Len')
print(number_most_subjective_tweets_textblob)
print('-------------------------')

most_subjective_tweets_textblob.to_csv('4_5_201_10_SMI1_most_subjective_tweets_textblob_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# most_subjective_tweets_textblob.to_excel('4_5_201_10_SMI1_most_subjective_tweets_textblob.xlsx', header=True)


# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Subjective Tweets - Value Counts')
most_subjective_tweets_textblob.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Subjective_Tweets_Textblob_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Subjective Tweets - Value Counts - Bars')
most_subjective_tweets_textblob.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Subjective_Tweets_Textblob_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# MOST subjective TWEETS

subjective_tweets_textblob = tweets_smi_1[(tweets_smi_1['textblob_sentiment_subjectivity'] == '-1')]
most_subjective_tweets_textblob = subjective_tweets_textblob.value_counts(ascending=False)

print('-------------------------')
print('Most subjective Tweets Head')
print(most_subjective_tweets_textblob[:10])
print('-------------------------')

print('-------------------------')
print('Most subjective Tweets DTYPES')
print(most_subjective_tweets_textblob.dtypes)
print('-------------------------')

number_most_subjective_tweets_textblob = len(most_subjective_tweets_textblob)

# number_most_subjective_tweets_textblob = most_subjective_tweets_textblob['textblob_sentiment_subjectivity'].cumsum()

print('-------------------------')
print('Most subjective Tweets Len')
print(number_most_subjective_tweets_textblob)
print('-------------------------')


most_subjective_tweets_textblob.to_csv('4_5_201_10_SMI1_most_subjective_tweets_textblob_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# most_subjective_tweets_textblob.to_excel('4_5_201_10_SMI1_most_subjective_tweets_textblob.xlsx', header=True)

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Subjective Tweets - Value Counts')
most_subjective_tweets_textblob.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Subjective_Tweets_Textblob_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Subjective Tweets - Value Counts - Bars')
most_subjective_tweets_textblob.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_201_10_SMI1_Most_Subjective_Tweets_Textblob_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###################################################################################################################
#
# 	 			 TEXT CLASSIFICATION
#                                               
###################################################################################################################	
	
# WITH TEXTBLOB - BASIC CLASSIFICATION

textblob_train_data = [
	('fucking love it', 'positive'),	
	('fucking great', 'positive'),
	('fucking amazing', 'positive'),
	('fucking kidding', 'negative'),
	('fucking bad', 'negative'),
	('fucking waste', 'negative')
]

textblob_test_data = [
	('fucking love it', 'positive'),	
	('fucking great', 'positive'),
	('fucking amazing', 'positive'),
	('fucking kidding', 'negative'),
	('fucking bad', 'negative'),
	('fucking bad', 'negative')
]

###########################################################

# NAIVE BAYES CLASSIFIER


textblob_classifier = NaiveBayesClassifier(textblob_train_data)

textblob_test_phrase_1 = 'This lipstick is fucking amazing'
textblob_test_phrase_2 = 'This lipstick is fucking waste of money'

print('-------------------------')
print('TextBlob NaiveBayes Classifier  ------------ NEED TO DOOOOOO')
print(textblob_test_phrase_1)
print('is:')
print(textblob_classifier.classify(textblob_test_phrase_1))
print('-------------------------')

print('-------------------------')
print('TextBlob NaiveBayes Classifier')
print(textblob_test_phrase_2)
print('is:')
print(textblob_classifier.classify(textblob_test_phrase_2))
print('-------------------------')

# NOT WORKING 

######################################################################################################################

print('MAIN SMI: Done Initial TextBlob')
print(main_smi)
print('-------------------------')

###################################################################################################

# textblob_results = [TextBlob(i).sentiment.polarity for i in x_validation]

# textblob_pred = [0 if n < 0 else 1 doe n in textblob_results]

################################################################

# METHOD 2: 

word_1_query = tweets_smi_1.query('text == "love"')

print('---')
print('Word 1 Query: METHOD 2')
print(word_1_query.head)
print('---')

number_word_1 = (word_1_query).count()

print('---')
print('Word 1 Query: METHOD 2')
print(word_1_query.head)
print('---')

word_2_query = tweets_smi_1.query('text == "word_2"')
number_word_2 = len(word_2_query)

word_3_query = tweets_smi_1.query('text == "word_3"')
number_word_3 = len(word_3_query)
  
word_4_query = tweets_smi_1.query('text == "word_4"')
number_word_4 = len(word_4_query)
 
word_5_query = tweets_smi_1.query('text == "word_5"')
number_word_5 = len(word_5_query)
 
word_6_query = tweets_smi_1.query('text == "word_6"')
number_word_6 = len(word_6_query)
 
word_7_query = tweets_smi_1.query('text == "word_7"')
number_word_7 = len(word_7_query)
 
word_8_query = tweets_smi_1.query('text == "word_8"')
number_word_8 = len(word_8_query)
 
word_9_query = tweets_smi_1.query('text == "word_9"')
number_word_9 = len(word_9_query)
 
word_10_query = tweets_smi_1.query('text == "word_10"')
number_word_10 = len(word_10_query)

word_11_query = tweets_smi_1.query('text == "word_11"')
number_word_11 = len(word_11_query)

word_12_query = tweets_smi_1.query('text == "word_12"')
number_word_12 = len(word_12_query)

word_13_query = tweets_smi_1.query('text == "word_13"')
number_word_13 = len(word_13_query)

word_14_query = tweets_smi_1.query('text == "word_14"')
number_word_14 = len(word_14_query)

word_15_query = tweets_smi_1.query('text == "word_15"')
number_word_15 = len(word_15_query)

word_16_query = tweets_smi_1.query('text == "word_16"')
number_word_16 = len(word_16_query)

word_17_query = tweets_smi_1.query('text == "word_17"')
number_word_17 = len(word_17_query)

word_18_query = tweets_smi_1.query('text == "word_18"')
number_word_18 = len(word_18_query)

word_19_query = tweets_smi_1.query('text == "word_19"')
number_word_19 = len(word_19_query)

word_20_query = tweets_smi_1.query('text == "word_20"')
number_word_20 = len(word_20_query)

word_21_query = tweets_smi_1.query('text == "word_21"')
number_word_21 = len(word_21_query)

word_22_query = tweets_smi_1.query('text == "word_22"')
number_word_22 = len(word_22_query)

word_23_query = tweets_smi_1.query('text == "word_23"')
number_word_23 = len(word_23_query)

word_24_query = tweets_smi_1.query('text == "word_24"')
number_word_24 = len(word_24_query)

word_25_query = tweets_smi_1.query('text == "word_25"')
number_word_25 = len(word_25_query)

word_26_query = tweets_smi_1.query('text == "word_26"')
number_word_26 = len(word_26_query)

word_27_query = tweets_smi_1.query('text == "word_27"')
number_word_27 = len(word_27_query)

 
# initialize list of Lists 
selected_tweets_words_counts = [[word_1, number_word_1], [word_2, number_word_2], [word_3, number_word_3], [word_4, number_word_4], [word_5, number_word_5], [word_6, number_word_6], [word_7, number_word_7], [word_8, number_word_8], [word_9, number_word_9], [word_10, number_word_10], [word_11, number_word_11], [word_12, number_word_12], [word_13, number_word_13], [word_14, number_word_14], [word_15, number_word_15], [word_16, number_word_16], [word_17, number_word_17], [word_18, number_word_18], [word_19, number_word_19], [word_20, number_word_20], [word_21, number_word_21], [word_22, number_word_22], [word_23, number_word_23], [word_24, number_word_24], [word_25, number_word_25], [word_26, number_word_26], [word_27, number_word_27]] 
 
# Create the pandas DataFrame 
selected_tweets_words_counts_df = pd.DataFrame(selected_tweets_words_counts, columns = ['tweets_words', 'Counts']) 

selected_tweets_words_counts_df.to_csv('4_5_211_SMI1_Selected_Tweets_Words_Counts_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# selected_tweets_words_counts_df.to_excel('4_5_211_SMI1_Selected_Tweets_Words_Counts_DF.xlsx', header=True)

# NOT WORKING 

# Selected tweets_words Plot

# TABLE PLOT NEED TO DO 

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies')
# selected_tweets_words_counts_df.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_211_SMI1_Selected_Tweets_Words_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies - Pie')
# plt.pie(selected_tweets_words_counts_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.legend(selected_tweets_words_counts_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_211_SMI1_Selected_Tweets_Words_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies - Bars')
# selected_tweets_words_counts_df.plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_211_SMI1_Selected_Tweets_Words_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# NOT WORKING

## DELETE VARIABLE

del selected_tweets_words_counts
del selected_tweets_words_counts_df

##############################################################################################

# METHOD 0

print('METHOD 0 ---------')

word_1_count_textblob = textblob_obj_text_c.word_counts[word_1]
word_2_count_textblob = textblob_obj_text_c.word_counts[word_2]
word_3_count_textblob = textblob_obj_text_c.word_counts[word_3]
word_4_count_textblob = textblob_obj_text_c.word_counts[word_4]
word_5_count_textblob = textblob_obj_text_c.word_counts[word_5]
word_6_count_textblob = textblob_obj_text_c.word_counts[word_6]
word_7_count_textblob = textblob_obj_text_c.word_counts[word_7]
word_8_count_textblob = textblob_obj_text_c.word_counts[word_8]
word_9_count_textblob = textblob_obj_text_c.word_counts[word_9]
word_10_count_textblob = textblob_obj_text_c.word_counts[word_10]
word_11_count_textblob = textblob_obj_text_c.word_counts[word_11]
word_12_count_textblob = textblob_obj_text_c.word_counts[word_12]
word_13_count_textblob = textblob_obj_text_c.word_counts[word_13]
word_14_count_textblob = textblob_obj_text_c.word_counts[word_14]
word_15_count_textblob = textblob_obj_text_c.word_counts[word_15]
word_16_count_textblob = textblob_obj_text_c.word_counts[word_16]
word_17_count_textblob = textblob_obj_text_c.word_counts[word_17]
word_18_count_textblob = textblob_obj_text_c.word_counts[word_18]
word_19_count_textblob = textblob_obj_text_c.word_counts[word_19]
word_20_count_textblob = textblob_obj_text_c.word_counts[word_20]
word_21_count_textblob = textblob_obj_text_c.word_counts[word_21]
word_22_count_textblob = textblob_obj_text_c.word_counts[word_22]
word_23_count_textblob = textblob_obj_text_c.word_counts[word_23]
word_24_count_textblob = textblob_obj_text_c.word_counts[word_24]
word_25_count_textblob = textblob_obj_text_c.word_counts[word_25]
word_26_count_textblob = textblob_obj_text_c.word_counts[word_26]
word_27_count_textblob = textblob_obj_text_c.word_counts[word_27]

# initialize list of Lists 
selected_tweets_words_counts_textblob = [[word_1, number_word_1], [word_2, number_word_2], [word_3, number_word_3], [word_4, number_word_4], [word_5, number_word_5], [word_6, number_word_6], [word_7, number_word_7], [word_8, number_word_8], [word_9, number_word_9], [word_10, number_word_10], [word_11, number_word_11], [word_12, number_word_12], [word_13, number_word_13], [word_14, number_word_14], [word_15, number_word_15], [word_16, number_word_16], [word_17, number_word_17], [word_18, number_word_18], [word_19, number_word_19], [word_20, number_word_20], [word_21, number_word_21], [word_22, number_word_22], [word_23, number_word_23], [word_24, number_word_24], [word_25, number_word_25], [word_26, number_word_26], [word_27, number_word_27]] 
 
# Create the pandas DataFrame 
selected_tweets_words_counts_textblob_df = pd.DataFrame(selected_tweets_words_counts_textblob, columns = ['tweets_words', 'Counts']) 

selected_tweets_words_counts_textblob_df.to_csv('4_5_211_SMI1_Selected_Tweets_Words_Counts_Textblob_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# selected_tweets_words_counts_textblob_df.to_excel('4_5_211_SMI1_Selected_Tweets_Words_Counts_Textblob_DF.xlsx', header=True)

# NOT WORKING

# Selected tweets_words Plot


# TABLE PLOT NEED TO DO 

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies - Textblob')
# selected_tweets_words_counts_textblob_df.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_5_211_SMI1_Selected_Tweets_Words_Textblob_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()
 
# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies Textblob - Pie')
# plt.pie(selected_tweets_words_counts_textblob_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
# plt.legend(selected_tweets_words_counts_textblob_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_211_SMI1_Selected_Tweets_Words_Textblob_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Frequencies TextBlob - Bars')
# selected_tweets_words_counts_textblob_df.plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_211_SMI1_Selected_Tweets_Words_Textblob_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#########################################################################################################################

# PLOT PLOT - MULTIPLE - SELECTED WORDS ## NEED TO DO - FIX 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

# r1 = np.arange(len(tweets_smi_1['favorites'].value_counts()[:10]))
# r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES // NEED TO CHANGE

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Value Counts - Bars')

plt.plot(tweets_smi_1['created'], tweets_smi_1['number_word_1'], color='red', label='love', alpha=0.9) #73C2FB
plt.plot(tweets_smi_1['created'], tweets_smi_1['number_word_2'], color='black', label='hate', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['number_word_3'], color='blue', label='like', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['number_word_4'], color='green', label='brand', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['number_word_5'], color='orange', label='buy', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['number_word_6'], color='pink', label='fuck', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['number_word_7'], color='yellow', label='thanks', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['number_word_8'], color='purple', label='friend', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['number_word_9'], color='brown', label='follow', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['number_word_10'], color='grey', label='bitch', alpha=0.9)

plt.xticks(rotation=50)
plt.xlabel('Favorites / Retweets Number Value')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_211_SMI1_Selected_Tweets_Words_Textblob_Multi_Plot_Part1.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# PLOT PLOT - MULTIPLE - Tweets ABOUT AND BY SMI ## NEED TO DO - FIX 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

# r1 = np.arange(len(tweets_smi_1['favorites'].value_counts()[:10]))
# r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES // NEED TO CHANGE

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Value Counts - Bars')

plt.plot(tweets_smi_1['created'], tweets_smi_1['word_11_count'], color='red', label='sister', alpha=0.9) #73C2FB
plt.plot(tweets_smi_1['created'], tweets_smi_1['word_12_count'], color='black', label='video', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['word_13_count'], color='blue', label='omg', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['word_14_count'], color='green', label='good', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['word_15_count'], color='orange', label='bad', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['word_16_count'], color='pink', label='makeup', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['word_17_count'], color='yellow', label='queen', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['word_18_count'], color='purple', label='give', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['word_19_count'], color='brown', label='review', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['word_20_count'], color='grey', label='share', alpha=0.9)


# PLOT PLOT - MULTIPLE - Tweets ABOUT AND BY SMI ## NEED TO DO - FIX 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

# r1 = np.arange(len(tweets_smi_1['favorites'].value_counts()[:10]))
# r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES // NEED TO CHANGE

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Selected Words Value Counts - Bars')

plt.plot(tweets_smi_1['created'], tweets_smi_1['word_11_count'], color='red', label='recommend', alpha=0.9) #73C2FB
plt.plot(tweets_smi_1['created'], tweets_smi_1['word_12_count'], color='black', label='feel', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['word_13_count'], color='blue', label='racist', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['word_14_count'], color='green', label='ily', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['word_15_count'], color='orange', label='nigger', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['word_16_count'], color='pink', label='christmas', alpha=0.9)
plt.plot(tweets_smi_1['created'], tweets_smi_1['word_17_count'], color='yellow', label='homophobic', alpha=0.9)
# plt.plot(tweets_smi_1['created'], tweets_smi_1['word_18_count'], color='purple', label='', alpha=0.9)
# plt.plot(tweets_smi_1['created'], tweets_smi_1['word_19_count'], color='brown', label='', alpha=0.9)
# plt.plot(tweets_smi_1['created'], tweets_smi_1['word_20_count'], color='grey', label='', alpha=0.9)

plt.xticks(rotation=50)
# plt.xlabel('Favorites / Retweets Number')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_211_SMI1_Selected_Tweets_Words_Textblob_Multi_Plot_Part3.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



###############################################################################################################
#
#                                        QUANTITATIVE ANALYSIS - PART 2
#
################################################################################################################

print('-------------------------------')
print('STARTING QUANTITATIVE ANALYSIS XXXXXXXXXXXXXXXXXXXXXXXXXXX')
print('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')

################################################################################################################

number_total_tweets = len(tweets_smi_1['created'])

print('---')
print('Variable number_total_tweets Number Total Tweets')
print(number_total_tweets)
print('---')

number_total_favorites = sum(tweets_smi_1['favorites'])

number_retweets = sum(tweets_smi_1['retweets'])


# COME MUCHA MEMORIA !!!

# tweets_smi_1['percentage_favorites'] = (tweets_smi_1['favorites'] * 100)/number_total_favorites

print('---')
print('Percentage Favorites Head')
# print(tweets_smi_1['percentage_favorites'].head)
print('---')

# tweets_smi_1['percentage_retweets'] = (tweets_smi_1['retweets'] * 100)/number_retweets

print('---')
print('Percentage Retweets Head')
# print(tweets_smi_1['percentage_retweets'].head)
print('---')


######################################################################################

# TOTAL MEANS FOR DATAFRAME

# = sns.catplot(x='favorites', y='', hue='is_follower', height=3.5, aspect=1.5, kind=box, legend=False, data=tweets_smi_1)
# total_means.add_legend(title='is_follower')

####################################################################################

print('---')
print('Tweets Shape and Types BEFORE STATISTICS')
print(tweets_smi_1.shape)
print(tweets_smi_1.dtypes)
print('---')

print('---')
print('Favorites Head')
print(tweets_smi_1['favorites'].head)
print('---')

print('---')
print('Retweets Head')
print(tweets_smi_1['retweets'].head)
print('---')

tweets_smi_1['favorites'] = pd.to_numeric(tweets_smi_1['favorites'])
tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int32, errors='ignore')
tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int32, errors='ignore')
tweets_smi_1['retweets'] = pd.to_numeric(tweets_smi_1['retweets'])
# tweets_smi_1['followers_count'] = tweets_smi_1['followers_count'].astype(np.int64, errors='ignore')
# tweets_smi_1['friends_count'] = tweets_smi_1['friends_count'].astype(np.int64, errors='ignore')
# # tweets_smi_1['followers'] = tweets_smi_1['followers'].astype(np.int32, errors='ignore')
# # tweets_smi_1['following'] = tweets_smi_1['following'].astype(np.int32, errors='ignore')
# tweets_smi_1['total_tweets'] = tweets_smi_1['total_tweets'].astype(np.int32, errors='ignore')
tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int32, errors='ignore')
# # tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int32, errors='ignore')
# tweets_smi_1['lists'] = tweets_smi_1['lists'].astype(np.int32, errors='ignore')


print('---')
print('Tweets Shape and Types BEFORE STATISTICS CONVERTED TYPES')
print(tweets_smi_1.shape)
print(tweets_smi_1.dtypes)
print('---')

print('---')
print('Favorites Head')
print(tweets_smi_1['favorites'].head)
print('---')

print('---')
print('Retweets Head')
print(tweets_smi_1['retweets'].head)
print('---')

# https://www.datacamp.com/community/tutorials/wordcloud-python

# CENTRALITY MEASURES: SUMMARY STATISTICS


print('Centrality Measures Favorites')

# Mean Favorites

mean_favorites = statistics.mean(tweets_smi_1['favorites'])
# mean_favorites.pd.astype(np.int32, errors='ignore')

print('---')
print('Mean Favorites')
print(statistics.mean(tweets_smi_1['favorites']))
print('---')


mean_favorites_df = pd.DataFrame([mean_favorites], columns=['mean_favorites'])

mean_favorites_df.to_csv('4_4_1_SMI1_Mean_Favorites_1_CSV.csv', sep='\t', encoding='utf-8', index=True)
# mean_favorites_df.to_excel('4_4_1_SMI1_Mean_Favorites_1.xlxs', header=True)

# NEED TO DO TABLE PLOT


# BOX PLOT 3 ########## NEED TO FIX  

# # plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale()
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean Favorites - Box')
plt.ioff()
plt.boxplot(tweets_smi_1['favorites'], patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_1_SMI1_Mean_Favorites_Box_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del mean_favorites
del mean_favorites_df

#################################################################################################################

# Median Favorites

median_favorites = statistics.median(tweets_smi_1['favorites'])
median_favorites

print('---')
print('Median Favorites')
print(median_favorites)
print('---')

median_favorites_df = pd.DataFrame([median_favorites], columns=['median_favorites'])

median_favorites_df.to_csv('4_4_2_SMI1_Median_Favorites_1_CSV.csv', sep='\t', encoding='utf-8', index=True)
# median_favorites_df.to_excel('4_4_2_SMI1_Median_Favorites_1.xlsx', header=True)

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO DO FIX ############### NEED TO FIX PLOT BOX

# # plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Median Favorites - Box')
plt.ioff()
# (statistics.median(tweets_smi_1['favorites'])).boxplot(grid=True)
# (statistics.median(tweets_smi_1['favorites'])).plot(kind=box)
# plt.plot(median_favorites)
# plt.boxplot(statistics.median(tweets_smi_1['favorites']), vert=False, notch=False, showfliers=False)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_2_SMI1_Median_Favorites_Box_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# # plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

## DELETE VARIABLE

del median_favorites
del median_favorites_df

#################################################################################################################

# Mean Retweets

mean_retweets = statistics.mean(tweets_smi_1['retweets'])

print('---')
print('Mean Retweets')
print(mean_retweets)
print('---')

mean_retweets_df = pd.DataFrame([mean_retweets], columns=['mean_retweets'])

mean_retweets_df.to_csv('4_4_3_SMI1_Mean_Retweets_CSV.csv', sep='\t', encoding='utf-8', index=True)
# mean_retweets_df.to_excel('4_4_3_SMI1_Mean_Retweets.xlsx', header=True)

# NEED TO DO TABLE PLOT

# BOX PLOT 3 ########## NEED TO FIX  

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale()
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean Retweets - No Fliers - Box')
plt.ioff()
# plt.boxplot(tweets_smi_1['retweets'], patch_artist=True, vert=False, notch=False, showfliers=False)
plt.boxplot(tweets_smi_1['retweets'])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_3_SMI1_Mean_Retweets_Box_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

## DELETE VARIABLE

del mean_retweets
del mean_retweets_df

#################################################################################################################

# Median Retweets

median_retweets = statistics.median(tweets_smi_1['retweets'])
median_retweets

print('---')
print('Median Retweets')
print(statistics.median(tweets_smi_1['retweets']))
print('---')

median_retweets_df = pd.DataFrame([median_retweets], columns=['median_retweets'])

median_retweets_df.to_csv('4_4_4_SMI1_Median_Retweets_CSV.csv', sep='\t', encoding='utf-8', index=True)
# median_retweets_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX ########## NEED TO FIX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Median Retweets - Box')
plt.ioff()
# plt.boxplot(statistics.median(tweets_smi_1['retweets']), vert=False, notch=False, showfliers=False) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_4_SMI1_Median_Retweets_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## DELETE VARIABLE

del median_retweets
del median_retweets_df

#################################################################################################################

# https://realpython.com/python-statistics/

# MEAN and MEDIAN BOXPLOT OF Favorites AND Retweets      ######## NEED TO DO!!!!

# NEED TO DO TABLE PLOT

# BOX PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean and Median of Favorites - Retweets - Box')
plt.ioff()
# tweets_smi_1.boxplot(column = 'favorites', grid=True) # , patch_artist=True, vert=False, notch=False, showfliers=True)
# tweets_smi_1.boxplot(column = 'retweets', grid=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_5_SMI1_Mean_and_Median_of_Favorites_Retweets_Box_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO



##########################################################################

# Population Variance Favorites

pvariance_favorites = statistics.pvariance(tweets_smi_1['favorites'])
pvariance_favorites

pvariance_favorites_df = pd.DataFrame([pvariance_favorites])

print('---')
print('Population Variance Favorites')
print(statistics.pvariance(tweets_smi_1['favorites']))
print('---')

pvariance_favorites_df.to_csv('SMI1_Pvariance_Favorites_10_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# pvariance_favorites_df.to_excel()

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Population Variance Favorites - Box')
plt.ioff()
# plt.plot(statistics.pvariance(tweets_smi_1['favorites']), alpha=0.9) 
# plt.boxplot(statistics.pvariance(tweets_smi_1['favorites']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_10_SMI1_Pvariance_Favorites_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO


#################################################################################################################

# Population Variance Retweets

pvariance_retweets = statistics.pvariance(tweets_smi_1['retweets'])
pvariance_retweets

print('---')
print('Population Variance Retweets')
print(statistics.pvariance(tweets_smi_1['retweets']))
print('---')

pvariance_retweets_df = pd.DataFrame([pvariance_retweets], columns = ['pvariance_reetweets'])

pvariance_retweets_df.to_csv('4_4_11_SMI1_pvariance_Retweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# pvariance_retweets_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Population Variance Retweets - Box')
plt.ioff()
# plt.plot(statistics.pvariance(tweets_smi_1['retweets']), alpha=0.9)
# plt.boxplot(statistics.pvariance(tweets_smi_1['retweets']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_11_SMI1_pvariance_Retweets_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Standard Deviation Favorites

stdev_favorites = statistics.stdev(tweets_smi_1['favorites'])
stdev_favorites

print('---')
print('Standard Deviation Favorites')
print(statistics.stdev(tweets_smi_1['favorites']))
print('---')

stdev_favorites_df = pd.DataFrame([stdev_favorites], columns=['stdev_favorites'])

stdev_favorites_df.to_csv('4_4_12_SMI1_Stdev_Favorites_df_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# stdev_favorites_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Standard Deviation Favorites - Box')
plt.ioff()
# plt.plot(statistics.stdev(tweets_smi_1['favorites']), alpha=0.9) 
# plt.boxplot(statistics.stdev(tweets_smi_1['favorites']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_12_SMI1_Stdev_Favorites_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################################################################################################

# Standard Deviation Retweets

stdev_retweets = statistics.stdev(tweets_smi_1['retweets'])
stdev_retweets

print('---')
print('Standard Deviation Retweets')
print(statistics.stdev(tweets_smi_1['retweets']))
print('---')

stdev_retweets_df = pd.DataFrame([stdev_retweets], columns=['stdev_retweets'])

stdev_retweets_df.to_csv('4_4_13_SMI1_Stdev_Retweets_df_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# stdev_retweets_df.to_excel('4_4_13_SMI1_Stdev_Retweets_df.xlsx', sep='\t', encoding='utf-8', index=True, header=True)

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Standard Deviation Retweets - Box')
plt.ioff()
# plt.boxplot(statistics.stdev(tweets_smi_1['retweets']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_13_SMI1_Stdev_Retweets_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLO NEED TO DO

#################################################################################################################

# Population Standard Deviation Favorites

pstdev_favorites = statistics.pstdev(tweets_smi_1['favorites'])
pstdev_favorites

print('---')

print('Standard Deviation Favorites')
print(statistics.pstdev(tweets_smi_1['favorites']))
print('---')

pstdev_favorites_df = pd.DataFrame([pstdev_favorites])

pstdev_favorites_df.to_csv('4_4_14_SMI1_pstdev_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Population Standard Deviation Favorites - Box')
plt.ioff()
# plt.plot(statistics.pstdev(tweets_smi_1['favorites']))
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_14_SMI1_pstdev_Favorites_Box.png', bbox_inches='tight')
# plt.close(fig='all')
# plt.clf()

# Bars NEED TO DO

#################################################################################################################

# Population Standard Deviation Retweets

pstdev_retweets = statistics.pstdev(tweets_smi_1['retweets'])
pstdev_retweets

print('---')
print('Population Standard Deviation Retweets')
print(statistics.pstdev(tweets_smi_1['retweets']))
print('---')

pstdev_retweets_df = pd.DataFrame([pstdev_retweets])

pstdev_retweets_df.to_csv('4_4_15_SMI1_Pstdev_Retweets_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True) ## NEED TO DO: SAVE AS CSV
# pstdev_retweets_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Population Standard Deviation Retweets - Box')
plt.ioff()
# plt.boxplot(statistics.pstdev(tweets_smi_1['retweets']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_15_SMI1_Pstdev_Retweets_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

#################################################################################################################

# Skewness Favorites

# The sample skewness measures the asymmetry of a data sample. Usually, negative skewness values indicate that there�s 
# a dominant tail on the left side, which you can see with the first set. Positive skewness values correspond to a 
# longer or fatter tail on the right side, which you can see in the second set. If the skewness is close to 0 
# (for example, between -0.5 and 0.5), then the dataset is considered quite symmetrical.


skewness_favorites = scipy.stats.skew(tweets_smi_1['favorites'], bias=False)
skewness_favorites

print('---')
print('Skewness Favorites')
print(scipy.stats.skew(tweets_smi_1['favorites'], bias=False))
print('---')

skewness_favorites_df = pd.DataFrame([skewness_favorites], columns=['skewness_favorites'])

skewness_favorites_df.to_csv('4_4_16_SMI1_Skewness_Favorites_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# skewness_favorites_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10)) 
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Skewness Favorites - Box')
plt.ioff()
# plt.boxplot(scipy.stats.skew(tweets_smi_1['favorites']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_16_SMI1_Skewness_Favorites_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

#########################

# total_favorites INFO - TIME SERIES

min_total_favorites = tweets_smi_1['favorites'].min()
max_total_favorites = tweets_smi_1['favorites'].max()

# mean_total_favorites = statistics.mean(tweets_smi_1['favorites'])
# mean_total_favorites

print('---')
print('Min total_favorites')
print(min_total_favorites)
print('---')

print('---')
print('Max total_favorites')
print(max_total_favorites)
print('---')

print('---')
print('Mean total_favorites')
# print(mean_total_favorites)
print('---')

# Initialize the list

total_favorites_stats = [['Min total_favorites', min_total_favorites], ['Max total_favorites', max_total_favorites]]

total_favorites_stats_df = pd.DataFrame(total_favorites_stats, columns=['total_favorites_measure', 'total_favorites_value'])

total_favorites_stats_df.to_csv('4_4_1_SMI1_Total_Favorites_Stats_df_CSV.csv', sep='\t', encoding='utf-8', index=True)
# total_favorites_stats_df.to_excel('4_1_1_SMI1_Total_favorites_Stats_df.xlsx', header=True)

# NEED TO DO TABLE PLOT


# PLOT 1 ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean All Favorites')
plt.ioff()
# total_favorites_stats_df.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_1_SMI1_Total_Favorites_Stats_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# BAR PLOT 1 ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean All Favorites - Bars')
plt.ioff()
# total_favorites_stats_df.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_1_SMI1_Total_Favorites_Stats_Bar.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### DELETE VARIABLE

# del total_favorites_stats
# del total_favorites_stats_df

####################################################################################################
####################################################################################################

# Skewness Retweets

skewness_retweets = scipy.stats.skew(tweets_smi_1['retweets'], bias=False)
skewness_retweets

print('---')
print('Skewness Retweets')
print(scipy.stats.skew(tweets_smi_1['retweets'], bias=False))
print('---')

skewness_retweets_df = pd.DataFrame([skewness_retweets], columns=['skewness_retweets'])

skewness_retweets_df.to_csv('4_4_17_SMI1_Skewness_Retweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# skewness_retweets_df.to_excel()

# NEED TO DO TABLE PLOT


# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Skewness Retweets - Box')
plt.ioff()
# plt.boxplot(scipy.stats.skew(tweets_smi_1['retweets']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_17_SMI1_Skewness_Retweets_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO
 
#################################################################################################################

# Percentiles Favorites

# The sample ?? percentile is the element in the dataset such that ??% of the elements in the dataset are less than or 
# equal to that value.

quantiles_favorites = np.percentile(tweets_smi_1['favorites'], [25, 50, 75])
quantiles_favorites

print('---')
print('Percentiles Favorites')
print(np.percentile(tweets_smi_1['favorites'], [25, 50, 75]))
print('---')


quantiles_favorites_df = pd.DataFrame(quantiles_favorites, columns = ['quantiles_favorites'])

quantiles_favorites_df.to_csv('4_4_18_SMI1_Quantiles_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# quantiles_favorites_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO DO - FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentiles Favorites - Box')
plt.ioff()
plt.plot(quantiles_favorites, alpha=0.9) # , [25, 50, 75]).box.plot(alpha=0.9) 
plt.xticks(rotation=50)
# plt.boxplot(quantiles_favorites_df, patch_artist=True, vert=False, notch=False, showfliers=True)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_18_SMI1_Quantiles_Favorites_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentiles Favorites - Bars')
plt.ioff()
# (np.percentile(tweets_smi_1['favorites'], [25, 50, 75])).plot.bar(alpha=0.9) # , [25, 50, 75]).plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_18_SMI1_Quantiles_Favorites_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################################################################################################

# Percentiles Retweets

quantiles_retweets = np.percentile(tweets_smi_1['retweets'], [25, 50, 75])
quantiles_retweets

print('---')
print('Percentiles Retweets')
print(np.percentile(tweets_smi_1['retweets'], [25, 50, 75]))
print('---')

quantiles_retweets_df = pd.DataFrame(quantiles_retweets, columns=['quantiles_retweets'])

quantiles_retweets_df.to_csv('4_4_19_SMI1_Quantiles_Retweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True) ## NEED TO FINISH
# quantiles_retweets_df.to_excel(('4_4_19_SMI1_Quantiles_Retweets_DF.csv', sep='\t', encoding='utf-8', index=True)

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentiles Retweets - Box')
plt.ioff()
# plt.boxplot(np.percentile(tweets_smi_1['retweets'], [25, 50, 75]), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_19_SMI1_Quantiles_Retweets_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentiles Retweets - Bars')
plt.ioff()
# quantiles_retweets_df.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_19_SMI1_Quantiles_Retweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################################################################################################

# SUMMARY OF DESCRIPTIVE STATISTICS Favorites

# describe() returns an object that holds the Following descriptive statistics:

# nobs: the number of observations or elements in your dataset
# minmax: the tuple with the minimum and maximum values of your dataset
# mean: the mean of your dataset
# variance: the variance of your dataset
# skewness: the skewness of your dataset
# kurtosis: the kurtosis of your dataset

print('---')
print('Statistical Summary for Descriptive Statistics Favorites')
print(scipy.stats.describe(tweets_smi_1['favorites'], ddof=1, bias=False))
print('---')

summ_stats_result_favs = scipy.stats.describe(tweets_smi_1['favorites'], ddof=1, bias=False)

summ_stats_result_favs_df = pd.DataFrame([summ_stats_result_favs])

# summ_stats_result_favs

summ_stats_result_favs_df.to_csv('4_4_22_SMI1_Summ_Stats_Result_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# summ_stats_result_favs_df.to_excel('4_4_22_SMI1_Summ_Stats_Result_Favorites_DF.xlsx', index=True, header=True) # Only argument is a string of the output file path

print('-- NEED TO DO SUMM STATS TABLE TO CSV')

# PLOT TABLE ################### NEED TO DO PLOT TO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Statistical Summary for Favorites')
plt.ioff()
# plt.plot(summ_stats_result_favs)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_22_SMI1_Summ_Stats_Result_favs.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

#################################################################################################################

# Summary Statistics of all Favorites  ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

tweets_smi_1['favorites'].describe()

print('---')
print('Summary Statistics of All Favorites - Method 2')
print(tweets_smi_1['favorites'].describe())
print('---')

# PLOT ################### NEED TO DO PLOT TO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Statistical Summary for Favorites')
plt.ioff()
plt.plot(tweets_smi_1['favorites'].describe(), alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_23_SMI1_Summ_Stats_Result_Favorites_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################

# SUMMARY OF DESCRIPTIVE STATISTICS Retweets

summ_stats_result_rts = scipy.stats.describe(tweets_smi_1['retweets'], ddof=1, bias=False)

summ_stats_result_rts_df = pd.DataFrame([summ_stats_result_rts])

print('---')
print('Statistical Summary for Descriptive Statistics Retweets')
print(scipy.stats.describe(tweets_smi_1['retweets'], ddof=1, bias=False))
print('---')

summ_stats_result_rts_df.to_csv('4_4_24_SMI1_Summ_Stats_Result_rts_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# summ_stats_result_rts_df.to_excel('4_4_24_SMI1_Summ_Stats_Result_rts_DF.xlsx', index=True, header=True) # Only argument is a string of the output file path

# PLOT TABLE plt.plot # NEED TO DO FIX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Statistical Summary for Retweets')
plt.ioff()
# plt.plot(scipy.stats.describe(tweets_smi_1['retweets'], ddof=1, bias=False, alpha=0.9))
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_24_SMI1_Summ_Stats_Result_rts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# summ_stats_result_rts

print('---')
print('Statistical Summary for Descriptive Statistics Retweets')
print(summ_stats_result_rts)
print('---')

print('-- NEED TO DO: SAVE TO CSV AND PRINT TABLES')

# NEED TO PLOT TABLE


#################################################################################################################

# SUMMARY OF DESCRIPTIVE STATISTICS Favorites

# describe() returns an object that holds the Following descriptive statistics:

# nobs: the number of observations or elements in your dataset
# minmax: the tuple with the minimum and maximum values of your dataset
# mean: the mean of your dataset
# variance: the variance of your dataset
# skewness: the skewness of your dataset
# kurtosis: the kurtosis of your dataset


####
####
####

###############################################################################
#################################################################################################################

#################################################################################################################

# Measures of Correlation Between Pairs of Data

# You�ll often need to examine the relationship between the corresponding elements of two variables in a dataset. Say there are two variables, ?? and ??, with an equal number of elements, ??. Let ??1 from ?? correspond to ??1 from ??, ??2 from ?? to ??2 from ??, and so on. You can then say that there are ?? pairs of corresponding elements: (??1, ??1), (??2, ??2), and so on.

# You�ll see the Following measures of correlation between pairs of data:

# Positive correlation exists when larger values of ?? correspond to larger values of ?? and vice versa.
# Negative correlation exists when larger values of ?? correspond to smaller values of ?? and vice versa.
# Weak or no correlation exists if there is no such apparent relationship.

# Note: There�s one important thing you should always have in mind when working with correlation among a pair of 
# variables, and that�s that correlation is not a measure or indicator of causation, but only of association!

# The two statistics that measure the correlation between datasets are covariance and the correlation coefficient.

# Covariance

# The sample covariance is a measure that quantifies the strength and direction of a relationship between a pair of 
# variables:

# If the correlation is positive, then the covariance is positive, as well. A stronger relationship corresponds to a 
# higher value of the covariance.
# If the correlation is negative, then the covariance is negative, as well. A stronger relationship corresponds to a 
# lower (or higher absolute) value of the covariance.
# If the correlation is weak, then the covariance is close to zero.

# Covariance matrix:

cov_matrix_favs_rts = np.cov(tweets_smi_1['favorites'], tweets_smi_1['retweets'], bias='False')
cov_matrix_favs_rts_df = pd.DataFrame(cov_matrix_favs_rts)

cov_matrix_favs_rts_df.to_csv('4_4_24_SMI1_Cov_Matrix_Favorites_Retweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# cov_matrix_favs_rts_df.to_excel('4_4_24_SMI1_Cov_Matrix_Favorites_Retweets_df.xlsx', index=True, header=True) # Only argument is a string of the output file path


print('---')
print('Covariance Matrix for Favorites and Retweets')
print(np.cov(tweets_smi_1['favorites'], tweets_smi_1['retweets'], bias='False'))
print('---')

# PLOT plt.plot 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Covariance Matrix for Favorites and Retweets')
plt.ioff()
plt.plot(cov_matrix_favs_rts, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_24_SMI1_Cov_Matrix_Favorites_Retweets_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Covariance Matrix for Favorites and Retweets - Bars')
plt.ioff()
# cov_matrix_favs_rts.plot.bars(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_24_SMI1_Cov_Matrix_Favorites_rts_Bars_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Correlation Coefficient : Pearson

# The correlation coefficient, or Pearson product-moment correlation coefficient, is denoted by the symbol ??. The 
# coefficient is another measure of the correlation between data. You can think of it as a standardized covariance. 
# Here are some important facts about it:

# The value ?? > 0 indicates positive correlation.
# The value ?? < 0 indicates negative correlation.
# The value r = 1 is the maximum possible value of ??. It corresponds to a perfect positive linear relationship 
# between variables.
# The value r = -1 is the minimum possible value of ??. It corresponds to a perfect negative linear relationship 
# between variables.
# The value r � 0, or when ?? is around zero, means that the correlation between variables is weak.

# pearsonr() returns a tuple with two numbers. The first one is ?? and the second is the ??-value.

corr_coef_favs_rts_pearson = scipy.stats.pearsonr(tweets_smi_1['favorites'], tweets_smi_1['retweets'])

corr_coef_favs_rts_pearson_df = pd.DataFrame(corr_coef_favs_rts_pearson)

corr_coef_favs_rts_pearson_df.to_csv('4_4_25_SMI1_Corr_Coef_Favorites_Retweets_Pearson_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header='corr_coef_favs_rts_pearson_df')
# corr_coef_favs_rts_pearson_df.to_excel()

print('---')
print('Correlation Coefficient: Pearson Favorites vs Retweets')
print(corr_coef_favs_rts_pearson)
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4)) 
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient: Pearson Favorites vs Retweets - Box')
plt.ioff()
# plt.boxplot(scipy.stats.pearsonr(tweets_smi_1['favorites'], tweets_smi_1['retweets']), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_25_SMI1_Corr_Coef_Favorites_Retweets_Pearson_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTERPLOT - NEED TO SET DIF COLORS FOR X AND Y!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10)) 
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient: Pearson Favorites vs Retweets - Scatter')
plt.ioff()
# (scipy.stats.pearsonr(tweets_smi_1['favorites'], tweets_smi_1['retweets'])).plot(alpha=0.9)
# corr_coef_favs_rts_pearson_df.plot.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_25_SMI1_Corr_Coef_Favorites_Retweets_Pearson_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4)) 
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient: Pearson Favorites vs Retweets - Bars')
plt.ioff()
# plt.plot(scipy.stats.pearsonr(tweets_smi_1['favorites'], tweets_smi_1['retweets']))
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_25_SMI1_Corr_Coef_Favorites_Retweets_Pearson_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Correlation Coefficient Matrix

# Similar to the case of the covariance matrix, you can apply np.corrcoef() with x_ and y_ as the arguments and 
# get the correlation coefficient matrix:

corr_matrix_favs_rts = np.corrcoef(tweets_smi_1['favorites'], tweets_smi_1['retweets'])
corr_matrix_favs_rts_df = pd.DataFrame(corr_matrix_favs_rts)

print('---')
print('Correlation Coefficient Matrix Favorites vs Retweets')
print(np.corrcoef(tweets_smi_1['favorites'], tweets_smi_1['retweets']))
print('---')

corr_matrix_favs_rts_df.to_csv('4_4_26_SMI1_Corr_Matrix_Favorites_Retweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# corr_matrix_favs_rts_df.to_excel('4_4_26_SMI1_Corr_Matrix_Favorites_Retweets_DF.xlsx', index=True, header=True) # Only argument is a string of the output file path

# PLOT TABLE plt.plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient Matrix Favorites vs Retweets')
plt.ioff()
plt.plot(corr_matrix_favs_rts, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_26_SMI1_Corr_Matrix_Favorites_Retweets_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient Matrix Favorites vs Retweets - Bars')
plt.ioff()
# corr_matrix_favs_rts.plot.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_26_SMI1_Corr_Matrix_Favorites_Retweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Linear Regession

# inregress() takes x_ and y_, performs linear regression, and returns the results. slope and intercept define the equation of the regression line, while rvalue is the correlation coefficient. To access particular values from the result of linregress(), including the correlation coefficient, use dot notation:

linar_reg_favs_rts = scipy.stats.linregress(tweets_smi_1['favorites'], tweets_smi_1['retweets'])
r_linar_reg_favs_rts = linar_reg_favs_rts.rvalue
r_linar_reg_favs_rts_df = pd.DataFrame([r_linar_reg_favs_rts])

r_linar_reg_favs_rts_df.to_csv('4_4_27_SMI1_R_Linear_Reg_Favorites_Retweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# r_linar_reg_favs_rts_df.to_excel()

print('---')
print('Linear Regression Favorites vs Retweets')
print(scipy.stats.linregress(tweets_smi_1['favorites'], tweets_smi_1['retweets']))
print('---')

# PLOT ####### NEED TO FIX DO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale()
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Linear Regression Favorites vs Retweets')
plt.plot(r_linar_reg_favs_rts, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_27_SMI1_R_Linear_Reg_Favorites_Retweets_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Linear Regression Favorites vs Retweets - Box')
plt.ioff()
# plt.boxplot(scipy.stats.linregress(tweets_smi_1['favorites'], tweets_smi_1['retweets']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_27_SMI1_R_Linear_Reg_Favorites_Retweets_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# SCATTERPLOT

r_reg_favs_rts_array = scipy.stats.linregress(tweets_smi_1['favorites'], tweets_smi_1['retweets'])

## NEED TO DO SCATTERPLOT NEED TO GET FDIF COLORS X AND Y 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10)) 
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Linear Regression Favorites vs Retweets - Scatter')
plt.ioff()
plt.plot(scipy.stats.linregress(tweets_smi_1['favorites'], tweets_smi_1['retweets']))
plt.scatter(tweets_smi_1['favorites'], tweets_smi_1['retweets'], alpha=0.9)
plt.plot(r_linar_reg_favs_rts)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_27_SMI1_Corr_Coef_Favorites_Retweets_Pearson_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS ####### NEED TO FIX DO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale()
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Linear Regression Favorites vs Retweets - Bars')
# r_linar_reg_favs_rts.bars.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_27_SMI1_R_Linear_Reg_Favorites_Retweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

#################################################################################

# ANALYSING THE DATA ########### NEED TO DO - GROUPED BY FAVS OR RETS OR IS IT REPETATED?

# Retweets STATS

# MEAN

mean_df_rts_2 = tweets_smi_1['retweets'].mean()

mean_df_rts_2_df = pd.DataFrame([mean_df_rts_2], columns=['mean_df_rts_2'])

mean_df_rts_2_df.to_csv('4_4_29_SMI1_Mean_df_Retweets_2_df.csv')
# mean_df_rts_2_df.to_excel()

print('---')
print('Mean Retweets')
# print(tweets_smi_1['retweets'].mean())
print('---')

############################################################

# BOX PLOT ########## NEED TO FIX 2 means 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10)) 
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean Favorites - Retweets - Box')
plt.ioff()
# plt.boxplot(tweets_smi_1['favorites'].mean(), patch_artist=True, vert=False, notch=False, showfliers=True) 
# plt.boxplot(tweets_smi_1['retweets'].mean(), patch_artist=True, vert=False, notch=False, showfliers=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_28_SMI1_Mean_DF_Retweets_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################################################

# MEDIAN

median_df_rts_2 = tweets_smi_1['retweets'].median()
median_df_rts_2

median_df_rts_2_df = pd.DataFrame([median_df_rts_2], columns = ['median_retweets'])

median_df_rts_2_df.to_csv('4_4_29_SMI1_median_df_rts_2_df.csv')
# median_df_rts_2_df.to_excel()

print('---')
print('Median Retweets')
# print(tweets_smi_1['retweets'].median())
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Median Retweets - Box')
plt.ioff()
# plt.boxplot(median_df_rts_2_df, patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_29_SMI1_Median_Df_Retweets_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Median Retweets - Bars')
plt.ioff()
# median_df_rts_2_df.plot.bars() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_29_SMI1_Median_Df_Retweets_2_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################################################

# Standard Deviation

std_df_rts_2 = tweets_smi_1['retweets'].std() 

std_df_rts_2_df = pd.DataFrame([std_df_rts_2], columns=['standard_deviation_retweets'])

std_df_rts_2_df.to_csv('4_4_29_SMI1_std_df_Retweets_2_CSV.csv')
# std_df_rts_2_df.to_excel()

print('---')
print('Standard Deviation Retweets')
print(tweets_smi_1['retweets'].std())
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Standard Deviation Retweets - Box')
plt.ioff()
# std_df_rts_2_df.plt.box()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_29_SMI1_Std_df_Retweets_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Standard Deviation Retweets - Bars')
plt.ioff()
# std_df_rts_2.plt.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_29_SMI1_Std_df_Retweets_2_Bars.png', bbox_inches='tight')
# plt.close(fig='all')
# plt.clf()

##############################################################################

# MAXIMUM OF EACH ATTRIBUTE

max_df_rts_2 = tweets_smi_1['retweets'].max()

max_df_rts_2_df = pd.DataFrame([max_df_rts_2], columns=['max_retweets'])

max_df_rts_2_df.to_csv('4_4_29_SMI1_Max_df_Retweets_2_CSV.csv')
# std_df_rts_2_df.to_excel()

print('---')
print('Maximum of Each Attribute vs Retweets')
print(tweets_smi_1['retweets'].max())
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Maximum of Each Attribute Retweets - Box')
plt.ioff()
plt.plot(tweets_smi_1['retweets'].max())
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_30_SMI1_Max_DF_Retweets_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Maximum of Each Attribute Retweets - Bars')
plt.ioff()
# (tweets_smi_1['retweets'].max()).plot.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_30_SMI1_Max_DF_Retweets_2_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################################################

# MINIMUM OF EACH ATTRIBUTE

min_df_rts_2 = tweets_smi_1['retweets'].min()

min_df_rts_2_df = pd.DataFrame([min_df_rts_2])

min_df_rts_2_df.to_csv('4_4_30_SMI1_min_df_rts_2_df.csv')
# excel()

print('---')
print('Minimum of Each Attribute / Retweets')
print(tweets_smi_1['retweets'].min())
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Minimum of Each Attribute / Retweets - Box')
plt.ioff()
plt.plot(tweets_smi_1['retweets'].min()) 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_30_SMI1_Min_DF_Retweets_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################################################
 
# DESCRIPTIVE STATISTICS SUMMARY   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

df_tweets_smi_processes_describe_rts_1 = tweets_smi_1['retweets'].describe()
df_tweets_smi_processes_describe_rts_1_df = pd.DataFrame([df_tweets_smi_processes_describe_rts_1])

df_tweets_smi_processes_describe_rts_1_df.to_csv('4_4_31_SMI1_DF_Tweets_SMI_Processes_Describe_Retweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header='df_tweets_smi_processes_describe_rts')
# df_tweets_smi_processes_describe_rts_1_df.to_excel('4_4_31_SMI1_DF_Tweets_SMI_Processes_Describe_Retweets_DF.xlsx', index=False, header=True)

print('---')
print('Descriptive Statistics Summary Retweets')
print(tweets_smi_1['retweets'].describe())
print('---')


# CREATE TABLE plt.plot ############# NEED TO FIX CREATING TABLES!!!!!!!!!!!!!!

# table_df_tweets_smi_processes_describe_rts_1 = table(show_header=True, header_style='bold blue', cellText='blue') 
# table_df_tweets_smi_processes_describe_rts_1 = table(cellText='blue')
# table_df_tweets_smi_processes_describe_rts_1.add_column('Metrics')
# table_df_tweets_smi_processes_describe_rts_1.add_row(df_tweets_smi_processes_rts_1.describe(include=['O']).T)
# console.print(table_df_tweets_smi_processes_describe_rts_1)

# TABLE PLOT NEED TO DO

# df_tweets_smi_processes_describe_rts_1

# PLOT ??????????

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10)) 
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Descriptive Statistics Summary Retweets')
plt.ioff()
plt.plot(df_tweets_smi_processes_describe_rts_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_31_SMI1_DF_Tweets_SMI_Processes_Describe_Retweets.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff() 

# plt.figure(figsize=(14,10)) 
# plt.autoscale()
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Descriptive Statistics Summary Retweets - Bars')
plt.ioff()
# df_tweets_smi_processes_describe_rts_1_df[:10].plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_31_SMI1_Describe_Summ_Stats_Retweets_Bars.png', bbox_inches='tight')
# plt.close(fig='all')
# plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10)) 
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Descriptive Statistics Summary Retweets - Bars')
plt.ioff()
df_tweets_smi_processes_describe_rts_1[:10].plot.bar(alpha=0.9)
plt.xlabel('Values')
plt.ylabel('Measures')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_31_SMI1_DF_Tweets_SMI_Processes_Describe_Retweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

########################################################################################################################

# ANALYSING THE DATA  #########  NEED TO DO : REPEATED???

# Favorites STATS

# MEAN

mean_df_favs_2 = tweets_smi_1['favorites'].mean()

mean_df_favs_2_df = pd.DataFrame([mean_df_favs_2])

mean_df_favs_2_df.to_csv('4_4_32_SMI1_Mean_df_Favorites_2_df.csv')
# mean_df_favs_2.to_excel()

print('---')
print('Mean Favorites')
print(tweets_smi_1['favorites'].mean())
print('---')

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean Favorites - Box')
plt.ioff()
# plt.plot(tweets_smi_1['favorites'].mean()) 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_32_SMI1_Mean_DF_Favorites_2_Box.png', bbox_inches='tight')
# plt.close(fig='all')
# plt.clf()


##############################################################################

# MEDIAN

median_df_favs_2 = tweets_smi_1['favorites'].median()

print('---')
print('Median Favorites')
print(tweets_smi_1['favorites'].median())
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Median Favorites - Box')
plt.ioff()
# plt.plot(tweets_smi_1['favorites'].median()) 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_32_SMI1_Median_Df_Favorites_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################################################

# Standard Deviation

std_df_favs_2 = tweets_smi_1['favorites'].std() 

print('---')
print('Standard Deviation Favorites')
print(tweets_smi_1['favorites'].std())
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Standard Deviation Favorites - Box')
plt.ioff()
plt.plot(tweets_smi_1['favorites'].std()) 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_32_SMI1_Std_DF_Favorites_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################################################

# MAXIMUM OF EACH ATTRIBUTE

max_df_favs_2 = tweets_smi_1['favorites'].max()

max_df_favs_2_df = pd.DataFrame([max_df_favs_2])

# MINIMUM OF EACH ATTRIBUTE

min_df_favs_2 = tweets_smi_1['favorites'].min()

min_df_favs_2_df = pd.DataFrame([min_df_favs_2])

min_df_favs_2_df.to_csv('4_4_32_SMI1_Max_Min_df_Favorites_2_df_CSV.csv', sep='\t', encoding='utf-8', index=False, header='df_tweets_smi_processes_describe_favs_df')
# min_df_favs_2_df.to_excel('4_4_32_SMI1_Max_Min_df_Favorites_2_df.xlsx', header=True)

# MAX AND MIN


print('---')
print('Minimum of Each Attribute - Favorites')
print(tweets_smi_1['favorites'].min())
print('---')

max_df_favs_2_df = pd.DataFrame([max_df_favs_2])

max_df_favs_2_df.to_csv('4_4_32_Max_df_Favorites_2_df_CSV.csv', sep='\t', encoding='utf-8', index=False, header='df_tweets_smi_processes_describe_favs_df')
# max_df_favs_2_df.to_excel('4_4_32_Max_df_Favorites_2_df.xlsx', header=True)

print('---')
print('Maximum of Each Attribute - Favorites')
print(tweets_smi_1['favorites'].max())
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Maximum of Each Attribute - Favorites - Box')
plt.ioff()
plt.plot(tweets_smi_1['favorites'].max()) 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_32_SMI1_Max_DF_Favorites_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################################################


# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Minimum of Each Attribute - Favorites - Box')
plt.ioff()
plt.plot(tweets_smi_1['favorites'].min()) 
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_32_SMI1_Min_DF_Favorites_2_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

##############################################################################

# DESCRIPTIVE STATISTICS SUMMARY FAVS         ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

df_tweets_smi_processes_describe_favs_1 = tweets_smi_1['favorites'].describe()

print('---')
print('Descriptive Statistics Summary Favorites')
print(tweets_smi_1['favorites'].describe())
print('---')

df_tweets_smi_processes_describe_favs_df = pd.DataFrame([df_tweets_smi_processes_describe_favs_1])

df_tweets_smi_processes_describe_favs_df.to_csv('4_4_33_SMI1_DF_Tweets_SMI_Processes_Describe_Favorites_CSV.csv', sep='\t', encoding='utf-8', index=False, header='df_tweets_smi_processes_describe_favs_df')
# df_tweets_smi_processes_describe_favs_df.to_excel('4_4_33_SMI1_DF_Tweets_SMI_Processes_Describe_Favorites.xlsx', header=True)

# CREATE TABLE plt.plot ## NEED TO DO

# BOX PLOT NEED TO DO


# Bars

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Descriptive Statistics Favorites - Bars')
plt.ioff()
(tweets_smi_1['favorites'].describe()).plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_33_SMI1_DF_Tweets_smi_Processes_Describe_Favorites_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#################################################################################################################

# DESCRIPTIVE STATISTICS SUMMARY FAVS         ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

df_tweets_smi_processes_describe_rts_1 = tweets_smi_1['retweets'].describe()

print('---')
print('Descriptive Statistics Summary Retweets')
print(tweets_smi_1['retweets'].describe())
print('---')

df_tweets_smi_processes_describe_rts_df_1 = pd.DataFrame([df_tweets_smi_processes_describe_rts_1])

df_tweets_smi_processes_describe_rts_df_1.to_csv('4_4_34_SMI1_DF_Tweets_SMI_Processes_Describe_Retweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# df_tweets_smi_processes_describe_rts_df_1.to_excel('4_4_34_SMI1_DF_Tweets_SMI_Processes_Describe_Retweets_DF.xlsx', header=True)

# CREATE TABLE plt.plot ## NEED TO DO 

# table_df_tweets_smi_processes_describe_rts_1 = ff.create_table(df_tweets_smi_processes_rts_1.describe(include=['O']).T)

# NEED TO DO TABLE PLOT

# BOX PLOT NEED TO DO 

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Descriptive Statistics Retweets - Bars')
plt.ioff()
(tweets_smi_1['retweets'].describe()).plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_34_SMI1_DF_Tweets_smi_Processes_Describe_Retweets_1_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Number of Tweets Analized

# ids_tweets = tweets_smi_1['text']    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

number_tweets = len(tweets_smi_1['text'])
number_tweets 

print('---')
print('Number of Tweets')
print(number_tweets)
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT NEED TO DO

# PLOT TABLE plt.plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets')
plt.ioff()
# plt.plot(number_tweets)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_35_SMI1_Number_Tweets_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Tweets - Bars')
plt.ioff()
# ([number_tweets]).plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_35_SMI1_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Number of Tweets with Favorites

tweets_without_favorites = tweets_smi_1[(tweets_smi_1['favorites'] == 0)] 
tweets_with_favorites = tweets_smi_1[(tweets_smi_1['favorites'] != 0)]

number_tweets_without_favorites = len(tweets_without_favorites)
   
number_tweets_with_favorites = number_tweets - number_tweets_without_favorites


percentage_tweets_without_favorites = ((number_tweets_without_favorites * 100)/number_tweets)


percentage_tweets_with_favorites = 100 - percentage_tweets_without_favorites

# Inicialize List of Lists

tweets_favorites_numbers_item_values = [['Tweets without Favorites', number_tweets_without_favorites, percentage_tweets_without_favorites], ['Tweets With Favorites', number_tweets_with_favorites, percentage_tweets_with_favorites]]

# Create DataFrame

tweets_favorites_numbers_item_values_df = pd.DataFrame(tweets_favorites_numbers_item_values, columns =['total_tweets_with_favorites_item', 'total_tweets_with_favorites_number', 'total_tweets_with_favorites_percentage'])

tweets_favorites_numbers_item_values_df.to_csv('4_4_37_SMI1_Tweets_Favorites_Numbers_Item_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_favorites_numbers_item_values_df.to_excel('4_4_37_SMI1_Tweets_Favorites_Numbers_Item_Values_DF.xlsx', header=True)

print('---')
print('Tweets and Values Favorites: OJO REVISAR')
print(tweets_favorites_numbers_item_values_df.head)
print('---')

# TABLE ## NEED TO DO

# plot.legend()

# Pie 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets with and without Favorites - Pie')
plt.ioff()
plt.pie(tweets_favorites_numbers_item_values_df['total_tweets_with_favorites_number'], colors=colors_blue, labels=tweets_favorites_numbers_item_values_df['total_tweets_with_favorites_number'], startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(labels=tweets_favorites_numbers_item_values_df['total_tweets_with_favorites_item'], bbox_to_anchor=(1.05, 1.05), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_35_1_SMI1_Tweets_Favorites_Numbers_Item_Values_df_PLT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets With and Without Favorites - Bars')
plt.ioff()
tweets_favorites_numbers_item_values_df['total_tweets_with_favorites_number'].plot.bar(alpha=0.9)
# ax.bar(x=tweets_favorites_numbers_item_values_df['total_tweets_with_favorites_item'], y=tweets_favorites_numbers_item_values_df['total_tweets_with_favorites_number'])
# ax.bar(tweets_favorites_numbers_item_values_df['total_tweets_with_favorites_item'], tweets_favorites_numbers_item_values_df['total_tweets_with_favorites_number'])
plt.xlabel('Tweets Without Favorites / Tweets With Favorites')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend(labels=tweets_favorites_numbers_item_values_df['total_tweets_with_favorites_item']) 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_35_1_SMI1_Tweets_Favorites_Numbers_Item_Values_df_PLT_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Number of Tweets with Retweets

tweets_without_retweets = tweets_smi_1[(tweets_smi_1['retweets'] == 0)] 
tweets_with_retweets = tweets_smi_1[(tweets_smi_1['retweets'] != 0)] 

number_tweets_without_retweets = len(tweets_without_retweets)
   
number_tweets_with_retweets = number_tweets - number_tweets_without_retweets


percentage_tweets_without_retweets = ((number_tweets_without_retweets * 100)/number_tweets)


percentage_tweets_with_retweets = 100 - percentage_tweets_without_retweets

# Inicialize List of Lists

tweets_retweets_numbers_item_values = [['Tweets without Retweets', number_tweets_without_retweets, percentage_tweets_without_retweets], ['Tweets With Retweets', number_tweets_with_retweets, percentage_tweets_with_retweets]]

# Create DataFrame

tweets_retweets_numbers_item_values_df = pd.DataFrame(tweets_retweets_numbers_item_values, columns =['total_tweets_with_retweets_item', 'total_tweets_with_retweets_number', 'total_tweets_with_retweets_percentage'])

tweets_retweets_numbers_item_values_df.to_csv('4_4_37_SMI1_Tweets_Retweets_Numbers_Item_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_retweets_numbers_item_values_df.to_excel('4_4_37_SMI1_Tweets_Retweets_Numbers_Item_Values_DF.xlsx', header=True)

print('---')
print('Tweets and Values Retweets: OJO REVISAR')
print(tweets_retweets_numbers_item_values_df.head)
print('---')

# TABLE ## NEED TO DO

# plot.legend()

# Pie 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets with and without Retweets - Pie')
plt.ioff()
plt.pie(tweets_retweets_numbers_item_values_df['total_tweets_with_retweets_number'], colors=colors_blue, labels=tweets_retweets_numbers_item_values_df['total_tweets_with_retweets_number'], startangle=80, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(labels=tweets_retweets_numbers_item_values_df['total_tweets_with_retweets_item'], bbox_to_anchor=(1.05, 1.05), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_35_1_SMI1_Tweets_Retweets_Numbers_Item_Values_df_PLT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets With and Without Retweets - Bars')
plt.ioff()
tweets_retweets_numbers_item_values_df['total_tweets_with_retweets_number'].plot.bar(label='total_tweets_with_retweets_item', alpha=0.9)
# ax.bar(x=tweets_retweets_numbers_item_values_df['total_tweets_with_retweets_item'], y=tweets_retweets_numbers_item_values_df['total_tweets_with_retweets_number'])
# ax.bar(tweets_retweets_numbers_item_values_df['total_tweets_with_retweets_item'], tweets_retweets_numbers_item_values_df['total_tweets_with_retweets_number'])
plt.xlabel('Tweets Without Retweets / Tweets With Retweets')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend(labels=tweets_retweets_numbers_item_values_df['total_tweets_with_retweets_item']) 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_35_1_SMI1_Tweets_Retweets_Numbers_Item_Values_df_PLT_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del tweets_without_retweets
del tweets_with_retweets
del number_tweets_without_retweets
del percentage_tweets_with_retweets
del tweets_retweets_numbers_item_values
del tweets_retweets_numbers_item_values_df

#################################################################################################################
###

# UNIVARIATE DATA ANALYS

print('---')
print('Statistical Summary for Categorical or Text Variables')
# print((tweets_smi_1.describe(include=['O']).T, index=True, index_title='Categorical columns'))
print('---')

# Statistical summary for categorical or string variables will show �count�, �unique�, �top�, and �freq�


# categorical_variables_summary_df = pd.DataFrame((tweets_smi_1.describe(include=['O']).T, index=True, index_title='Categorical columns'))

# categorical_variables_summary_df.to_csv('4_4_36_SMI1_Categorical_Variables_Summary_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# categorical_variables_summary_df.to_excel('4_4_36_SMI1_Categorical_Variables_Summary_DF.xlsx', header=True)

# PLOT TABLE plt.plot ## NEED TO DO


# table_cat_smi_tweets_1 = ff.create_table((tweets_smi_1.describe(include=['O']).T, index=True, index_title='Categorical columns')
# table_cat_smi_tweets_df = pd.DataFrame(table_cat_smi_tweets_1)

# PLOT ## NEED TO DO FIX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Statistical Summary for Categorical - Text Variables')
plt.ioff()
# plt.plot((tweets_smi_1.describe(include=['O']).T, index=True, index_title='Categorical columns'))
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_36_SMI1_DF_Tweets_SMI_Processes_Describe_Cat_Data_1_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO 


# Bars  ## NEED TO DO - FIX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Statistical Summary for Categorical - Text Variables - Bars')
plt.ioff()
# ((tweets_smi_1.describe(include=['O']).T, index=True, index_title='Categorical columns').plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_36_SMI1_DF_Tweets_SMI_Processes_Describe_Cat_Data_1_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('---')
print(main_smi)
print('---')

####################################################################################################################

# Number of Unique Tweets Analized

tweets_smi_1 = tweets_smi_1.reset_index()

print('---')
print('Tweets smi_1 dtypes')
print(tweets_smi_1.dtypes)
print('---')

print('Number of Unique Tweets ')

unique_tweets = tweets_smi_1['text'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 
# total_tweets = tweets_smi_1['url']

number_unique_tweets = len(unique_tweets)
number_unique_tweets 

print('---')
print('Number Unique Tweets')
print(number_unique_tweets)
print('---')


number_repeated_tweets = number_total_tweets - number_unique_tweets

percentage_tweets_unique = ((number_unique_tweets * 100)/number_total_tweets)

# percentage_tweets_repeated = (((number_total_tweets - number_unique_tweets) * 100)/number_total_tweets)

percentage_tweets_repeated = 100 - percentage_tweets_unique

# Inicialize List of Lists

tweets_numbers_item_values = [['Number Repeated Tweets', number_repeated_tweets, percentage_tweets_repeated], ['Number Unique Tweets', number_unique_tweets, percentage_tweets_unique]]

# Create DataFrame

tweets_numbers_item_values_df = pd.DataFrame(tweets_numbers_item_values, columns =['tweets_by_item_description', 'tweets_by_number_value', 'tweets_by_percentage'])

tweets_numbers_item_values_df.to_csv('4_4_37_SMI1_Tweets_Numbers_Item_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_numbers_item_values_df.to_excel('4_4_37_SMI1_Tweets_Numbers_Item_Values_DF.xlsx', header=True)

print('---')
print('Tweets and Values: OJO REVISAR')
print(tweets_numbers_item_values_df.head)
print('---')

# tweets_numbers_item_values_df['tweets_by_number_value'] = np.arange(tweets_numbers_item_values_df['tweets_by_number_value']) ## NEED TO DO FiX

# TABLE ## NEED TO DO

# plot.legend()

# Pie 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Retweets vs Unique Tweets - Pie')
plt.ioff()
plt.pie(tweets_numbers_item_values_df['tweets_by_number_value'], colors=colors_blue, labels=tweets_numbers_item_values_df['tweets_by_item_description'], startangle=80, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweets_numbers_item_values_df['tweets_by_item_description'], loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_37_SMI1_Total_Unique_SMI_Tweets_PLT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Retweets vs Unique Tweets - Bars')
plt.ioff()
tweets_numbers_item_values_df['tweets_by_number_value'].plot.bar(label='tweets_by_item_description')
# ax.bar(x=tweets_numbers_item_values_df['tweets_by_item_description'], y=tweets_numbers_item_values_df['tweets_by_number_value'], alpha=0.9)
# ax.bar(tweets_numbers_item_values_df['tweets_by_item_description'], tweets_numbers_item_values_df['tweets_by_number_value'], alpha=0.9)
plt.xlabel('Repeated Tweets / Retweets / Unique Tweets')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend(labels=tweets_numbers_item_values_df['tweets_by_item_description']) 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_37_SMI1_Total_Unique_SMI_Tweets_PLT_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### DELETE VARIABLE

del tweets_numbers_item_values
del tweets_numbers_item_values_df 

#################################################################################################
#################################################################################################

# METHOD 1 FAVORITES

fp_favorites = tweets_smi_1['favorites'].to_string()

# fp_favorites = fp_favorites_temp.to_string()

tweets_text_favorites = nltk.word_tokenize(fp_favorites)

# value_counts_favorites = pd.value_counts(tweets_text_favorites) 

value_counts_favorites = pd.value_counts(tweets_smi_1['favorites'], ascending=False, normalize=True)

smi1_value_counts_favorites = value_counts_favorites.sort_values(ascending=False)

# smi1_value_counts_favorites_freq_dist = tweets_text_favorites.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Favorites - Frequency')
print(smi1_value_counts_favorites.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Favorites')
# print(smi1_value_counts_favorites.describe().head)
print('---')

smi1_value_counts_favorites_describe = smi1_value_counts_favorites.describe()
smi1_value_counts_favorites_describe_df = pd.DataFrame(smi1_value_counts_favorites_describe, columns=['df_smi1_value_counts_favorites_describe'])

smi1_value_counts_favorites_describe_df.to_csv('4_4_43_100_SMI1_Value_Counts_Favorites_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_favorites_describe_df.to_excel('4_4_43_100_SMI1_Value_Counts_Favorites_Descrobe_DF.xlsx', header=True)

smi1_value_counts_favorites_df = pd.DataFrame(smi1_value_counts_favorites, columns=['favorites_frequency'])

smi1_value_counts_favorites_df.to_csv('4_4_43_100_SMI1_Value_Counts_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_favorites_df.to_excel('4_4_43_100_SMI1_Value_Counts_Favorites_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Value Counts')
plt.ioff()
plt.plot(smi1_value_counts_favorites[:10], alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Favorites_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Value Counts - Pie')
plt.ioff()
smi1_value_counts_favorites[:6].plot(kind='pie', colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True)
plt.legend(smi1_value_counts_favorites, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Favorites_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites Value Counts - Bars')
plt.ioff()
smi1_value_counts_favorites[:10].plot.bar(alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_favorites) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Favorites_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


### DELETE VARIABLE

del fp_favorites
del tweets_text_favorites
# del value_counts_favorites
# del smi1_value_counts_favorites
del smi1_value_counts_favorites_df
del smi1_value_counts_favorites_describe
del smi1_value_counts_favorites_describe_df

####################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Common Tweet Favorites

value_counts_favorites_2 = pd.value_counts(tweets_smi_1['favorites'], ascending=False, normalize=True)

print('---')
print('Most Common Tweets Favorites')
# print(value_counts_favorites_2)
print('---')

###

value_counts_favorites_2_df = pd.DataFrame(value_counts_favorites_2)

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_favorites_2_df.to_csv('4_4_43_75_SMI1_df_Top_Value_Counts_Favorites_2_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_favorites_2_df.to_excel('4_4_43_75_SMI1_df_Top_Value_Counts_Favorites_2.xlsx', index=False, header=True)


value_counts_favorites_2 = value_counts_favorites_2.sort_values(ascending=False)

# NEED TO PLOT TABLE

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()


##### fig1, ax1 = plt.subplots()
###### ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)
######### ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Favorites - Pie') 
plt.ioff()
tweets_smi_1['favorites'].value_counts()[:6].plot(kind='pie', colors=colors_blue, startangle=70, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=True)
# ax1.pie(explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90, colors=colors_blue)
plt.legend(labels=tweets_smi_1['favorites'], bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_75_SMI1_Top_Value_Counts_Favorites_2_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars

# TOP NUMBERS OF Favorites In Tweets 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Favorites - Bars')
plt.ioff()
value_counts_favorites_2[:10].plot.bar(alpha=0.9)
plt.xlabel('Favorites')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_75_SMI1_Top_Value_Counts_Favorites_2_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('---')
print('Value Counts Favorites 2 DF')
# print(value_counts_favorites_2.info)
print('---')

percentage_value_counts_favorites_2 = pd.value_counts(tweets_smi_1['favorites'], normalize=True) * 100


# Inicialize List of Lists

value_counts_favorites_2_item = [['favorites', value_counts_favorites_2, percentage_tweets_repeated]]

# Create DataFrame

value_counts_favorites_2_item_df = pd.DataFrame(value_counts_favorites_2_item, columns =['favorites_number', 'favorites_counts', 'favorites_percentages'])


# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_favorites_2_item_df.to_csv('4_4_43_75_SMI1_Value_Counts_Favorites_2_Item_df_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_favorites_2_item_df.to_excel('4_4_43_75_SMI1_Value_Counts_Favorites_2_Item_df.xlsx', index=False, header=True)

# value_counts_favorites


# NEED TO PLOT TABLE

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Favorites - Pie')
plt.ioff()
# value_counts_favorites_2_item[:6].plot(kind='pie', colors=colors_blue, startangle=120, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.pie(value_counts_favorites_2_item_df, labels=[top_favorites_tweets], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.pie(value_counts_favorites_2_item_df, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend[labels=value_counts_favorites_2_item_df, loc='upper right', borderaxespad=0.) 
# value_counts_favorites_2_item_df.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=value_counts_favorites_2_item_df, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_75_SMI1_Value_Counts_Favorites_2_Item_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars

# TOP NUMBERS OF Favorites In Tweets 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Favorites - Bars')
plt.ioff()
# value_counts_favorites_2_item_df.plot.bar(alpha=0.9)
# plt.xlabel('Favorites')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_43_75_SMI1_Value_Counts_Favorites_2_Item_df_Bars.png', bbox_inches='tight')
# plt.close(fig='all')
# plt.clf()


## DELETE VARIABLE

del value_counts_favorites_2
del value_counts_favorites_2_df
del percentage_value_counts_favorites_2
del value_counts_favorites_2_item
del value_counts_favorites_2_item_df


#############################################################################################
#####

# METHOD 1 RETWEETS

fp_retweets = tweets_smi_1['retweets'].to_string()

# fp_retweets = fp_retweets_temp.to_string()

tweets_text_retweets = nltk.word_tokenize(fp_retweets)

# value_counts_retweets = pd.value_counts(tweets_text_retweets, ascending=False, normalize=True) 

value_counts_retweets_2 = pd.value_counts(tweets_smi_1['retweets'], ascending=False, normalize=True)

smi1_value_counts_retweets_2 = value_counts_retweets_2.sort_values(ascending=False)

# smi1_value_counts_retweets_2_freq_dist = tweets_text_retweets_2.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Retweets 2 - Frequency')
# print(smi1_value_counts_retweets_2)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Retweets')
print(smi1_value_counts_retweets_2.describe().head)
print('---')


smi1_value_counts_retweets_2_describe = smi1_value_counts_retweets_2.describe()

smi1_value_counts_retweets_2_describe_df = pd.DataFrame(smi1_value_counts_retweets_2_describe, columns=['smi1_value_counts_retweets_2_describe'])

smi1_value_counts_retweets_2_describe_df.to_csv('4_4_43_100_SMI1_Value_Counts_Retweets_2_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_retweets_2_describe_df.to_excel('4_4_43_100_SMI1_Value_Counts_Retweets_Describe_2_DF.xlsx', index=True, header=True)


smi1_value_counts_retweets_2_df = pd.DataFrame(smi1_value_counts_retweets_2, columns=['retweets_frequency'])

smi1_value_counts_retweets_2_df.to_csv('4_4_43_100_SMI1_Value_Counts_Retweets_2_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_retweets_2_df.to_excel('4_4_43_100_SMI1_Value_Counts_Retweets_2_DF.xlsx', index=True, header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ReTweet Value Counts')
plt.ioff()
plt.plot(smi1_value_counts_retweets_2[:10], alpha=0.9)
plt.xlabel('Retweets')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Retweets_2_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Retweets Value Count - Pie')
plt.ioff()
smi1_value_counts_retweets_2[:6].plot(kind='pie', colors=colors_blue, startangle=120, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True)
# ax1.pie(explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90, colors=colors_blue)
plt.legend(smi1_value_counts_retweets_2, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Retweets_2_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Retweets Value Count - Bars')
plt.ioff()
smi1_value_counts_retweets_2[:10].plot.bar(alpha=0.9)
plt.xlabel('Retweets')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_100_SMI1_Top_Retweets_2_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################
# https://tutswiki.com/pandas-cookbook/chapter2

# Most Common Tweet Retweets

value_counts_retweets = pd.value_counts(tweets_smi_1['retweets'], ascending=False, normalize=True)

print('---')
print('Most Common Tweets Retweets')
# print(value_counts_retweets)
print('---')

top_favorites_tweets = value_counts_retweets.sort_values(ascending=False)


value_counts_retweets_df = pd.DataFrame(top_favorites_tweets)

print('---')
print('Most Common Tweets Retweets')
# print(value_counts_retweets_df)
print('---')

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_retweets_df.to_csv('4_4_43_76_SMI1_df_Top_Value_Counts_Retweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_retweets_df.to_excel('4_4_43_76_SMI1_df_Top_Value_Counts_Retweets_DF.xlsx', header=True)

# value_counts_favorites


# NEED TO DO PLOT!!!!!!!!!!!!!!!!

# TABLE PLOT

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Retweets - Pie')
plt.ioff()
tweets_smi_1['retweets'].value_counts()[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=True)
# ax1.pie(explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90, colors=colors_blue)
# plt.legend(tweets_smi_1['retweets'], loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_76_SMI1_Top_Retweets_Values_Number_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# NEED TP FOX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Retweets - Bars')
plt.ioff()
tweets_smi_1['retweets'].value_counts()[:6].plot.bar(alpha=0.9)
plt.xlabel('Number of Retweets')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_76_1_SMI1_Top_Retweets_Values_Number_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###

percentage_value_counts_retweets = (value_counts_retweets * 100)/number_total_tweets

# Inicialize List of Lists

value_counts_retweets_item = [['retweets', value_counts_retweets, percentage_tweets_repeated]]

# Create DataFrame

value_counts_retweets_item_df = pd.DataFrame(value_counts_retweets_item, columns =['retweets_number', 'retweets_counts', 'retweets_percentages'])


# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

percentage_value_counts_retweets.to_csv('4_4_43_76_SMI1_Percentage_Value_Counts_Retweets_Item_df_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_retweets_item_df.to_excel('4_4_43_75_SMI1_Percentage_Value_Counts_Retweets_Item_df.xlsx', index=False, header=True)

# value_counts_retweets


# NEED TO PLOT TABLE

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Retweets - Pie')
plt.ioff()
# plt.pie(value_counts_retweets_item_df, labels=[top_retweets_tweets], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend[labels=value_counts_retweets_item_df, loc='upper right', borderaxespad=0.) 
plt.pie(percentage_value_counts_retweets, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# ax1.pie(explode=explode, labels=labels, autopct='%1.1f%%', shadow=False, startangle=90, colors=colors_blue)
# plt.legend(labels=percentage_value_counts_retweets, loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_37_75_SMI1_Value_Counts_Retweets_Item_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Retweets - Bars')
plt.ioff()
# percentage_value_counts_retweets.plot.bar(alpha=0.9)
plt.xlabel('Number of Retweets')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_37_75_2_SMI1_Value_Counts_Retweets_Item_df_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### DELETE VARIABLE

del fp_retweets
del tweets_text_retweets
# del value_counts_retweets
# del smi1_value_counts_retweets
# del smi1_value_counts_retweets_df
# del smi1_value_counts_retweets_describe
# del smi1_value_counts_retweets_describe_df

###############################################################################################
###############################################################################################

# Percentage of 

percentage_value_counts_favorites = ((value_counts_favorites * 100)/number_total_tweets)

print('---')
print('Top Favorites Number Value Counts Percentages')
print(percentage_value_counts_favorites)
print('---')

percentage_value_counts_retweets = ((value_counts_retweets * 100)/number_total_tweets)

print('---')
print('Top Retweets Number Value Counts Percentages')
print(percentage_value_counts_retweets)
print('---')


# NEED TO DO - FIX - CHANGE

# users_favorite_retweet_list = [['Favorites', value_counts_favorites, percentage_value_counts_favorites], ['Retweets', value_counts_retweets, percentage_value_counts_retweets], ['xx', 'xx', 'xx']]
users_favorite_retweet_list = [['favorites_value_counts', value_counts_favorites, percentage_value_counts_favorites], ['retweets_value_counts', value_counts_retweets, percentage_value_counts_retweets]]


# Create the pandas DataFrame 
users_favorite_retweet_list_df = pd.DataFrame(users_favorite_retweet_list, columns = ['description_item_value', 'item_value_count', 'item_value_percentage']) 

print('--------')

print('Top Favorites - Retweets Number Value Counts Percentages DF - NEED TO FIX')
# print(users_favorite_retweet_list_df)
print('--------')

users_favorite_retweet_list_df.to_csv('4_4_37_77_SMI1_Users_Favorite_ReTweet_List_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# users_favorite_retweet_list_df.to_excel('4_4_37_77_SMI1_Users_Favorite_ReTweet_List_DF.xlsx', header=True)

# NEED TO DO PLOT!!!!!!!!!!!!!!!!

# TABLE PLOT

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Retweets - Pie')
plt.ioff()
# plt.pie(users_favorite_retweet_list_df.value_counts()[:6], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(users_favorite_retweet_list_df, loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_37_77_SMI1_Users_Favorite_ReTweet_List_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Retweets - Bars')
plt.ioff()
# users_favorite_retweet_list_df[:6].plot.bar(alpha=0.9)
plt.xlabel('Number of Retweets')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_37_77_3_SMI1_Users_Favorite_ReTweet_List_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del value_counts_favorites
del value_counts_retweets
del percentage_value_counts_favorites
del percentage_value_counts_retweets

##########################################################################################################################
##########################################################################################################################
#########################################################################################################################

# PLOT BARS - MULTIPLE - Tweets ABOUT AND BY SMI ## NEED TO DO - FIX 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

r1 = np.arange(len(tweets_smi_1['favorites'].value_counts()[:10]))
r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES // NEED TO CHANGE NEED TO CHECK FIX !!!!!!!!

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Favorites / Retweets Value Counts - Bars')
plt.ioff()

plt.bar(r1, smi1_value_counts_favorites[:10], color='#73C2FB', edgecolor='white', label='Tweets About', alpha=0.9)
plt.bar(r2, smi1_value_counts_retweets_2[:10], color='blue', edgecolor='white', label='Tweets By Author', alpha=0.9)

plt.xticks(rotation=50)
plt.xlabel('Favorites / Retweets Number')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_37_77_SMI1_Users_Favorite_ReTweet_List_PLT_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIBLE

del r1
del r2
del smi1_value_counts_favorites
del smi1_value_counts_retweets_2


##################################################################################################################
##################################################################################################################
####################################################################################################################
#########################################################################################

# CANDLESTICK GRAPH ######### NEED TO DO - NOT WORKING

candestick_data = tweets_smi_1

# candestick_data.append()

x = 0
y = len(tweets_smi_1['created'])

ohlc = []

# while x, y >> 0:
#	append_candlestick = created[x], Favorites[x], Retweets[x]
#	ohlc.append(append_candlestick) 
#	x+=1

# candlestick_ohlc(ax1, ohlc)

# ax1.xaxis.set.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S))

# plt.figure(figsize=(14,10))

plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Created, Favorited and Retweets - CandleStick')
plt.ioff()
# candlestick_ohlc(ax1, ohlc, width=0.4, colorup='#77d879', colordown='#db3f3f')
# ax1.xaxis.set.set_major_locator(mticker.MaxNLocator(10))
plt.xlabel('Date')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_37_78_SMI1_Date_Fravorites_Retweets_CandleStick.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################
##############################################################

# https://towardsdatascience.com/data-science-with-python-intro-to-loading-and-subsetting-data-with-pandas-9f26895ddd7f

#### TWEETS WITH NO FAVORITES NOT UNIQUE

# SUBSETS

# Number of Tweets With Favorites  ########### NEED TO FIX

tweets_with_favorites = tweets_smi_1[(tweets_smi_1['favorites'] != 0)]  ######### NEED TO ADD CONDITION - NOT WORKING

print('---')
print('Tweets With Favorites Info -- SERIES VALUE')
# print(tweets_with_favorites)
print('---')

tweets_with_favorites_count = tweets_with_favorites.count()

print('---')
print('Tweets With Favorites Count')
print(tweets_with_favorites_count)
print('---')


tweets_without_favorites_filter = tweets_smi_1[(tweets_smi_1['favorites'] == 0)]

# tweets_without_favorites_filter = pd.DataFrame(tweets_without_favorites_filter, columns=['tweets_withput_favorites_filter'])

number_tweets_without_favorites_filter = len(tweets_without_favorites_filter)
number_tweets_without_favorites_filter

print('---')
print('Number of Tweets Without Favorites - FILTER')
# print(number_tweets_without_favorites_filter)
print('---')

percentage_tweets_without_favorites_filter = ((number_tweets_without_favorites_filter * 100)/number_total_tweets)
percentage_tweets_without_favorites_filter

print('---')
print('Percentage of Tweets Without Favorites - Filter')
# print(percentage_tweets_without_favorites_filter)
print('---')

number_tweets_with_favorites_not_unique = number_total_tweets - number_tweets_without_favorites_filter
number_tweets_with_favorites_not_unique

print('---')
print('Number of Tweets With Favorites')
# print(number_tweets_with_favorites_not_unique)
print('---')

percentage_tweets_with_favorites_not_unique = ((number_tweets_with_favorites_not_unique * 100)/number_total_tweets)
percentage_tweets_with_favorites_not_unique

print('---')
print('Percentage of Tweets With Favorites')
# print(percentage_tweets_with_favorites_not_unique)
print('---')

number_tweets_no_favorites = number_total_tweets - number_tweets_with_favorites_not_unique

print('---')
print('Number of Tweets Without Favorites')
# print(number_tweets_no_favorites)
print('---')

percentage_tweets_no_favorites = 100 - percentage_tweets_with_favorites_not_unique

print('---')
print('Percentage of Tweets Without Favorites')
# print(percentage_tweets_no_favorites)
print('---')

# percentage_tweets_retweets
# percentage_tweets_favorites
# percentage_tweets_image_link
# percentage_tweets_emojis_unicode
# percentage_tweets_emojis_converted
# percentage_tweets_languages

##############

# Inicialize List of Lists TWEETS WITH FAVORITES NOT UNIQUES FAVORITES

tweet_info_favorites_not_unique = [['Tweets With Favs', number_tweets_with_favorites_not_unique, percentage_tweets_with_favorites_not_unique], ['Tweets With NO Favs', number_tweets_without_favorites_filter, percentage_tweets_without_favorites_filter]]

# Create DataFrame

tweet_info_favorites_not_unique_df = pd.DataFrame(tweet_info_favorites_not_unique, columns =['tweet_info_favorites_not_unique', 'number_tweet_info_favorites_not_unique', 'percentage_tweet_info_favorites_not_unique'])

print('---')
print('Tweet Info Favorites NOT UNIQUE Information')
# print(tweet_info_favorites_not_unique_df)
print('---')

tweet_info_favorites_not_unique_df.to_csv('4_4_38_SMI1_Tweet_Info_Favorites_Not_Unique_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_favorites_not_unique_df.to_excel('4_4_38_SMI1_Tweet_Info_Favorites_Not_Unique_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets With Favorites Not Unique - Pie')
plt.ioff()
# plt.pie(tweet_info_favorites_df['number_tweet_info_favorites'], labels=tweet_info_favorites_df['tweet_info_favorites'])
plt.pie(tweet_info_favorites_not_unique_df['number_tweet_info_favorites_not_unique'], labels=tweet_info_favorites_not_unique_df['tweet_info_favorites_not_unique'], colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweet_info_favorites_not_unique_df['tweet_info_favorites_not_unique'], loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_38_SMI1_Tweet_Info_Favorites_Not_Unique_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Favorites Counts Not Unique - Bars')
plt.ioff()
tweet_info_favorites_not_unique_df['number_tweet_info_favorites_not_unique'].plot.bar(x=tweet_info_favorites_not_unique_df['number_tweet_info_favorites_not_unique'], alpha=0.9)
# ax.bar(tweet_info_favorites_not_unique_df['tweet_info_favorites_not_unique'], tweet_info_favorites_not_unique_df['number_tweet_info_favorites_not_unique'])
plt.xticks(rotation=50)
plt.xlabel('Tweets With Favorites / Tweets With No Favorites')
plt.ylabel('Count')
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_38_SMI1_Tweet_Info_Favorites_Not_Unique_df_Counts_Bars_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###############################################################################################################

# https://towardsdatascience.com/data-science-with-python-intro-to-loading-and-subsetting-data-with-pandas-9f26895ddd7f

###### TWEETS WITH NO RETWEETS NOT UNIQUE

# SUBSETS

# Number of Tweets With Retweets ALL NOT UNIQUE  ########### NEED TO FIX


tweets_with_retweets = tweets_smi_1[(tweets_smi_1['retweets'] != 0)] ######### NEED TO ADD CONDITION - NOT WORKING

print('---')
print('Tweets With Retweets Info NOT Unique -- SERIES VALUE')
print(tweets_with_retweets)
print('---')

tweets_with_retweets_count = tweets_with_retweets.count()

print('---')
print('Tweets With Retweets Count')
print(tweets_with_retweets_count.head)
print('---')


tweets_without_retweets_filter = tweets_smi_1[(tweets_smi_1['retweets'] != 0)]

# tweets_without_retweets_filter = pd.DataFrame(tweets_without_retweets_filter, columns=['tweets_without_retweets_filter']))

number_tweets_without_retweets_filter = len(tweets_without_retweets_filter)
number_tweets_without_retweets_filter

print('---')
print('Number of Tweets Without Retweets')
print(number_tweets_without_retweets_filter)
print('---')


percentage_tweets_without_retweets_filter = ((number_tweets_without_retweets_filter * 100)/number_total_tweets)
percentage_tweets_without_retweets_filter

print('---')
print('Percentage of Tweets Without Retweets')
# print(percentage_tweets_without_retweets_filter)
print('---')

number_tweets_with_retweets_not_unique = number_total_tweets - number_tweets_without_retweets_filter
number_tweets_with_retweets_not_unique

print('---')
print('Number of Tweets With Retweets - NOT UNIQUE')
print(number_tweets_with_retweets_not_unique)
print('---')

percentage_tweets_with_retweets_not_unique = ((number_tweets_with_retweets_not_unique * 100)/number_total_tweets)
percentage_tweets_with_retweets_not_unique

print('---')
print('Percentage of Tweets With Retweets - NOT UNIQUE')
# print(percentage_tweets_with_retweets_not_unique)
print('---')


##############

# Inicialize List of Lists NOT UNIQUE RETWEETS

tweet_info_retweets_not_unique = [['Tweets With RTs', number_tweets_with_retweets_not_unique, percentage_tweets_with_retweets_not_unique], ['Tweets With NO RTs', number_tweets_without_retweets_filter, percentage_tweets_without_retweets_filter]]

# Create DataFrame

tweet_info_retweets_not_unique_df = pd.DataFrame(tweet_info_retweets_not_unique, columns =['tweet_info_retweets_not_unique', 'number_tweet_info_retweets_not_unique', 'percentage_tweet_info_retweets_not_unique'])

print('---')
print('Tweet Info Retweets NOT UNIQUE Information')
# print(tweet_info_retweets_not_unique_df)
print('---')

tweet_info_retweets_not_unique_df.to_csv('4_4_39_SMI1_Tweet_Info_Retweets_Not_Unique_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_retweets_not_unique_df.to_excel('4_4_39_SMI1_Tweet_Info_Retweets_Not_Unique_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets With Retweets Not Unique - Pie')
plt.ioff()
# plt.pie(tweet_info_retweets_not_unique_df['number_tweets_with_retweets_not_unique'], labels=tweet_info_retweets_df['tweet_info_retweets'])
plt.pie(tweet_info_retweets_not_unique_df['number_tweet_info_retweets_not_unique'], labels=tweet_info_retweets_not_unique_df['tweet_info_retweets_not_unique'], colors=colors_blue, startangle=30, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweet_info_retweets_not_unique_df['tweet_info_retweets_not_unique'], loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_39_SMI1_Tweet_info_Retweets_Not_Unique_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets With Retweets Not Unique - Bars')
plt.ioff()
tweet_info_retweets_not_unique_df['number_tweet_info_retweets_not_unique'].plot.bar(alpha=0.9)
# ax.bar(tweet_info_retweets_not_unique_df['number_tweets_with_retweets_not_unique'], tweet_info_retweets_not_unique_df['percentage_tweets_without_retweets_filter'])
plt.xticks(rotation=50)
plt.xlabel('Tweets With Retweets / Tweets With No Retweets')
plt.ylabel('Count')
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_39_SMI1_Tweet_Info_Retweets_Not_Unique_df_Counts_Bars_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###################################################################################################
###################################################################################################
##############

# Inicialize List of Lists NOT UNIQUE FAVORITES AND RETWEETS

tweet_info_favs_rts_not_unique = [['Tweets With Favs', number_tweets_with_favorites_not_unique, percentage_tweets_with_favorites_not_unique], ['Tweets With NO Favs', number_tweets_without_favorites_filter, percentage_tweets_without_favorites_filter], ['Tweets With RTs', number_tweets_with_retweets_not_unique, percentage_tweets_with_retweets_not_unique], ['Tweets With NO RTs', number_tweets_without_retweets_filter, percentage_tweets_without_retweets_filter]]

# Create DataFrame

tweet_info_favs_rts_not_unique_df = pd.DataFrame(tweet_info_favorites_not_unique, columns =['tweet_info_favs_rts_not_unique', 'number_tweet_info_favs_rts_not_unique', 'percentage_tweet_info_favs_rts_not_unique'])

print('---')
print('Tweet Info Favorites and Retweets NOT UNIQUE Information')
# print(tweet_info_retweets_not_unique_df)
print('---')

tweet_info_favs_rts_not_unique_df.to_csv('4_4_40_SMI1_Tweet_info_Retweets_Not_Unique_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_favs_rts_not_unique_df.to_excel('4_4_40_SMI1_Tweet_info_Retweets_Not_Unique_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# PLOT BARS - MULTIPLE - Tweets FAVORITES AND RETWEETS NOT UNIQUE 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

r1 = np.arange(len(tweet_info_favorites_not_unique_df['number_tweet_info_favorites_not_unique']))
r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets Favorites and Retweets Not Unique - Bars')
plt.ioff()

plt.bar(r1, tweet_info_favorites_not_unique_df['number_tweet_info_favorites_not_unique'], color='#73C2FB', edgecolor='white', label='Favorites', alpha=0.9)
plt.bar(r2, tweet_info_retweets_not_unique_df['number_tweet_info_retweets_not_unique'], color='blue', edgecolor='white', label='Retweets', alpha=0.9)

plt.xticks(rotation=50)
plt.xlabel('With Favorites / Without Favorites / With Retweets / Without Retweets')
plt.ylabel('Count')
plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True)
# plt.show()
plt.savefig('4_4_40_SMI1_Tweet_Info_Favorites_rts_Not_Unique_df_Bar_Plot_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################################################################
###################################################################################################

############################################# UNIQUES FAVORITES AND RETWEETS - NEED TO DO

# DF WITH UNIQUE VALUES TO CHANGE

# UNIQUE TWEETS WITH FAVORITES

tweets_without_favorites_filter = tweets_smi_1[(tweets_smi_1['favorites'] != 0)]

print('---')
print('Tweets with Favorites ALL - NOT Unique Information')
# print(tweets_with_favorites_filter.shape)
print('---')

unique_tweets_with_favorites = tweets_smi_1['text'].unique()
unique_tweets_with_favorites

print('---')
print('Tweet with Favorites Unique Information')
# print(unique_tweets_with_favorites.shape)
print('---')

number_unique_tweets_with_favorites = len(unique_tweets_with_favorites)
number_unique_tweets_with_favorites

print('---')
print('Number of Unique Tweets With Favorites') 
# print(number_unique_tweets_with_favorites)
print('---')

percentage_unique_tweets_with_favorites = ((number_unique_tweets_with_favorites * 100)/number_total_tweets)
percentage_unique_tweets_with_favorites

print('---')
print('Percentage of Unique Tweets With Favorites')
print(percentage_unique_tweets_with_favorites)
print('---')


# TWEETS UNIQUE NO FAVORITES

tweets_without_favorites_filter = tweets_smi_1[(tweets_smi_1['favorites'] == 0)]

print('---')
print('Tweets NO Favorites ALL - NOT Unique Information')
# print(tweets_without_favorites_filter.shape)
print('---')

# unique_tweets_without_number_favorites = tweets_without_favorites['text'].unique() ## NEED TO DO FROM THE FILTERED DATAFRAMES 

unique_tweets_without_favorites = tweets_without_favorites_filter['text'].unique()
unique_tweets_without_favorites

print('---')
print('Tweet Without Favorites Unique Information')
print(unique_tweets_without_favorites.shape)
print('---')

number_unique_tweets_without_favorites = len(unique_tweets_without_favorites)
number_unique_tweets_without_favorites

print('---')
print('Number of Unique Tweets Without Favorites') 
# print(number_unique_tweets_without_favorites)
print('---')

percentage_unique_tweets_without_favorites = ((number_unique_tweets_without_favorites * 100)/number_total_tweets)
percentage_unique_tweets_without_favorites

print('---')
print('Percentage of Unique Tweets Without Favorites')
print(percentage_unique_tweets_without_favorites)
print('---')


############## NEED TO DO FIX - 

# Inicialize List of Lists UNIQUE FAVORITES

tweet_info_unique_tweets_with_favorites = [['Unique With Favorites', number_unique_tweets_with_favorites, percentage_unique_tweets_with_favorites], ['Unique Without Favorites', number_unique_tweets_without_favorites, percentage_unique_tweets_without_favorites]]

# Create DataFrame

tweet_info_unique_tweets_with_favorites_df = pd.DataFrame(tweet_info_unique_tweets_with_favorites, columns =['tweet_info_unique_tweets_with_favorites_description', 'number_unique_tweets_with_favorites', 'percentage_unique_tweets_with_favorites'])

print('---')
print('Tweet Info Favorites UNIQUE Information')
# print(tweet_info_unique_tweets_with_favorites_df)
print('---')

tweet_info_unique_tweets_with_favorites_df.to_csv('4_4_41_SMI1_Tweet_Info_Unique_Tweets_with_Favorites_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_unique_tweets_with_favorites_df.to_excel('4_4_41_SMI1_Tweet_Info_Unique_Tweets_with_Favorites.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets With Favorites Unique - Pie')
plt.ioff()
plt.pie(tweet_info_unique_tweets_with_favorites_df['number_unique_tweets_with_favorites'], labels=tweet_info_unique_tweets_with_favorites_df['tweet_info_unique_tweets_with_favorites_description'], colors=colors_blue, startangle=20, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweet_info_unique_tweets_with_favorites_df['tweet_info_unique_tweets_with_favorites_description'], loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_41_SMI1_Tweet_Info_Unique_Tweets_with_Favorites_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets With Favorites Unique - Bars')
plt.ioff()
tweet_info_unique_tweets_with_favorites_df['number_unique_tweets_with_favorites'].plot.bar(x=tweet_info_unique_tweets_with_favorites_df['tweet_info_unique_tweets_with_favorites_description'], alpha=0.9)
# ax.bar(tweet_info_unique_tweets_with_favorites_df['number_unique_tweets_with_favorites'], tweet_info_unique_tweets_with_favorites_df['number_unique_tweets_without_favorites'])
plt.xticks(rotation=50)
plt.xlabel('Unique Tweets With Favorites / Without Favorites')
plt.ylabel('Count')
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_41_SMI1_Tweet_Info_Unique_Tweets_with_Favorites_df_Counts_Bars_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############ 

# DF WITH UNIQUE VALUES TO CHANGE

# UNIQUE TWEETS WITH RETWEETS

tweets_without_retweets_filter = tweets_smi_1[(tweets_smi_1['retweets'] != 0)]

print('---')
print('Tweets with Retweets ALL - NOT Unique Information')
# print(tweets_with_retweets_filter.shape)
print('---')

# unique_tweets_with_number_retweets = tweets_with_retweets['text'].unique() ## NEED TO DO FROM THE FILTERED DATAFRAMES 

unique_tweets_with_retweets = tweets_without_retweets_filter['text'].unique()
unique_tweets_with_retweets

print('---')
print('Tweet with Retweets Unique Information')
print(unique_tweets_with_retweets.shape)
print('---')

number_unique_tweets_with_retweets = len(unique_tweets_with_retweets)

print('---')
print('Number of Unique Tweets With Retweets') 
print(number_unique_tweets_with_retweets)
print('---')

percentage_unique_tweets_with_retweets = ((number_unique_tweets_with_retweets * 100)/number_total_tweets)

print('---')
print('Percentage of Unique Tweets With Retweets')
print(percentage_unique_tweets_with_retweets)
print('---')


# UNIQUE TWEETS NO RETWEETS

tweets_without_retweets_filter = tweets_smi_1[(tweets_smi_1['retweets'] == 0)]

print('---')
print('Tweet Retweets ALL - NOT Unique Information')
# print(tweets_without_retweets_filter.shape)
print('---')

# unique_tweets_without_number_retweets = tweets_without_retweets['text'].unique() ## NEED TO DO FROM THE FILTERED DATAFRAMES 

unique_tweets_without_retweets = tweets_without_retweets_filter['text'].unique()

print('---')
print('Tweet Without Retweets Unique Information')
print(unique_tweets_without_retweets.shape)
print('---')

number_unique_tweets_without_retweets = len(unique_tweets_without_retweets)


print('---')
print('Number of Unique Tweets Without Retweets') 
# print(number_unique_tweets_without_retweets)
print('---')

percentage_unique_tweets_without_retweets = ((number_unique_tweets_without_retweets * 100)/number_total_tweets)

print('---')
print('Percentage of Unique Tweets Without Retweets')
# print(percentage_unique_tweets_without_retweets)
print('---')


############## NEED TO DO FIX - 

# Inicialize List of Lists UNIQUE Retweets

tweet_info_unique_tweets_with_retweets = [['Unique With Retweets', number_unique_tweets_without_retweets, percentage_unique_tweets_with_retweets], ['Unique Without Retweets', number_unique_tweets_without_retweets, percentage_unique_tweets_without_retweets]]

# Create DataFrame

tweet_info_unique_tweets_with_retweets_df = pd.DataFrame(tweet_info_unique_tweets_with_retweets, columns =['tweet_info_unique_tweets_with_retweets_description', 'number_unique_tweets_with_retweets', 'percentage_unique_tweets_with_retweets'])

print('---')
print('Tweet Info Retweets UNIQUE Information')
# print(tweet_info_unique_tweets_with_retweets_df)
print('---')

tweet_info_unique_tweets_with_retweets_df.to_csv('4_4_42_SMI1_Tweet_Info_unique_tweets_with_retweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_unique_tweets_with_retweets_df.to_excel('4_4_42_SMI1_Tweet_Info_unique_tweets_with_retweets.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets With Retweets Unique - Pie')
plt.ioff()
# plt.pie(tweet_info_retweets_df['number_tweet_info_retweets'], labels=tweet_info_retweets_df['tweet_info_retweets'])
plt.pie(tweet_info_unique_tweets_with_retweets_df['number_unique_tweets_with_retweets'], labels=tweet_info_unique_tweets_with_retweets_df['tweet_info_unique_tweets_with_retweets_description'], colors=colors_blue, startangle=20, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweet_info_unique_tweets_with_retweets_df['tweet_info_unique_tweets_with_retweets_description'], loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_42_SMI1_Tweet_Info_Unique_tweets_with_retweets_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets With Retweets Unique - Bars')
plt.ioff()
tweet_info_unique_tweets_with_retweets_df['number_unique_tweets_with_retweets'].plot.bar(alpha=0.9)
# ax.bar(tweet_info_unique_tweets_with_retweets_df['number_unique_tweets_with_retweets'], tweet_info_unique_tweets_with_retweets_df['number_unique_tweets_without_retweets'])
plt.xticks(rotation=50)
plt.xlabel('Unique Tweets with Retweets / Without Retweets')
plt.ylabel('Count')
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True)
 
# plt.show()
plt.savefig('4_4_42_SMI1_Tweet_Info_Unique_Tweets_with_Retweets_df_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###################################################################################################
###################################################################################################


# Inicialize List of Lists UNIQUE FAVORITES AND RETWEETS

tweet_info_favs_rts_not_unique = [['Unique Tweets With Favs', number_unique_tweets_with_favorites, percentage_unique_tweets_with_favorites], ['Unique Tweets Without Favs', number_unique_tweets_without_favorites, percentage_unique_tweets_without_favorites], ['Unique Tweets with RTs', unique_tweets_with_retweets, percentage_unique_tweets_with_retweets], ['Unique Tweets Without RTs', number_unique_tweets_without_retweets, percentage_unique_tweets_without_retweets]]

# Create DataFrame

tweet_info_favs_rts_not_unique_df = pd.DataFrame(tweet_info_favorites_not_unique, columns =['tweet_info_favs_rts_unique', 'number_tweet_info_favs_rts_unique', 'percentage_tweet_info_favs_rts_unique'])

print('---')
print('Tweet Info Favorites and Retweets UNIQUE Information')
# print(tweet_info_favs_rts_not_unique_df)
print('---')

tweet_info_favs_rts_not_unique_df.to_csv('4_4_43_SMI1_Tweet_Info_Favorites_Retweets_Not_Unique_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_favs_rts_not_unique_df.to_excel('4_4_43_SMI1_Tweet_Info_Favorites_Retweets_Not_Unique_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# PLOT BARS - MULTIPLE - Tweets FAVORITES AND RETWEETS UNIQUE 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

r1 = np.arange(len(tweet_info_unique_tweets_with_favorites_df['number_unique_tweets_with_favorites']))
r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Tweets Favorites and Retweets - Bars')
plt.ioff()

plt.bar(r1, tweet_info_unique_tweets_with_favorites_df['number_unique_tweets_with_favorites'], color='#73C2FB', edgecolor='white', label='Favorites', alpha=0.9)
plt.bar(r2, tweet_info_unique_tweets_with_retweets_df['number_unique_tweets_with_retweets'], color='blue', edgecolor='white', label='Retweets', alpha=0.9)

plt.xticks(rotation=50)
plt.xlabel('Unique With Favorites / Without Favorites / Unique With Retweets / Without Retweets')
plt.ylabel('Count')
plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True)
 
# plt.show()
plt.savefig('4_4_43_SMI1_Tweet_Info_Favorites_Retweets_Not_Unique_DF_Bar_Plot_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del r1
del r2
del number_unique_tweets_with_favorites
# del number_unique_tweets_with_retweets
del tweet_info_unique_tweets_with_favorites_df
# del tweet_info_unique_tweets_with_retweets_df


## DELETE VARIABLE

del tweets_without_retweets_filter
del number_unique_tweets_with_retweets
# del percentage_unique_tweets_with_retweets
del unique_tweets_without_retweets
# del number_unique_tweets_without_retweets
del percentage_unique_tweets_without_retweets
del tweet_info_unique_tweets_with_retweets
# del tweet_info_retweets_df

#########################################################################################################################

# PLOT BARS - MULTIPLE - Tweets ABOUT AND BY SMI ## NEED TO DO - FIX 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

r1 = np.arange(len(tweets_smi_1['year'].unique()))
r2 = [x + barWidth for x in r1]
r3 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES // NEED TO CHANGE

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Total Tweets Favorites Retweets / Year - Multiple Bars')
plt.ioff()

# plt.bar(r1, (tweets_smi_1['favorites'].sum()).groupby(['created']), color='#73C2FB', edgecolor='white', label='Tweets', alpha=0.9)
# plt.bar(r2, (tweets_smi_1['retweets'].sum()).groupby(['created']), color='blue', edgecolor='white', label='Favorites', alpha=0.9)
# plt.bar(r3, (tweets_smi_1['single_tweet'].sum()).groupby(['created']), color='orange', edgecolor='white', label='Retweets', alpha=0.9)

# tweets_about_percentages_df['tweets_about_smi_number'].plot.bar(alpha=0.9)
# ax.bar(tweets_about_percentages_df['tweets_about_smi_item'], tweets_about_percentages_df['tweets_about_smi_number'])
# tweets_by_percentages_df['number_tweets_by'].plot.bar(alpha=0.9)
# ax.bar(x + (2 * barWidth), tweets_by_percentages_df['tweets_by_smi'], tweets_by_percentages_df['number_tweets_by'])
# ax.bar(x + (2 * barWidth), tweets_by_percentages_df['tweets_by_smi'], tweets_by_percentages_df['number_tweets_by'])

plt.xticks(rotation=50)
plt.xlabel('Users Who Tweet / Followers / Friends / Total Users')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_63_SMI1_Bars_Chart_Users_Total_Tweets_Favorites_Retweets_Year_PLT_BARS.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###############################################################################################
###############################################################################################
###############################################################################################
###############################################################################################

# Friends Count FRIEND AND FOLLOWER FOLLOWERS ANALYSIS

# https://www.datacamp.com/community/tutorials/wordcloud-python

tweets_smi_1['followers_count'] = pd.to_numeric(tweets_smi_1['followers_count'])
tweets_smi_1['favorites'] = tweets_smi_1['favorites'].astype(np.int32, errors='ignore')
# tweets_smi_1['retweets'] = tweets_smi_1['retweets'].astype(np.int32, errors='ignore'

print('---')
print('Dtypes followers_count')
print(tweets_smi_1.dtypes)
print('---')

# CENTRALITY MEASURES: SUMMARY STATISTICS

print('Centrality Measures')

# Mean Followers

mean_followers_count = statistics.mean(tweets_smi_1['followers_count'])
# mean_followers_count.pd.astype(np.int32, errors='ignore')

print('---')
print('Mean followers_count')
print(statistics.mean(tweets_smi_1['followers_count']))
print('---')


mean_followers_count_df = pd.DataFrame([mean_followers_count], columns=['mean_followers_count'])

mean_followers_count_df.to_csv('4_4_1_SMI1_Mean_Followers_Count_1_CSV.csv', sep='\t', encoding='utf-8', index=True)
# mean_followers_count_df.to_excel('4_4_1_SMI1_Mean_Followers_Count_1.xlxs', header=True)

# NEED TO DO TABLE PLOT

# BOX PLOT 3 ########## NEED TO FIX  

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale()
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean Followers No Fliers - Box')
plt.ioff()
plt.boxplot(tweets_smi_1['followers_count'], patch_artist=True, vert=False, notch=False, showfliers=False)
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_1_SMI1_Mean_Followers_Count_1_Box_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Median followers_count

median_followers_count = statistics.median(tweets_smi_1['followers_count'])
median_followers_count

print('---')
print('Median followers_count')
print(median_followers_count)
print('---')

median_followers_count_df = pd.DataFrame([median_followers_count], columns=['median_followers_count'])

median_followers_count_df.to_csv('4_4_2_SMI1_Median_Followers_Count_1_CSV.csv', sep='\t', encoding='utf-8', index=True)
# median_followers_count_df.to_excel('4_4_2_SMI1_Median_Followers_Count_1.xlsx', header=True)

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO DO FIX ############### NEED TO FIX PLOT BOX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Median Followers Count - Box')
plt.ioff()
# (statistics.median(tweets_smi_1['followers_count'])).boxplot(grid=True)
# (statistics.median(tweets_smi_1['followers_count'])).plot(kind=box)
# plt.plot(median_followers_count)
# plt.boxplot(statistics.median(tweets_smi_1['followers_count']), vert=False, notch=False, showfliers=False)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_2_SMI1_Median_Followers_Count_Box_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO



##########################################################################################

#################################################################################################################

#################################################################################################################

# SUMMARY OF DESCRIPTIVE STATISTICS followers_count

# describe() returns an object that holds the Following descriptive statistics:

# nobs: the number of observations or elements in your dataset
# minmax: the tuple with the minimum and maximum values of your dataset
# mean: the mean of your dataset // # variance: the variance of your dataset
# skewness: the skewness of your dataset // # kurtosis: the kurtosis of your dataset

print('---')
print('Statistical Summary for Descriptive Statistics followers_count')
print(scipy.stats.describe(tweets_smi_1['followers_count'], ddof=1, bias=False))
print('---')

summ_stats_result_followers_count = scipy.stats.describe(tweets_smi_1['followers_count'], ddof=1, bias=False)

summ_stats_result_followers_count_df = pd.DataFrame(summ_stats_result_followers_count)

# summ_stats_result_followers_count

# summ_stats_result_followers_count_df.to_csv('4_4_22_SMI1_Summ_Stats_Result_followers_count_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# summ_stats_result_followers_count_df.to_excel('4_4_22_SMI1_Summ_Stats_Result_followers_count_DF.xlsx', index=True, header=True) # Only argument is a string of the output file path

print('-- NEED TO DO SUMM STATS TABLE TO CSV')

# PLOT TABLE ################### NEED TO DO PLOT TO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Statistical Summary for Followers')
# plt.plot(summ_stats_result_followers_count)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_22_SMI1_Summ_Stats_Result_followers_count.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')



###################################################################################################################
#
# 	        TOPIC MODELLING : LDA Latent Dirichhlet Allocation
#                                                 
###################################################################################################################

# towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24

print('---')
print('Loading Libs 12')
print('---')

# Word Statistics

word_1 = 'love'
word_2 = 'hate'
word_3 = 'like' # NEED TO ADD LIKED
word_4 = 'brand'
word_5 = 'buy'
word_6 = 'fuck'
word_7 = 'thanks' # NEED TO ADD THANK YOU
word_8 = 'friend'
word_9 = 'follow'
word_10 = 'bitch'
word_11 = 'sister'
word_12 = 'video' # NEED TO ADD VIDEOS
word_13 = 'omg'
word_14 = 'good'
word_15 = 'bad'
word_16 = 'makeup'
word_17 = 'youtube'
word_18 = 'new'
word_19 = 'christmas'
word_20 = 'nigger'
word_21 = 'racist'
word_22 = 'homophobic'
word_23 = 'recommend'
word_24 = 'review'
word_25 = 'share'
word_26 = 'ily'
word_27 = 'feel'



#################################################################################################################

# Measures of Correlation Between Pairs of Data

# You�ll often need to examine the relationship between the corresponding elements of two variables in a dataset. Say there are two variables, ?? and ??, with an equal number of elements, ??. Let ??1 from ?? correspond to ??1 from ??, ??2 from ?? to ??2 from ??, and so on. You can then say that there are ?? pairs of corresponding elements: (??1, ??1), (??2, ??2), and so on.

# You�ll see the Following measures of correlation between pairs of data:

# Positive correlation exists when larger values of ?? correspond to larger values of ?? and vice versa.
# Negative correlation exists when larger values of ?? correspond to smaller values of ?? and vice versa.
# Weak or no correlation exists if there is no such apparent relationship.

# Note: There�s one important thing you should always have in mind when working with correlation among a pair of 
# variables, and that�s that correlation is not a measure or indicator of causation, but only of association!

# The two statistics that measure the correlation between datasets are covariance and the correlation coefficient.

# Covariance

# The sample covariance is a measure that quantifies the strength and direction of a relationship between a pair of 
# variables:

# If the correlation is positive, then the covariance is positive, as well. A stronger relationship corresponds to a 
# higher value of the covariance.
# If the correlation is negative, then the covariance is negative, as well. A stronger relationship corresponds to a 
# lower (or higher absolute) value of the covariance.
# If the correlation is weak, then the covariance is close to zero.

# Covariance matrix:

cov_matrix_followers_count_friends_count = np.cov(tweets_smi_1['followers_count'], tweets_smi_1['friends_count'], bias='False')
cov_matrix_followers_count_friends_count_df = pd.DataFrame(cov_matrix_followers_count_friends_count)

cov_matrix_followers_count_friends_count_df.to_csv('4_4_24_SMI1_Cov_Matrix_Followers_Count_Friends_Count_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# cov_matrix_followers_count_friends_count_df.to_excel('4_4_24_SMI1_Cov_Matrix_followers_count_friends_count_df.xlsx', index=True, header=True) # Only argument is a string of the output file path


print('---')
print('Covariance Matrix for Followers and friends_count')
print(np.cov(tweets_smi_1['followers_count'], tweets_smi_1['friends_count'], bias='False'))
print('---')

# PLOT plt.plot 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Covariance Matrix for Followers and Friends')
plt.plot(cov_matrix_followers_count_friends_count, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
 
# plt.show()
plt.savefig('4_4_24_SMI1_Cov_Matrix_Followers_count_friends_count_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Covariance Matrix for Followers and Friends - Bars')
# cov_matrix_followers_count_friends_count.plot.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_24_SMI1_Cov_Matrix_Followers_Count_Friends_Count_Bars_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELELTE VARIABLE

del cov_matrix_followers_count_friends_count
del cov_matrix_followers_count_friends_count_df

#################################################################################################################

# Correlation Coefficient : Pearson

# The correlation coefficient, or Pearson product-moment correlation coefficient, is denoted by the symbol ??. The 
# coefficient is another measure of the correlation between data. You can think of it as a standardized covariance. 
# Here are some important facts about it:

# The value ?? > 0 indicates positive correlation.
# The value ?? < 0 indicates negative correlation.
# The value r = 1 is the maximum possible value of ??. It corresponds to a perfect positive linear relationship 
# between variables.
# The value r = -1 is the minimum possible value of ??. It corresponds to a perfect negative linear relationship 
# between variables.
# The value r � 0, or when ?? is around zero, means that the correlation between variables is weak.

# pearsonr() returns a tuple with two numbers. The first one is ?? and the second is the ??-value.

corr_coef_followers_count_friends_count_pearson = scipy.stats.pearsonr(tweets_smi_1['followers_count'], tweets_smi_1['friends_count'])

corr_coef_followers_count_friends_count_pearson_df = pd.DataFrame(corr_coef_followers_count_friends_count_pearson)

corr_coef_followers_count_friends_count_pearson_df.to_csv('4_4_25_SMI1_Corr_Coef_Followers_Count_friends_count_pearson_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header='corr_coef_followers_count_friends_count_pearson_df')
# corr_coef_followers_count_friends_count_pearson_df.to_excel()

print('---')
print('Correlation Coefficient: Pearson Followers Count vs Friends Count')
print(corr_coef_followers_count_friends_count_pearson)
print('---')

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4)) 
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient: Pearson Followers vs Friends - Box')
plt.plot(scipy.stats.pearsonr(tweets_smi_1['followers_count'], tweets_smi_1['friends_count']), alpha=0.9)
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_25_SMI1_Corr_Coef_followers_count_friends_count_pearson_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTERPLOT - NEED TO SET DIF COLORS FOR X AND Y!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10)) 
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient: Pearson Followers vs Friends - Scatter')
# (scipy.stats.pearsonr(tweets_smi_1['followers_count'], tweets_smi_1['friends_count'])).plot(alpha=0.9)
# corr_coef_followers_count_friends_count_pearson_df.plot.bars(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_25_SMI1_Corr_Coef_followers_count_friends_count_pearson_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4)) 
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient: Pearson Followers vs Friends - Bars')
# plt.plot(scipy.stats.pearsonr(tweets_smi_1['followers_count'], tweets_smi_1['friends_count']), alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_25_SMI1_Corr_Coef_followers_count_friends_count_pearson_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Correlation Coefficient Matrix

# Similar to the case of the covariance matrix, you can apply np.corrcoef() with x_ and y_ as the arguments and 
# get the correlation coefficient matrix:

corr_matrix_followers_count_friends_count = np.corrcoef(tweets_smi_1['followers_count'], tweets_smi_1['friends_count'])
corr_matrix_followers_count_friends_count_df = pd.DataFrame(corr_matrix_followers_count_friends_count)

print('---')
print('Correlation Coefficient Matrix Followers Count vs friends_count')
print(np.corrcoef(tweets_smi_1['followers_count'], tweets_smi_1['friends_count']))
print('---')

corr_matrix_followers_count_friends_count_df.to_csv('4_4_26_SMI1_Corr_Matrix_Followers_Count_Friends_count_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# corr_matrix_followers_count_friends_count_df.to_excel('4_4_26_SMI1_Corr_Matrix_Followers_Count_Friends_count_DF.xlsx', index=True, header=True) # Only argument is a string of the output file path

# PLOT TABLE plt.plot

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient Matrix Followers vs Friends')
plt.plot(corr_matrix_followers_count_friends_count, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_26_SMI1_Corr_Matrix_Followers_Count_Friends_Count_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Correlation Coefficient Matrix Followers vs Friends - Bars')
# corr_matrix_followers_count_friends_count.plot.bars()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_26_SMI1_Corr_Matrix_Followers_Count_friends_count_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Linear Regession

# inregress() takes x_ and y_, performs linear regression, and returns the results. slope and intercept define the equation of the regression line, while rvalue is the correlation coefficient. To access particular values from the result of linregress(), including the correlation coefficient, use dot notation:

linar_reg_friends_count_followers_count = scipy.stats.linregress(tweets_smi_1['followers_count'], tweets_smi_1['friends_count'])
r_linar_reg_friends_count_followers_count = linar_reg_friends_count_followers_count.rvalue
r_linar_reg_friends_count_followers_count_df = pd.DataFrame([r_linar_reg_friends_count_followers_count])

r_linar_reg_friends_count_followers_count_df.to_csv('Total_Missing_Geo_SMI1_R_Linar_Reg_Friends_Count_Followers_Count_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# r_linar_reg_friends_count_followers_count_d.to_excel()

print('---')
print('Linear Regression Followers Count vs friends_count')
print(scipy.stats.linregress(tweets_smi_1['followers_count'], tweets_smi_1['friends_count']))
print('---')

# PLOT ####### NEED TO FIX DO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale()
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Linear Regression Followers vs Friends')
plt.plot(r_linar_reg_friends_count_followers_count, alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('SMI1_4_4_27_Total_Missing_Geo_SMI1_R_Linar_Reg_Friends_Count_Followers_Count_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Linear Regression Followers vs Friends - Box')
# plt.boxplot(scipy.stats.linregress(tweets_smi_1['followers_count'], tweets_smi_1['friends_count']), patch_artist=True, vert=False, notch=False, showfliers=False)
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_27_SMI1_R_Linar_Reg_Friends_Count_Followers_Count_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# SCATTERPLOT

r_reg_array = scipy.stats.linregress(tweets_smi_1['followers_count'], tweets_smi_1['friends_count'])

## NEED TO DO SCATTERPLOT NEED TO GET FDIF COLORS X AND Y 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10)) 
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Linear Regression Followers vs Friends - Scatter')
plt.plot(scipy.stats.linregress(tweets_smi_1['followers_count'], tweets_smi_1['friends_count']), alpha=0.9)
plt.scatter(tweets_smi_1['followers_count'], tweets_smi_1['friends_count'], alpha=0.9)
plt.plot(r_linar_reg_friends_count_followers_count)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_25_SMI1_Corr_Coef_Followers_Count_Friends_Count_Pearson_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BARS ####### NEED TO FIX DO TABLE

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale()
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Linear Regression Followers vs Friends - Bars')
# r_linar_reg_friends_count_followers_count.bars.plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_27_SMI1_R_Followers_Count_Friends_Count_Linar_Reg_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')


#################################################################################################################
###

# UNIVARIATE DATA ANALYS

print('---')
print('Statistical Summary for Categorical or Text Variables')
# print((tweets_smi_1.describe(include=['O']).T, index=True, index_title='Categorical columns'))
print('---')

# Statistical summary for categorical or string variables will show �count�, �unique�, �top�, and �freq�


# categorical_variables_summary_df = pd.DataFrame((tweets_smi_1.describe(include=['O']).T, index=True, index_title='Categorical columns'))

# categorical_variables_summary_df.to_csv('4_4_36_SMI1_categorical_variables_summary_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# categorical_variables_summary_df.to_excel('4_4_36_SMI1_categorical_variables_summary_DF.xlsx', header=True)

# PLOT TABLE plt.plot ## NEED TO DO


# table_cat_smi_tweets_1 = ff.create_table((tweets_smi_1.describe(include=['O']).T, index=True, index_title='Categorical columns')
# table_cat_smi_tweets_df = pd.DataFrame(table_cat_smi_tweets_1)

# PLOT ## NEED TO DO FIX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Statistical Summary for Categorical or Text Variables')
# plt.plot((tweets_smi_1.describe(include=['O']).T, index=True, index_title='Categorical columns'))
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_36_SMI1_DF_Tweets_smi_Processes_Describe_cat_data_1_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO 


# Bars  ## NEED TO DO - FIX


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Statistical Summary for Categorical or Text Variables - Bars')
# ((tweets_smi_1.describe(include=['O']).T, index=True, index_title='Categorical columns').plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_36_SMI1_DF_Tweets_smi_Processes_Describe_cat_data_1_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('---')
print(main_smi)
print('---')

####################################################################################################################

# Number of Unique Tweets Analized TEXXXXXXXT

print('Number of Unique Tweets ')

unique_tweets = tweets_smi_1['text'].unique()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 
total_tweets = tweets_smi_1['text']

number_unique_tweets = len(unique_tweets)
number_unique_tweets 

print('---')
print('Number Unique Tweets')
print(number_unique_tweets)
print('---')


number_repeated_tweets = number_total_tweets - number_unique_tweets

percentage_tweets_unique = ((number_unique_tweets * 100)/number_total_tweets)

percentage_tweets_repeated = (((number_total_tweets - number_unique_tweets) * 100)/number_total_tweets)

percentage_tweets_repeated = 100 - percentage_tweets_unique

# Inicialize List of Lists

tweets_numbers_item_values = [['Number Repeated Tweets', number_repeated_tweets, percentage_tweets_repeated], ['Number Unique Tweets', number_unique_tweets, percentage_tweets_unique]]

# Create DataFrame

tweets_numbers_item_values_df = pd.DataFrame(tweets_numbers_item_values, columns =['tweets_by_item_description', 'tweets_by_number_value', 'tweets_by_percentage'])

tweets_numbers_item_values_df.to_csv('4_4_37_SMI1_Tweets_Numbers_Item_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_numbers_item_values_df.to_excel('4_4_37_SMI1_Tweets_Numbers_Item_Values_DF.xlsx', header=True)

print('---')
print('Tweets and Values: OJO REVISAR')
print(tweets_numbers_item_values_df.head)
print('---')

# tweets_numbers_item_values_df['tweets_by_number_value'] = np.arange(tweets_numbers_item_values_df['tweets_by_number_value']) ## NEED TO DO FiX

# TABLE ## NEED TO DO

# plot.legend()

# Pie 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Friends vs Unique Tweets - Pie')
plt.pie(tweets_numbers_item_values_df['tweets_by_number_value'], colors=colors_blue, labels=tweets_numbers_item_values_df['tweets_by_item_description'], startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweets_numbers_item_values_df['tweets_by_item_description'], bbox_to_anchor=(0.6, 0.6), loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_37_SMI1_Total_Unique_SMI_Tweets_PLT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number of Friends vs Unique Tweets - Bars')
tweets_numbers_item_values_df['tweets_by_number_value'].plot.bar(label='tweets_by_item_description')
# ax.bar(x=tweets_numbers_item_values_df['tweets_by_item_description'], y=tweets_numbers_item_values_df['tweets_by_number_value'], alpha=0.9)
# ax.bar(tweets_numbers_item_values_df['tweets_by_item_description'], tweets_numbers_item_values_df['tweets_by_number_value'], alpha=0.9)
plt.xlabel('Repeated Tweets / Friends / Unique')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend(labels=tweets_numbers_item_values_df['tweets_by_item_description']) 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_37_SMI1_Total_Unique_SMI_Tweets_PLT_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################
####################################################################################################
#################################################################################################

# TEXT ANALYSTICS IS_FOLLOWERS

fp_followers = tweets_smi_1[(tweets_smi_1['is_follower'] == 'True')]

# METHOD 1 Followers text


fp_followers_text = fp_followers['text'].to_string()

# fp_followers_text = fp_followers_text_temp.to_string()

tweets_text_followers_text = nltk.word_tokenize(fp_followers_text)

value_counts_followers_text = pd.value_counts(tweets_text_followers_text, ascending=False, normalize=True) 

smi1_value_counts_followers_text = value_counts_followers_text.sort_values(ascending=False)

# smi1_value_counts_followers_text_freq_dist = tweets_text_followers_text.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Followers Text - Frequency')
print(smi1_value_counts_followers_text.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Followers text')
# print(smi1_value_counts_followers_text.describe().head)
print('---')

smi1_value_counts_followers_text_df = pd.DataFrame(smi1_value_counts_followers_text, columns=['followers_text_frequency'])

smi1_value_counts_followers_text_df.to_csv('4_4_50_100_SMI1_Value_Counts_Followers_text_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_followers_text_df.to_excel('4_4_50_100_SMI1_Value_Counts_Followers_text_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Text Value Counts')
# plt.plot(smi1_value_counts_followers_text[:10], alpha=0.9)
plt.xlabel('Text')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Text_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(6.5,4.5))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Text Value Counts - Pie')
# plt.pie(smi1_value_counts_followers_text[:6], colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_followers_text, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Text_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Text Value Counts - Bars')
# smi1_value_counts_followers_text[:10].plot.bar(alpha=0.9)
plt.xlabel('Text')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_followers_text) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Text_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################
#####

# METHOD 1 Followers MENTIONS
 

fp_followers_mentions = fp_followers['mentions'].to_string()

# fp_followers_mentions = fp_followers_mentions_temp.to_string()

tweets_text_followers_mentions = nltk.word_tokenize(fp_followers_mentions)

value_counts_followers_mentions = pd.value_counts(tweets_text_followers_mentions, ascending=False, normalize=True) 

smi1_value_counts_followers_mentions = value_counts_followers_mentions.sort_values(ascending=False)

# smi1_value_counts_followers_mentions_freq_dist = tweets_text_followers_mentions.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Followers Mentions - Frequency')
# print(smi1_value_counts_followers_mentions.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Followers Mentions')
# print(smi1_value_counts_followers_mentions.describe().head)
print('---')

smi1_value_counts_followers_mentions_df = pd.DataFrame(smi1_value_counts_followers_mentions, columns=['followers_mentions_frequency'])

smi1_value_counts_followers_mentions_df.to_csv('4_4_50_100_SMI1_Value_Counts_Followers_Mentions_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_followers_mentions_df.to_excel('4_4_50_100_SMI1_Value_Counts_Followers_Mentions_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Mentions Value Counts')
# plt.plot(smi1_value_counts_followers_mentions[:10], alpha=0.9)
plt.xlabel('Mentions')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Mentions_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Mentions Value Counts - Pie')
# plt.pie(smi1_value_counts_followers_mentions[:6], colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_followers_mentions, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Mentions_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Mentions Value Counts - Bars')
# smi1_value_counts_followers_mentions[:10].plot.bar(alpha=0.9)
plt.xlabel('Mentions')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_followers_mentions) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Mentions_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################
#####

# METHOD 1 Followers hashtags


fp_followers_hashtags = fp_followers['hashtags'].to_string()

# fp_followers_hashtags = fp_followers_hashtags_temp.to_string()

tweets_text_followers_hashtags = nltk.word_tokenize(fp_followers_hashtags)

value_counts_followers_hashtags = pd.value_counts(tweets_text_followers_hashtags, ascending=False, normalize=True) 

smi1_value_counts_followers_hashtags = value_counts_followers_hashtags.sort_values(ascending=False)

# smi1_value_counts_followers_hashtags_freq_dist = tweets_text_followers_hashtags.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Followers Hashtags - Frequency')
print(smi1_value_counts_followers_hashtags.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Followers hashtags')
# print(smi1_value_counts_followers_hashtags.describe().head)
print('---')

smi1_value_counts_followers_hashtags_df = pd.DataFrame(smi1_value_counts_followers_hashtags, columns=['followers_hashtags_frequency'])

smi1_value_counts_followers_hashtags_df.to_csv('4_4_50_100_SMI1_Value_Counts_Followers_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_followers_hashtags_df.to_excel('4_4_50_100_SMI1_Value_Counts_Followers_Hashtags_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Hashtags Value Counts')
# plt.plot(smi1_value_counts_followers_hashtags[:10], alpha=0.9)
plt.xlabel('Hashtags')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Hashtags_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Hashtags Value Counts - Pie')
# plt.pie(smi1_value_counts_followers_hashtags[:6], colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_followers_hashtags, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Hashtags_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Hashtags Value Counts - Bars')
# smi1_value_counts_followers_hashtags[:10].plot.bar(alpha=0.9)
plt.xlabel('Hashtags')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_followers_hashtags) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Hashtags_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLES

del smi1_value_counts_followers_hashtags

####################################################################################################
#####

# METHOD 1 Followers emojis_unicode

fp_followers_emojis_unicode = fp_followers['emojis_unicode'].replace('[', '')
fp_followers_emojis_unicode = fp_followers['emojis_unicode'].replace(']', '')
fp_followers_emojis_unicode = fp_followers['emojis_unicode'].replace(',', '')

fp_followers_emojis_unicode = fp_followers['emojis_unicode'].to_string()

# fp_followers_emojis_unicode = fp_followers_emojis_unicode_temp.to_string()

tweets_text_followers_emojis_unicode = nltk.word_tokenize(fp_followers_emojis_unicode)

value_counts_followers_emojis_unicode = pd.value_counts(tweets_text_followers_emojis_unicode, ascending=False, normalize=True) 

smi1_value_counts_followers_emojis_unicode = value_counts_followers_emojis_unicode.sort_values(ascending=False)

# smi1_value_counts_followers_emojis_unicode_freq_dist = tweets_text_followers_emojis_unicode.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Followers emojis_unicode - Frequency')
# print(smi1_value_counts_followers_emojis_unicode.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Followers emojis_unicode')
# print(smi1_value_counts_followers_emojis_unicode.describe().head)
print('---')

smi1_value_counts_followers_emojis_unicode_df = pd.DataFrame(smi1_value_counts_followers_emojis_unicode, columns=['followers_emojis_unicode_frequency'])

smi1_value_counts_followers_emojis_unicode_df.to_csv('4_4_50_100_SMI1_Value_Counts_Followers_Emojis_Unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_followers_emojis_unicode_df.to_excel('4_4_50_100_SMI1_Value_Counts_Followers_Emojis_Unicode_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Emojis Value Counts')
# plt.plot(smi1_value_counts_followers_emojis_unicode[:10], alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Emojis_Unicode_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Emojis Value Counts - Pie')
# plt.pie(smi1_value_counts_followers_emojis_unicode[:6], colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_followers_emojis_unicode, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Emojis_unicode_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Emojis Value Counts - Bars')
# smi1_value_counts_followers_emojis_unicode[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_followers_emojis_unicode) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Emojis_Unicode_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLES

del fp_followers_emojis_unicode

####################################################################################################
#####

# METHOD 1 Followers emojis_converted

fp_followers_emojis_converted = fp_followers['emojis_converted'].to_string()

# fp_followers_emojis_converted = fp_followers_emojis_converted_temp.to_string()

tweets_text_followers_emojis_converted = nltk.word_tokenize(fp_followers_emojis_converted)

# smi1_value_counts_followers_emojis_converted_freq_dist = tweets_text_followers_emojis_converted.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Followers Emojis - Frequency')
# print(smi1_value_counts_followers_emojis_converted.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Followers emojis_converted')
# print(smi1_value_counts_followers_emojis_converted.describe().head)
print('---')


value_counts_followers_emojis_converted = pd.value_counts(tweets_text_followers_emojis_converted, ascending=False, normalize=True) 
smi1_value_counts_followers_emojis_converted = value_counts_followers_emojis_converted.sort_values(ascending=False)

smi1_value_counts_followers_emojis_converted_df = pd.DataFrame(smi1_value_counts_followers_emojis_converted, columns=['followers_emojis_converted_frequency'])

smi1_value_counts_followers_emojis_converted_df.to_csv('4_4_50_100_SMI1_Value_Counts_Followers_Emojis_Converted_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_followers_emojis_converted_df.to_excel('4_4_50_100_SMI1_Value_Counts_Followers_Emojis_Converted_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Emojis Value Counts')
# plt.plot(smi1_value_counts_followers_emojis_converted_df[:10], alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_EMOJIS_Converted_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Emojis Value Counts - Pie')
# smi1_value_counts_followers_emojis_converted[:6].plot(kind='pie', colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_followers_emojis_converted_df, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_EMOJIS_Converted_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Emojis Value Counts - Bars')
# smi1_value_counts_followers_emojis_converted_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_followers_emojis_converted_df) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_EMOJIS_Converted_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLES 

del tweets_text_followers_emojis_converted
del fp_followers_emojis_converted
del smi1_value_counts_followers_emojis_converted
del smi1_value_counts_followers_emojis_converted_df

####################################################################################################
#####

# METHOD 1 Followers language


fp_followers_language = fp_followers['language'].to_string()

# fp_followers_language = fp_followers_language_temp.to_string()

tweets_text_followers_language = nltk.word_tokenize(fp_followers_language)

value_counts_followers_language = pd.value_counts(tweets_text_followers_language, ascending=False, normalize=True) 

smi1_value_counts_followers_language = value_counts_followers_language.sort_values(ascending=False)

# smi1_value_counts_followers_language_freq_dist = tweets_text_followers_language.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Followers language - Frequency')
print(smi1_value_counts_followers_language.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Followers language')
# print(smi1_value_counts_followers_language.describe().head)
print('---')

smi1_value_counts_followers_language_df = pd.DataFrame(smi1_value_counts_followers_language, columns=['followers_language_frequency'])

smi1_value_counts_followers_language_df.to_csv('4_4_50_100_SMI1_Value_Counts_Followers_Language_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_followers_language_df.to_excel('4_4_50_100_SMI1_Value_Counts_Followers_Language_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Language Value Counts')
# plt.plot(smi1_value_counts_followers_language[:10], alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Language_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Language Value Counts - Pie')
# plt.pie(smi1_value_counts_followers_language[:6], colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_followers_language, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Language_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Language Value Counts - Bars')
# smi1_value_counts_followers_language[:10].plot.bar(alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_followers_language) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Language_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################
#####

# METHOD 1 Followers location


fp_followers_location = fp_followers['location'].to_string()

# fp_followers_location = fp_followers_location_temp.to_string()

tweets_text_followers_location = nltk.word_tokenize(fp_followers_location)

value_counts_followers_location = pd.value_counts(tweets_text_followers_location, ascending=False, normalize=True) 

smi1_value_counts_followers_location = value_counts_followers_location.sort_values(ascending=False)

# smi1_value_counts_followers_location_freq_dist = tweets_text_followers_location.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Followers location - Frequency')
print(smi1_value_counts_followers_location.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Followers location')
# print(smi1_value_counts_followers_location.describe().head)
print('---')

smi1_value_counts_followers_location_df = pd.DataFrame(smi1_value_counts_followers_location, columns=['followers_location_frequency'])

smi1_value_counts_followers_location_df.to_csv('4_4_50_100_SMI1_Value_Counts_Followers_Location_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_followers_location_df.to_excel('4_4_50_100_SMI1_Value_Counts_Followers_Location_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Location Value Counts')
# plt.plot(smi1_value_counts_followers_location[:10], alpha=0.9)
plt.xlabel('Location')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Location_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Location Value Counts - Pie')
# smi1_value_counts_followers_location[:6].plot(kind='pie', colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_followers_location, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Location_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Followers Location Value Counts - Bars')
# smi1_value_counts_followers_location[:10].plot.bar(alpha=0.9)
plt.xlabel('Location')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_followers_location) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Followers_Location_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################
#################################################################################################

# TEXT ANALYSTICS is_friend

fp_is_friend = tweets_smi_1[(tweets_smi_1['is_friend'] == 'True')]

# METHOD 1 is_friend text


fp_is_friend_text = fp_is_friend['text'].to_string()

# fp_is_friend_text = fp_is_friend_text_temp.to_string()

tweets_text_is_friend_text = nltk.word_tokenize(fp_is_friend_text)

value_counts_is_friend_text = pd.value_counts(tweets_text_is_friend_text, ascending=False, normalize=True) 

smi1_value_counts_is_friend_text = value_counts_is_friend_text.sort_values(ascending=False)

# smi1_value_counts_is_friend_text_freq_dist = tweets_text_is_friend_text.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts is_friend Text - Frequency')
print(smi1_value_counts_is_friend_text.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts is_friend text')
# print(smi1_value_counts_is_friend_text.describe().head)
print('---')

smi1_value_counts_is_friend_text_df = pd.DataFrame(smi1_value_counts_is_friend_text, columns=['is_friend_text_frequency'])

smi1_value_counts_is_friend_text_df.to_csv('4_4_50_100_SMI1_Value_Counts_is_friend_Text_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_is_friend_text_df.to_excel('4_4_50_100_SMI1_Value_Counts_is_friend_Text_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Text Value Counts')
# plt.plot(smi1_value_counts_is_friend_text[:10], alpha=0.9)
plt.xlabel('Text')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_Text_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Text Value Counts - Pie')
# smi1_value_counts_is_friend_text[:6].plot(kind='pie', colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.3, labeldistance=1.7, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_is_friend_text, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_Text_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Text Value Counts - Bars')
# smi1_value_counts_is_friend_text[:10].plot.bar(alpha=0.9)
plt.xlabel('Text')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_is_friend_text) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_Text_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################
#####

# METHOD 1 is_friend MENTIONS
 

fp_is_friend_mentions = fp_is_friend['mentions'].to_string()

# fp_is_friend_mentions = fp_is_friend_mentions_temp.to_string()

tweets_text_is_friend_mentions = nltk.word_tokenize(fp_is_friend_mentions)

value_counts_is_friend_mentions = pd.value_counts(tweets_text_is_friend_mentions, ascending=False, normalize=True) 

smi1_value_counts_is_friend_mentions = value_counts_is_friend_mentions.sort_values(ascending=False)

# smi1_value_counts_is_friend_mentions_freq_dist = tweets_text_is_friend_mentions.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts is_friend Mentions - Frequency')
print(smi1_value_counts_is_friend_mentions.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts is_friend Mentions')
# print(smi1_value_counts_is_friend_mentions.describe().head)
print('---')

smi1_value_counts_is_friend_mentions_df = pd.DataFrame(smi1_value_counts_is_friend_mentions, columns=['is_friend_mentions_frequency'])

smi1_value_counts_is_friend_mentions_df.to_csv('4_4_50_100_SMI1_Value_Counts_is_Friend_Mentions_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_is_friend_mentions_df.to_excel('4_4_50_100_SMI1_Value_Counts_is_Friend_Mentions_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Mentions Value Counts')
# plt.plot(smi1_value_counts_is_friend_mentions[:10], alpha=0.9)
plt.xlabel('Mentions')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_Mentions_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Mentions Value Counts - Pie')
# smi1_value_counts_is_friend_mentions[:6].plot(kind='pie', colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_is_friend_mentions, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_Mentions_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Mentions Value Counts - Bars')
# smi1_value_counts_is_friend_mentions[:10].plot.bar(alpha=0.9)
plt.xlabel('Mentions')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_is_friend_mentions) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_Mentions_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################
#####

# METHOD 1 is_friend hashtags


fp_is_friend_hashtags = fp_is_friend['hashtags'].to_string()

# fp_is_friend_hashtags = fp_is_friend_hashtags_temp.to_string()

tweets_text_is_friend_hashtags = nltk.word_tokenize(fp_is_friend_hashtags)

value_counts_is_friend_hashtags = pd.value_counts(tweets_text_is_friend_hashtags, ascending=False, normalize=True) 

smi1_value_counts_is_friend_hashtags = value_counts_is_friend_hashtags.sort_values(ascending=False)

# smi1_value_counts_is_friend_hashtags_freq_dist = tweets_text_is_friend_hashtags.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts is_friend Hashtags - Frequency')
print(smi1_value_counts_is_friend_hashtags.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts is_friend hashtags')
# print(smi1_value_counts_is_friend_hashtags.describe().head)
print('---')

smi1_value_counts_is_friend_hashtags_df = pd.DataFrame(smi1_value_counts_is_friend_hashtags, columns=['is_friend_hashtags_frequency'])

smi1_value_counts_is_friend_hashtags_df.to_csv('4_4_50_100_SMI1_Value_Counts_is_Friend_Hashtags_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_is_friend_hashtags_df.to_excel('4_4_50_100_SMI1_Value_Counts_is_Friend_Hashtags_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Hashtags Value Counts')
# plt.plot(smi1_value_counts_is_friend_hashtags[:10], alpha=0.9)
plt.xlabel('Hashtags')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_friend_Hashtags_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Hashtags Value Counts - Pie')
# smi1_value_counts_is_friend_hashtags[:6].plot(kind='pie', colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_is_friend_hashtags, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_Hashtags_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Hashtags Value Counts - Bars')
# smi1_value_counts_is_friend_hashtags[:10].plot.bar(alpha=0.9)
plt.xlabel('Hashtags')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_is_friend_hashtags) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_Hashtags_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### DELETE VARIABLE

del smi1_value_counts_is_friend_hashtags

####################################################################################################
#####

# METHOD 1 is_friend emojis_unicode


fp_is_friend_emojis_unicode = fp_is_friend['emojis_unicode'].to_string()

# fp_is_friend_emojis_unicode = fp_is_friend_emojis_unicode_temp.to_string()

tweets_text_is_friend_emojis_unicode = nltk.word_tokenize(fp_is_friend_emojis_unicode)

value_counts_is_friend_emojis_unicode = pd.value_counts(tweets_text_is_friend_emojis_unicode, ascending=False, normalize=True) 

smi1_value_counts_is_friend_emojis_unicode = value_counts_is_friend_emojis_unicode.sort_values(ascending=False)

# smi1_value_counts_is_friend_emojis_unicode_freq_dist = tweets_text_is_friend_emojis_unicode.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts is_friend emojis_unicode - Frequency')
print(smi1_value_counts_is_friend_emojis_unicode.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts is_friend emojis_unicode')
# print(smi1_value_counts_is_friend_emojis_unicode.describe().head)
print('---')

smi1_value_counts_is_friend_emojis_unicode_df = pd.DataFrame(smi1_value_counts_is_friend_emojis_unicode, columns=['is_friend_emojis_unicode_frequency'])

smi1_value_counts_is_friend_emojis_unicode_df.to_csv('4_4_50_100_SMI1_Value_Counts_is_Friend_Emojis_Unicode_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_is_friend_emojis_unicode_df.to_excel('4_4_50_100_SMI1_Value_Counts_is_Friend_Emojis_Unicode_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Emojis Value Counts')
# plt.plot(smi1_value_counts_is_friend_emojis_unicode[:10], alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_EMOJIS_Unicode_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Emojis Value Counts - Pie')
# smi1_value_counts_is_friend_emojis_unicode[:6].plot(kind='pie', colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_is_friend_emojis_unicode, loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_EMOJIS_Unicode_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Emojis Value Counts - Bars')
# smi1_value_counts_is_friend_emojis_unicode[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_is_friend_emojis_unicode) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_EMOJIS_Unicode_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################
#####

# METHOD 1 is_friend emojis_converted


fp_is_friend_emojis_converted = fp_is_friend['emojis_converted'].to_string()

# fp_is_friend_emojis_converted = fp_is_friend_emojis_converted_temp.to_string()

tweets_text_is_friend_emojis_converted = nltk.word_tokenize(fp_is_friend_emojis_converted)

value_counts_is_friend_emojis_converted = pd.value_counts(tweets_text_is_friend_emojis_converted, ascending=False, normalize=True) 

smi1_value_counts_is_friend_emojis_converted = value_counts_is_friend_emojis_converted.sort_values(ascending=False)

# smi1_value_counts_is_friend_emojis_converted_freq_dist = tweets_text_is_friend_emojis_converted.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts is_friend Emojis - Frequency')
print(smi1_value_counts_is_friend_emojis_converted.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts is_friend Emojis Converted')
# print(smi1_value_counts_is_friend_emojis_converted.describe().head)
print('---')

smi1_value_counts_is_friend_emojis_converted_df = pd.DataFrame(smi1_value_counts_is_friend_emojis_converted, columns=['is_friend_emojis_converted_frequency'])

smi1_value_counts_is_friend_emojis_converted_df.to_csv('4_4_50_100_SMI1_Value_Counts_is_Friend_Emojis_Converted_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_is_friend_emojis_converted_df.to_excel('4_4_50_100_SMI1_Value_Counts_is_Friend_Emojis_Converted_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Emojis Value Counts')
# plt.plot(smi1_value_counts_is_friend_emojis_converted[:10], alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_EMOJIS_Converted_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Emojis Value Counts - Pie')
# smi1_value_counts_is_friend_emojis_converted[:6].plot(kind='pie', colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_is_friend_emojis_converted, loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_friend_EMOJIS_Converted_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Emojis Value Counts - Bars')
# smi1_value_counts_is_friend_emojis_converted[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_is_friend_emojis_converted) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_EMOJIS_Converted_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################
#####

# METHOD 1 is_friend language


fp_is_friend_language = fp_is_friend['language'].to_string()

# fp_is_friend_language = fp_is_friend_language_temp.to_string()

tweets_text_is_friend_language = nltk.word_tokenize(fp_is_friend_language)

value_counts_is_friend_language = pd.value_counts(tweets_text_is_friend_language, ascending=False, normalize=True) 

smi1_value_counts_is_friend_language = value_counts_is_friend_language.sort_values(ascending=False)

# smi1_value_counts_is_friend_language_freq_dist = tweets_text_is_friend_language.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts is_friend language - Frequency')
print(smi1_value_counts_is_friend_language.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts is_friend Language')
# print(smi1_value_counts_is_friend_language.describe().head)
print('---')

smi1_value_counts_is_friend_language_df = pd.DataFrame(smi1_value_counts_is_friend_language, columns=['is_friend_language_frequency'])

smi1_value_counts_is_friend_language_df.to_csv('4_4_50_100_SMI1_Value_Counts_is_friend_language_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_is_friend_language_df.to_excel('4_4_50_100_SMI1_Value_Counts_is_friend_language_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Language Value Counts')
# plt.plot(smi1_value_counts_is_friend_language[:10], alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_Language_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Language Value Counts - Pie')
# smi1_value_counts_is_friend_language[:6].plot(kind='pie', colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.7, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_is_friend_language, loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_Language_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Language Value Counts - Bars')
# smi1_value_counts_is_friend_language[:10].plot.bar(alpha=0.9)
plt.xlabel('Language')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_is_friend_language) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_Language_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################
#####

# METHOD 1 is_friend location


fp_is_friend_location = fp_is_friend['location'].to_string()

# fp_is_friend_location = fp_is_friend_location_temp.to_string()

tweets_text_is_friend_location = nltk.word_tokenize(fp_is_friend_location)

value_counts_is_friend_location = pd.value_counts(tweets_text_is_friend_location, ascending=False, normalize=True) 

smi1_value_counts_is_friend_location = value_counts_is_friend_location.sort_values(ascending=False)

# smi1_value_counts_is_friend_location_freq_dist = tweets_text_is_friend_location.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts is_friend location - Frequency')
print(smi1_value_counts_is_friend_location.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts is_friend location')
# print(smi1_value_counts_is_friend_location.describe().head)
print('---')

smi1_value_counts_is_friend_location_df = pd.DataFrame(smi1_value_counts_is_friend_location, columns=['is_friend_location_frequency'])

smi1_value_counts_is_friend_location_df.to_csv('4_4_50_100_SMI1_Value_Counts_is_friend_location_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_is_friend_location_df.to_excel('4_4_50_100_SMI1_Value_Counts_is_friend_location_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Location Value Counts')
# plt.plot(smi1_value_counts_is_friend_location[:10], alpha=0.9)
plt.xlabel('Location')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_Location_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Location Value Counts - Pie')
# smi1_value_counts_is_friend_location[:6].plot(kind='pie', colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_is_friend_location, loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_Location_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top is Friend Location Value Counts - Bars')
# smi1_value_counts_is_friend_location[:10].plot.bar(alpha=0.9)
plt.xlabel('Location')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_is_friend_location) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_is_Friend_Location_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################
####################################################################################################
####################################################################################################
####################################################################################################
####################################################################################################
####################################################################################################
####################################################################################################
####################################################################################################
####################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Common Tweet Followers_count

value_followers_count = pd.value_counts(tweets_smi_1['followers_count'], ascending=False, normalize=True)

print('---')
print('Most Common Tweets value_followers_count')
print(value_followers_count.head)
print('---')


# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_followers_count.to_csv('4_4_50_75_SMI1_df_Top_Value_Followers_Count_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_followers_count.to_excel('4_4_50_75_SMI1_df_Top_Value_Followers_Count.xlsx', index=False, header=True)

# value_followers_count

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Value Followers Count')
plt.plot(value_followers_count[:10], alpha=0.9)
plt.xlabel('Followers')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Value_Followers_Count_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# NEED TO PLOT TABLE

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Value Followers Count - Pie')
plt.pie(value_followers_count[:6], labels=value_followers_count[:6], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.5, labeldistance=1.9, radius=1.0, rotatelabels=False)
# plt.legend([labels=top_followers_tweets], loc='upper right', borderaxespad=0.) 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_75_SMI1_Top_Value_Followers_Count_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Value Followers Count - Bars')
value_followers_count[:10].plot.bar(alpha=0.9)
plt.xlabel('Followers')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Value_Followers_Count_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



####################################################

value_followers_count = pd.DataFrame(value_followers_count)

print('---')
print('value_followers_count DF')
# print(value_followers_count.info)
print('---')

percentage_value_followers_count = pd.value_counts(tweets_smi_1['followers_count'], normalize=True) * 100


# Inicialize List of Lists

value_followers_count_item = [['followers_count', value_followers_count, percentage_tweets_repeated]]

# Create DataFrame

value_followers_count_item_df = pd.DataFrame(value_followers_count_item, columns =['followers_number', 'followers_counts', 'followers_percentages'])


# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_followers_count_item_df.to_csv('4_4_50_75_SMI1_value_followers_count_item_df_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_followers_count_item_df.to_excel('4_4_50_75_SMI1_value_followers_count_item_df.xlsx', index=False, header=True)

# value_followers_count


# NEED TO PLOT TABLE

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Value Followers - Pie')
# plt.pie(value_followers_count_item_df[:6], labels=[top_followers_tweets], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend[labels=value_followers_count_item_df[:6], loc='upper right', borderaxespad=0.) 
# value_followers_count_item_df.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=value_followers_count_item_df, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_75_SMI1_Value_Followers_Count_Item_df_Pie_Chart_PLT.png', bbox_inches='tight')
# plt.close(fig='all')
# plt.clf()


# Bars

# TOP NUMBERS OF Followers In Tweets 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Value Followers - Bars')
# value_followers_count_item_df[:10].plot.bar(alpha=0.9)
# plt.xlabel('Number of Followers')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_50_75_SMI1_value_followers_count_item_df_Bars.png', bbox_inches='tight')
# plt.close(fig='all')
# plt.clf()

#############################################################################################

#####

# METHOD 1 friends

fp_friend_count = tweets_smi_1['friends_count'].to_string()

# fp_friends = fp_friends_temp.to_string()

tweets_text_friend_count = nltk.word_tokenize(fp_friend_count)

tweets_text_friend_count_values = pd.value_counts(tweets_text_friend_count, ascending=False, normalize=True) 

smi1_tweets_text_friend_count_values = tweets_text_friend_count_values.sort_values(ascending=False)

print('----')
print('tweets_text_friend_count_values')
# print(tweets_text_friend_count_values)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - tweets_text_friend_count_values')
# print(tweets_text_friend_count_values.describe().head)
print('---')

tweets_text_friend_count_values_df = pd.DataFrame(tweets_text_friend_count_values, columns=['tweets_text_friend_count_values'])

tweets_text_friend_count_values_df.to_csv('4_4_50_100_SMI1_Tweets_Text_Friend_Count_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# tweets_text_friend_count_values_df.to_excel('4_4_50_100_SMI1_Tweets_Text_Friend_Count_Values_DF.xlsx', index=True, header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Friends Value Count')
plt.plot(tweets_text_friend_count_values[:10], alpha=0.9)
plt.xlabel('Friends')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_50_100_SMI1_Tweets_Text_Friend_Count_Values_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Friends Value Count - Pie')
tweets_text_friend_count_values[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.3, labeldistance=1.6, radius=1.0, rotatelabels=True)
# plt.legend(tweets_text_friend_count_values, loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Tweets_Text_Friend_Count_Values_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Friends Value Count - Bars')
tweets_text_friend_count_values[:10].plot.bar(alpha=0.9)
plt.xlabel('Friends')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Tweets_Text_Friend_Count_Values_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# https://tutswiki.com/pandas-cookbook/chapter2


# Most Common Tweet Friends

value_counts_friends = pd.value_counts(tweets_smi_1['friends_count'], ascending=False, normalize=True)

print('---')
print('Most Common Tweets Friends')
# print(value_counts_friends)
print('---')

value_counts_friends_df = pd.DataFrame(value_counts_friends)

print('---')
print('Most Common Tweets Friends')
# print(value_counts_friends_df)
print('---')

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_friends.to_csv('4_4_50_76_SMI1_df_Top_Value_Counts_friends_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_friends.to_excel('4_4_50_76_SMI1_df_Top_Value_Counts_friends.xlsx', header=True)

# value_followers_count


# NEED TO DO PLOT!!!!!!!!!!!!!!!!

# TABLE PLOT

# Pie

# plt.rcdefaults()
# fig, ax = plt.subplots(1, 1)
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Friends - Pie')
# tweets_smi_1['friends_count'].value_counts()[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['friends_count'], bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
# plt.savefig('4_4_50_76_SMI1_Top_Friends_Values_Number_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# NEED TP FOX

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Friends - Bars')
tweets_smi_1['friends_count'].value_counts()[:6].plot.bar(alpha=0.9)
plt.xlabel('Number of Friends')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_76_SMI1_Top_Friends_Values_Number_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###


percentage_value_counts_friends = (value_counts_friends * 100)/number_total_tweets

# Inicialize List of Lists

value_counts_friends_item = [['friends_count', value_counts_friends, percentage_tweets_repeated]]

# Create DataFrame

value_counts_friends_item_df = pd.DataFrame(value_counts_friends_item, columns =['friends_number', 'friends_counts', 'friends_percentages'])


# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

percentage_value_counts_friends.to_csv('4_4_50_76_SMI1_Value_Counts_Friends_Item_df_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_friends_item_df.to_excel('4_4_50_75_SMI1_Value_Counts_Friends_Item_df.xlsx', index=False, header=True)

# value_counts_friends


# NEED TO PLOT TABLE

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Friends - Pie')
# plt.pie(value_counts_friends_item_df, labels=[top_friends_tweets], colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend[labels=value_counts_friends_item_df, loc='upper right', borderaxespad=0.) 
# percentage_value_counts_friends.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=percentage_value_counts_friends, loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_75_SMI1_Value_Counts_Friends_item_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Friends - Bars')
# percentage_value_counts_friends.plot.bar(alpha=0.9)
plt.xlabel('Number of Friends')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_75_SMI1_Value_Counts_Friends_Item_df_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#############################################################################################
###########################################################################################################################################################

# Percentage of 

value_followers_count

value_counts_friends

percentage_value_followers_count = ((value_followers_count * 100)/number_total_tweets)
percentage_value_followers_count

print('---')
print('Top Followers Number Value Counts Percentages')
print(percentage_value_followers_count)
print('---')

percentage_value_counts_friends = ((value_counts_friends * 100)/number_total_tweets)
percentage_value_counts_friends

print('---')
print('Top Friends value_followers_count Percentages')
print(percentage_value_counts_friends)
print('---')


# NEED TO DO - FIX - CHANGE

# users_followers_friends_list = [['followers_count', value_followers_count, percentage_value_followers_count], ['friends_count', value_counts_friends, percentage_value_counts_friends], ['xx', 'xx', 'xx']]
users_followers_friends_list = [['followers_value_counts', value_followers_count, percentage_value_followers_count], ['friends_value_counts', value_counts_friends, percentage_value_counts_friends]]


# Create the pandas DataFrame 
users_followers_friends_list_df = pd.DataFrame(users_followers_friends_list, columns = ['description_item_value', 'item_value_count', 'item_value_percentage']) 

print('--------')
print('Top Followers - Friends Number Value Counts Percentages DF - NEED TO FIX')
# print(users_followers_retweet_list_df)
print('--------')

users_followers_friends_list_df.to_csv('4_4_50_77_Users_followers_friends_list_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# users_followers_friends_list_df.to_excel('4_4_50_77_Users_followers_friends_list_DF.xlsx', header=True)

# NEED TO DO PLOT!!!!!!!!!!!!!!!!

top_friends_tweets = value_counts_friends.sort_values(ascending=False)



# TABLE PLOT

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Values of Friends - Bars')
top_friends_tweets[:10].plot(alpha=0.9)
plt.xlabel('Number of Friends')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_77_SMI1_Top_Friends_Values_Number_PLot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Friends - Pie')
# top_friends_tweets[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
# plt.legend(users_followers_friends_list_df, loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
# plt.savefig('4_4_50_77_SMI1_Top_Friends_Values_Number_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Friends - Bars')
top_friends_tweets[:6][:6].plot.bar(alpha=0.9)
plt.xlabel('Number of Friends')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_77_SMI1_Top_Friends_Values_Number_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###########################################################################################


# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Values of Friends - Bars')
# users_followers_friends_list_df[:10].plot(alpha=0.9)
plt.xlabel('Number of Friends')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_77_Top_Users_Followers_Friends_List_df_Number_PLot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# TABLE PLOT

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Friends - Pie')
# users_followers_friends_list_df[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
# plt.legend(users_followers_friends_list_df, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_77_SMI1_Top_Users_Followers_Friends_List_df_Number_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Friends - Bars')
# users_followers_friends_list_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Number of Friends')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_77_SMI1_Top_Users_Followers_Friends_List_Number_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()




#################################################################################################################
##############################################################

# https://towardsdatascience.com/data-science-with-python-intro-to-loading-and-subsetting-data-with-pandas-9f26895ddd7f

#### Users with NO Followers NOT UNIQUE

# SUBSETS

# Number of Users with Followers  ########### NEED TO FIX

tweets_with_followers = tweets_smi_1[(tweets_smi_1['followers_count'] != 0)]  ######### NEED TO ADD CONDITION - NOT WORKING

print('---')
print('Users with Followers Info -- SERIES VALUE')
# print(tweets_with_followers)
print('---')

tweets_with_followers_count = tweets_with_followers.count()

print('---')
print('Users with Followers Count')
print(tweets_with_followers_count)
print('---')


tweets_without_followers_filter = tweets_smi_1[(tweets_smi_1['followers_count'] == 0)]

# tweets_without_followers_filter = pd.DataFrame(tweets_without_followers_filter, columns=['tweets_withput_followers_filter'])

number_tweets_without_followers_filter = len(tweets_without_followers_filter)
number_tweets_without_followers_filter

print('---')
print('Number of Users without Followers - FILTER')
# print(number_tweets_without_followers_filter)
print('---')

percentage_tweets_without_followers_filter = ((number_tweets_without_followers_filter * 100)/number_total_tweets)
percentage_tweets_without_followers_filter

print('---')
print('Percentage of Users without Followers - Filter')
# print(percentage_tweets_without_followers_filter)
print('---')

number_tweets_with_followers_not_unique = number_total_tweets - number_tweets_without_followers_filter
number_tweets_with_followers_not_unique

print('---')
print('Number of Users with Followers ')
# print(number_tweets_with_followers_not_unique)
print('---')

percentage_tweets_with_followers_not_unique = ((number_tweets_with_followers_not_unique * 100)/number_total_tweets)
percentage_tweets_with_followers_not_unique

print('---')
print('Percentage of Users with Followers ')
# print(percentage_tweets_with_followers_not_unique)
print('---')

number_tweets_no_followers = number_total_tweets - number_tweets_with_followers_not_unique

print('---')
print('Number of Users without Followers ')
print(number_tweets_no_followers)
print('---')

percentage_tweets_no_followers = 100 - percentage_tweets_with_followers_not_unique

print('---')
print('Percentage of Users without Followers ')
# print(percentage_tweets_no_followers)
print('---')

##############

# Inicialize List of Lists Users with Followers NOT UNIQUES Followers

tweet_info_followers_not_unique = [['Users with Followers', number_tweets_with_followers_not_unique, percentage_tweets_with_followers_not_unique], ['Users with NO Followers', number_tweets_without_followers_filter, percentage_tweets_without_followers_filter]]

# Create DataFrame

tweet_info_followers_not_unique_df = pd.DataFrame(tweet_info_followers_not_unique, columns =['tweet_info_followers_not_unique', 'number_tweet_info_followers_not_unique', 'percentage_tweet_info_followers_not_unique'])

print('---')
print('Tweet Info Followers NOT UNIQUE Information')
# print(tweet_info_followers_not_unique_df)
print('---')

tweet_info_followers_not_unique_df.to_csv('4_4_38_SMI1_Tweet_Info_Followers_Not_Unique_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_followers_not_unique_df.to_excel('4_4_38_SMI1_Tweet_Info_Followers_Not_Unique_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Users with Followers Not Unique - Pie')
# plt.pie(tweet_info_followers_df['number_tweet_info_followers'], labels=tweet_info_followers_df['tweet_info_followers'])
plt.pie(tweet_info_followers_not_unique_df['number_tweet_info_followers_not_unique'], labels=tweet_info_followers_not_unique_df['tweet_info_followers_not_unique'], colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweet_info_followers_not_unique_df['tweet_info_followers_not_unique'], loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_38_SMI1_Tweet_Info_Followers_Not_Unique_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Followerss Not Unique - Bars')
tweet_info_followers_not_unique_df['number_tweet_info_followers_not_unique'].plot.bar(x=tweet_info_followers_not_unique_df['number_tweet_info_followers_not_unique'], alpha=0.9)
# ax.bar(tweet_info_followers_not_unique_df['tweet_info_followers_not_unique'], tweet_info_followers_not_unique_df['number_tweet_info_followers_not_unique'])
plt.xticks(rotation=50)
plt.xlabel('Users with Followers, Users with NO Followers')
plt.ylabel('Count')
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_38_SMI1_Tweet_Info_Followers_Not_Unique_df_Counts_Bars_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###############################################################################################################

# https://towardsdatascience.com/data-science-with-python-intro-to-loading-and-subsetting-data-with-pandas-9f26895ddd7f

###### Users with NO Friends NOT UNIQUE

# SUBSETS

# Number of Users with Friends ALL NOT UNIQUE  ########### NEED TO FIX


tweets_with_friends = tweets_smi_1[(tweets_smi_1['friends_count'] != 0)] ######### NEED TO ADD CONDITION - NOT WORKING

print('---')
print('Users with Friends Info NOT Unique -- SERIES VALUE')
# print(tweets_with_friends)
print('---')

tweets_with_friends_count = tweets_with_friends.count()

print('---')
print('Users with Friends Count')
# print(tweets_with_friends_count)
print('---')


tweets_without_friends_filter = tweets_smi_1[(tweets_smi_1['friends_count'] != 0)]

# tweets_without_friends_filter = pd.DataFrame(tweets_without_friends_filter, columns=['tweets_without_friends_filter']))

number_tweets_without_friends_filter = len(tweets_without_friends_filter)
number_tweets_without_friends_filter

print('---')
print('Number of Users without Friends')
print(number_tweets_without_friends_filter)
print('---')


percentage_tweets_without_friends_filter = ((number_tweets_without_friends_filter * 100)/number_total_tweets)
percentage_tweets_without_friends_filter

print('---')
print('Percentage of Users without Friends')
# print(percentage_tweets_without_friends_filter)
print('---')

number_tweets_with_friends_not_unique = number_total_tweets - number_tweets_without_friends_filter
number_tweets_with_friends_not_unique

print('---')
print('Number of Users with Friends - NOT UNIQUE')
print(number_tweets_with_friends_not_unique)
print('---')

percentage_tweets_with_friends_not_unique = ((number_tweets_with_friends_not_unique * 100)/number_total_tweets)
percentage_tweets_with_friends_not_unique

print('---')
print('Percentage of Users with Friends - NOT UNIQUE')
# print(percentage_tweets_with_friends_not_unique)
print('---')


##############

# Inicialize List of Lists NOT UNIQUE Friends

tweet_info_friends_not_unique = [['Users with Friends', number_tweets_with_friends_not_unique, percentage_tweets_with_friends_not_unique], ['Users with NO Friends', number_tweets_without_friends_filter, percentage_tweets_without_friends_filter]]

# Create DataFrame

tweet_info_friends_not_unique_df = pd.DataFrame(tweet_info_friends_not_unique, columns =['tweet_info_friends_not_unique', 'number_tweet_info_friends_not_unique', 'percentage_tweet_info_friends_not_unique'])

print('---')
print('Tweet Info Friends NOT UNIQUE Information')
# print(tweet_info_friends_not_unique_df)
print('---')

tweet_info_friends_not_unique_df.to_csv('4_4_39_SMI1_Tweet_Info_Friends_Not_Unique_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_friends_not_unique_df.to_excel('4_4_39_SMI1_Tweet_Info_Friends_Not_Unique_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Users with Friends Not Unique - Pie')
# plt.pie(tweet_info_friends_not_unique_df['number_tweets_with_friends_not_unique'], labels=tweet_info_friends_df['tweet_info_friends'])
plt.pie(tweet_info_friends_not_unique_df['number_tweet_info_friends_not_unique'], labels=tweet_info_friends_not_unique_df['tweet_info_friends_not_unique'], colors=colors_blue, startangle=30, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweet_info_friends_not_unique_df['tweet_info_friends_not_unique'], loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_39_SMI1_Tweet_Info_Friends_Not_Unique_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Users With Friends Not Unique - Bars')
tweet_info_friends_not_unique_df['number_tweet_info_friends_not_unique'].plot.bar(alpha=0.9)
# ax.bar(tweet_info_friends_not_unique_df['number_tweets_with_friends_not_unique'], tweet_info_friends_not_unique_df['percentage_tweets_without_friends_filter'])
plt.xticks(rotation=50)
plt.xlabel('Users with Friends, Users with No Friends')
plt.ylabel('Count')
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_39_SMI1_Tweet_Info_Friends_Not_Unique_df_Counts_Bars_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###################################################################################################
###################################################################################################
##############

# Inicialize List of Lists NOT UNIQUE Followers AND Friends

tweet_info_followers_friends_not_unique = [['Users with Followers', number_tweets_with_followers_not_unique, percentage_tweets_with_followers_not_unique], ['Users with NO Followers', number_tweets_without_followers_filter, percentage_tweets_without_followers_filter], ['Users with Friends', number_tweets_with_friends_not_unique, percentage_tweets_with_friends_not_unique], ['Users with NO Friends', number_tweets_without_friends_filter, percentage_tweets_without_friends_filter]]

# Create DataFrame

tweet_info_followers_friends_not_unique_df = pd.DataFrame(tweet_info_followers_not_unique, columns =['tweet_info_followers_friends_not_unique', 'number_tweet_info_followers_friends_not_unique', 'percentage_tweet_info_followers_friends_not_unique'])

print('---')
print('Tweet Info Followers and Friends NOT UNIQUE Information')
# print(tweet_info_friends_not_unique_df)
print('---')

tweet_info_followers_friends_not_unique_df.to_csv('4_4_40_SMI1_Tweet_Info_Friends_Not_Unique_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_followers_friends_not_unique_df.to_excel('4_4_40_SMI1_Tweet_Info_Friends_Not_Unique_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# PLOT BARS - MULTIPLE - Tweets Followers AND Friends NOT UNIQUE 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

# '#73C2FB', '#6593F5',

r1 = np.arange(len(tweet_info_followers_not_unique_df['number_tweet_info_followers_not_unique']))
r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets Followers and Friends Not Unique - Bars')

plt.bar(r1, tweet_info_followers_not_unique_df['number_tweet_info_followers_not_unique'], color='#73C2FB', edgecolor='white', label='Followers', alpha=0.9)
plt.bar(r2, tweet_info_friends_not_unique_df['number_tweet_info_friends_not_unique'], color='blue', edgecolor='white', label='Friends', alpha=0.9)

plt.xticks(rotation=50)
plt.xlabel('Users with Followers, Users without Followers, Users with Friends, Users without Friends')
plt.ylabel('Count')
plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True)
# plt.show()
plt.savefig('4_4_40_SMI1_Tweet_Info_Followers_Friends_Not_Unique_df_Bar_Plot_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################################################################
###################################################################################################

############################################# UNIQUES Followers AND Friends - NEED TO DO

# DF WITH UNIQUE VALUES TO CHANGE

# UNIQUE Users with Followers

tweets_without_followers_filter = tweets_smi_1[(tweets_smi_1['followers_count'] != 0)]

print('---')
print('Users with Followers ALL - NOT Unique Information')
# print(tweets_with_followers_filter.shape)
print('---')

unique_tweets_with_followers = tweets_smi_1['text'].unique()
unique_tweets_with_followers

print('---')
print('Tweet with Followers Unique Information')
# print(unique_tweets_with_followers.shape)
print('---')

number_unique_tweets_with_followers = len(unique_tweets_with_followers)
number_unique_tweets_with_followers

print('---')
print('Number of Unique Users with Followers ') 
# print(number_unique_tweets_with_followers)
print('---')

percentage_unique_tweets_with_followers = ((number_unique_tweets_with_followers * 100)/number_total_tweets)
percentage_unique_tweets_with_followers

print('---')
print('Percentage of Unique Users with Followers ')
print(percentage_unique_tweets_with_followers)
print('---')


# TWEETS UNIQUE NO Followers

tweets_without_followers_filter = tweets_smi_1[(tweets_smi_1['followers_count'] == 0)]

print('---')
print('Tweets NO Followers ALL - NOT Unique Information')
# print(tweets_without_followers_filter.shape)
print('---')

# unique_tweets_without_number_followers = tweets_without_followers['text'].unique() ## NEED TO DO FROM THE FILTERED DATAFRAMES 

unique_tweets_without_followers = tweets_without_followers_filter['text'].unique()
unique_tweets_without_followers

print('---')
print('Tweet Without Followers Unique Information')
print(unique_tweets_without_followers.shape)
print('---')

number_unique_tweets_without_followers = len(unique_tweets_without_followers)
number_unique_tweets_without_followers

print('---')
print('Number of Unique Users without Followers ') 
# print(number_unique_tweets_without_followers)
print('---')

percentage_unique_tweets_without_followers = ((number_unique_tweets_without_followers * 100)/number_total_tweets)
percentage_unique_tweets_without_followers

print('---')
print('Percentage of Unique Users without Followers ')
print(percentage_unique_tweets_without_followers)
print('---')


############## NEED TO DO FIX - 

# Inicialize List of Lists UNIQUE Followers

tweet_info_unique_tweets_with_followers = [['Unique Users with Followers', number_unique_tweets_with_followers, percentage_unique_tweets_with_followers], ['Unique Users without Followers', number_unique_tweets_without_followers, percentage_unique_tweets_without_followers]]

# Create DataFrame

tweet_info_unique_tweets_with_followers_df = pd.DataFrame(tweet_info_unique_tweets_with_followers, columns =['tweet_info_unique_tweets_with_followers_description', 'number_unique_tweets_with_followers', 'percentage_unique_tweets_with_followers'])

print('---')
print('Tweet Info Followers UNIQUE Information')
# print(tweet_info_unique_tweets_with_followers_df)
print('---')

tweet_info_unique_tweets_with_followers_df.to_csv('4_4_41_SMI1_Tweet_Info_Unique_Tweets_with_Followers_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_unique_tweets_with_followers_df.to_excel('4_4_41_SMI1_Tweet_Info_Unique_Tweets_with_Followers.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Users with Followers Unique - Pie')
plt.pie(tweet_info_unique_tweets_with_followers_df['number_unique_tweets_with_followers'], labels=tweet_info_unique_tweets_with_followers_df['tweet_info_unique_tweets_with_followers_description'], colors=colors_blue, startangle=65, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweet_info_unique_tweets_with_followers_df['tweet_info_unique_tweets_with_followers_description'], loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_41_SMI1_Tweet_info_unique_tweets_with_followers_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Users with Followers Unique - Bars')
tweet_info_unique_tweets_with_followers_df['number_unique_tweets_with_followers'].plot.bar(x=tweet_info_unique_tweets_with_followers_df['tweet_info_unique_tweets_with_followers_description'], alpha=0.9)
# ax.bar(tweet_info_unique_tweets_with_followers_df['number_unique_tweets_with_followers'], tweet_info_unique_tweets_with_followers_df['number_unique_tweets_without_followers'])
plt.xticks(rotation=50)
plt.xlabel('Users with Followers, Unique Users without Followers')
plt.ylabel('Count')
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True)
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_41_SMI1_Tweet_info_unique_tweets_with_Followers_df_Counts_Bars_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############ 

# DF WITH UNIQUE VALUES TO CHANGE

# UNIQUE Users with Friends

tweets_without_friends_filter = tweets_smi_1[(tweets_smi_1['friends_count'] != 0)]

print('---')
print('Users with Friends ALL - NOT Unique Information')
# print(tweets_with_friends_filter.shape)
print('---')

# unique_tweets_with_number_friends = tweets_with_friends['text'].unique() ## NEED TO DO FROM THE FILTERED DATAFRAMES 

unique_tweets_with_friends = tweets_without_friends_filter['text'].unique()
unique_tweets_with_friends

print('---')
print('Tweet with Friends Unique Information')
print(unique_tweets_with_friends.shape)
print('---')

number_unique_tweets_with_friends = len(unique_tweets_with_friends)
number_unique_tweets_with_friends

print('---')
print('Number of Unique Users with Friends') 
print(number_unique_tweets_with_friends)
print('---')

percentage_unique_tweets_with_friends = ((number_unique_tweets_with_friends * 100)/number_total_tweets)
percentage_unique_tweets_with_friends

print('---')
print('Percentage of Unique Users with Friends')
print(percentage_unique_tweets_with_friends)
print('---')


# UNIQUE TWEETS NO Friends

tweets_without_friends_filter = tweets_smi_1[(tweets_smi_1['friends_count'] == 0)]

print('---')
print('Tweet Friends ALL - NOT Unique Information')
# print(tweets_without_friends_filter.shape)
print('---')

# unique_tweets_without_number_friends = tweets_without_friends['text'].unique() ## NEED TO DO FROM THE FILTERED DATAFRAMES 

unique_tweets_without_friends = tweets_without_friends_filter['text'].unique()
unique_tweets_without_friends

print('---')
print('Tweet Without Friends Unique Information')
print(unique_tweets_without_friends.shape)
print('---')

number_unique_tweets_without_friends = len(unique_tweets_without_friends)
number_unique_tweets_without_friends

print('---')
print('Number of Unique Users without Friends') 
# print(number_unique_tweets_without_friends)
print('---')

percentage_unique_tweets_without_friends = ((number_unique_tweets_without_friends * 100)/number_total_tweets)
percentage_unique_tweets_without_friends

print('---')
print('Percentage of Unique Users without Friends')
# print(percentage_unique_tweets_without_friends)
print('---')


############## NEED TO DO FIX - 

# Inicialize List of Lists UNIQUE Friends

tweet_info_unique_tweets_with_friends = [['Unique Users with Friends', number_unique_tweets_without_friends, percentage_unique_tweets_with_friends], ['Unique Users without Friends', number_unique_tweets_without_friends, percentage_unique_tweets_without_friends]]

# Create DataFrame

tweet_info_unique_tweets_with_friends_df = pd.DataFrame(tweet_info_unique_tweets_with_friends, columns =['tweet_info_unique_tweets_with_friends_description', 'number_unique_tweets_with_friends', 'percentage_unique_tweets_with_friends'])

print('---')
print('Tweet Info Friends UNIQUE Information')
# print(tweet_info_unique_tweets_with_friends_df)
print('---')

tweet_info_unique_tweets_with_friends_df.to_csv('4_4_42_SMI1_Tweet_Info_Unique_Tweets_with_Friends_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_unique_tweets_with_friends_df.to_excel('4_4_42_SMI1_Tweet_Info_Unique_Tweets_with_Friends.xlsx', header=True)

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Users with Friends Unique')
plt.plot(tweet_info_unique_tweets_with_friends_df['number_unique_tweets_with_friends'], alpha=0.9)
# ax.bar(tweet_info_unique_tweets_with_friends_df['number_unique_tweets_with_friends'], tweet_info_unique_tweets_with_friends_df['number_unique_tweets_without_friends'])
plt.xticks(rotation=50)
plt.xlabel('Users with Friends, Unique Users without Friends')
plt.ylabel('Count')
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True)
# plt.show()
plt.savefig('4_4_42_SMI1_Tweet_info_unique_Tweets_with_Friends_df_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Users with Friends Unique - Pie')
# plt.pie(tweet_info_friends_df['number_tweet_info_friends'], labels=tweet_info_friends_df['tweet_info_friends'])
plt.pie(tweet_info_unique_tweets_with_friends_df['number_unique_tweets_with_friends'], labels=tweet_info_unique_tweets_with_friends_df['tweet_info_unique_tweets_with_friends_description'], colors=colors_blue, startangle=86, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=tweet_info_unique_tweets_with_friends_df['tweet_info_unique_tweets_with_friends_description'], loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_42_SMI1_Tweet_info_unique_Tweets_with_Friends_df_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars ## NEED TO DO - FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Users with Friends Unique - Bars')
tweet_info_unique_tweets_with_friends_df['number_unique_tweets_with_friends'].plot.bar(alpha=0.9)
# ax.bar(tweet_info_unique_tweets_with_friends_df['number_unique_tweets_with_friends'], tweet_info_unique_tweets_with_friends_df['number_unique_tweets_without_friends'])
plt.xticks(rotation=50)
plt.xlabel('Users with Friends, Unique Users without Friends')
plt.ylabel('Count')
# plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True)
# plt.show()
plt.savefig('4_4_42_SMI1_Tweet_info_unique_Tweets_with_Friends_df_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###################################################################################################
###################################################################################################
##############

# Inicialize List of Lists UNIQUE Followers AND Friends

tweet_info_followers_friends_not_unique = [['Unique Users with Followers', number_unique_tweets_with_followers, percentage_unique_tweets_with_followers], ['Unique Users without Followers', number_unique_tweets_without_followers, percentage_unique_tweets_without_followers], ['Unique Users with Friends', unique_tweets_with_friends, percentage_unique_tweets_with_friends], ['Unique Users without Friends', number_unique_tweets_without_friends, percentage_unique_tweets_without_friends]]

# Create DataFrame

tweet_info_followers_friends_not_unique_df = pd.DataFrame(tweet_info_followers_not_unique, columns =['tweet_info_followers_friends_unique', 'number_tweet_info_followers_friends_unique', 'percentage_tweet_info_followers_friends_unique'])

print('---')
print('Tweet Info Followers and Friends UNIQUE Information')
# print(tweet_info_followers_friends_not_unique_df)
print('---')

tweet_info_followers_friends_not_unique_df.to_csv('4_4_50_SMI1_Tweet_Info_Followers_Friends_Not_Unique_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_followers_friends_not_unique_df.to_excel('4_4_50_SMI1_Tweet_Info_Followers_Friends_Not_Unique_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# PLOT BARS - MULTIPLE - Tweets Followers AND Friends UNIQUE 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

r1 = np.arange(len(tweet_info_unique_tweets_with_followers_df['number_unique_tweets_with_followers']))
r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Tweets Followers and Friends - Bars')

plt.bar(r1, tweet_info_unique_tweets_with_followers_df['number_unique_tweets_with_followers'], color='#73C2FB', edgecolor='white', label='Followers', alpha=0.9)
plt.bar(r2, tweet_info_unique_tweets_with_friends_df['number_unique_tweets_with_friends'], color='blue', edgecolor='white', label='Friends', alpha=0.9)

plt.xticks(rotation=50)
plt.xlabel('Unique Users with Followers, Without Followers, Unique Users with Friends, Without Friends')
plt.ylabel('Count')
plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_SMI1_Tweet_Info_Followers_Friends_not_unique_df_Bar_Plot_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

####################################################################################################
####################################################################################################

# List Total Followers ####################################### NEED TO GET HASTAGS AND hashtags!!!!!!

tweets_smi_1.groupby('year')

number_total_followers = tweets_smi_1['followers_count'].sum()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

print('---')
print('List Total Followers ')
# print(number_total_followers)
print('---')

number_total_followers_df = pd.DataFrame([number_total_followers], columns=['number_total_followers'])

number_total_followers_df.to_csv('4_4_50_SMI1_Number_Total_Followers_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# number_total_followers_df.to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Followers ')
# plt.plot(number_total_followers_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_SMI1_Number_Total_Followers_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Followers - Pie')
# plt.pie(tweet_info_friends_df['number_total_followers_df'], labels=number_total_followers_df)
# plt.pie(number_total_followers['number_total_followers_df'], labels=number_total_followers, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=number_total_followers, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_SMI1_Number_Total_Followers_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Followers - Bars')
# number_total_followers.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_SMI1_Number_Total_Followers_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################
####################################################################################################

# List Total Friends ####################################### NEED TO GET HASTAGS AND hashtags!!!!!!

number_total_friends = tweets_smi_1['friends_count'].sum()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


print('---')
print('List Total Friends')
# print(number_total_friends)
print('---')

number_total_friends_df = pd.DataFrame([number_total_friends], columns=['number_total_friends'])

number_total_friends_df.to_csv('4_4_50_SMI1_Number_Total_Friends_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# number_total_friends_df.to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Friends')
# plt.plot(number_total_friends_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_SMI1_Number_Total_Friends_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Friends - Pie')
# plt.pie(tweet_info_friends_df['number_total_friends_df'], labels=number_total_friends_df)
# plt.pie(number_total_friends['number_total_friends_df'], labels=number_total_friends, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=number_total_friends, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_SMI1_Number_Total_Friends_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Total Friends - Bars')
# number_total_friends.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_SMI1_Number_Total_Friends_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# END FRIENDS fav
# END FOLLOWERS rt



#################################################################################################
#
#		MISSING GEO PATTERN AND GET
#
#################################################################################################

##################################################################################################################

# COMPLETE MISSING COUNTRY

print('COMPLETE MISSING COUNTRY')

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore')

# PLACES NAMES

tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' the uk', ' the ~uk ')

# DOUBLE PLACES

# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' orlando from the uk', ' ~orlando from the ~uk ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' orlando from the uk', ' ~unitedkingdom')
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('san diego from unitedkingdom', ' ~sandiego from ~uk ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('san diego from unitedkingdom', ' ~unitedkingdom')

tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' pittsburgh,pa', ' ~usa ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' knoxville tn', ' ~usa ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' chihuahua mx', ' ~mexico ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' chihuahua, mx', ' ~mexico ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' chihuahua mejico', ' ~mexico ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' chihuahua, mejico', ' ~mexico ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' chihuahua mexico', ' ~mexico ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' chihuahua, mexico', ' ~mexico ')


tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('visiting the us ', 'visiting the ~usa ')

# williamsburg, va -> d iin williamsburg, va westanding // NEED TO CHECK

# NEW HERE FIRST AND GENERAL

tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' republic of ireland', ' ~ireland ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' republicofireland', ' ~ireland ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' ireland', ' ~ireland ')

tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' republic of china', ' ~china ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' china', ' ~china ')

tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' south africa,', ' ~southafrica ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' south africa ', ' ~southafrica ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' africa ', ' ~africa ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' asia ', ' ~asia ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' europe ', ' ~europe ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' north america ', ' ~northamerica ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' central america ', ' ~centralamerica ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' south america ', ' ~southamerica ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' northamerica ', ' ~northamerica ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' centralamerica ', ' ~centralamerica ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' southamerica ', ' ~southamerica ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' north korea ', ' ~northkorea ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' northkorea ', ' ~northkorea ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' south korea ', ' ~southhkorea ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' southkorea ', ' ~southhkorea ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' republic of korea ', ' ~korea ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' republicofkorea ', ' ~korea ')

tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' united arab emirates', ' ~unitedarabemirates ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' unitedarabemirates', ' ~unitedarabemirates ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' u\.a\.e\. ', ' ~unitedarabemirates ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' u\.a\.e ', ' ~unitedarabemirates ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' uae ', ' ~unitedarabemirates ')

tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' vietnam thailand', ' ~vietnam, ~thailand ')

tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' in the states', ' in the ~usa ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' states united ', ' in the ~usa ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' live united states', ' live ~usa ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' in america', ' in ~usa ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' come to america ', ' come to ~usa ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' come u\.s\.', ' come ~usa ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('the u\.\s\. ', ' the ~unitedstates ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('the us ', ' the ~unitedstates ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('in the states', ' in the ~unitedstates')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' th e states', ' the ~unitedstates')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('because america ', ' because ~unitedstates ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' u\.s\.a', ' ~unitedstates')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('the unitedstates ', ' the ~unitedstates ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('in unitedstates ', 'in ~unitedstates ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('to unitedstates ', 'to ~unitedstates ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' unitedstates ', ' ~unitedstates ')

tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' britain', ' ~unitedkingdom')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' great britain', ' ~unitedkingdom')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' greatbritain', ' ~unitedkingdom')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' u\.k\.', ' ~unitedkingdom')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' uk,', ' ~unitedkingdom')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' uk ', ' ~unitedkingdom ')

tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' newcastle upon tyne', ' ~newcastleupontyne')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' newcastleupontyne', ' ~newcastleupontyne')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' new castle', ' ~newcastle')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' newcastle', ' ~newcastle')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' new amsterdam', ' ~newamsterdam')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' newamsterdam', ' ~newamsterdam')

tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' new delhi', ' ~delhi')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' newdelhi', ' ~delhi')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' delhi', ' ~delhi')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' new jersey', ' ~newjersey')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' newjersey', ' ~newjersey')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('new yorkk', ' ~newyork')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' new york ', ' ~newyork ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' northampton', ' ~northampton')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' new orleans', ' ~neworleans')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' neworleans', ' ~neworleans')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' for nyc', ' for ~newyork')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' for ny', ' for ~newyork')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' in nyc', ' in ~newyork')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' in ny', ' in ~newyork')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' visit ny', ' visit ~newyork')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' nyc ', ' ~newyork ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' 2 ny ', ' to ~newyork ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' n\.y\.c. ', ' ~newyork')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' n\.y\. ', ' ~newyork ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' new york', ' ~newyork')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' newyork', ' ~newyork')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' santiago de chile', ' ~santiagodechile')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' santiagodechile', ' ~santiagodechile')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' santiago, chile', ' ~santiagodechile')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' santiago chile', ' ~santiagodechile')

# ALL OTHER PLACES

tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' aberdeen', ' ~aberdeen')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' alabama', ' ~alabama')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' alaska', ' ~alaska')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' algeria', ' ~algeria')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' angola', ' ~angola')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' amsterdam', ' ~amsterdam')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' argentinaaaa', ' ~argentina')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' argentina', ' ~argentina')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' arkansas', ' ~arkansas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' arizona', ' ~arizona')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' az,', ' ~arizona')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' az ', ' ~arizona ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' aspen', ' ~aspen')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' athens', ' ~athens')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' atlantic city', ' ~atlanticcity')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' atlanticcity', ' ~atlanticcity')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' atlanta', ' ~atlanta')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' austin', ' ~austin')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('vidcon aus', ' vidcon ~australia')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' aus\!', ' ~australia')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' australia', ' ~australia')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' austria', ' ~austria')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' austria ', ' ~austria ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' bangladore', ' ~bangladore')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' belarus', ' ~belarus')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' belgium', ' ~belgium')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' barcelona', ' ~barcelona')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' belfast', ' ~belfast')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' belgium', ' ~belgium')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' bolivia ', ' ~bolivia ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' bogota', ' ~bogota')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' budapest', ' ~budapest')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' bahamas', ' ~bahamas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' baltimore', ' ~baltimore')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' bangkok', ' ~bangkok')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' berlin', ' ~berlin')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' birmingham', ' ~birmingham')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' blackpool', ' ~blackpool')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' bogota', ' ~bogota')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' bora bora', ' ~borabora')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' borabora', ' ~borabora')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' boston', ' ~boston')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' bradford', ' ~bradford')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' brazil ', ' ~brazil ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' bremen', ' ~bremen')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' brighton', ' ~brighton')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' brisbane', ' ~brisbane')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' bristol', ' ~bristol')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' brooklyn', ' ~brooklyn')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' buthan', ' ~buthan')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' cabo', ' ~cabo')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' cairo', ' ~cairo')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' california', ' ~california')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('in cali ', ' in ~california ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('visiting cali ', ' visiting ~california ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('visit cali ', ' visit ~california ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' campbell', ' ~campbell')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' campbel ', ' ~campbell ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' canada', ' ~canada')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' cancun', ' ~cancun')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' caracas', ' ~caracas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' cardiff', ' ~cardiff')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' chapeltown', ' ~chapeltown')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' chicago', ' ~chicago')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' cchileeeee ', ' ~chile')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' chileeeee', ' ~chile')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' chileeee', ' ~chile')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' chileee', ' ~chile')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' chilee', ' ~chile')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' chile ', ' ~chile ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' cncinatti', ' ~cincinatti')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' china', ' ~china')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' chorlton', ' ~chorlton')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' cincinatti', ' ~cincinatti')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' cleveland', ' ~cleveland')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' colombia ', ' ~colombia ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' colorado', ' ~colorado')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' me in co', ' me in ~colorado')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' columbus', ' ~columbus')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' costa ricaaaaa', ' ~costarica')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' costa rica ', ' ~costarica')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' costarica ', ' ~costarica ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' cozumel', ' ~cozumel')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' coventry', ' ~coventry')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' copenhagen', ' ~copenhagen')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' czech republic', ' ~czechrepublic')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' czechrepublic', ' ~czechrepublic')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' cuba ', ' ~cuba ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' denmark', ' ~denmark')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' dallas', ' ~dallas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' denver', ' ~denver')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' detroit', ' ~detroit')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' devon', ' ~devon')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' dominican republic', ' ~dominicanrepublic')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' dominicanrepublic ', ' ~dominicanrepublic ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' dubai', ' ~dubai')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' dublin', ' ~dublin')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' ecuador', ' ~ecuador')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' edinburgh', ' ~edinburgh')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' egyptt', ' ~egypt')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' egypt', ' ~egypt')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' england', ' ~unitedkingdom')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' el paso', ' ~elpaso, ~texas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' elpaso', ' ~elpaso, ~texas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' essex', ' ~essex')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' finland', ' ~finland')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' florence', ' ~florence')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' florida', ' ~florida')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' france', ' ~france')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' georgia', ' ~georgia')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' germany', ' ~germany')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' glasgow', ' ~glasgow')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' greece', ' ~greece')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' guatemala', ' ~guatemala')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' haiti ', ' ~haiti ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' halifax', ' ~halifax')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' hannover', ' ~hannover')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' havana', ' ~havana')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' hawaiii ', ' ~hawaii ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' holland', ' ~holland')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' honduras', ' ~honduras')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' hong kong', ' ~hongkong') 
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' hongkong', ' ~hongkong')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' houston', ' ~houston')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' hull, ', ' ~hull')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' hull ', ' ~hull')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' hungary', ' ~hungary')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' iceland', ' ~iceland')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' indianapolis', ' ~indianapolis')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' indiana', ' ~indiana')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' india,', ' ~india')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' india.', ' ~india')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' india ', ' ~india ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' iowa', ' ~iowa')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' iowa\!', ' ~iowa')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' indonesia', ' ~indonesia')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' iran ', ' ~iran ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' iraq ', ' ~iraq ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' ireland', ' ~ireland')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' istanbul', ' ~istanbul')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' isle of man', ' ~isleofman')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' iran,', ' ~iran')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' israel ', ' ~israel')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' italy', ' ~italy')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' ixtapa', ' ~ixtapa')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' japan ', ' ~japan ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' jamaica ', ' ~jamaica ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('jerseyyyy', ' ~jersey')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' jersey', ' ~jersey')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' jerusalem', ' ~jerusalem')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' jordan ', ' ~jordan ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' kansas', ' ~kansas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' kenia', ' ~kenya')  
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' kenya ', ' ~kenya ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' knoxville', ' ~knoxville')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' diary:korea', ' diary ~korea')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' koreaa ', ' ~korea ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' korea ', ' ~korea ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' kuala lumpur', ' ~kualalumpur')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' kualalumpur', ' ~kualalumpur')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' kentucky', ' ~kentucky')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' kuwait', ' ~kuwait')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' beautycon la', ' beautycon ~losangeles')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' los angeles', ' ~losangeles')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' hot la ', ' hot ~losangeles ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' la areaaa', ' ~losangeles area')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' los angeles', ' ~losangeles')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('in la ', ' in ~losangeles ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('visiting la\.', ' visiting ~losangeles')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' l\.a\. ', ' ~losangeles ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('all over la', ' all over ~losangeles')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('back in la', ' back in ~losangeles')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('do an la', ' do a ~losangeles')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('visit la', ' visit ~losangeles')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' los angeles', ' ~losangeles')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' las vegas', ' ~lasvegas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' lasvegas ', ' ~lasvegas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' vegas ', ' ~lasvegas ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' las vegas', ' ~lasvegas') # JUST VEGAS
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' lebanon', ' ~lebanon')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' leeds', ' ~leeds')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' lerwick', ' ~lerwick')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' lima', ' ~lima')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' lisbon', ' ~lisbon')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' liverpool', ' ~liverpool')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' lithuania', ' ~lithuania')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' little rock', ' ~littlerock')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' littlerock', ' ~littlerock')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' louisiana', ' ~louisiana')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' luisiana', ' ~louisiana')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' london', ' ~london')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' madrid', ' ~madrid')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' maine', ' ~maine')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' malaysia ', ' ~malaysia ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' maldives', ' ~maldives')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' maltives', ' ~maldives')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' maltive', ' ~maldives')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' mallorca', ' ~mallorca')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' madrid', ' ~madrid')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' malaga', ' ~malaga')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' mlaga', ' ~malaga')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' manchester', ' ~manchester')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' manhattan', ' ~manhattan')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' manila', ' ~manila')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' maryland', ' ~maryland')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' massachusetts', ' ~massachusetts')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' massechusets', ' ~massachusetts')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' maui', ' ~maui')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' medellin', ' ~medellin')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' melbourne', ' ~melbourne')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' memphis', ' ~memphis')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' menphis', ' ~memphis')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' mexico city', ' ~mexicocity')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' mexicocity', ' ~mexicocity')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' mxico', ' ~mexico')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' mexico', ' ~mexico')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' mejico', ' ~mexico')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' mx ', ' ~mexico ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' miami', ' ~miami')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' michigan', ' ~michigan')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' milwaukee', ' ~milwaukee')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' minneapolis', ' ~minneapolis')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' minnesnowta', ' ~minnesota')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' minnesota', ' ~minnesota')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' missouri', ' ~missouri')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' munich', ' ~munich')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' montana', ' ~montana')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' montreal', ' ~montreal')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' morocco', ' ~morocco')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' monaco', ' ~monaco')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' monte video', ' ~montevideo')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' montevideo', ' ~montevideo')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' moscu', ' ~moscu')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' mountain view', ' ~mountainview')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' mountainview', ' ~mountainview')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' mumbai', ' ~mumbai')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' /mykonos ', ' ~mykonos')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' mykonos', ' ~mykonos')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' napa valley', ' ~napa')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' napavalley', ' ~napa')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' napa', ' ~napa')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' nashville', ' ~nashville')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' to nebraska', ' to ~nebraska')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' nebraska', ' ~nebraska')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' nevada', ' ~nevada')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' nepal', ' ~nepal')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' netherlands', ' ~netherland')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' netherland', ' ~netherland')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('come to nz', ' come to ~newzealand')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('to nz', ' to ~newzealand')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' new zealand', ' ~newzealand')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' newzealand', ' ~newzealand')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' nicaragua ', ' ~nicaragua')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' nigeria ', ' ~nigeria ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' north carolina', ' ~northcarolina')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' northcarolina', ' ~northcarolina')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' in nc ', ' in ~northcarolina')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' nc area', ' ~northcarolina area')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' norway', ' ~norway')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' norwich', ' ~norwich')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' nova scotia', ' ~novascotia')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' novascotia', ' ~novascotia')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' oklahoma city', ' ~oklahoma')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' oklahomacity', ' ~oklahoma')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' oklahoma', ' ~oklahoma')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' oman', ' ~oman')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' ontario', ' ~ontario')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' oregon', ' ~oregon')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' orlando', ' ~orlando')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' ontario', ' ~ontario')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' palm desert ', ' ~palmdesert ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' palmdesert ', ' ~palmdesert ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' palm springs', ' ~palmsprings')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' palmsprings', ' ~palmsprings')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' palo alto', ' ~paloalto')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' paloalto', ' ~paloalto')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' pasadena', ' ~pasadena')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' paraguay', ' ~paraguay')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' paris', ' ~paris')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' panama', ' ~panama')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' pakistan ', ' ~pakistan ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' pennsylvania', ' ~pennsylvania')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' perth', ' ~perth')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' peru ', ' ~peru ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' philadelphia', ' ~philadelphia')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' philly', ' ~philadelphia')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' republic philippines', ' ~philippines')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' philippines republic', ' ~philippines')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' philippines', ' ~philippines')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' pittsburgh', ' ~pittsburgh')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' puerto rico', ' ~puertorico')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' puertorico ', ' ~puertorico ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' pune', ' ~pune ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' punjab ', ' ~punjab ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' phoenix', ' ~phoenix')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' phx ', ' ~phoenix')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' plymouth', ' ~plymouth')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' poland', ' ~poland')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' portugal', ' ~portugal')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' punta cana', ' ~puntacana')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' puerto vallarta', ' ~puertovallarta')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' queretaro', ' ~queretaro')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' quertaro', ' ~queretaro')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' reno ', ' ~reno ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' rome', ' ~rome')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' ruanda', ' ~ruanda')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' russia', ' ~russia')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' rumania', ' ~rumania')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' sacramento', ' ~sacramento')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' saint helier', ' ~sainthelier')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' sainthelier', ' ~sainthelier')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' el salvador', ' ~salvador')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' san salvador', ' ~sansalvador')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' st helier', ' ~sainthelier')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' saint helier', ' ~sainthelier')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' sainthelier', ' ~sainthelier')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' salt lake city', ' ~saltlakecity')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' santorini', ' ~santorini')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' san antonio', ' ~sanantonio')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' sanantonio', ' ~sanantonio')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' san diego', ' ~sandiego')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' sandiego', ' ~sandiego')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('in sf and', ' in ~sanfrancisco and')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' san francisco', ' ~sanfrancisco')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' sanfrancisco', ' ~sanfrancisco')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' saudi arabia ', ' ~saudiarabia')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' saudiarabia ', ' ~saudiarabia')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' scandinavia ', ' ~scandinavia ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' scotland', ' ~scotland')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' scottsdale', ' ~scottsdale')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' seaatttlleeeeee', ' ~seatle')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' seattle', ' ~seattle')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' seoul', ' ~seoul')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' sheffield', ' ~sheffield')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' sri lanka ', ' ~srilanka ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' srilanka ', ' ~srilanka ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' singapore', ' ~singapore')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' espana', ' ~spain')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' spain', ' ~spain')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' southafrica ', ' ~southafrica ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' south carolina', ' ~southcarolina')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' southcarolina ', ' ~southcarolina')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' southampton', ' ~southampton')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' steubenville', ' ~steubenville')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' stornoway', ' ~stornoway')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' surrey', ' ~surrey')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' sussex', ' ~sussex')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' sydney', ' ~sydney')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' sweden', ' ~sweden')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' switzerland', ' ~switzerland')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' taiwan ', ' ~taiwan ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' tampa', ' ~tampa')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' tennessee', ' ~tennessee')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' thailand', ' ~thailand')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' tel\-aviv', ' ~telaviv')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' tel aviv', ' ~telaviv')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' telaviv', ' ~telaviv')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' texas', ' ~texas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('\"texas ', ' ~texas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('texas will', ' ~texas will')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' tx', ' ~texas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' tobago', ' ~tobago')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' tokio', ' ~tokyo')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' tokyo', ' ~tokyo')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' tokyo', ' ~tokyo')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' torkay', ' ~torkay')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' toronto', ' ~toronto')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' turkey', ' ~turkey')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' uganda', ' ~uganda')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' ukraine', ' ~ukraine')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' utah', ' ~utah')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' uruguay', ' ~uruguay')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' venezuela ', ' ~venezuela ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' venice', ' ~venice')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' vietnam ', ' ~vietnam ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' viet nam ', ' ~vietnam ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' vit nam', ' ~vietnam')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' virginia ', ' ~virginia ')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' wales', ' ~wales')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' from wales', ' from ~wales')

tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' waco texas', ' ~waco, ~texas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' waco, texas', ' ~waco, ~texas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' waco tx', ' ~waco, ~texas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' waco, tx', ' ~waco, ~texas')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' wales', ' ~wales')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' washington d\.c\.', ' ~washington')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' washington dc', ' ~washington')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' washington', ' ~washington')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' west midlands', ' ~westmidlands')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' williamsburg', ' ~williamsburg')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' wiltshire', ' ~wiltshire')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' wisconsin', ' ~wisconsin')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('west yorkshire', ' ~westyorkshire')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' westyorkshire', ' ~westyorkshire')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' yorkshire', ' ~yorkshire')
tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' yucatan', ' ~yucatan')

##### tweets_smi_1['text'] = tweets_smi_1['text'].str.replace('ny gb', '')  ????
# tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' brooklin', ' ~ ') # OJO CON EL PROGRAMA DE TV

tweets_smi_1['text'] = tweets_smi_1['text'].str.replace(' atlondon', ' at ~london')

tweets_smi_1['missing_geo'] = tweets_smi_1['text'].str.findall(pattern_geo, flags=re.IGNORECASE)

tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].fillna('undefined')

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].astype(str, errors='ignore')

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('vietnam thailand', 'vietnam, thailand')

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].astype(str, errors='ignore')


# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\[\]', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\[', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\]', '')

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\'nan\'', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace(' ', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace(' nan', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('nan', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace(' NaN', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace(', ,', '')

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.lstrip()

# tweets_smi_1['missing_geo_orig'] = tweets_smi_1['missing_geo']

print('Missing Geo Head')
# print(tweets_smi_1['missing_geo'].head(20))
print('---')

##################################################################################################

tweets_smi_1['missing_country'] = tweets_smi_1['missing_geo'].copy()
# tweets_smi_1['missing_country'] = tweets_smi_1['country'].copy()

# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].to_string()

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].astype(str, errors='ignore')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].astype(str, errors='ignore')
# # tweets_smi_1['country'] = tweets_smi_1['country'].astype(str, errors='ignore')

# williamsburg, va -> d iin williamsburg, va westanding // NEED TO CHECK

# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('', '')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('', '')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('', '')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('', '')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('', '')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('', '')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('', '')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('', '')

# NEW HERE FIRST AND GENERAL

# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('northkorea ', ' ~northkorea')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('newamsterdam', ' ~newamsterdam')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('northampton', ' ~northampton')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('jersey', ' ~jersey')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('malaysia ', ' ~malaysia')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('maldives', ' ~maldives')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('maltives', ' ~maldives')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('maltive', ' ~maldives')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('manila', ' ~manila')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('morocco', ' ~morocco')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('monaco', ' ~monaco')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('montevideo', ' ~montevideo')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('newzealand', ' ~newzealand')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('palmdesert ', ' ~palmdesert ')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('philippines', ' ~philippines')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('plymouth', ' ~plymouth')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('unitedarabemirates', ' ~unitedarabemirates')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('san salvador', ' ~salvador')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('amsterdam', ' ~amsterdam')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('bangladore', 'bangladore')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('belarus', ' ~belarus')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('bahamas', ' ~bahamas')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('birmingham', ' ~birmingham')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('borabora', ' ~borabora')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('bradford', ' ~bradford')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('campbell', ' ~campbell')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('campbel ', ' ~campbell ')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('chapeltown', ' ~chapeltown')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('singapore', ' ~singapore')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('south africa,', ' ~southafrica')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('south africa ', ' ~southafrica')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('southafrica ', ' ~southafrica ')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('southampton', ' ~southampton')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('iceland', ' ~iceland')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('ireland', ' ~ireland')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('stornoway', ' ~stornoway')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('hannover', ' ~hannover')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('holland', ' ~holland')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('hong kong', ' ~hongkong') 
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('hongkong', ' ~hongkong')
##### tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('ny gb', '')  ????
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('brooklin', ' ~ ') # OJO CON EL PROGRAMA DE TV

print('STARTING MISSING COUNTRY CHANGES')

tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('newjersey', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('novascotia', 'canada')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('copenhagen', 'denmark')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('seoul', 'southkorea')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('newcastle', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('aberdeen', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('kualalumpur', 'malaysia')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('lerwick', 'scotland')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('lisbon', 'portugal')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('istanbul', 'turkey')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('bremen', 'germany')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('bangkok', 'thailand')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('sainthelier', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('santorini', 'greece')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('steubenville', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('hull', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('jerunitedstateslem ', 'israel')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('telaviv', 'israel')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('wiltshire', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('newcastleupontyne', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('alabama', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('alaska', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('newyork', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('santiagodechile ', 'chile')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('arkansas', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('arizona', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('aspen', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('athens', 'greece')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('atlanticcity', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('atlanta', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('austin', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('barcelona', 'spain')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('belfast', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('budapest', 'hungary')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('baltimore', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('berlin', 'germany')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('blackpool', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('bogota', 'colombia')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('boston', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('brighton', 'australia')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('bristol', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('brooklyn', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('cabo', 'mexico')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('cairo', 'egypt')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('california', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('cancun', 'mexico')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('caracas', 'venezuela')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('cardiff', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('chicago', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('chihuahua', 'mexico')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('cincinatti', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('chorlton', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('cincinatti', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('cleveland', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('colorado', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('columbus', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('cozumel', 'mexico')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('coventry', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('dallas', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('denver', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('detroit', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('devon', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('dublin', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('edinburgh', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('el paso', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('essex', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('florence', 'italy')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('florida', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('georgia', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('glasgow', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('halifax', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('havana', 'cuba')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('hawaiii ', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('houston', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('knoxville', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('kentucky', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('losangeles', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('lasvegas ', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('leeds', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('lima', 'peru')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('indianapolis', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('indiana', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('iowa', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('isle of man', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('ixtapa', 'mexico')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('kansas', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('knoxville', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('liverpool', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('littlerock', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('louisiana', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('london', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('madrid', 'spain')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('maine', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('maryland', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('mallorca', 'spain')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('malaga', 'spain')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('manchester', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('manhattan', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('massachusetts', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('maui', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('medellin', 'colombia')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('melbourne', 'australia')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('memphis', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('mexicocity', 'mexico')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('miami', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('michigan', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('milwaukee', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('minneapolis', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('minnesota', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('missouri', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('munich', 'germany')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('montana', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('montreal', 'canada')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('moscu', 'russia')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('mountainview', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('mykonos', 'greece')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('napa', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('nashville', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('nebraska', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('nevada', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('nepal', 'india')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('northcarolina', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('norwich', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('oklahomacity', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('ontario', 'canada')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('oregon', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('orlando', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('palm springs', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('palmsprings', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('paloalto', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('pasadena', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('paris', 'france')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('panamacity', 'panama')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('pennsylvania', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('perth', 'australia')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('philadelphia', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('pittsburgh', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('phoenix', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('puntacana', 'mexico')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('puertovallarta', 'mexico')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('queretaro', 'mexico')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('reno ', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('rome', 'italy')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('sacramento', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('saltlakecity', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('sanantonio', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('sandiego', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('sanfrancisco', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('scotland', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('scottsdale', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('seattle', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('southcarolina ', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('sheffield', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('surrey', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('sussex', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('sydney', 'australia')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('tampa', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('tennessee', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('texas', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('torkay', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('toronto', 'canada')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('utah', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('venice', 'italy')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('virginia', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('waco', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('wales', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('washington', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('west midlands', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('williamsburg', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('wisconsin', 'unitedstates')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('west yorkshire', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('westyorkshire', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('yorkshire', 'unitedkingdom')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('yucatan', 'mexico')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('delhi', 'india')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('mumbai', 'india')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('newdelhi', 'india')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('pune', 'india')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('punjab', 'india')

# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('\"', '')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('\'', '')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('[', '')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace(']', '')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace(',', ' ')

tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace(' ', '')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('\'nan\'', '')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace(' nan', '')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('nan', 'NONE')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace(' NaN', 'NONE')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace(', ,', '')

# ADD MISSING COUNTRY

# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].fillna('none')

print('Missing Country Head')
print(tweets_smi_1['missing_country'].head(20))
print('---')

missing_country = pd.DataFrame(tweets_smi_1['missing_country'])

# SAVE DATAFRAME TO CSV 

missing_country.to_csv('1_6_1_SMI1_Missing_Country_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# missing_country.to_csv('1_6_1_SMI1_Missing_Country_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

# SAVE TO CSV 

# SAVE DATAFRAME TO CSV 

tweets_smi_1.to_csv('1_6_1_13A_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_13A_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

###############################################################################################################

# missing_geo = re.findall(pattern_geo, tweets, flags=re.IGNORECASE)

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].to_string()
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].astype(str, errors='ignore')

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\'nan\'', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\"', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\'', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\[', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\]', '')

# NEED TO PUT MISSING ITEM IN DATAFRAME AND ROW PER ROW AS ORIGINAL - NEED TO DO!!!!!!!!!

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].to_string()

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('~', '')

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].replace('\[', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].replace('\]', '')
tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('   ', ' ')
tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].replace('\'', '')
tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].replace('\"', '')
tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].replace('  ', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].replace('nan', '')

tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].replace('NaN', 'NONE')

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\!', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\*', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\ ', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('/', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\.', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace(',', ' ')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace(';', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\&', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\^', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\=', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace(': ', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\)', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\(', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('<', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('>', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\"', '')

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\"', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\'', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\]', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\[', '')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace(',', ' ')


print('Head Missing Geo')
print(tweets_smi_1['missing_geo'].head(20))
print('---')


missing_geo = pd.DataFrame(tweets_smi_1['missing_geo'])

# SAVE DATAFRAME TO CSV 

missing_geo.to_csv('1_6_1_SMI1_missing_geo_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# missing_geo.to_csv('1_6_1_SMI1_missing_geo_1_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)



#######################################################################################################


print('Head TOTAL missing_geo_total: OJO REVISAR 5')
# print(tweets_smi_1['missing_geo_total'].head)
print('---')

# tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace(',,', ',')

# tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('   ', ' ', regex=True)
############################ tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('\'', '', regex=True)

# tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('\'nan\'', '')

tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('NaN', 'NONE')

# tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace(' nan', '')
# tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('nan', '')

tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('\'0\'', '')
tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('\'\', \'\'', '')
tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('\'\', ', '')

############# tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace(' ', ',')
# tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace(']', '')
# tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('[', '')

tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('NaN', 'NONE')
# tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace(', ,', '')

tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.lstrip()

tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo_total'] 

print('---')
print('tweets_smi_1 total_missing_geo head')
print(tweets_smi_1['total_missing_geo'].head(20))


print('------------------------------')
print('Head TOTAL missing_geo:')
# print(tweets_smi_1['missing_geo'].head)
print('---')

tweets_smi_1 = tweets_smi_1.reset_index()

total_missing_geo = pd.DataFrame()

total_missing_geo[['created', 'screenName', 'missing_geo']] = tweets_smi_1[['created', 'screenName', 'missing_geo']].copy()
# total_missing_geo = tweets_smi_1['created'].copy()
# total_missing_geo['screenName'] = tweets_smi_1['screenName']
# total_missing_geo['missing_geo'] = tweets_smi_1['missing_geo']

# SAVE DATAFRAME TO CSV 

total_missing_geo.to_csv('1_6_1_SMI1_total_missing_geo_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# total_missing_geo.to_csv('1_6_1_SMI1_total_missing_geo_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

# SAVE DATAFRAME TO CSV 

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

#######################################################################################################

# CLEAR NANS GEO COUNTRIES ETC

tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.lstrip()

tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\'nan\'', '')
tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('NaN', '')
tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace(' nan', '')
tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('nan', '')
tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace('\'0\'', '')

tweets_smi_1['missing_geo_orig'] = tweets_smi_1['missing_geo_orig'].str.lstrip()

tweets_smi_1['missing_geo_orig'] = tweets_smi_1['missing_geo_orig'].str.replace('\'nan\'', '')
tweets_smi_1['missing_geo_orig'] = tweets_smi_1['missing_geo_orig'].str.replace('NaN', '')
tweets_smi_1['missing_geo_orig'] = tweets_smi_1['missing_geo_orig'].str.replace(' nan', '')
tweets_smi_1['missing_geo_orig'] = tweets_smi_1['missing_geo_orig'].str.replace('nan', '')
tweets_smi_1['missing_geo_orig'] = tweets_smi_1['missing_geo_orig'].str.replace('\'0\'', '')

tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.lstrip()

tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('\'nan\'', '')
tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('NaN', '')
tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace(' nan', '')
tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('nan', '')
tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('\'0\'', '')

tweets_smi_1['total_missing_geo'] = tweets_smi_1['total_missing_geo'].str.lstrip()

tweets_smi_1['total_missing_geo'] = tweets_smi_1['total_missing_geo'].str.replace('\'nan\'', '')
tweets_smi_1['total_missing_geo'] = tweets_smi_1['total_missing_geo'].str.replace('NaN', '')
tweets_smi_1['total_missing_geo'] = tweets_smi_1['total_missing_geo'].str.replace(' nan', '')
tweets_smi_1['total_missing_geo'] = tweets_smi_1['total_missing_geo'].str.replace('nan', '')
tweets_smi_1['total_missing_geo'] = tweets_smi_1['total_missing_geo'].str.replace('\'0\'', '')

# tweets_smi_1['missing_country_orig'] = tweets_smi_1['missing_country_orig'].str.lstrip()

# tweets_smi_1['missing_country_orig'] = tweets_smi_1['missing_country_orig'].str.replace('\'nan\'', '')
# tweets_smi_1['missing_country_orig'] = tweets_smi_1['missing_country_orig'].str.replace('NaN', '')
# tweets_smi_1['missing_country_orig'] = tweets_smi_1['missing_country_orig'].str.replace(' nan', '')
# tweets_smi_1['missing_country_orig'] = tweets_smi_1['missing_country_orig'].str.replace('nan', '')
# tweets_smi_1['missing_country_orig'] = tweets_smi_1['missing_country_orig'].str.replace('\'0\'', '')

# # tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.lstrip()

# # tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('\'nan\'', '')
# # tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('NaN', '')
# # tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace(' nan', '')
# # tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('nan', '')
# # tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('\'0\'', '')

# # tweets_smi_1['total_missing_country'] = tweets_smi_1['total_missing_country'].str.lstrip()

# # tweets_smi_1['total_missing_country'] = tweets_smi_1['total_missing_country'].str.replace('\'nan\'', '')
# # tweets_smi_1['total_missing_country'] = tweets_smi_1['total_missing_country'].str.replace('NaN', '')
# # tweets_smi_1['total_missing_country'] = tweets_smi_1['total_missing_country'].str.replace(' nan', '')
# # tweets_smi_1['total_missing_country'] = tweets_smi_1['total_missing_country'].str.replace('nan', '')
# # tweets_smi_1['total_missing_country'] = tweets_smi_1['total_missing_country'].str.replace('\'0\'', '')


print('----------------------------')
print('Tweets SMI_1 Head')
# print(tweets_smi_1.head)
print('----------------------------')


#######################################################################################################

# MAKE TOTAL missing_country and country

total_missing_country = pd.DataFrame()

# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].astype(str, errors='ignore')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].to_string()
# tweets_smi_1['country'] = tweets_smi_1['country'].astype(str, errors='ignore')
# # tweets_smi_1['country'] = tweets_smi_1['country'].to_string()

tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.lstrip()
# tweets_smi_1['country'] = tweets_smi_1['country'].str.lstrip()

tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('\'nan\'', '')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('NaN', '')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace(' nan', '')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('nan', '')
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace('\'0\'', '')

# tweets_smi_1['country'] = tweets_smi_1['country'].str.lstrip()

# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('\'nan\'', '')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('NaN', '')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace(' nan', '')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('nan', '')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('\'0\'', '')

tweets_smi_1['missing_country_orig'] = tweets_smi_1['missing_country'].copy()

tweets_smi_1['missing_country'] = tweets_smi_1[['missing_country_orig', 'country']].astype(str, errors='ignore').apply(' '.join, axis=1)
# tweets_smi_1['missing_country_total'] = tweets_smi_1[['missing_country_orig', 'country']].apply(' '.join, axis=1)

# tweets_smi_1['total_missing_country'] = tweets_smi_1['missing_country'].astype(str, errors='ignore') + ',' + tweets_smi_1['country'].astype(str, errors='ignore')

# COMBINE COLLUMNS

#### # tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace(' ', ',')
######### tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].str.replace(' ', ',')

# tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('\'nan\'', '')
# tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('NaN', '')
# tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace(' nan', '')
# tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('nan', '')
# tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('\'0\'', '')

##################### # tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('\"', '')
# # tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('\'', '')

print('Head TOTAL missing_country_total: OJO REVISAR 5')
# print(tweets_smi_1['missing_country_total'].head)
print('---')

# tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace(',,', ',')

# # tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('   ', ' ', regex=True)
############################ # tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('\'', '', regex=True)
# tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('\'nan\'', '')
# tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('NaN', '')
# tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('\'0\'', '')

# tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace(' ', ',')
# # tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace(']', '')
# # tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('[', '')

# tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.replace('\',\'', '')

# tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].str.lstrip()

tweets_smi_1['missing_country'] = tweets_smi_1['missing_country_total'] 

print('---')
print('tweets_smi_1 missing_country head')
# print(tweets_smi_1['missing_country'].head(20))
print('---')

print('---')
print('tweets_smi_1 total_missing_country head')
print(tweets_smi_1['total_missing_country'].head(20))
print('---')


print('---------------------------')
print('Head TOTAL missing_country:')
# print(tweets_smi_1['missing_country'].head)
print('---')

total_missing_country = pd.DataFrame()

total_missing_country[['created', 'screenName', 'missing_country']] = tweets_smi_1[['created', 'screenName', 'missing_country']].copy()
# total_missing_country = tweets_smi_1['created'].copy()
# total_missing_country['screenName'] = tweets_smi_1['screenName']
# total_missing_country['mentions'] = tweets_smi_1['missing_country']

# SAVE DATAFRAME TO CSV 

total_missing_country.to_csv('1_6_1_SMI1_total_missing_country_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# total_missing_country.to_csv('1_6_1_SMI1_total_missing_country_TXT_FILE.txt', sep='\t', encoding='utf-8', index=False, header=True)

# SAVE DATAFRAME TO CSV 

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

###############################################################################################################

# USING GEO TEXT 

# tweets_smi_1['text'] = tweets_smi_1['text'].to_string()
# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore')


# tweets_smi_1['geo_cities'] = GeoText(tweets_smi_1['text'].cities
# tweets_smi_1['geo_countries'] = GeoText(tweets_smi_1['text'].astype(str, errors='ignore')).country_mentions

print('---')
print('USING GEOTEXT: CITIES ')
# print(tweets_smi_1['geo_cities'].head)
print('USING GEOTEXT: COUNTRIES ')
# print(tweets_smi_1['geo_countries'].head)
print('---')

# SAVE DATAFRAME TO CSV 

# tweets_smi_1.to_csv('1_6_1_22A_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_22A_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)

tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_csv('1_6_1_SMI1_DF_Tweets_Processes_1.txt', sep='\t', encoding='utf-8', index=False, header=True)



# TO LOWERCASE 

tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].fillna('')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].astype(str, errors='ignore').str.lower()
tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].fillna('')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].astype(str, errors='ignore').str.lower()

# tweets_smi_1['missing_geo_orig'] = tweets_smi_1['missing_geo_orig'].astype(str, errors='ignore').str.lower()

# tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['total_missing_geo'] = tweets_smi_1['total_missing_geo'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['missing_country_orig'] = tweets_smi_1['missing_country_orig'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['missing_country_total'] = tweets_smi_1['missing_country_total'].astype(str, errors='ignore').str.lower()
# tweets_smi_1['total_missing_country'] = tweets_smi_1['total_missing_country'].astype(str, errors='ignore').str.lower()

##############################################################################################

# REMANE COLUMNS GEO LOCATION 

# # tweets_smi_1['geo'] = tweets_smi_1['geo'].astype(str, errors='ignore')
# # tweets_smi_1['geo'] = tweets_smi_1['geo'].to_string()

# # tweets_smi_1['country'] = tweets_smi_1['country'].astype(str, errors='ignore')
# # tweets_smi_1['country'] = tweets_smi_1['country'].to_string()

# vietnam thailand
# 'berlin', 'de'
# 'tokyo japan'
# 'miami', 'fl'
# 'united states'
# world of bitcoin

# # tweets_smi_1['location'] = tweets_smi_1['location'].astype(str, errors='ignore')
# # tweets_smi_1['location'] = tweets_smi_1['location'].to_string()
# # tweets_smi_1['location'] = tweets_smi_1['location'].str.replace(r'pattern_emojis_unicode', '')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'pattern_emojis_unicode', '')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].astype(str, errors='ignore')
# # tweets_smi_1['geo'] = tweets_smi_1['geo'].to_string()

# # tweets_smi_1['location'] = tweets_smi_1['location'].astype(str, errors='ignore')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].astype(str, errors='ignore')
# tweets_smi_1['country'] = tweets_smi_1['country'].astype(str, errors='ignore')

# COUNTRIES NEED TO DO!!!!

# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('\'uk\'', 'unitedkingdom')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('britain', 'unitedkingdom')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('great britain', 'unitedkingdom')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('greatbritain', 'unitedkingdom')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('u\.k\.', 'unitedkingdom')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('uk,', 'unitedkingdom')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('united states', 'unitedstates')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('usa', 'unitedstates')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('puerto rico', 'puertorico')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('costa rica', 'costarica')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('republic of ireland', 'ireland')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('new zealand', 'newzealand')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('czech republic', 'czechrepublic')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('dominicanrepublic', 'dominicanrepublic')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('el salvador', 'elsalvador')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('sri lanka', 'srilanka')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('republic of china', 'china')

# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('south africa,', 'southafrica')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('south africa', 'southafrica')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('africa', 'africa')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('asia', 'asia')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('europe', 'europe')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('north america', 'northamerica')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('central america', 'centralamerica')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('south america', 'southamerica')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('northamerica', 'northamerica')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('centralamerica', 'centralamerica')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('southamerica', 'southamerica')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('north korea', 'northkorea')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('northkorea', 'northkorea')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('south korea', 'southhkorea')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('southkorea', 'southhkorea')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('republic of korea', 'korea')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('republicofkorea', 'korea')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('saudi arabia', 'saudiarabia')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('united arab emirates', 'unitedarabemirates')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('unitedarabemirates', 'unitedarabemirates')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('u\.a\.e\.', 'unitedarabemirates')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('u\.a\.e', 'unitedarabemirates')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('uae', 'unitedarabemirates')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('republic philippines', 'philippines')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('philippines republic', 'philippines')

# # tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('', '')
# # tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('', '')
# # tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('', '')

# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace('NaN', '')
# tweets_smi_1['country'] = tweets_smi_1['country'].str.replace(', ,', '')

print('---')
print('Country Head 1')
print(tweets_smi_1['country'].head(20))
print('---')


# TOTAL FIELDS TO LIST TO_LIST

tweets_smi_1['missing_geo'] = list(tweets_smi_1['missing_geo'])
tweets_smi_1['missing_geo_total'] = list(tweets_smi_1['missing_geo_total'])
# tweets_smi_1['missing_country'] = list(tweets_smi_1['missing_geo_total'])


# tweets_smi_1['missing_emojis_unicode'] = list(tweets_smi_1['missing_emojis_unicode'])

tweets_smi_1['location'] = list(tweets_smi_1['location'])
tweets_smi_1['country'] = list(tweets_smi_1['country'])
tweets_smi_1['geo'] = list(tweets_smi_1['geo'])

############################################################################################################
#
# 			COUNT MENTIONS HASHTAGS AND EMOJIS
#
######################################################################################################

# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\[', '')
# tweets_smi_1['hashtags'] = tweets_smi_1['hashtags'].str.replace('\]', '')

# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\[', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\]', '')

# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace('\[', '')
# tweets_smi_1['emojis_unicode'] = tweets_smi_1['emojis_unicode'].str.replace('\]', '')

tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.replace('\[', '')
tweets_smi_1['emojis_converted'] = tweets_smi_1['emojis_converted'].str.replace('\]', '')

tweets_smi_1['number_total_hashtags'] = tweets_smi_1['hashtags'].apply(lambda x: len(x))

print('---')
print('number_hashtags HEAD ')
print(tweets_smi_1['number_total_hashtags'].head)
print('---')

# tweets_smi_1['missing_hashtags'] = tweets_smi_1['missing_hashtags'].str.replace('\[', '')
# tweets_smi_1['missing_hashtags'] = tweets_smi_1['missing_hashtags'].str.replace('\]', '')

# tweets_smi_1['number_missing_hashtags'] = tweets_smi_1['missing_hashtags'].apply(lambda x: len(x))
# tweets_smi_1['number_total_hashtags'] = tweets_smi_1['number_hashtags'] + tweets_smi_1['number_missing_hashtags']

print('---')
print('number_hashtags HEAD ')
# print(tweets_smi_1['number_total_missing_hashtags'].head)
print('---')

tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\[\]', '')
# tweets_smi_1['mentions'] = tweets_smi_1['mentions'].str.replace('\]', '')

tweets_smi_1['number_total_mentions'] = tweets_smi_1['mentions'].apply(lambda x: len(x))

print('---')
print('number_mentions HEAD ')
print(tweets_smi_1['number_total_mentions'].head)
print('---')

# tweets_smi_1['missing_mentions'] = tweets_smi_1['missing_mentions'].str.replace('\[\]', '')
# tweets_smi_1['missing_mentions'] = tweets_smi_1['missing_mentions'].str.replace('\]', '')

# tweets_smi_1['number_missing_mentions'] = tweets_smi_1['missing_mentions'].apply(lambda x: len(x))
# tweets_smi_1['number_total_mentions'] = tweets_smi_1['number_mentions'] + tweets_smi_1['number_missing_mentions']


print('number_mentions HEAD ')
# print(tweets_smi_1['number_missing_mentions'].head)
print('---')


################################################################################################
################################################################################################
################################################################################################

# DOUBLE PLACES

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'san diego', 'sandiego')


# williamsburg, va -> d iin williamsburg, va westanding // NEED TO CHECK

# NEW HERE FIRST AND GENERAL

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'republic of ireland', 'ireland')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'republicofireland', 'ireland')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'republic of china', 'china')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'south africa,', 'southafrica')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'south africa', 'southafrica')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'north america', 'northamerica')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'central america', 'centralamerica')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'south america', 'southamerica')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'northamerica', 'northamerica')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'centralamerica', 'centralamerica')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'southamerica', 'southamerica')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'north korea', 'northkorea')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'northkorea', 'northkorea')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'south korea', 'southhkorea')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'southkorea', 'southhkorea')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'republic of korea', 'korea')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'republicofkorea', 'korea')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'united arab emirates', 'unitedarabemirates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'unitedarabemirates', 'unitedarabemirates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'u\.a\.e\.', 'unitedarabemirates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'u\.a\.e', 'unitedarabemirates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'uae', 'unitedarabemirates')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'vietnam thailand', 'vietnam,thailand')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'in the states', 'unitedstates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'states united', 'unitedstates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'live united states', 'unitedstates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'in america', 'unitedstates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'come to america', 'unitedstates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'come u\.s\.', 'unitedstates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'the u\.\s\.', 'unitedstates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'the us', 'unitedstates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'in the states', 'unitedstates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'th e states', 'unitedstates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'because america', 'unitedstates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'u\.s\.a', 'unitedstates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'the unitedstates', 'unitedstates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'in unitedstates', 'unitedstates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'to unitedstates', 'unitedstates')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'unitedstates', 'unitedstates')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'britain', 'unitedkingdom')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'great britain', 'unitedkingdom')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'greatbritain', 'unitedkingdom')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'u\.k\.', 'unitedkingdom')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'uk,', 'unitedkingdom')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'uk', 'unitedkingdom')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'newcastle upon tyne', 'newcastleupontyne')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'newcastleupontyne', 'newcastleupontyne')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'new castle', 'newcastle')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'newcastle', 'newcastle')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'new amsterdam', 'newamsterdam')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'new delhi', 'delhi')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'newdelhi', 'delhi')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'new jersey', 'newjersey')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'newjersey', 'newjersey')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'new yorkk', 'newyork')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'new york', 'newyork')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'new orleans', 'neworleans')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'nyc', 'newyork')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\'ny', 'newyork')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'nyc', 'newyork')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'n\.y\.c.', 'newyork')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'n\.y\.', 'newyork')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'new york', 'newyork')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'newyork', 'newyork')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'santiago de chile', 'santiagodechile')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'santiagodechile', 'santiagodechile')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'santiago, chile', 'santiagodechile')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'santiago chile', 'santiagodechile')

# ALL OTHER PLACES

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'brummie in ', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'brummie in ', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'oy', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'oy', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'here', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'here', '')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\'ca\'', 'california')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\'fl\'', 'florida')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'argentinaaaa', 'argentina')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'az,', 'arizona')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'atlantic city', 'atlanticcity')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'atlanticcity', 'atlanticcity')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'aus\!', 'australia')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\'cali\'', ' california')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'cchileeeee', 'chile')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'chileeeee', 'chile')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'chileeee', 'chile')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'chileee', 'chile')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'chilee', 'chile')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'cncinatti', 'cincinatti')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'me in co', 'colorado')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'columbus', 'columbus')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'costa ricaaaaa', 'costarica')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'costa rica', 'costarica')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'czech republic', 'czechrepublic')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'dominican republic', 'dominicanrepublic')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'egyptt', 'egypt')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'england', 'unitedkingdom')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'el paso', 'elpaso,texas')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'elpaso', 'elpaso,texas')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'hong kong', 'hongkong')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'iowa\!', 'iowa')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'isle of man', 'isleofman')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'jerseyyyyyyy', 'jersey')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'kuala lumpur', 'kualalumpur')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'kualalumpur', 'kualalumpur')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'kentucky', 'kentucky')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'kuwait', 'kuwait')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'los angeles', 'losangeles')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'hot la', 'losangeles')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'la areaaaa', 'losangeles')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'los angeles', 'losangeles')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'in la', 'losangeles')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'visiting la\.', 'losangeles')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'l\.a\.', 'losangeles')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'all over la', 'losangeles')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'back in la', 'losangeles')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'do an la', 'losangeles')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'visit la', 'losangeles')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'los angeles', 'losangeles')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'las vegas', 'lasvegas')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'lasvegas', 'lasvegas')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'vegas', 'lasvegas')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'las vegas', 'lasvegas') # JUST VEGAS
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'little rock', 'littlerock')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'massechusets', 'massachusetts')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'mexico city', 'mexicocity')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'mexicocity', 'mexicocity')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'mxico', 'mexico')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'mexico', 'mexico')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'mejico', 'mexico')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'mx', 'mexico')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'monte video', 'montevideo')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'moscu', 'moscu')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'mountain view', 'mountainview')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'mountainview', 'mountainview')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'mumbai', 'mumbai')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'/mykonos', 'mykonos')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'mykonos', 'mykonos')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'napa valley', 'napa')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'napavalley', 'napa')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'napa', 'napa')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'nashville', 'nashville')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'to nebraska', 'nebraska')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'nebraska', 'nebraska')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'nevada', 'nevada')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'nepal', 'nepal')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'netherlands', 'netherland')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'netherland', 'netherland')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'come to nz', 'newzealand')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'to nz', 'newzealand')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'new zealand', 'newzealand')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'newzealand', 'newzealand')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'nicaragua', 'nicaragua')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'nigeria', 'nigeria')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'north carolina', 'northcarolina')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'northcarolina', 'northcarolina')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('in nc', 'northcarolina')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('nc area', 'northcarolina')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('nova scotia', 'novascotia')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('novascotia', 'novascotia')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('oklahoma city', 'oklahoma')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('oklahomacity', 'oklahoma')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('palm desert', 'palmdesert')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('palmdesert', 'palmdesert')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('palm springs', 'palmsprings')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('palmsprings', 'palmsprings')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('palo alto', 'paloalto')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('paloalto', 'paloalto')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('philly', 'philadelphia')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('republic philippines', 'philippines')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('philippines republic', 'philippines')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'puerto rico', 'puertorico')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'puertorico', 'puertorico')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'phx', 'phoenix')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'punta cana', 'puntacana')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'puerto vallarta', 'puertovallarta')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'queretaro', 'queretaro')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'quertaro', 'queretaro')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'saint helier', 'sainthelier')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'sainthelier', 'sainthelier')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'el salvador', 'salvador')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'san salvador', 'sansalvador')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'saint helier', 'sainthelier')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'st helier', 'sainthelier')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'salt lake city', 'saltlakecity')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'san antonio', 'sanantonio')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'san diego', 'sandiego')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'sandiego', 'sandiego')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'in sf and', 'sanfrancisco')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'san francisco', 'sanfrancisco')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'sanfrancisco', 'sanfrancisco')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'saudi arabia', 'saudiarabia')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'seaatttlleeeeee', 'seatle')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'sri lanka', 'srilanka')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'espana', 'spain')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'southafrica', 'southafrica')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'south carolina', 'southcarolina')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'southcarolina', 'southcarolina')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'tel\-aviv', 'telaviv')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'tel aviv', 'telaviv')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'telaviv', 'telaviv')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\"texas', 'texas')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'texas will', 'texas')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'tx', 'texas')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'tokio', 'tokyo')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'viet nam', 'vietnam')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'vit nam', 'vietnam')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'virginia', 'virginia')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'wales', 'wales')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'from wales', 'wales')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'waco texas', 'waco,texas')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'waco, texas', 'waco,texas')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'waco tx', 'waco,texas')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'waco, tx', 'waco,texas')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'wales', 'wales')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'washington d\.c\.', 'washington')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'washington dc', 'washington')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'washington', 'washington')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'west midlands', 'westmidlands')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'williamsburg', 'williamsburg')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'wiltshire', 'wiltshire')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'wisconsin', 'wisconsin')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'west yorkshire', 'westyorkshire')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('new york', 'newyork')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('san francisco', 'sanfrancisco')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('san antonio', 'sanantonio')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('puerto rico', 'puertorico')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('united kingdom', 'unitedkingdom')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('brumie in', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('not sure\.', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('c\.\.', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('\(not currently though\)', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('earth', '') 
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('\á', 'a')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('\ã', 'a')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('t\ürkiye', 'turkey')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('\ü', 'u')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('belgi\ë', 'belgium')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('\ë', 'e')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('paradise for hopium', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('the moon', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('the internet', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('nearest trashcan', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('not sure\.', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('decentralised', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('/',',')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('out in the sticks', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('high, ', ',')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('is this a\.\.\. what day is this\?', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('a whales vagina\.', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('cosmos', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('tweets arent ficial advice', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('is this a\.\.\. what day is this\?', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('blockchain', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('worldwide', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r' \& ', ',')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('tweets aren\'t financial advice', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('there and back again', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('meme orange coin to the moon', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('orthogonal subspace', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('grapefruit', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('metaverse', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('la luna', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('teh cybers', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('bitcoin hq', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('end me please', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('worldwide', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('\'here\'', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('work hard everywhere', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('world of bitcoin', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('crypto island', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('work hard everyw', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('hope world', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('meme orange coin to ', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('portland\', \'or', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('central ca', 'california')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('\'us\'', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\•', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'#name\?', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\?', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+0001f1e8\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+0001f1e6\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+9999\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+6e2f\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+b300\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+2661\> ', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+5e02\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+4eac\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+1515\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+1587\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+5357\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+15e9\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+15f0\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+1s5f0\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+146d\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+144c\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+1455\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+ad6c\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+c131\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+c218\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+ad6d\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+bbfc\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+d55c\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+0001f1e8\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+0001f1e6\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+2661\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+6e2f\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+6e2f\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+d55c\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+b300\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\<u\+0001f1e8\>', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'<u\+0001f1e6\>', '')

# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'\'nan\'', '')
# # tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'nan', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r'NaN', '')
# tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace(r', ,', '')

# # tweets_smi_1['geo'] = tweets_smi_1['geo'].str.replace('', '')

print('---')
print('Location NAME Head 1')
print(tweets_smi_1['geo'].head(20))
print('---')


#######################################################################################################

# MAKE TOTAL missing_geo

total_missing_geo = pd.DataFrame()

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].astype(str, errors='ignore')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].to_string()

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].astype(str, errors='ignore')
# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].to_string()


# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].astype(str, errors='ignore')
# tweets_smi_1['missing_country'] = tweets_smi_1['missing_country'].astype(str, errors='ignore')


tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.lstrip()

tweets_smi_1['missing_geo_orig'] = tweets_smi_1['missing_geo'].copy()

# tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].astype(str)
# tweets_smi_1['geo'] = tweets_smi_1['geo'].astype(str)

tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].transform(str)
# # tweets_smi_1['geo'] = tweets_smi_1['geo'].transform(str)

print('---------')
print('TWEETS SMI 1 DTYPES')
print(tweets_smi_1.dtypes)
print('---------')

tweets_smi_1['missing_geo'] = tweets_smi_1[['missing_geo_orig', 'location_name']].astype(str, errors='ignore').apply(' '.join, axis=1)
tweets_smi_1['missing_geo_total'] = tweets_smi_1[['missing_geo_orig', 'location_name']].apply(' '.join, axis=1)

tweets_smi_1['total_missing_geo'] = tweets_smi_1['missing_geo'].astype(str, errors='ignore') + ',' + tweets_smi_1['geo'].astype(str, errors='ignore')

# COMBINE COLLUMNS

#### tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace(' ', ',')
######### tweets_smi_1['missing_geo'] = tweets_smi_1['missing_geo'].str.replace(' ', ',')


##################### tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('\"', '')
##################### tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('\'', '')

# MORE COUNTRY NAME REPLACEMENTS

tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('vietnam thailand', 'vietnam,thailand')
tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('newyork, ny', 'newyork,unitedstates')
tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('sanfrancisco,sanfrancisco', 'sanfrancisco,unitedstates')
tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('fullerton, ca', 'california,unitedstates')
tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace(' indonesia', 'indonesia')
tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('vietnam ', 'vietnam')
tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('indonesia yogyakarta', 'indonesia,yogyakarta')
# tweets_smi_1['missing_geo_total'] = tweets_smi_1['missing_geo_total'].str.replace('', '')

######################


tweets_smi_1['total_missing_geo'] = tweets_smi_1['total_missing_geo'].str.replace('vietnam thailand', 'vietnam,thailand')
tweets_smi_1['total_missing_geo'] = tweets_smi_1['total_missing_geo'].str.replace('newyork, ny', 'newyork,unitedstates')
tweets_smi_1['total_missing_geo'] = tweets_smi_1['total_missing_geo'].str.replace('sanfrancisco,sanfrancisco', 'sanfrancisco,unitedstates')
tweets_smi_1['total_missing_geo'] = tweets_smi_1['total_missing_geo'].str.replace('fullerton, ca', 'california,unitedstates')
tweets_smi_1['total_missing_geo'] = tweets_smi_1['total_missing_geo'].str.replace(' indonesia', 'indonesia')
tweets_smi_1['total_missing_geo'] = tweets_smi_1['total_missing_geo'].str.replace('vietnam ', 'vietnam')
tweets_smi_1['total_missing_geo'] = tweets_smi_1['total_missing_geo'].str.replace('indonesia yogyakarta', 'indonesia,yogyakarta')
# tweets_smi_1['total_missing_geo'] = tweets_smi_1['total_missing_geo'].str.replace('', '')

#################################################################################################

# STEMMING ## NEED TO DO 

tweets_text_words_porter = PorterStemmer().stem(tweets_text_words)  #### NOT WORKING NEED TO DO 

tweets_text_words_lancaster = LancasterStemmer().stem(tweets_text_words) #### NOT WORKING NEED TO DO

tweets_text_words_snowball = SnowballStemmer('english').stem(tweets_text_words)

# Initialize the List

tweets_text_words_stemmer = (['Porter', tweets_text_words_porter], ['Lancaster', tweets_text_words_lancaster], ['Snowball', tweets_text_words_snowball])

print('---')
print('Stemming Method Head')
print(tweets_text_words_stemmer_df.head)
print('---')


# Create the pandas DataFrame 
tweets_text_words_stemmer_df = pd.DataFrame(selected_tweets_words_counts, columns = ['stemming_method', 'stems']) 

tweets_text_words_stemmer_df.to_csv('4_5_210_SMI1_Tweets_Text_Words_Stemmer_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_text_words_stemmer_df.to_excel('4_5_210_SMI1_Tweets_Text_Words_Stemmer_DF.xlsx', header=True)


# TABLE PLOT NEED TO DO 

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Words Stemmer Methods')
# tweets_text_words_stemmer_df.plot(10,cumulative=False, alpha=0.9)
# tweets_text_words_stemmer_df[:10].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_210_SMI1_Tweets_Text_Words_Stemmer_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Words Stemmer Methods - Pie')
# plt.pie(tweets_text_words_stemmer_df[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(tweets_text_words_stemmer_df, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_210_SMI1_Tweets_Text_Words_Stemmer_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Words Stemmer Methods - Bars')
tweets_text_words_stemmers_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_210_SMI1_Tweets_Text_Words_Stemmer_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


##############################################################################################
###################################################################################################################

# DRAWING PARSE TREE ## NEED TO DO 

# USING NLTK 

# fp_text_c_tagged = nltk.pos_tag(fp_text_c_sentence_tokens)

fp_text_c_tagged = nltk.pos_tag(tweets_smi_1['text'])

# text_nltk = tweets_smi_1['text']
text_nltk = fp_text_c

tokenized_text=sent_tokenize(text_nltk)

tokenized_text_df = pd.DataFrame(tokenized_text)

print('---')
print('NLTK TOKENIZED POS TAG')
print(tokenized_text_df.head())
print('---')
# NEED TO DO ARRIBA?????

tokenized_text_df.to_csv('4_5_211_SMI1_Tokenized_Sent_CSV.csv', sep='\t', encoding='utf-8', index=True)
# tokenized_text_df.to_excel('4_5_211_SMI1_Tokenized_Sent.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# tokenized_word=word_tokenize(fp_text_c)
tokenized_word= nltk.word_tokenize(fp_text_c)



# PLOT  # NEED COUNT

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentences')
# tokenized_text.plot(10,cumulative=False)
# sns.distplot(tokenized_text[:10])
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_211_SMI1_Freq_Dist_Tokenized_Sentence.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentences - Pie')
# plt.pie(tokenized_text[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(tokenized_text, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_211_SMI1_Freq_Dist_Tokenized_Sentence_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentences - Bars')
# tokenized_text[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_211_SMI1_Freq_Dist_Tokenized_Sentence_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


###################################################################################

# Word Tokenization

tokenized_tweets_words = nltk.tokenize.word_tokenize(text)
print(tokenized_word.head)

# tokenized_tweets_words = mosestokenizer.MosesTokenizer(text)

tokenized_tweets_words.to_csv('4_5_212_SMI1_Tokenized_Tweets_Words_CSV.csv', sep='\t', encoding='utf-8', index=True)
# tokenized_tweets_words.to_excel('4_5_212_SMI1_Tokenized_Tweets_Words.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Words')
# tokenized_tweets_words.plot(10,cumulative=False)
sns.distplot(tokenized_tweets_words[:10], edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_212_SMI1_Freq_Dist_Tokenized_Tweets_Words.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Words - Pie')
# plt.pie(tokenized_tweets_words[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(tokenized_tweets_words, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_212_SMI1_Freq_Dist_Tokenized_Tweets_Words_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars # NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Words - Bars')
tokenized_tweets_words[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_212_SMI1_Freq_Dist_Tokenized_Tweets_Words_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


######################################################################
#########################################################################################################################################################

# Stoptweets_words

# Stoptweets_words considered as noise in the text. Text may contain stop tweets_words such as is, am, are, this, a, an, the, etc.
# In NLTK for removing stoptweets_words, you need to create a list of stoptweets_words and filter out your list of tokens from these tweets_words.

# NEED TO DO - NOT WORKING!!!!!!!!!!!

# stop_tweets_words = nltk.corpus.stoptweets_words.tweets_words('english')

# stop_tweets_words = stoptweets_words.tweets_words('english')

print('---')
print('Stop tweets_words NOT WORKING NEED TO FIX')
# print(stop_tweets_words)
print('---')

filtered_sent=[]
for w in tokenized_tweets_words:
    if w not in stop_tweets_words:
        filtered_sent.append(w)
# print("Tokenized Sentence:",tokenized_sent)
# print("Filterd Sentence:",filtered_sent)

tokenized_sent.to_csv('4_5_213_SMI1_Tokenized_Sent_No_Stoptweets_words_CSV.csv', sep='\t', encoding='utf-8', index=True)
# tokenized_sent.to_excel('4_5_213_SMI1_Tokenized_Sent_No_Stoptweets_words.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# PLOT TOKENIZED SENT - 1 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentiment')
# tokenized_sent.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)
tokenized_sent[:10].plot(edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_213_SMI1_Freq_Dist_Tokenized_Sent.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Tokenized Sentiment - Pie')
# plt.pie(tokenized_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.pie(tokenized_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(tokenized_sent, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_213_SMI1_Freq_Dist_Tokenized_Sent_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

############################################################################

filtered_sent.to_csv('4_5_214_SMI1_Filtered_Tweets_Words_CSV.csv', sep='\t', encoding='utf-8', index=True)
# filtered_sent.to_excel('4_5_214_SMI1_Filtered_Tweets_Words.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

# PLOT SENTIMENT OR SENTENCES????????? - 2

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Filtered Sentiment')
# filtered_sent.plot(10,cumulative=False, edgecolor='white', label=' ', alpha=0.9)
filtered_sent[:10].plot(edgecolor='white', label=' ', alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_214_SMI1_Freq_Dist_Filtered_Sent.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Frequency Distribution of Filtered Sentiment - Pie')
plt.pie(filtered_sent[:6], textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(filtered_sent, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_214_SMI1_Freq_Dist_Filtered_Sent_Pie_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

#############################################################################################################

# SPACY TEXT VISUALIZATION 

nlp = spacy.load('en')

text_corpus = st.CorpusFromPandas(fp_text_c, category_col='', text_col='text', nlp=nlp).build

###############################################################################################################
#
#         USE PACKAGE CORPUS - NEED TO DO 
#
###############################################################################################################

# https://towardsdatascience.com/practical-statistics-visualization-with-python-plotly-770e96e35067


############# plotly.tools.set_credentials_file(username='XXX', api_key='XXX')


print('MAIN SMI:')
print(main_smi)
print('----------------------------------------')

######################################################################################################################
######################################################################################################################
#
#                       SENTIMENT DF - TEXTBLOB -  USING NLTK ##### NEED TO DO !!!!!
#
######################################################################################################################
######################################################################################################################


print('------------------')
print('TEXT HEAD 10-08')
print(tweets_smi_1['text'].head)
print('----------------------------------------------------------------------')

# tweets_smi_1['text'] = tweets_smi_1['text'].astype(str, errors='ignore')
# tweets_smi_1['text'] = tweets_smi_1['text'].to_string()
# tweets_smi_1['text'] = tweets_smi_1['text'].string()
# tweets_smi_1['text'] = string(tweets_smi_1['text'])

print('-------------------------')
print('Text type HEAD AZ')
print(tweets_smi_1['text'].head)
print('-------------------------')

print('-------------------------')
print('Text Dtype')
print(tweets_smi_1['text'].dtype)
print('-------------------------')


# TEXT SENTIMENT PER YEAR TEXTBLOB

for Text in tweets_smi_1['text']:
#	fp_text_temp_single_tweet = tweets_smi_1['text']
	# tweets_smi_1['fp_text_temp_single_tweet'] = tweets_smi_1['text'].astype(str, errors='ignore')
	tweets_smi_1['fp_text_temp_single_tweet'] = tweets_smi_1['text'].to_string()
#	fp_text_single_tweet_c = fp_text_temp_single_tweet.to_string()
#	fp_text_single_tweet_c = fp_text_single_tweet ### OJO QIE ESTA SIN ARREGLAR EL C
#	textblob_obj_text_single_tweet_c = TextBlob(fp_text_single_tweet_c) ## OJO QUE SI ES EL CORREGIDO O NO	
	# tweets_smi_1['textblob_obj_text_single_tweet_c'] = tweets_smi_1['fp_text_temp_single_tweet'].TextBlob() ## OJO QUE SI ES EL CORREGIDO O NO	
	# tweets_smi_1['textblob_obj_text_single_tweet_c'] = tweets_smi_1['text'].TextBlob() ## OJO QUE SI ES EL CORREGIDO O NO	
	# tweets_smi_1['textblob_obj_text_single_tweet_c'] = TextBlob(tweets_smi_1['text'].astype(str, errors='ignore')) ## OJO QUE SI ES EL CORREGIDO O NO		
	tweets_smi_1['textblob_obj_text_single_tweet_c'] = tweets_smi_1['text'].apply(lambda tweet: TextBlob(tweet).sentiment)
	tweets_smi_1['tweets_textblob_polarity'] = tweets_smi_1['text'].apply(lambda tweet: TextBlob(tweet).sentiment.polarity)
	tweets_smi_1['tweets_textblob_subjectivity'] = tweets_smi_1['text'].apply(lambda tweet: TextBlob(tweet).sentiment.subjectivity)

		
# tweets_smi_1['textblob_sentiment_polarity'] = tweets_smi_1['text'].apply(lambda x: TextBlob(x).sentiment.polarity)
# tweets_smi_1['textblob_sentiment_subjectivity'] = tweets_smi_1['text'].apply(lambda x: TextBlob(x).sentiment.subjectivity)

# tweets_smi_1['textblob_sentiment_polarity'] = str(tweets_smi_1['textblob_sentiment_polarity'])
# tweets_smi_1['textblob_sentiment_polarity'] = str(tweets_smi_1['textblob_sentiment_polarity'])

# get_pol(tweets_smi_1['text'])

print('-------------------------')
print('tweets_smi_1 textblob_sentiment_polarity 0 ')
# print(tweets_smi_1['textblob_sentiment_polarity'].head(20))
print('-------------------------')

print('-------------------------')
print('tweets_smi_1 textblob_sentiment_polarity DTYPES 0 ')
# print(tweets_smi_1['textblob_sentiment_polarity'].dtypes)
print('-------------------------')

# tweets_smi_1['textblob_sentiment_polarity'] = tweets_smi_1['textblob_sentiment_polarity'].astype(np.int32, errors='ignore')
# tweets_smi_1['textblob_sentiment_polarity'] = tweets_smi_1['textblob_sentiment_polarity'].astype(np.int32, errors='ignore')
# tweets_smi_1['textblob_sentiment_polarity'] = int(tweets_smi_1['textblob_sentiment_polarity']) 
# tweets_smi_1['textblob_sentiment_polarity'] = int(tweets_smi_1['textblob_sentiment_polarity']) 

print('-------------------------')
print('tweets_smi_1 textblob_sentiment_polarity 1')
# print(tweets_smi_1['textblob_sentiment_polarity'].head(20))
print('-------------------------')

print('-------------------------')
print('tweets_smi_1 textblob_sentiment_polarity DTYPES 1')
# print(tweets_smi_1['textblob_sentiment_polarity'].dtypes)
print('-------------------------')

print('-------------------------')
print('tweets_smi_1 textblob_sentiment_subjectivity')
# print(tweets_smi_1['textblob_sentiment_subjectivity'].head(20))
print('-------------------------')

print('-------------------------')
print('tweets_smi_1 textblob_sentiment_subjectivity DTYPES')
# print(tweets_smi_1['textblob_sentiment_subjectivity'].dtypes)
print('-------------------------')


print('----------')
print('TEXT HEAD G')
# print(tweets_smi_1['text'].head)
print('-----------------------------------')

# NOT WORKING!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!

tweets_smi_1.to_csv('4_5_201_10_SMI1_tweets_smi_1_WITH_SENTIMENTS_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_excel('4_5_201_10_SMI1_tweets_smi_1_WITH_SENTIMENTS.xlsx', header=True)


# tweets_smi_1.to_csv('4_5_201_03_SMI1_tweets_smi_1_SENTIMENTS_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweets_smi_1.to_excel('4_5_201_03_SMI1_tweets_smi_1_SENTIMENTS.xlsx', header=True)

###############################################################################################################

# USERS WHO FAVORITE OR RETWEET STATS ### NEED TO DO

# Initialize the List

users_favorite_retweet_list = [['tweets_words_freq_dist', 'value_counts_total_favorites', 'percentage_value_counts_tweets_words_freq_dist'], ['followers', value_counts_followers, percentage_value_counts_followers], ['xx', 'xx', 'xx']]

# Create the pandas DataFrame 

users_favorite_retweet_list_df = pd.DataFrame(users_favorite_retweet_list, columns = ['item_description', 'value_counts', 'value_percentage']) 

print('---')
print('tweets_words Frequency Distribution DataFrame')
# print('users_favorite_retweet_list_df')
print('---')
  
# SAVE TO CSV  ########## NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! NOT SAVING FREQDIST!!!

# users_favorite_retweet_list_df.to_csv('4_5A_119.csv',)
# users_favorite_retweet_list_df.to_excel('4_5A_119.xlsx', header=True)

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

#############################################################################################################

############ NEED TO DO = WHAT ABOUT THE OTHER VARIABLES?????????

# USERS WHO FAVORITE OR RETWEET STATS ### NEED TO DO

# Initialize the List

users_favorite_retweet_list = [['tweets_words_freq_dist', 'value_counts_favorites', 'percentage_value_counts_tweets_words_freq_dist'], ['Retweets', value_counts_retweets, percentage_value_counts_retweets], ['xx', 'xx', 'xx']]

# Create the pandas DataFrame 

users_favorite_retweet_list_df = pd.DataFrame(users_favorite_retweet_list, columns = ['item_description', 'value_counts', 'value_percentage']) 

print('---')
print('tweets_words Frequency Distribution DataFrame')
# print('users_favorite_retweet_list_df')
print('---')
  
# SAVE TO CSV  ########## NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! NOT SAVING FREQDIST!!!

# users_favorite_retweet_list_df.to_csv('4_4_119.csv',)
# users_favorite_retweet_list_df.to_excel('4_4_119.xlsx', header=True)

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT


#################################################

## NEED TO DO FAVS AND Retweets FOR THOSE DATES!!

# _df _df = pd.DataFrame()

# .to_csv('4_4_.csv', sep='\t', encoding='utf-8', index=True)
# excel




###############################################################################################################

# USERS WHO FAVORITE OR RETWEET STATS ### NEED TO DO

# Initialize the List

users_favorite_retweet_list = [['tweets_words_freq_dist', 'value_counts_total_favorites', 'percentage_value_counts_tweets_words_freq_dist'], ['followers', value_counts_followers, percentage_value_counts_followers], ['xx', 'xx', 'xx']]

# Create the pandas DataFrame 

users_favorite_retweet_list_df = pd.DataFrame(users_favorite_retweet_list, columns = ['item_description', 'value_counts', 'value_percentage']) 

print('---')
print('tweets_words Frequency Distribution DataFrame')
# print('users_favorite_retweet_list_df')
print('---')
  
# SAVE TO CSV  ########## NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! NOT SAVING FREQDIST!!!

# users_favorite_retweet_list_df.to_csv('4_5_119.csv',)
# users_favorite_retweet_list_df.to_excel('4_5_119.xlsx', header=True)

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

###############################################################################################################

# USERS WHO FAVORITE OR RETWEET STATS ### NEED TO DO

# Initialize the List

users_favorite_retweet_list = [['tweets_words_freq_dist', 'value_counts_favorites', 'percentage_value_counts_tweets_words_freq_dist'], ['Retweets', value_counts_retweets, percentage_value_counts_retweets], ['xx', 'xx', 'xx']]

# Create the pandas DataFrame 

users_favorite_retweet_list_df = pd.DataFrame(users_favorite_retweet_list, columns = ['item_description', 'value_counts', 'value_percentage']) 

print('---')
print('tweets_words Frequency Distribution DataFrame')
# print('users_favorite_retweet_list_df')
print('---')
  
# SAVE TO CSV  ########## NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! NOT SAVING FREQDIST!!!

# users_favorite_retweet_list_df.to_csv('4_5_119.csv',)
# users_favorite_retweet_list_df.to_excel('4_5_119.xlsx', header=True)

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT
###############################################################################################################

# USERS WHO FAVORITE OR RETWEET STATS ### NEED TO DO

# Initialize the List

users_favorite_retweet_list = [['tweets_words_freq_dist', 'value_counts_favorites', 'percentage_value_counts_tweets_words_freq_dist'], ['Retweets', value_counts_retweets, percentage_value_counts_retweets], ['xx', 'xx', 'xx']]

# Create the pandas DataFrame 

users_favorite_retweet_list_df = pd.DataFrame(users_favorite_retweet_list, columns = ['item_description', 'value_counts', 'value_percentage']) 

print('---')
print('tweets_words Frequency Distribution DataFrame')
# print('users_favorite_retweet_list_df')
print('---')
  
# SAVE TO CSV  ########## NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! NOT SAVING FREQDIST!!!

# users_favorite_retweet_list_df.to_csv('4_5A_119.csv',)
# users_favorite_retweet_list_df.to_excel('4_5A_119.xlsx', header=True)

## NEED TO PLOT

# TABLE PLOT NEED TO DO 

# PLOT
##################################################################################
###########################################################################################################################



# NEED TO DO - FIX PLOTLY

#############################################################################################################

# SPACY TEXT VISUALIZATION 

nlp = spacy.load('en')

text_corpus = st.CorpusFromPandas(fp_text_c, category_col='', text_col='text', nlp=nlp).build

####################################################################################################################

## nEED TO DO --------- total_favorites AND followers!!!

####################################################################################################################

# https://tutswiki.com/pandas-cookbook/chapter2/

# Most Commons Emojis Converted NEED TO FIX !!!!

value_counts_emojis_converted = pd.value_counts(tweets_smi_1['emojis_converted'], ascending=False, normalize=True)
value_counts_emojis_converted

print('---')
print('Most Common Emojis - Converted 3')
# print(value_counts_emojis_converted)
print('---')


value_counts_emojis_converted_df = pd.DataFrame(value_counts_emojis_converted)

value_counts_emojis_converted_df.to_csv('4_5_151_3_SMI1_Value_Counts_Emojis_Converted_Tweets_df_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# SAVE TO CSV   ######################################  NEED TO SAVE TEXT ON FIRST COLUMN / SECOND COUNT

value_counts_emojis_converted.to_csv('4_5_151_3_SMI1_df_Top_Emojis_Converted_and_No_Tweets_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# value_counts_emojis_converted.to_excel('4_5_151_3_SMI1_df_Top_Emojis_Converted_and_No_Tweets.xlsx', header=True)


## NEED TO PLOT

# Bars

# TOP NUMBERS OF EMOJIS CONVERTED IN Tweets 

# top_emojis_converted_tweets = value_counts_emojis_converted.sort_values(ascending=False)

top_emojis_converted_tweets = top_emojis_converted_tweets_df.sort_values(by=['col1'], ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Emojis - Bars')
top_emojis_converted_tweets[:10].plot.bar(alpha=0.9)
plt.xlabel('Emojis')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_151_3_SMI1_Top_Tweet_Emojis_Converted_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



####################################################################################################################

# PERCENTAGE OF Followers

percentage_tweets_followers = tweets_smi_1['followers'].value_counts(normalize=True) * 100
# percentage_tweets_followers

print('---')
print('Percentage of Tweets Followers')
# print(percentage_tweets_followers)
print('---')

# Pie: PERCENTAGE followers


smi1_followers_size_sort_values_df = pd.DataFrame(percentage_tweets_followers.size().sort_values(ascending=False))

smi1_followers_size_sort_values_df.to_csv('4_5_168_SMI1_followers_size_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Followers - Pie')
plt.pie(smi1_followers_size_sort_values_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_followers, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend() 

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_168_SMI1_Percentage_followers_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR
# PLOT # NEED TO DO


########################################################################################################

# PERCENTAGE OF Hashtags

percentage_tweets_hashtags = tweets_smi_1['hashtags'].value_counts(normalize=True) * 100
percentage_tweets_hashtags

print('---')
print('Percentage of Tweets Hashtags')
# print(percentage_tweets_hashtags)
print('---')

# Pie: PERCENTAGE OF HASHTAGS

smi1_hashtags_size_sort_values_df = pd.DataFrame(percentage_tweets_hashtags).sort_values(ascending=False)

smi1_hashtags_size_sort_values_df.to_csv('4_5_169_SMI1_Hashtags_size_sort_values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Hashtags - Pie')
plt.pie(smi1_hashtags.size_sort_values_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_hashtags, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_169_SMI1_Percentage_Hashtags_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO


########################################################################################################

# PERCENTAGE OF Mentions

percentage_tweets_mentions = tweets_smi_1['mentions'].value_counts(normalize=True) * 100
percentage_tweets_mentions

print('---')
print('Percentage of Tweets Mentions')
# print(percentage_tweets_mentions)
print('---')

# Pie: PERCENTAGE OF MENTIONS ## NEED TO FIX


smi1_mentions_size_sort_values_df = pd.DataFrame(percentage_tweets_mentions.sort_values(ascending=False))

smi1_mentions_size_sort_values_df.to_csv('4_5_170_SMI1_mentions_size_sort_values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Mentions - Pie')
plt.pie(smi1_mentions.size().sort_values(ascending=False), textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_mentions, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
# centre_circle = plt.Circle((0,0),0.70,fc='white')
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_170_SMI1_Percentage_Mentions_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

# PERCENTAGE OF emojis_unicode

percentage_tweets_emojis_unicode = tweets_smi_1['emojis_unicode'].value_counts(normalize=True) * 100
percentage_tweets_emojis_unicode

print('---')
print('Percentage of Tweets emojis_unicode')
# print(percentage_tweets_emojis_unicode)
print('---')

# Pie: PERCENTAGE OF MENTIONS ## NEED TO FIX


smi1_emojis_unicode_size_sort_values_df = pd.DataFrame(percentage_tweets_emojis_unicode.sort_values(ascending=False))

smi1_emojis_unicode_size_sort_values_df.to_csv('4_5_170_SMI1_emojis_unicode_size_sort_values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# Pie: PERCENTAGE OF EMOJIS_UNICODE ## NEED TO FIX

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Emojis - Pie')
plt.pie(smi1_emojis_unicode.size_sort_values_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_emojis_unicode, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
# centre_circle = plt.Circle((0,0),0.70,fc='white')
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle. 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_172_SMI1_Percentage_Emojis_Unicode_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO

########################################################################################################

# PERCENTAGE OF emojis_converted

percentage_tweets_emojis_converted = tweets_smi_1['emojis_converted'].value_counts(normalize=True) * 100
percentage_tweets_emojis_converted

print('---')
print('Percentage of Tweets emojis_converted')
# print(percentage_tweets_emojis_converted)
print('---')

# Pie: PERCENTAGE OF emojis_converted ## NEED TO FIX


smi1_emojis_converted_size_sort_values_df = pd.DataFrame(percentage_tweets_emojis_converted.sort_values(ascending=False))

smi1_emojis_converted_size_sort_values_df.to_csv('4_5_170_SMI1_emojis_Converted_size_sort_values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# Pie: PERCENTAGE OF EMOJIS_CONVERTED ## NEED TO FIX

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Emojis - Pie')
plt.pie(smi1_emojis_converted_size_sort_values_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_emojis_converted, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)

# Draw circle
# centre_circle = plt.Circle((0,0),0.70,fc='white')
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_173_SMI1_Percentage_Emojis_Converted_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars # NEED TO DO 

########################################################################################################

# https://stackoverflow.com/questions/27898830/python-how-to-change-autopct-text-color-to-be-white-in-a-pie-chart
# https://medium.com/@kvnamipara/a-better-visualisation-of-pie-chafollowers-by-matplotlib-935b7667d77f


# PERCENTAGE OF Languages

percentage_tweets_language = tweets_smi_1['language'].value_counts(normalize=True) * 100
percentage_tweets_language

print('---')
print('Percentage of Tweets Language')
# print(percentage_tweets_language)
print('---')

# Pie: PERCENTAGE OF Languages ## NEED TO FIX


smi1_language_size_sort_values_df = pd.DataFrame(percentage_tweets_language.sort_values(ascending=False))

smi1_language_size_sort_values_df.to_csv('4_5_170_SMI1_Language_Size_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()


# Pie : PERCENTAGE OF LANGUAGES ## NEED TO FIXs

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Percentage of Languages - Pie')
plt.pie(smi1_languages_size_sort_values_df, textprops={'color':"w"}, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, colors=colors_blue, startangle=90, rotatelabels=False)
plt.legend(smi1_languages, bbox_to_anchor=(1.9, 0.4), loc='upper right', borderaxespad=0.)
# plt.legend()

# Draw circle
centre_circle = plt.Circle((0,0),0.70,fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)
# centre_circle = plt.Circle((0,0),0.1,color='black', fc='white', linewidth=0)
# fig = plt.gcf()
# fig.gca().add_artist(centre_circle)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_174_SMI1_Percentage_Languages_Pie_Chart.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


########################################################################################################

# PERCENTAGE OF Followers

percentage_tweets_followers = tweets_smi_1['followers'].value_counts(normalize=True) * 100
percentage_tweets_followers

print('---')
print('Percentage of Tweets followers')
# print(percentage_tweets_followers)
print('---')

# Pie: PERCENTAGE OF MENTIONS ## NEED TO FIX


smi1_followers_size_sort_values_df = pd.DataFrame(percentage_tweets_followers.sort_values(ascending=False))

smi1_followers_size_sort_values_df.to_csv('4_5_170_SMI1_Followers_Size_Sort_Values_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# Bars

# followers

# Plot the data

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Followers / Time - Bars')
plt.plot(created, tweets_followers, label='linear')
dmi_followers_size_sort_values_df.plot.bar(alpha=0.9)
plt.xlabel('Year / Month')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_177_SMI1_Followers_vs_Time_Chart_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


####################################################################################################################

# df_tweets_smi_processes_tokens_1_fdist = FreqDist(tweets_words)

df_tweets_smi_processes_tokens_1_fdist = FreqDist(tweets_text_words)

print('--')
print(df_tweets_smi_processes_tokens_1_fdist)
print('--')

print('--')
print('Word Frequency Distribution')
print(df_tweets_smi_processes_tokens_1_fdist.most_common(2))
print('--')


## NEED TO PLOT????????????


df_tweets_smi_processes_tokens_1_fdist_df = pd.DataFrame(df_tweets_smi_processes_tokens_1_fdist)

df_tweets_smi_processes_tokens_1_fdist_df.to_csv('4_5_184_SMI1_DF_Tweets_SMI_Processes_Tokens_1_fdist_DF_CSV.csv')
# df_tweets_smi_processes_tokens_1_fdist_df.to_excel()

# TABLE PLOT NEED TO DO

# Pie NEED TO DO 

# PLOT

# Frequency Distribution Plot


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('SMI Tweet Word Frequencies')
df_tweets_smi_processes_tokens_1_fdist.plot(10,cumulative=False)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_184_SMI1_Tweets_Processes_Tokens_1_fdist_Most_Common.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


print('--')
print('Word Frequency Distribution')
print(df_tweets_smi_processes_tokens_1_fdist.most_common(2))
print('--')

df_tweets_smi_processes_tokens_1_fdist_most_common_2 = df_tweets_smi_processes_tokens_1_fdist.most_common(2)

## NEED TO PLOT????????????


df_tweets_smi_processes_tokens_1_fdist_most_common_2 = pd.DataFrame(df_tweets_smi_processes_tokens_1_fdist_most_common_2)

df_tweets_smi_processes_tokens_1_fdist_most_common_2.to_csv('4_5_184_SMI1_DF_Tweets_SMI_Processes_Tokens_1_fdist_Most_Common_2_CSV.csv')
# df_tweets_smi_processes_tokens_1_fdist_most_common_2.to_excel()

##########################################################################################


##########################################################################################

# ourcodingclub.github.io/tutorials/topic-modelling-python/

# Hashtag Correlations

# Take the rows from the hashtag colum 

# hashtags_list_df = tweets_smi_1[tweets_smi_1.hashtags.apply(lambda hashtags_list: hashtags_list !=[]), ['hashtag']]

# Create a DataFrame where each of the hashtags has its own row via list comprehension

flattened_hashtags_df = pd.DataFrame(
#	[hashtag in hashtags_list in hashtags_list_df.hashtags
	[hashtag in tweets_smi_1['hashtags']
#	for hashtag in hashtags_list], 
	for hashtag in tweets_smi_1['hashtags']],
	columns=['hashtag'])

# Number of Unique Hashtags

number_unique_hashtags = flattened_hashtags_df['hashtags'].unique().size

# Count the appereances of each hashtag

popular_hashtags = flattened_hashtags_df.groupby('hashtags').size()\
					 .reset_index('counts')\
					 .sort_values('counts', ascending=False)\
					 .reset_index(drop=True)


popular_hashtags.to_csv('4_5_183_SMI1_Popular_Hashtags_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# popular_hashtags.to_excel('4_4_183_SMI1_Popular_Hashtags.xlsx', header=True)

# Number of total_favoritess each hashtag appears

hashtag_counts = flattened_hashtags_df.groupby('hashtags').size()\
					 .reset_index('counts')\
					 .counts


# Define bins for histogram

hashtags_bins = np.arrange(0,counts.max()+2, 5)-0.5

# Plot Histogram of tweet counts


# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Popular Hashtags - Histogram')
plt.hist(hashtag_counts, bins = hashtags_bins)
plt.xlabels = np.arrange(1,hashtag_counts.max()+1, 1)
plt.xlabel('Hashtags')
plt.ylabel('Frequency')
plt.yscale('log', nonposy='clip')
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_183_SMI1_Popular_Hashtags_Hist_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# TABLE ## NEED TO DO

# plot.legend()

# Pie 

# plt.rcdefaults()
fig, ax = plt.subplots()

# explode_tweets_numbers_item_values_df = (0.1,0.1)

# plt.subplot(223)
# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Popular Hashtags - Pie')
plt.pie(hashtag_counts, colors=colors_blue, labels=tweets_numbers_item_values_df['tweets_by_item_description'], startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.xlabel('Hashtags')
# plt.ylabel('Count')
plt.legend(labels=tweets_numbers_item_values_df['tweets_by_item_description'], bbox_to_anchor=(0.7, 0.7), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_183_SMI1_Popular_Hashtags_PLT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars ## NEED TO DO # FIX LABEL X AXIS AND MEASURES SHOWING

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Popular Hashtags - Bars')
hashtag_counts.plot.bar
plt.xlabel('Hashtags')
plt.ylabel('Frequency')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
 
# plt.show()
plt.savefig('4_5_183_SMI1_Popular_Hashtags_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

###################################################################################################################

# STATISTICS DF # NEED TO DO  NOT WORKING NEED TO FIX FOLLOWERS MESCLADOS CON OTROS 


# initialize list of Lists 

# quant_stats_1_pairs = [['Mean followers', median_followers, 'Median followers', median_followers, 'Mode followers', mode_followers, 'Mode followers', mode_followers], ['Variance total_favorites', variance_total_favorites, 'Variance followers', variance_followers, 'Population Variance total_favorites', pvariance_total_favorites, 'Population Variance followers', pvariance_followers, 'Standard Deviation followers', stdev_followers, 'Population Standard Deviation total_favorites', pstdev_total_favorites, 'Population Standard Deviation followers', pstdev_followers, 'Skewness followers', skewness_followers, 'Skewness followers', skewness_followers, 'Percentiles total_favorites (25, 50, 75)', quantiles_total_favorites, 'Percentiles Followers (25, 50, 75)', quantiles_followers, 'Ranges total_favorites', ptp_total_favorites, 'Ranges followers', ptp_followers, 'Correlation Coefficient - Pearson Regression', corr_coef_total_favorites_followers_pearson, 'Linear Regession', r_linar_reg],['Number of Tweets Analyzed', number_tweets, 'Number of Unique Tweets Analyzed', number_unique_tweets, 'Number of tweets_words in Text', number_of_tweets_words, 'List Unique Followers ReTweeting, Commenting, Engaged', number_unique_engaged_users, 'Number of Users Who Favorite', number_unique_tweets_with_total_favorites, 'Number of Unique Tweets with followers', 'number_unique_followers_users', 'List Unique Hashtags', 'number_unique_hashtags', 'List Unique Mentions', 'number_unique_mentions', 'List Unique Emojis', 'number_unique_emojis_unicode', 'List Unique Emojis', 'number_unique_emojis_converted', 'List Unique Language', 'number_unique_languages', 'Summary Statistics All followers / Desc', 'summ_stats_all_followers_desc', 'Summary Statistics All Followers / Desc', 'summ_stats_all_followers_desc']]

# Create the pandas DataFrame 
# quant_stats_measures_1 = pd.DataFrame(quant_stats_1_pairs, columns = ['Measures of Centrality', 'Measures of Variability', 'General User Stats', 'Other Stats']) 

# quant_stats_measures_1.to_csv('4_5_170_SMI1_Quant_Stats_Measures_Followers_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# quant_stats_measures_1.to_excel('4_5_170_SMI1_Quant_Stats_Measures_Followers.xlsx', header=True)

### NEED TO DO PLOT?????????????????


#################################################################################################################

# SETTING COLOR MAPS ## NEED TO DO NOT WORKING 

# plt.rcParams['image.cmap']='PuBu_r'
# plt.set_cmap('PuBu_r')

plt.rcParams['image.cmap']='Blues'
plt.set_cmap('Blues')
plt.rcParams['figure.facecolor']='#6593F5'
plt.rcParams['figure.edgecolor']='white'
plt.interactive(False)

def ioff():
	matplotlib.interactive(False)
	uninstall_repl_display_hook()

plt.rcParams['image.cmap']='GnBu'
plt.set_cmap('GnBu')

colors_blue = ['#73C2FB', '#6593F5', '#0F52BA', '#000080', 'blue', 'lightskyblue', 'blue']
explode_pie = (0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1)

# plt.rcParams['image.cmap']='#73C2FB'
# plt.set_cmap('colors_blue')

# figure.max_open_warning

font = FontProperties()
# font.set_family('serif')
font.set_name('Segoe UI Emoji')

# plt.rcParams.update({'font.size': 16})

# plt.rcParams['xtick']=labelsize=14)
# plt.rcParams['ytick']=labelsize=14)

axis_font = {'fontname':'Segoe UI Emoji', 'size': 10}

legend_font = {'fontname':'Segoe UI Emoji', 'size': 10}

sns.set(style='ticks')
# sns.palplot(sns.color_palette('GnBu_d'))
sns.palplot(sns.color_palette('Blues'))

#################################################################################################################
#################################################################################################################
#################################################################################################################

# Groupby by ######################################### NEED TO DO NOT WORKING!!!!!!!!

smi1_screenname = tweets_smi_1.groupby('screenName')
smi1_dates = tweets_smi_1.groupby('created')
smi1_created = tweets_smi_1.groupby('created')
smi1_favorites = tweets_smi_1.groupby('favorites')
smi1_retweets = tweets_smi_1.groupby('retweets')
smi1_followers = tweets_smi_1.groupby('followers')
smi1_text = tweets_smi_1.groupby('text')
smi1_hashtags = tweets_smi_1.groupby('hashtags')
smi1_hashtags = tweets_smi_1['hashtags_total']
smi1_mentions = tweets_smi_1.groupby('mentions')
smi1_mentions = tweets_smi_1['mentions_total']
smi1_emojis_unicode = tweets_smi_1.groupby('emojis_unicode')
smi1_emojis_converted = tweets_smi_1.groupby('emojis_converted')
smi1_languages = tweets_smi_1.groupby('language')

# smi1_screenname = pd.groupby(df['screenName'])
# smi1_created = pd.groupby(df['created'])
# smi1_favorites = pd.groupby(df['favorites'])
# smi1_retweets = pd.groupby(df['retweets'])
# smi1_followers = pd.groupby(df['followers'])
# smi1_text = pd.groupby(df['text'])
# smi1_hashtags = pd.groupby(df['hashtags'])
# smi1_mentions = pd.groupby(df['mentions'])
# smi1_image_link = pd.groupby(df['image_link'])
# smi1_emojis_unicode = pd.groupby(df['emojis_unicode'])
# smi1_emojis_converted = pd.groupby(df['emojis_converted'])
# smi1_language = pd.groupby(df['language'])

# print('-- grouped terms')


#################################################################################################################

# Groupby by ######################################### NEED TO DO NOT WORKING!!!!!!!!

# smi1_screenname = tweets_smi_1.groupby('screenName')
# smi1_dates = tweets_smi_1.groupby('created')
# smi1_created = tweets_smi_1.groupby('created')
# smi1_favorites = tweets_smi_1.groupby('favorites')
# smi1_retweets = tweets_smi_1.groupby('retweets')
# smi1_followers = tweets_smi_1.groupby('followers')
# smi1_text = tweets_smi_1.groupby('text')
# smi1_hashtags = tweets_smi_1.groupby('hashtags')
# smi1_hashtags = hashtags_total_1
# smi1_mentions = tweets_smi_1.groupby('mentions')
# smi1_mentions = missing_mentions_1
# smi1_emojis_unicode = tweets_smi_1.groupby('emojis_unicode')
# smi1_emojis_converted = tweets_smi_1.groupby('emojis_converted')
# smi1_languages = tweets_smi_1.groupby('language')

# smi1_screenname = pd.groupby(df['screenName'])
# smi1_created = pd.groupby(df['created'])
# smi1_favorites = pd.groupby(df['favorites'])
# smi1_retweets = pd.groupby(df['retweets'])
# smi1_followers = pd.groupby(df['followers'])
# smi1_text = pd.groupby(df['text'])
# smi1_hashtags = pd.groupby(df['hashtags'])
# smi1_mentions = pd.groupby(df['mentions'])
# smi1_image_link = pd.groupby(df['image_link'])
# smi1_emojis_unicode = pd.groupby(df['emojis_unicode'])
# smi1_emojis_converted = pd.groupby(df['emojis_converted'])
# smi1_language = pd.groupby(df['language'])

# print('-- grouped terms')

#################################################################################

#################################################################################################################

# Ranges Favorites

# The range of data is the difference between the maximum and minimum element in the dataset.

ptp_favorites = np.ptp(tweets_smi_1['favorites'])
ptp_favorites

print('---')
print('Ranges Favorites')
print(np.ptp(tweets_smi_1['favorites']))
print('---')


ptp_favorites_df = pd.DataFrame([ptp_favorites], columns=['ranges_favorites'])

ptp_favorites_df.to_csv('4_4_20_SMI1_PTP_Ranges_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# .to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Ranges Favorites - Box')
plt.ioff()
# plt.boxplot(np.ptp(tweets_smi_1['favorites']), patch_artist=True, vert=False, notch=False, showfliers=True)
# plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_20_SMI1_PTP_Favorites_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
# plt.autoscale() 
plt.figure(figsize=(4,7))
plt.suptitle(main_smi, y=1.0)
plt.title('Ranges Favorites - Bars')
plt.ioff()
ptp_favorites_df.plot.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_20_SMI1_PTP_Favorites_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# Ranges Retweets

ptp_retweets = np.ptp(tweets_smi_1['retweets'])
ptp_retweets

print('---')
print('Ranges Retweets')
print(np.ptp(tweets_smi_1['retweets']))
print('---')

ptp_retweets_df = pd.DataFrame([ptp_retweets], columns=['ranges_retweets'])

ptp_retweets_df.to_csv('4_4_21_SMI1_ptp_Ranges_Retweets_1_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# ptp_retweets_df.to_excel()

# NEED TO DO TABLE PLOT

# BOX PLOT ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Ranges Retweets - Box')
plt.ioff()
# plt.boxplot(np.ptp(tweets_smi_1['retweets']), patch_artist=True, vert=False, notch=False, showfliers=True) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_21_SMI1_ptp_Retweets_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Ranges Retweets - Bars')
plt.ioff()
# ptp_retweets_df.plt.bar(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True) 
# plt.show()
plt.savefig('4_4_21_SMI1_PTP_Retweets_Bar_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLE

del ptp_retweets
del ptp_retweets_df


##################################################################################################################

# top_screnname_followers = tweets_smi_1.groupby('screenName')[['followers_count']].sum()
# top_screenname_followers = top_screenname_followers.sort_values(ascending=False)[:10]

top_screnname_followers = tweets_smi_1['followers_count'].value_counts(ascending=False)

top_screnname_followers_df = pd.DataFrame([top_screnname_followers])

# NEED TO DO PLOT!!!!!!!!!!!!!!!!

# TABLE PLOT

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames by Tweet Number and Followers - Pie')
plt.ioff()
top_screnname_followers_df[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['screenName'], bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_37_77_SMI1_Top_Screenname_Followers_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames by Tweet Number and Followers - Bars')
plt.ioff()
top_screnname_followers_df[:10].plot.bar(alpha=0.9)
plt.xlabel('ScreenName')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_37_77_SMI1_Top_ScreenName_Followers_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLE

del top_screenname_followers

##################################################################################################################

# top_screnname_friends_count = tweets_smi_1.groupby('screenName')[['friends_count']].sum()
# top_screenname_friends_count = top_screenname_friends_count.sort_values(ascending=False)[:10]

top_screnname_friends_count = tweets_smi_1['friends_count'].value_counts(ascending=False)

# NEED TO DO PLOT!!!!!!!!!!!!!!!!

# TABLE PLOT

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames by Tweet Number and Friends - Pie')
plt.ioff()
top_screnname_friends_count[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(tweets_smi_1['screenName'], bbox_to_anchor=(1.05, 1.1), loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_37_77_SMI1_Top_ScreenName_Friends_Count_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames by Tweet Number and Friends - Bars')
plt.ioff()
top_screnname_friends_count[:10].plot.bar(alpha=0.9)
plt.xlabel('ScreenNames')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_37_77_SMI1_Top_ScreenName_Friends_Count_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del top_sreenname_friends_count


##############################################################################################

# List Total Favorites ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!


number_total_favorites = tweets_smi_1['favorites'].sum()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


print('---')
print('List Total Favorites')
# print(number_total_favorites.head)
print('---')

number_total_favorites_df = pd.DataFrame([number_total_favorites], columns=['number_total_favorites'])

number_total_favorites_df.to_csv('4_4_43_SMI1_Number_Total_Favorites_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# number_total_favorites_df.to_excel()

number_total_favorites_year = tweets_smi_1.groupby(['year'])['favorites'].sum()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


print('---')
print('List Total Favorites Year')
# print(number_total_favorites_year.head)
print('---')

number_total_favorites_year_df = pd.DataFrame([number_total_favorites_year], columns=['number_total_favorites_year'])

number_total_favorites_year_df.to_csv('4_4_43_SMI1_Number_Total_Favorites_Year_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# number_total_favorites_df.to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Favorites - Year')
plt.ioff()
number_total_favorites_year_df.plot()
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Favorites_Year_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Favorites - Pie')
plt.ioff()
# plt.pie(tweet_info_retweets_df['number_total_favorites_df'], labels=number_total_favorites_df)
# plt.pie(number_total_favorites['number_total_favorites_df'], labels=number_total_favorites, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=number_total_favorites, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Favorites_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Favorites - Bars')
plt.ioff()
number_total_favorites_year_df.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Favorites_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# List Total Retweets ####################################### NEED TO GET HASTAGS AND MENTIONS!!!!!!

number_retweets = tweets_smi_1['retweets'].sum()    ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


print('---')
print('List Total Retweets')
# print(number_retweets)
print('---')

number_retweets_df = pd.DataFrame([number_retweets], columns=['number_retweets'])

number_retweets_df.to_csv('4_4_43_SMI1_Number_Total_Retweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# number_retweets_df.to_excel()

## NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Retweets Year')
plt.ioff()
tweets_smi_1.groupby(['created']).sum()['retweets'].plot(alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Retweets_Year_DF_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Retweets - Pie')
plt.ioff()
# plt.pie(tweet_info_retweets_df['number_retweets_df'], labels=number_retweets_df)
# plt.pie(number_retweets['number_retweets_df'], labels=number_retweets, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(labels=number_retweets, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Retweets_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Number Retweets - Bars')
plt.ioff()
# number_retweets.plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_SMI1_Number_Total_Retweets_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#################################################################################################################

# https://realpython.com/python-statistics/

# MEAN and MEDIAN BOXPLOT OF Followers Count AND Friends Count      ######## NEED TO DO!!!!

# NEED TO DO TABLE PLOT

# BOX PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Mean and Median of Followers / Friends Count - Box')
plt.ioff()
tweets_smi_1.boxplot(column = 'followers_count', grid=True)
tweets_smi_1.boxplot(column = 'friends_count', grid=True)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_5_SMI1_Mean_and_Median_of_Followers_Count_Friends_Count_Box_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

####################################################################################################
#####

# METHOD 1 Following location


fp_following_location = fp_is_following['location'].to_string()

# fp_following_location = fp_following_location_temp.to_string()

tweets_text_following_location = nltk.word_tokenize(fp_following_location)

value_counts_following_location_df = pd.value_counts(tweets_text_following_location, ascending=False, normalize=True) 

smi1_value_counts_following_location_df = value_counts_following_location_df.sort_values(ascending=False)

# smi1_value_counts_following_location_freq_dist = tweets_text_following_location.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Following location - Frequency')
# print(smi1_value_counts_following_location.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Following location')
# print(smi1_value_counts_following_location.describe().head)
print('---')

smi1_value_counts_following_location_df = pd.DataFrame(smi1_value_counts_following_location, columns=['following_location_frequency'])

smi1_value_counts_following_location_df.to_csv('4_4_50_100_SMI1_Value_Counts_Is_Following_Location_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_following_location_df.to_excel('4_4_50_100_SMI1_Value_Counts_Is_Following_Location_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Is Following Location Value Counts')
# plt.plot(smi1_value_counts_following_location[:10], alpha=0.9)
plt.xlabel('Location')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Is_Following_Location_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Is Following Location Value Counts - Pie')
smi1_value_counts_following_location[:6].plot(kind='pie', colors=colors_blue, startangle=60, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_following_location, loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Is_Following_Location_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')

# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Is Following Location Value Counts - Bars')
plt.ioff()
smi1_value_counts_following_location[:10].plot.bar(alpha=0.9)
plt.xlabel('Location')
plt.ylabel('Count')
# plt.legend(smi1_value_counts_following_location) 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_100_SMI1_Top_Is_Following_Location_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


## DELETE VARIABLE

del smi1_value_counts_following_location
del smi1_value_counts_following_location_df

####################################################################################################

###########################################################################################################################################################

# Percentage of 

value_counts_followers

value_counts_following

percentage_value_counts_followers = ((value_counts_followers * 100)/number_total_tweets)
percentage_value_counts_followers

print('---')
print('Top Followers Number Value Counts Percentages')
print(percentage_value_counts_followers)
print('---')

percentage_value_counts_following = ((value_counts_following * 100)/number_total_tweets)
percentage_value_counts_following

print('---')
print('Top Following Number Value Counts Percentages')
print(percentage_value_counts_following)
print('---')


# NEED TO DO - FIX - CHANGE

# users_followers_following_list = [['followers', value_counts_followers, percentage_value_counts_followers], ['following', value_counts_following, percentage_value_counts_following], ['xx', 'xx', 'xx']]
users_followers_following_list = [['followers_value_counts', value_counts_followers, percentage_value_counts_followers], ['following_value_counts', value_counts_following, percentage_value_counts_following]]


# Create the pandas DataFrame 
users_followers_following_list_df = pd.DataFrame(users_followers_following_list, columns = ['description_item_value', 'item_value_count', 'item_value_percentage']) 

print('--------')
print('Top Followers - Following Number Value Counts Percentages DF - NEED TO FIX')
# print(users_followers_retweet_list_df)
print('--------')

users_followers_following_list_df.to_csv('4_4_50_77_Users_Followers_Following_list_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# users_followers_following_list_df.to_excel('4_4_50_77_Users_Followers_Following_list_DF.xlsx', header=True)

# NEED TO DO PLOT!!!!!!!!!!!!!!!!

top_following_tweets = value_counts_following.sort_values(ascending=False)



# TABLE PLOT

# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Values of Following - Bars')
top_following_tweets[:10].plot(alpha=0.9)
plt.xlabel('Number of Following')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_77_SMI1_Top_following_Values_Number_PLot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Following - Pie')
top_following_tweets[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
# plt.legend(users_followers_following_list_df, loc='upper right', borderaxespad=0.)
# plt.legend()
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_77_SMI1_Top_following_Values_Number_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Following - Bars')
top_following_tweets[:6][:6].plot.bar(alpha=0.9)
plt.xlabel('Number of Following')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_77_SMI1_Top_following_Values_Number_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del top_following_tweets

###########################################################################################


# Plot 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Values of Following - Bars')
# users_followers_following_list_df[:10].plot(alpha=0.9)
plt.xlabel('Number of Following')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_77_Top_Users_Followers_Following_List_df_Number_PLot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# TABLE PLOT

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Following - Pie')
# users_followers_following_list_df[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
# plt.legend(users_followers_following_list_df, loc='upper right', borderaxespad=0.)
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_50_77_SMI1_Top_Users_Followers_following_List_df_Number_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Frequent Values of Following - Bars')
# users_followers_following_list_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Number of Following')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_77_SMI1_Top_Users_Followers_following_List_Number_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del users_followers_following_list
del users_followers_following_list_df

##############

# Inicialize List of Lists NOT UNIQUE Followers AND Following

tweet_info_followers_following_not_unique = [['Users with Followers', number_tweets_with_followers_not_unique, percentage_tweets_with_followers_not_unique], ['Users with NO Followers', number_tweets_without_followers_filter, percentage_tweets_without_followers_filter], ['Users with Following', number_tweets_with_following_not_unique, percentage_tweets_with_following_not_unique], ['Users with NO Following', number_tweets_without_following_filter, percentage_tweets_without_following_filter]]

# Create DataFrame

tweet_info_followers_following_not_unique_df = pd.DataFrame(tweet_info_followers_not_unique, columns =['tweet_info_followers_following_not_unique', 'number_tweet_info_followers_following_not_unique', 'percentage_tweet_info_followers_following_not_unique'])

print('---')
print('Tweet Info Followers and Following NOT UNIQUE Information')
# print(tweet_info_following_not_unique_df)
print('---')

tweet_info_followers_following_not_unique_df.to_csv('4_4_40_SMI1_Tweet_Info_Following_Not_Unique_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_followers_following_not_unique_df.to_excel('4_4_40_SMI1_Tweet_Info_Following_Not_Unique_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# PLOT BARS - MULTIPLE - Tweets Followers AND Following NOT UNIQUE 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

# '#73C2FB', '#6593F5',

r1 = np.arange(len(tweet_info_followers_not_unique_df['number_tweet_info_followers_not_unique']))
r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Tweets Followers and Following Not Unique - Bars')

plt.bar(r1, tweet_info_followers_not_unique_df['number_tweet_info_followers_not_unique'], color='#73C2FB', edgecolor='white', label='followers', alpha=0.9)
plt.bar(r2, tweet_info_following_not_unique_df['number_tweet_info_following_not_unique'], color='blue', edgecolor='white', label='following', alpha=0.9)

plt.xticks(rotation=50)
plt.xlabel('Users with Followers, Users without Followers, Users with Following, Users without Following')
plt.ylabel('Count')
plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True)
# plt.show()
plt.savefig('4_4_40_SMI1_Tweet_Info_Followers_following_Not_Unique_df_Bar_Plot_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLES

del tweet_info_followers_following_not_unique
del tweet_info_followers_following_not_unique_df

###################################################################################################

# Inicialize List of Lists UNIQUE Followers AND Following

tweet_info_followers_following_not_unique = [['Unique Users with Followers', number_unique_tweets_with_followers, percentage_unique_tweets_with_followers], ['Unique Users without Followers', number_unique_tweets_without_followers, percentage_unique_tweets_without_followers], ['Unique Users with Following', unique_tweets_with_following, percentage_unique_tweets_with_following], ['Unique Users without Following', number_unique_tweets_without_following, percentage_unique_tweets_without_following]]

# Create DataFrame

tweet_info_followers_following_not_unique_df = pd.DataFrame(tweet_info_followers_not_unique, columns =['tweet_info_followers_following_unique', 'number_tweet_info_followers_following_unique', 'percentage_tweet_info_followers_following_unique'])

print('---')
print('Tweet Info Followers and Following UNIQUE Information')
# print(tweet_info_followers_following_not_unique_df)
print('---')

tweet_info_followers_following_not_unique_df.to_csv('4_4_50_SMI1_Tweet_Info_Followers_following_Not_Unique_DF_CSV.csv', sep='\t', encoding='utf-8', index=False, header=True)
# tweet_info_followers_following_not_unique_df.to_excel('4_4_50_SMI1_Tweet_Info_Followers_following_not_unique_DF.xlsx', header=True)

# PLOT TABLE NEED TO DO 

# PLOT BARS - MULTIPLE - Tweets Followers AND Following UNIQUE 

# Set Parameters

fig, ax = plt.subplots(1, 1) 
plt.ioff()
barWidth = 0.2 # Width of Bar

# Set the position of bar on X axis

r1 = np.arange(len(tweet_info_unique_tweets_with_followers_df['number_unique_tweets_with_followers']))
r2 = [x + barWidth for x in r1]

# Bars - MULTIPLE VARIABLES

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Unique Tweets Followers and Following - Bars')

plt.bar(r1, tweet_info_unique_tweets_with_followers_df['number_unique_tweets_with_followers'], color='#73C2FB', edgecolor='white', label='followers', alpha=0.9)
plt.bar(r2, tweet_info_unique_tweets_with_following_df['number_unique_tweets_with_following'], color='blue', edgecolor='white', label='following', alpha=0.9)

plt.xticks(rotation=50)
plt.xlabel('Unique Users with Followers, Without Followers, Unique Users with Following, Without Following')
plt.ylabel('Count')
plt.legend() 
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.legend()
# ax.grid(True)
# plt.show()
plt.savefig('4_4_50_SMI1_Tweet_Info_Followers_Following_Not_Unique_DF_Bar_Plot_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

## NEED TO DO SCREENNAME STAS!!!!!!!!!!!!!!

############################################################################################################

# Value Counts screenNames   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_screenname = pd.value_counts(tweets_smi_1['screenName'], ascending=False, normalize=True)

smi1_value_counts_screenname = value_counts_screenname.sort_values(ascending=False)

print(value_counts_screenname)

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics of ScreenNames - Grouped')
print(smi1_value_counts_screenname.describe().head())
print('---')

smi1_value_counts_screenname_df = pd.DataFrame(value_counts_screenname, columns =['screenname'])

smi1_value_counts_screenname_df.to_csv('4_5_105A_SMI1_ScreenNames_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_screenname_df.to_excel('4_5_105A_SMI1_Screennames_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Value Counts')
plt.ioff()
# smi1_value_counts_screenname.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_screenname_df[:10].plot(alpha=0.9)
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_105A_SMI1_Top_ScreenNames_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Value Counts - Pie')
plt.ioff()
# plt.pie(smi1_value_counts_screenname[:6], labels=smi1_tweets_text_words_fdist['screenname'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_screenname_df[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
# plt.legend(smi1_value_counts_screenname, bbox_to_anchor=(1.05, 1.15), loc='upper right', borderaxespad=0.2)
# plt.legend() 
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_5_105A_SMI1_Top_ScreenNames_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Value Counts - Bars')
plt.ioff()
smi1_value_counts_screenname_df[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_105_SMI1_Top_ScreenNames_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del smi1_value_counts_screenname
del smi1_value_counts_screenname_df


###############################################################################################################

# TOP NUMBERS OF HASHTAGS IN Tweets  XXX NEED TO FIX NOT WORKING NEED TO COUNT THE NUMBER OF HASHTAGS

top_hashtags_tweets = value_counts_hashtags.sort_values(ascending=False)

top_hashtags_tweets_df = pd.DataFrame(top_hashtags_tweets)

top_hashtags_tweets_df.to_csv('4_5_124_3_SMI1_Top_Hashtags_tweets_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

print('---')
print('Most Common Tweet Hashtags 3')
# print(pd.value_counts(tweets_smi_1['hashtags'], ascending=False, normalize=True))
print('---')

# BARS

# plt.rcdefaults()
fig, ax = plt.subplots()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Most Used Hashtags Used - Bars')
plt.ioff()
top_hashtags_tweets[:10].plot.bar(alpha=0.9)
plt.xticks(rotation=50)
plt.xlabel('Hashtags')
plt.ylabel('Count')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_124_3_SMI1_Top_Tweet_Hashtags_Number_Tweets_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del top_hashtags_tweets
del top_hashtags_tweets_df

# Frequency Distribution  

## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# METHOD 1

# smi1_value_counts_words_freq_dist = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True) #### NEED TO DO BUT FOR SENTENCES

value_counts_words = pd.value_counts(tweets_text_words, ascending=False, normalize=True) 

smi1_value_counts_words = value_counts_words.sort_values(ascending=False)

# smi1_value_counts_words_freq_dist = tweets_text_words.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Words - Frequency')
# print(smi1_value_counts_words.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Words')
# print(smi1_value_counts_words.describe().head)
print('---')

smi1_value_counts_words_df = pd.DataFrame(smi1_value_counts_words, columns=['word','word_frequency'])

smi1_value_counts_words_df.to_csv('4_5A_100_SMI1_Value_Counts_Words_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# smi1_value_counts_words_df.to_excel('4_5A_100_SMI1_Value_Counts_Words_DF.xlsx', header=True)

xx

# NEED TO DO TABLE PLOT !!!!!!!!

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Value Counts Words Frequency - Pie')
plt.ioff()
# plt.pie(smi1_value_counts_words.describe(), labels=top_retweets_tweets, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_words[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_words,bbox_to_anchor=(1.05, 1), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_100_SMI1_Top_Value_Counts_Words_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Value Counts Words Frequency - Bars')
plt.ioff()
smi1_value_counts_words[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_100_SMI1_Top_Value_Counts_Words_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

############################################################################################################

### NOT WORKING NEED TO DO

# Frequency Distribution  

## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# METHOD 1 WORDS

# smi1_value_counts_words_freq_dist = pd.value_counts(tweets_smi_1['text']) #### NEED TO DO BUT FOR SENTENCES

# value_counts_words = pd.value_counts(tweets_text_words) 

value_counts_words = collections.Counter(tweets_text_words, ascending=False) 

smi1_value_counts_words = value_counts_words.most_common(10)

# smi1_value_counts_words = value_counts_words.sort_values(ascending=False)

# smi1_value_counts_words_freq_dist = tweets_text_words.sort_values(by='', axis=0, ascending=False, na_position='last')



# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Words')
# print(smi1_value_counts_words.describe().head)
print('---')

smi1_value_counts_words_df = pd.DataFrame(smi1_value_counts_words, columns=['word', 'word_frequency'])

# smi1_value_counts_words_df = pd.DataFrame(smi1_value_counts_words, columns=['word_frequency'])

print('----')
print('Value Counts Words - Frequency HEAD')
print(smi1_value_counts_words_df.head)
print('----')

print('----')
print('Value Counts Words - Frequency DTYPES')
print(smi1_value_counts_words_df.dtypes)
print('----')

smi1_value_counts_words_df.to_csv('4_4_100_SMI1_Value_Counts_Words_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_words_df.to_excel('4_4_100_SMI1_Value_Counts_Words_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Words Value Counts')
plt.ioff()
# plt.plot(smi1_value_counts_words[:10], alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_100_SMI1_Top_Words_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Words Value Counts - Pie')
plt.ioff()
# smi1_value_counts_words[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_words, loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_100_SMI1_Top_Words_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Words Value Counts - Bars')
plt.ioff()
# smi1_value_counts_words[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_100_SMI1_Top_Words_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#######################################################################################################################

### NOT WORKING NEED TO DO

# Frequency Distribution  

## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# METHOD 1

# smi1_value_counts_words_freq_dist = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True) #### NEED TO DO BUT FOR SENTENCES

value_counts_words = pd.value_counts(tweets_text_words, ascending=False, normalize=True) 

smi1_value_counts_words = value_counts_words.sort_values(ascending=False)

# smi1_value_counts_words_freq_dist = tweets_text_words.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Words - Frequency')
# print(smi1_value_counts_words)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Words')
# print(smi1_value_counts_words.describe().head())
print('---')

smi1_value_counts_words_df = pd.DataFrame(smi1_value_counts_words, columns=['word_frequency'])

smi1_value_counts_words_df.to_csv('4_5_100_SMI1_Value_Counts_Words_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_words_df.to_excel('4_5_100_SMI1_Value_Counts_Words_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.subplot(223)
# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Value Counts Words Frequency - Pie')
plt.ioff()
# plt.pie(smi1_value_counts_words.describe(), labels=top_followers_tweets, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_words[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_words,bbox_to_anchor=(1.05, 1), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_100_SMI1_Top_Value_Counts_Words_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Value Counts Words Frequency - Bars')
plt.ioff()
smi1_value_counts_words[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_100_SMI1_Top_Value_Counts_Words_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## DELETE VARIABLE

del smi1_value_counts_words
del smi1_value_counts_words_df


###################################################################################################

# Frequency Distribution  

## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# METHOD 1

# smi1_value_counts_words_freq_dist = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True) #### NEED TO DO BUT FOR SENTENCES

value_counts_words = pd.value_counts(tweets_text_words, ascending=False, normalize=True) 

smi1_value_counts_words = value_counts_words.sort_values(ascending=False)

# smi1_value_counts_words_freq_dist = tweets_text_words.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Words - Frequency')
# print(smi1_value_counts_words.head)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Words A')
# print(smi1_value_counts_words.describe().head)
print('---')

smi1_value_counts_words_df = pd.DataFrame(smi1_value_counts_words, columns=['word','word_frequency'])

smi1_value_counts_words_df.to_csv('4_5A_100A_SMI1_Value_Counts_Words_DF_CSV.csv', sep=';', encoding='utf-8', index=True)
# smi1_value_counts_words_df.to_excel('4_5A_100A_SMI1_Value_Counts_Words_DF.xlsx', header=True)

xx

# NEED TO DO TABLE PLOT !!!!!!!!

# PIE PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(20,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Value Counts Words Frequency - Pie')
plt.ioff()
# plt.pie(smi1_value_counts_words.describe(), labels=top_followers_tweets, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_words[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_words,bbox_to_anchor=(1.05, 1), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5A_100A_SMI1_Top_Value_Counts_Words_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BAR PLOT - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Value Counts Words Frequency - Bars')
plt.ioff()
smi1_value_counts_words[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5A_100A_SMI1_Top_Value_Counts_Words_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################################################

### NOT WORKING NEED TO DO

# Frequency Distribution  

## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# METHOD 1

# smi1_value_counts_words_freq_dist = pd.value_counts(tweets_smi_1['text'], ascending=False, normalize=True) #### NEED TO DO BUT FOR SENTENCES

value_counts_words = pd.value_counts(tweets_text_words, ascending=False, normalize=True) 

smi1_value_counts_words = value_counts_words.sort_values(ascending=False)

# smi1_value_counts_words_freq_dist = tweets_text_words.sort_values(by='', axis=0, ascending=False, na_position='last')

print('----')
print('Value Counts Words - Frequency B')
# print(smi1_value_counts_words)
print('----')


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Words')
# print(smi1_value_counts_words.describe().head())
print('---')

smi1_value_counts_words_df = pd.DataFrame(smi1_value_counts_words, columns=['word_frequency'])

smi1_value_counts_words_df.to_csv('4_5_100B_SMI1_Value_Counts_Words_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_words_df.to_excel('4_5_100B_SMI1_Value_Counts_Words_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# Pie

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.subplot(223)
# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Value Counts Words Frequency - Pie')
plt.ioff()
# plt.pie(smi1_value_counts_words.describe(), labels=top_retweets_tweets, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_words[:10].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_value_counts_words,bbox_to_anchor=(1.05, 1), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_5_100B_SMI1_Top_Value_Counts_Words_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Value Counts Words Frequency - Bars')
smi1_value_counts_words[:10].plot.bar(alpha=0.9)
plt.xlabel('Words')
plt.ylabel('Count')
plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_5_100B_SMI1_Top_Value_Counts_Words_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()




##############    #########

############################################################################################################

# Value Counts screenNames   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_screenname = pd.value_counts(tweets_smi_1['screenName'], ascending=False, normalize=True)

smi1_value_counts_screenname = value_counts_screenname.sort_values(ascending=False)

print('---')
print('value_counts_screenname')
# print(value_counts_screenname)
print('---')

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics of ScreenNames - Grouped')
# print(smi1_value_counts_screenname.describe().head)
print('---')

smi1_value_counts_screenname_df = pd.DataFrame(value_counts_screenname, columns =['screenname'])

smi1_value_counts_screenname_df.to_csv('4_4_105_SMI1_Screennames_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_screenname_df.to_excel('4_4_105_SMI1_Screennames_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Value Counts')
plt.ioff()
# smi1_value_counts_screenname.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_screenname[:10].plot(alpha=0.9)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_105_SMI1_Top_ScreenNames_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Value Counts - Pie')
plt.ioff()
# plt.pie(smi1_value_counts_screenname[:6], labels=smi1_tweets_text_words_fdist['screenname'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_screenname[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(smi1_value_counts_screenname, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_105_SMI1_Top_ScreenNames_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Value Counts - Bars')
plt.ioff()
# smi1_value_counts_screenname[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_105_SMI1_Top_ScreenNames_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics - All Value Counts Mentions 1 NEED TO DO FIX !!!')
print(smi1_value_counts_mentions_1_df.describe().head)
print('---')

# smi1_value_counts_mentions_1_df = pd.DataFrame(smi1_value_counts_mentions_1, columns=['mention_frequency'])

smi1_value_counts_mentions_1_df.to_csv('4_4_43_108A_SMI1_Value_Counts_Mentions_1_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_value_counts_mentions_1_df.to_excel('4_4_43_108A_SMI1_Value_Counts_Mentions_1_DF.xlsx', header=True)


# NEED TO DO TABLE PLOT !!!!!!!!

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts')
plt.ioff()
# plt.plot(smi1_value_counts_mentions_1_df[:10], alpha=0.9)
plt.xlabel('Mentions')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_108A_SMI1_Top_Mentions_1_Value_Counts_Plot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Pie')
plt.ioff()
# smi1_value_counts_mentions_1_df[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False, subplots=True)
# plt.legend(smi1_value_counts_mentions_1, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4)
# plt.show()
plt.savefig('4_4_43_108A_SMI1_Top_Mentions_1_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars - NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top Mentions Value Counts - Bars')
plt.ioff()
# smi1_value_counts_mentions_1_df[:10].plot.bar(alpha=0.9)
plt.xlabel('Mentions')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_43_108A_SMI1_Top_Mentions_1_Value_Counts_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


############################################################################################################

# Summary Statistics of Emojis Unicode          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_emojis_unicode_describe = tweets_smi_1['emojis_unicode'].describe()

print('---')
print('Summary Statistics of Emojis Unicode')
# print(smi1_emojis_unicode.describe())
print('---')


# smi1_emojis_unicode_describe_df = pd.DataFrame(smi1_emojis_unicode.describe())

# smi1_emojis_unicode_describe_df.to_csv('4_4_176_SM1_Emojis_Unicode_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

# PLOT TABLE plt.plot NEED TO DO 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of Emojis - Grouped')
# plt.plot(smi1_emojis_unicode_df.describe(), alpha=0.9)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_176_SMI1_Emojis_Unicode_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

## NEED TO PLOT


# Pie - NEED TO DO

# Bars - NEED TO DO


## DELETE VARIABLE

# del smi1_emojis_unicode
# del smi1_emojis_unicode_df

############################################################################################################

# Summary Statistics of Emojis Converted          ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

# smi1_emojis_converted.describe = twetts_smi_1['emojis_converted'].describe()

# smi1_emojis_converted_describe_df = pd.DataFrame(smi1_emojis_converted_describe)

# smi1_emojis_converted_describe_df.to_csv('4_4_177_SMI1_Emojis_Converted_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True)
# .to_excel()

## NEED TO DO TABLE 

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Summary Statistics of Emojis - Grouped')
# plt.plot(smi1_emojis_converted_describe_df)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_177_SMI1_Emojis_Converted_Describe_DF.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie - NEED TO DO

# Bars - NEED TO DO


## DELETE VARIABLE

# del smi1_emojis_converted_describe
# del smi1_emojis_converted_describe_df



############################################################################################################

# Value Counts screenNames   ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 

value_counts_screenname = pd.value_counts(tweets_smi_1['screenName'], ascending=False, normalize=True)

smi1_value_counts_screenname = value_counts_screenname.sort_values(ascending=False)

print('---')
print('value_counts_screenname')
# print(value_counts_screenname)
print('---')

# NEED TO DO !!!!!!!! NOT WORKING

print('---')
print('Summary Statistics of ScreenNames - Grouped')
# print(smi1_value_counts_screenname.describe().head)
print('---')

smi1_value_counts_screenname_df = pd.DataFrame(value_counts_screenname, columns =['screenname'])

smi1_value_counts_screenname_df.to_csv('4_4_105_SMI1_Screennames_Describe_DF_CSV.csv', sep='\t', encoding='utf-8', index=True, header=True)
# smi1_value_counts_screenname_df.to_excel('4_4_105_SMI1_Screennames_Describe_DF.xlsx', header=True)

# NEED TO DO PLOT

# TABLE PLOT NEED TO DO 

# PLOT 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Value Counts')
# smi1_value_counts_screenname.plot(10,cumulative=False, alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO DO FIX -SHOWING FEW
smi1_value_counts_screenname[:10].plot(alpha=0.9)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_105_SMI1_Top_ScreenNames_Value_Counts_PLOT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Pie NEED TO DO

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))       ########### NEED TO FIX -SHOWING FEW
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Value Counts - Pie')
# plt.pie(smi1_value_counts_screenname[:6], labels=smi1_tweets_text_words_fdist['screenname'], colors=colors_blue,startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
smi1_value_counts_screenname[:6].plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
plt.legend(smi1_value_counts_screenname, bbox_to_anchor=(1.8, 1.6), loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_105_SMI1_Top_ScreenNames_Value_Counts_PLOT_Pie.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# Bars NEED TO DO

## PLOT BARS ## NEED TO DO FIX NOT WORKING

print('PLOT BARS - NEED TO FIX')

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Top ScreenNames Value Counts - Bars')
# smi1_value_counts_screenname[:10].plot.bar(alpha=0.9)   # CHANGE TO BARS?     ########### NEED TO FIX -SHOWING FEW
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_105_SMI1_Top_ScreenNames_Value_Counts_Plot_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


#######################################################################################

# https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk

# screennames FREQ DISTRIBUTION

# Calculate frequency distribution

smi1_screennames_fdist = nltk.FreqDist(tweets_smi_1['screenName'])

# Output top 50 tweets_words

# for smi1_screennames, frequency in smi1_screennames_fdist.most_common(10):
#    print(u'{};{}'.format(smi1_screennames, frequency))
    
# SAVE TO CSV   ####################################################  NEED TO SAVE // ## NEED TO PUT TABLE WITH COUNT NEXT TO THEM!!!! 


# smi1_screennames_fdist_df = pd.DataFrame(smi1_screennames_fdist)

smi1_screennames_fdist_df = pd.DataFrame([smi1_screennames_fdist])

print('---')
print('ScreenNames Frequency Distribution A')
# print('smi1_screennames_fdist_df.head')
print('---')

smi1_screennames_fdist_df.to_csv('4_4_106_SMI1_Screennames_Freq_Dist_CSV.csv', sep='\t', encoding='utf-8', index=True)
# smi1_screennames_fdist_df.to_excel('4_4_106_SMI1_Screennames_Freq_Dist.xlsx', header='frequency_distribution') # Only argument is a string of the output file path

########### NEED TO DO TABLE PLOT FIX - SHOWING FEW

# PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames Frequency Distribution 1')
plt.ioff()
# smi1_screennames_fdist.plot(10,cumulative=False, alpha=0.9) 
# smi1_screennames_fdist[:10].plot(alpha=0.9)  
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_106_1_SMI1_Screennames_Freq_Dist.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# BOX PLOT ########## NEED TO FIX CANDLESTICK

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames Frequency Distribution - Box')
plt.ioff()
# plt.boxplot(smi1_screennames_fdist, patch_artist=True, vert=False, notch=False, showfliers=True)
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_106_SMI1_ScreenNames_Freq_Dist_Box.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Pie ############## NEED TO DO : NOT WORKING!!!!

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('ScreenNames Frequency Distribution - Pie')
plt.ioff()
# smi1_screennames_fdist[:6], labels=top_smi1_screennames_fdist, colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# smi1_screennames_fdist.plot(kind='pie', colors=colors_blue, startangle=90, autopct='%1.1f%%', pctdistance=1.9, labeldistance=1.4, radius=1.0, rotatelabels=False)
# plt.legend(smi1_screennames_fdist, loc='upper right', borderaxespad=0.)
# plt.legend() 
# plt.tight_layout(pad=4) 
# plt.show()
plt.savefig('4_4_106_SMI1_ScreenNames_Freq_Dist_Pie_Chart_PLT.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# Bars  ######### NEED TO DO!!!!!!!!!!!!!

# top_smi1_screennames_fdist = smi1_screennames_fdist.sort_values(ascending=False)

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Screennames Frequency Distribution - Bars')
plt.ioff()
smi1_screennames_fdist[:10].plot.bar(alpha=0.9)
plt.xlabel('ScreenNames')
# plt.ylabel('Count')
# plt.legend() 
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_106_SMI1_ScreenNames_Freq_Dist_Bars.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()




################################################################################################################
#
# 			SEABORN DATA ANALYSIS SNS GRAPHS 
#
###################################################################################################################
###################################################################################################################

# http://seaborn.pydata.org/tutorial/relational.html

# Visualizing statistical relationships

# Statistical analysis is a process of understanding how variables in a dataset relate to each other and how those relationships depend on other variables. Visualization can be a core component of this process because, when data are visualized properly, the human visual system can see trends and patterns that indicate a relationship.
# We will discuss three seaborn functions in this tutorial. The one we will use most is relplot(). This is a figure-level function for visualizing statistical relationships using two common approaches: scatter plots and line plots. relplot() combines a FacetGrid with one of two axes-level functions:
# scatterplot() (with kind="scatter"; the default)
# lineplot() (with kind="line')
# As we will see, these functions can be quite illuminating because they use simple and easily-understood representations of data that can nevertheless represent complex dataset structures. They can do so because they plot two-dimensional graphics that can be enhanced by mapping up to three additional variables using the semantics of hue, size, and style.

# Relating variables with scatter plots

# The scatter plot is a mainstay of statistical visualization. It depicts the joint distribution of two variables using a cloud of points, where each point represents an observation in the dataset. This depiction allows the eye to infer a substantial amount of information about whether there is any meaningful relationship between them.
# There are several ways to draw a scatter plot in seaborn. The most basic, which should be used when both variables 
# are numeric, is the scatterplot() function. In the categorical visualization tutorial, we will see specialized tools 
# for using scatterplots to visualize categorical data. The scatterplot() is the default kind in relplot() (it can also 
# be forced by setting kind="scatter'):

# SNS SEABORN RELATIONSHIPS PLOTS  



############

# SEABORN PAIR PLOTS

# rel_graphs_tweets_smi_1_is_friend = sns.PairGrid(tweets_smi_1, hue='is_friend', palette='Set2') 


# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.figure(figsize=(16,14))
# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Retweets - Scatter')
plt.ioff()
# sns.pairplot(data=tweets_smi_1, hue='retweets')
# rel_graphs_tweets_smi_1_is_friend.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_is_friend.add_legend()
# rel_graphs_tweets_smi_1_is_friend.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_01_SMI1_Rel_Graphs_Total_Retweets_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Favorites - Scatter')
plt.ioff()
# sns.pairplot(data=tweets_smi_1, hue='total_favorites')
# rel_graphs_tweets_smi_1_is_friend.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_is_friend.add_legend()
# rel_graphs_tweets_smi_1_is_friend.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_01_SMI1_Rel_Graphs_Total_Favorites_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Retweets - Scatter')
plt.ioff()
# sns.pairplot(data=tweets_smi_1, hue='retweets')
# rel_graphs_tweets_smi_1_is_friend.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_is_friend.add_legend()
# rel_graphs_tweets_smi_1_is_friend.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_01_SMI1_Rel_Graphs_Total_Retweets_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


### DELETE VARIABLE

# del rel_graphs_tweets_smi_1_is_friend

#################################################################################################################

# SEABORN PAIR PLOTS

rel_graphs_tweets_smi_1 = sns.PairGrid(tweets_smi_1, palette='Set2') 

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.figure(figsize=(16,14))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships Total - Scatter')
plt.ioff()
rel_graphs_tweets_smi_1.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1.add_legend()
# rel_graphs_tweets_smi_1.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_01_SMI1_Rel_Graphs_Total_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### DELETE VARIABLE

del rel_graphs_tweets_smi_1

############



############

# SEABORN PAIR PLOTS

# rel_graphs_tweets_smi_1_is_friend = sns.PairGrid(tweets_smi_1, hue='is_friend', palette='Set2') 

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Favorites - Scatter')
plt.ioff()
# sns.pairplot(data=tweets_smi_1, hue='total_favorites')
# rel_graphs_tweets_smi_1_is_friend.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_is_friend.add_legend()
# rel_graphs_tweets_smi_1_is_friend.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_02_SMI1_rel_graphs_Total_Favorites_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Retweets - Scatter')
# sns.pairplot(data=tweets_smi_1, hue='retweets')
# rel_graphs_tweets_smi_1_is_friend.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_is_friend.add_legend()
# rel_graphs_tweets_smi_1_is_friend.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_02_SMI1_Rel_Graphs_Total_Retweets_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()



# SB SCATTER PLOT PLOT 1 ########## NEED TO FIX 

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Number Hashtags - Scatter')
# sns.pairplot(data=tweets_smi_1, hue='number_total_hashtags')
# rel_graphs_tweets_smi_1_is_friend.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_is_friend.add_legend()
# rel_graphs_tweets_smi_1_is_friend.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_02_SMI1_Rel_Graphs_Total_Number_Hashtags_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()


# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Number Mentions - Scatter')
# sns.pairplot(data=tweets_smi_1, hue='number_total_mentions')
# rel_graphs_tweets_smi_1_is_friend.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_is_friend.add_legend()
# rel_graphs_tweets_smi_1_is_friend.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_02_SMI1_Rel_Graphs_Total_Number_Mentions_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Followers - Scatter')
# sns.pairplot(data=tweets_smi_1, hue='followers_count')
# rel_graphs_tweets_smi_1_is_friend.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_is_friend.add_legend()
# rel_graphs_tweets_smi_1_is_friend.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_02_SMI1_Rel_Graphs_Total_followers_count_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Friends - Scatter')
# sns.pairplot(data=tweets_smi_1, hue='friends_count')
# rel_graphs_tweets_smi_1_is_friend.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_is_friend.add_legend()
# rel_graphs_tweets_smi_1_is_friend.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_02_SMI1_Rel_Graphs_Total_Friends_Count_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT PLOT 1 ########## NEED TO FIX 


# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationships All Year - Scatter')
# sns.pairplot(data=tweets_smi_1, hue='year')
# rel_graphs_tweets_smi_1_is_friend.map(plt.scatter, alpha=0.9)
# rel_graphs_tweets_smi_1_is_friend.add_legend()
# rel_graphs_tweets_smi_1_is_friend.fig.subplots_adjust(wspace=0.2, hspace=0.2)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# # ax.grid(True)
# plt.show()
plt.savefig('4_4_02_SMI1_Rel_Graphs_Total_Year_SB_Scattered.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### DELETE VARIABLE

# del rel_graphs_tweets_smi_1_is_friend

###########################################################################################################
################################################################################################################


# SCATTER PLOT

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

plt.figure(figsize=(11,7))
# plt.figure(figsize=(14,10))
plt.autoscale() 
# plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Relationship Followers / Favorites - Scatter')
plt.ioff()
# sns.relplot(x="followers", y="total_favorites", data=tweets_smi_1, colors=colors_blue)
# sns.relplot(x="followers", y="total_favorites", data=tweets_smi_1)
plt.xlabel('Followers')
plt.ylabel('Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_234_SMI1_SB_Scatter_Plot_Rel_Total_Favorites_followers_Numeric_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#####################

# In the simplest invocation, both functions draw a scatterplot of two variables, x and y, and then fit the regression model 
# y x and plot the resulting regression line and a 95% confidence interval for that regression:

# SCATTER PLOT REG

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Regression Followers / Favorites 95% Confidence Interval - Scatter')
plt.ioff()
# sns.regplot(x="followers", y="total_favorites", data=tweets_smi_1, colors=colors_blue)
# sns.regplot(x="followers", y="total_favorites", data=tweets_smi_1)
plt.xlabel('Followers')
plt.ylabel('Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True) 
# plt.show()
plt.savefig('4_4_235_SMI1_SB_Scatter_Plot_Reg_Total_Favorites_Followers_REG_PLOT_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT LM

# plt.rcdefaults()
fig, ax = plt.subplots(1, 1) 
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Scatter Plot Regression Followers / Favorites 95% Confidence Interval - ScatterPlot')
plt.ioff()
# sns.lmplot(x="followers", y="total_favorites", data=tweets_smi_1, colors=colors_blue)
sns.lmplot(x="followers", y="total_favorites", data=tweets_smi_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
# plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
# ax.grid(True)
# plt.show()
plt.savefig('4_4_236_SMI1_SB_Scatter_Plot_Reg_Total_Favorites_Followers_LM_PLOT_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('done - using seaborn')

#################################################################################

# _df _df = pd.DataFrame()
# .to_csv('4_4_.csv', sep='\t', encoding='utf-8', index=True)
# excel

##################################################################################################################

# Scatter Plot Faceted on Two Variables

#################################################################################################################

# Seaborn visualization library

sns.set(color_codes=True)

# screenName author_id created Followers total_favorites Text latitude longitude mentions hashtags id url emojis_unicode emojis_converted image_link language

tweets_smi_1_numeric = pd.DataFrame(tweets_smi_1)
# del tweets_smi_1_numeric['screenName']
# df.drop(['column_nameA', 'column_nameB'], axis=1, inplace=True)
# del tweets_smi_1_numeric['screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', 'url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language']

# tweets_smi_1_numeric.drop('screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', axis=1, inplace=True)
# tweets_smi_1_numeric.drop('url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language', axis=1, inplace=True)

# tweets_smi_1_numeric.drop(['screenName', 'text', 'latitude', 'longitude', 'mentions', 'hashtags', 'url', 'emojis_unicode', 'emojis_converted', 'image_link', 'language'], axis=1, inplace=True)
# tweets_smi_1_numeric = tweets_smi_1[['author_id', 'created', 'followers', 'total_favorites', 'id']]

# Create the default pairplot

# PLOT  # NEED TO DO NOT WORKING !!!!!

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Pair Plot of SMI Numeric Data')
plt.ioff()
# sns.pairplot(tweets_smi_1_numeric, colors=colors_blue)
# sns.pairplot(tweets_smi_1_numeric)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_197_SMI1_Pair_Plot_Numeric.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

### DELETE VARIABLE

# del tweets_smi_1_numeric

print('creating plots')

print('MAIN SMI: EZ')
print(main_smi)
print('----------------------------------------')


###################################################################################################################

# http://seaborn.pydata.org/tutorial/relational.html

# Visualizing Statistical Relationships # NEED TO DO 

# Statistical analysis is a process of understanding how variables in a dataset relate to each other and how those relationships depend on other variables. Visualization can be a core component of this process because, when data are visualized properly, the human visual system can see trends and patterns that indicate a relationship.
# We will discuss three seaborn functions in this tutorial. The one we will use most is relplot(). This is a figure-level function for visualizing statistical relationships using two common approaches: scatter plots and line plots. relplot() combines a FacetGrid with one of two axes-level functions:
# scatterplot() (with kind="scatter"; the default)
# lineplot() (with kind="line')
# As we will see, these functions can be quite illuminating because they use simple and easily-understood representations of data that can nevertheless represent complex dataset structures. They can do so because they plot two-dimensional graphics that can be enhanced by mapping up to three additional variables using the semantics of hue, size, and style.

# Relating variables with scatter plots

# The scatter plot is a mainstay of statistical visualization. It depicts the joint distribution of two variables using a cloud of points, where each point represents an observation in the dataset. This depiction allows the eye to infer a substantial amount of information about whether there is any meaningful relationship between them.
# There are several ways to draw a scatter plot in seaborn. The most basic, which should be used when both variables 
# are numeric, is the scatterplot() function. In the categorical visualization tutorial, we will see specialized tools 
# for using scatterplots to visualize categorical data. The scatterplot() is the default kind in relplot() (it can also 
# be forced by setting kind="scatter'):

# SCATTER PLOT

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Scatter Plot Followers / Favorites - SNS')
plt.ioff()
# sns.relplot(x='followers', y='total_favorites', data=tweets_smi_1, colors=colors_blue)
sns.relplot(x='followers', y='total_favorites', data=tweets_smi_1)
plt.xlabel('Followers')
plt.ylabel('Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_198_SMI1_SB_Scatter_Plot_Rel_Total_Favorites_Followers_Numeric_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

#####################

# In the simplest invocation, both functions draw a scatterplot of two variables, x and y, and then fit the regression model 
# y ~ x and plot the resulting regression line and a 95% confidence interval for that regression:

# SCATTER PLOT REG

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Scatter Plot Regression Followers / Favorites 95% Conf Int SNS')
plt.ioff()
# sns.regplot(x='followers', y='total_favorites', data=tweets_smi_1, colors=colors_blue)
sns.regplot(x='followers', y='total_favorites', data=tweets_smi_1)
plt.xlabel('Followers')
plt.ylabel('Favorites')
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True) 
# plt.show()
plt.savefig('4_5_198_SMI1_SB_Scatter_Plot_Reg_Total_Favorites_Followers_REG_PLOT_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

# SCATTER PLOT LM

# plt.rcdefaults()
fig, ax = plt.subplots()
plt.ioff()

# plt.figure(figsize=(14,10))
plt.autoscale() 
plt.figure(figsize=(7,4))
plt.suptitle(main_smi, y=1.0)
plt.title('Scatter Plot Regression Followers / Favorites 95% Conf Int SNS')
plt.ioff()
# sns.lmplot(x='followers', y='total_favorites', data=tweets_smi_1, colors=colors_blue)
sns.lmplot(x='followers', y='total_favorites', data=tweets_smi_1)
plt.xticks(rotation=50)
# plt.tight_layout(pad=4)
plt.legend() 
plt.grid(True, 'major', 'y', ls='--', lw=0.5, c='k', alpha=0.3)
ax.grid(True)
# plt.show()
plt.savefig('4_5_198_SMI1_SB_Scatter_Plot_Reg_Total_Favorites_Followers_LM_PLOT_ScatterPlot.png', bbox_inches='tight')
plt.close(fig='all')
plt.clf()

print('done - using seaborn')
